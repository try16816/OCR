(()=>{
    var e = "undefined" != typeof globalThis ? globalThis : "undefined" != typeof self ? self : "undefined" != typeof window ? window : "undefined" != typeof global ? global : {};
    function t(e, t, n, s) {
        Object.defineProperty(e, t, {
            get: n,
            set: s,
            enumerable: !0,
            configurable: !0
        })
    }
    function n(e, t) {
        return Object.keys(t).forEach((function(n) {
            "default" === n || "__esModule" === n || e.hasOwnProperty(n) || Object.defineProperty(e, n, {
                enumerable: !0,
                get: function() {
                    return t[n]
                }
            })
        }
        )),
        e
    }
    var s = {}
      , r = {}
      , a = e.parcelRequired024;
    null == a && ((a = function(e) {
        if (e in s)
            return s[e].exports;
        if (e in r) {
            var t = r[e];
            delete r[e];
            var n = {
                id: e,
                exports: {}
            };
            return s[e] = n,
            t.call(n.exports, n, n.exports),
            n.exports
        }
        var a = new Error("Cannot find module '" + e + "'");
        throw a.code = "MODULE_NOT_FOUND",
        a
    }
    ).register = function(e, t) {
        r[e] = t
    }
    ,
    e.parcelRequired024 = a),
    a.register("foUwZ", (function(e, t) {}
    )),
    a.register("gj6Et", (function(e, t) {
        !function(e, t, n) {
            function s(e) {
                var t, n = this, s = (t = 4022871197,
                function(e) {
                    e = String(e);
                    for (var n = 0; n < e.length; n++) {
                        var s = .02519603282416938 * (t += e.charCodeAt(n));
                        s -= t = s >>> 0,
                        t = (s *= t) >>> 0,
                        t += 4294967296 * (s -= t)
                    }
                    return 2.3283064365386963e-10 * (t >>> 0)
                }
                );
                n.next = function() {
                    var e = 2091639 * n.s0 + 2.3283064365386963e-10 * n.c;
                    return n.s0 = n.s1,
                    n.s1 = n.s2,
                    n.s2 = e - (n.c = 0 | e)
                }
                ,
                n.c = 1,
                n.s0 = s(" "),
                n.s1 = s(" "),
                n.s2 = s(" "),
                n.s0 -= s(e),
                n.s0 < 0 && (n.s0 += 1),
                n.s1 -= s(e),
                n.s1 < 0 && (n.s1 += 1),
                n.s2 -= s(e),
                n.s2 < 0 && (n.s2 += 1),
                s = null
            }
            function r(e, t) {
                return t.c = e.c,
                t.s0 = e.s0,
                t.s1 = e.s1,
                t.s2 = e.s2,
                t
            }
            function a(e, t) {
                var n = new s(e)
                  , a = t && t.state
                  , i = n.next;
                return i.int32 = function() {
                    return 4294967296 * n.next() | 0
                }
                ,
                i.double = function() {
                    return i() + 11102230246251565e-32 * (2097152 * i() | 0)
                }
                ,
                i.quick = i,
                a && ("object" == typeof a && r(a, n),
                i.state = function() {
                    return r(n, {})
                }
                ),
                i
            }
            t && t.exports ? t.exports = a : n && n.amd ? n((function() {
                return a
            }
            )) : this.alea = a
        }(0, e, "function" == typeof define && define)
    }
    )),
    a.register("4gDjz", (function(e, t) {
        !function(e, t, n) {
            function s(e) {
                var t = this
                  , n = "";
                t.x = 0,
                t.y = 0,
                t.z = 0,
                t.w = 0,
                t.next = function() {
                    var e = t.x ^ t.x << 11;
                    return t.x = t.y,
                    t.y = t.z,
                    t.z = t.w,
                    t.w ^= t.w >>> 19 ^ e ^ e >>> 8
                }
                ,
                e === (0 | e) ? t.x = e : n += e;
                for (var s = 0; s < n.length + 64; s++)
                    t.x ^= 0 | n.charCodeAt(s),
                    t.next()
            }
            function r(e, t) {
                return t.x = e.x,
                t.y = e.y,
                t.z = e.z,
                t.w = e.w,
                t
            }
            function a(e, t) {
                var n = new s(e)
                  , a = t && t.state
                  , i = function() {
                    return (n.next() >>> 0) / 4294967296
                };
                return i.double = function() {
                    do {
                        var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / 2097152
                    } while (0 === e);
                    return e
                }
                ,
                i.int32 = n.next,
                i.quick = i,
                a && ("object" == typeof a && r(a, n),
                i.state = function() {
                    return r(n, {})
                }
                ),
                i
            }
            t && t.exports ? t.exports = a : n && n.amd ? n((function() {
                return a
            }
            )) : this.xor128 = a
        }(0, e, "function" == typeof define && define)
    }
    )),
    a.register("HLBv4", (function(e, t) {
        !function(e, t, n) {
            function s(e) {
                var t = this
                  , n = "";
                t.next = function() {
                    var e = t.x ^ t.x >>> 2;
                    return t.x = t.y,
                    t.y = t.z,
                    t.z = t.w,
                    t.w = t.v,
                    (t.d = t.d + 362437 | 0) + (t.v = t.v ^ t.v << 4 ^ e ^ e << 1) | 0
                }
                ,
                t.x = 0,
                t.y = 0,
                t.z = 0,
                t.w = 0,
                t.v = 0,
                e === (0 | e) ? t.x = e : n += e;
                for (var s = 0; s < n.length + 64; s++)
                    t.x ^= 0 | n.charCodeAt(s),
                    s == n.length && (t.d = t.x << 10 ^ t.x >>> 4),
                    t.next()
            }
            function r(e, t) {
                return t.x = e.x,
                t.y = e.y,
                t.z = e.z,
                t.w = e.w,
                t.v = e.v,
                t.d = e.d,
                t
            }
            function a(e, t) {
                var n = new s(e)
                  , a = t && t.state
                  , i = function() {
                    return (n.next() >>> 0) / 4294967296
                };
                return i.double = function() {
                    do {
                        var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / 2097152
                    } while (0 === e);
                    return e
                }
                ,
                i.int32 = n.next,
                i.quick = i,
                a && ("object" == typeof a && r(a, n),
                i.state = function() {
                    return r(n, {})
                }
                ),
                i
            }
            t && t.exports ? t.exports = a : n && n.amd ? n((function() {
                return a
            }
            )) : this.xorwow = a
        }(0, e, "function" == typeof define && define)
    }
    )),
    a.register("ktaoY", (function(e, t) {
        !function(e, t, n) {
            function s(e) {
                var t = this;
                t.next = function() {
                    var e, n, s = t.x, r = t.i;
                    return e = s[r],
                    n = (e ^= e >>> 7) ^ e << 24,
                    n ^= (e = s[r + 1 & 7]) ^ e >>> 10,
                    n ^= (e = s[r + 3 & 7]) ^ e >>> 3,
                    n ^= (e = s[r + 4 & 7]) ^ e << 7,
                    e = s[r + 7 & 7],
                    n ^= (e ^= e << 13) ^ e << 9,
                    s[r] = n,
                    t.i = r + 1 & 7,
                    n
                }
                ,
                function(e, t) {
                    var n, s = [];
                    if (t === (0 | t))
                        s[0] = t;
                    else
                        for (t = "" + t,
                        n = 0; n < t.length; ++n)
                            s[7 & n] = s[7 & n] << 15 ^ t.charCodeAt(n) + s[n + 1 & 7] << 13;
                    for (; s.length < 8; )
                        s.push(0);
                    for (n = 0; n < 8 && 0 === s[n]; ++n)
                        ;
                    for (8 == n ? s[7] = -1 : s[n],
                    e.x = s,
                    e.i = 0,
                    n = 256; n > 0; --n)
                        e.next()
                }(t, e)
            }
            function r(e, t) {
                return t.x = e.x.slice(),
                t.i = e.i,
                t
            }
            function a(e, t) {
                null == e && (e = +new Date);
                var n = new s(e)
                  , a = t && t.state
                  , i = function() {
                    return (n.next() >>> 0) / 4294967296
                };
                return i.double = function() {
                    do {
                        var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / 2097152
                    } while (0 === e);
                    return e
                }
                ,
                i.int32 = n.next,
                i.quick = i,
                a && (a.x && r(a, n),
                i.state = function() {
                    return r(n, {})
                }
                ),
                i
            }
            t && t.exports ? t.exports = a : n && n.amd ? n((function() {
                return a
            }
            )) : this.xorshift7 = a
        }(0, e, "function" == typeof define && define)
    }
    )),
    a.register("gBs5C", (function(e, t) {
        !function(e, t, n) {
            function s(e) {
                var t = this;
                t.next = function() {
                    var e, n, s = t.w, r = t.X, a = t.i;
                    return t.w = s = s + 1640531527 | 0,
                    n = r[a + 34 & 127],
                    e = r[a = a + 1 & 127],
                    n ^= n << 13,
                    e ^= e << 17,
                    n ^= n >>> 15,
                    e ^= e >>> 12,
                    n = r[a] = n ^ e,
                    t.i = a,
                    n + (s ^ s >>> 16) | 0
                }
                ,
                function(e, t) {
                    var n, s, r, a, i, o = [], l = 128;
                    for (t === (0 | t) ? (s = t,
                    t = null) : (t += "\0",
                    s = 0,
                    l = Math.max(l, t.length)),
                    r = 0,
                    a = -32; a < l; ++a)
                        t && (s ^= t.charCodeAt((a + 32) % t.length)),
                        0 === a && (i = s),
                        s ^= s << 10,
                        s ^= s >>> 15,
                        s ^= s << 4,
                        s ^= s >>> 13,
                        a >= 0 && (i = i + 1640531527 | 0,
                        r = 0 == (n = o[127 & a] ^= s + i) ? r + 1 : 0);
                    for (r >= 128 && (o[127 & (t && t.length || 0)] = -1),
                    r = 127,
                    a = 512; a > 0; --a)
                        s = o[r + 34 & 127],
                        n = o[r = r + 1 & 127],
                        s ^= s << 13,
                        n ^= n << 17,
                        s ^= s >>> 15,
                        n ^= n >>> 12,
                        o[r] = s ^ n;
                    e.w = i,
                    e.X = o,
                    e.i = r
                }(t, e)
            }
            function r(e, t) {
                return t.i = e.i,
                t.w = e.w,
                t.X = e.X.slice(),
                t
            }
            function a(e, t) {
                null == e && (e = +new Date);
                var n = new s(e)
                  , a = t && t.state
                  , i = function() {
                    return (n.next() >>> 0) / 4294967296
                };
                return i.double = function() {
                    do {
                        var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / 2097152
                    } while (0 === e);
                    return e
                }
                ,
                i.int32 = n.next,
                i.quick = i,
                a && (a.X && r(a, n),
                i.state = function() {
                    return r(n, {})
                }
                ),
                i
            }
            t && t.exports ? t.exports = a : n && n.amd ? n((function() {
                return a
            }
            )) : this.xor4096 = a
        }(0, e, "function" == typeof define && define)
    }
    )),
    a.register("ktLSh", (function(e, t) {
        !function(e, t, n) {
            function s(e) {
                var t = this
                  , n = "";
                t.next = function() {
                    var e = t.b
                      , n = t.c
                      , s = t.d
                      , r = t.a;
                    return e = e << 25 ^ e >>> 7 ^ n,
                    n = n - s | 0,
                    s = s << 24 ^ s >>> 8 ^ r,
                    r = r - e | 0,
                    t.b = e = e << 20 ^ e >>> 12 ^ n,
                    t.c = n = n - s | 0,
                    t.d = s << 16 ^ n >>> 16 ^ r,
                    t.a = r - e | 0
                }
                ,
                t.a = 0,
                t.b = 0,
                t.c = -1640531527,
                t.d = 1367130551,
                e === Math.floor(e) ? (t.a = e / 4294967296 | 0,
                t.b = 0 | e) : n += e;
                for (var s = 0; s < n.length + 20; s++)
                    t.b ^= 0 | n.charCodeAt(s),
                    t.next()
            }
            function r(e, t) {
                return t.a = e.a,
                t.b = e.b,
                t.c = e.c,
                t.d = e.d,
                t
            }
            function a(e, t) {
                var n = new s(e)
                  , a = t && t.state
                  , i = function() {
                    return (n.next() >>> 0) / 4294967296
                };
                return i.double = function() {
                    do {
                        var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / 2097152
                    } while (0 === e);
                    return e
                }
                ,
                i.int32 = n.next,
                i.quick = i,
                a && ("object" == typeof a && r(a, n),
                i.state = function() {
                    return r(n, {})
                }
                ),
                i
            }
            t && t.exports ? t.exports = a : n && n.amd ? n((function() {
                return a
            }
            )) : this.tychei = a
        }(0, e, "function" == typeof define && define)
    }
    ));
    class i {
        constructor(e, t) {
            this.backend = e,
            this.dataMover = t,
            this.data = new WeakMap,
            this.dataIdsCount = 0
        }
        get(e) {
            return this.data.has(e) || this.dataMover.moveData(this.backend, e),
            this.data.get(e)
        }
        set(e, t) {
            this.dataIdsCount++,
            this.data.set(e, t)
        }
        has(e) {
            return this.data.has(e)
        }
        delete(e) {
            return this.dataIdsCount--,
            this.data.delete(e)
        }
        numDataIds() {
            return this.dataIdsCount
        }
    }
    class o {
        refCount(e) {
            return l("refCount")
        }
        incRef(e) {
            return l("incRef")
        }
        timerAvailable() {
            return !0
        }
        time(e) {
            return l("time")
        }
        read(e) {
            return l("read")
        }
        readSync(e) {
            return l("readSync")
        }
        readToGPU(e, t) {
            return l("readToGPU")
        }
        numDataIds() {
            return l("numDataIds")
        }
        disposeData(e, t) {
            return l("disposeData")
        }
        write(e, t, n) {
            return l("write")
        }
        move(e, t, n, s, r) {
            return l("move")
        }
        createTensorFromGPUData(e, t, n) {
            return l("createTensorFromGPUData")
        }
        memory() {
            return l("memory")
        }
        floatPrecision() {
            return l("floatPrecision")
        }
        epsilon() {
            return 32 === this.floatPrecision() ? 1e-7 : 1e-4
        }
        dispose() {
            return l("dispose")
        }
    }
    function l(e) {
        throw new Error(`'${e}' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen`)
    }
    var u = {};
    function c(e) {
        let t = e.length
          , n = 0;
        for (; t > 0; )
            n = Math.random() * t | 0,
            t--,
            f(e, t, n)
    }
    function h(e, t) {
        if (e.length !== t.length)
            throw new Error(`Array sizes must match to be shuffled together First array length was ${e.length}Second array length was ${t.length}`);
        let n = e.length
          , s = 0;
        for (; n > 0; )
            s = Math.random() * n | 0,
            n--,
            f(e, n, s),
            f(t, n, s)
    }
    function p(e, t, n) {
        return Math.max(e, Math.min(t, n))
    }
    function d(e) {
        return e % 2 == 0 ? e : e + 1
    }
    function f(e, t, n) {
        const s = e[t];
        e[t] = e[n],
        e[n] = s
    }
    function m(e) {
        let t = 0;
        for (let n = 0; n < e.length; n++)
            t += e[n];
        return t
    }
    function g(e, t) {
        const n = Math.random();
        return t * n + (1 - n) * e
    }
    function y(e, t) {
        let n = 0;
        for (let s = 0; s < e.length; s++) {
            const r = Number(e[s]) - Number(t[s]);
            n += r * r
        }
        return n
    }
    function b(e, t) {
        if (!e)
            throw new Error("string" == typeof t ? t : t())
    }
    function x(e, t, n="") {
        b(I(e, t), (()=>n + ` Shapes ${e} and ${t} must match`))
    }
    function w(e) {
        b(null != e, (()=>"The input to the tensor constructor must be a non-null value."))
    }
    function v(e) {
        if (0 === e.length)
            return 1;
        let t = e[0];
        for (let n = 1; n < e.length; n++)
            t *= e[n];
        return t
    }
    function k(e) {
        return 0 === e.length
    }
    function I(e, t) {
        if (e === t)
            return !0;
        if (null == e || null == t)
            return !1;
        if (e.length !== t.length)
            return !1;
        for (let n = 0; n < e.length; n++)
            if (e[n] !== t[n])
                return !1;
        return !0
    }
    function S(e) {
        return e % 1 == 0
    }
    function N(e) {
        if (null != Math.tanh)
            return Math.tanh(e);
        if (e === 1 / 0)
            return 1;
        if (e === -1 / 0)
            return -1;
        {
            const t = Math.exp(2 * e);
            return (t - 1) / (t + 1)
        }
    }
    function T(e) {
        const t = Math.ceil(Math.sqrt(e));
        return [t, Math.ceil(e / t)]
    }
    function C(e) {
        const t = new Uint32Array(e);
        for (let n = 0; n < e; ++n)
            t[n] = n;
        return c(t),
        t
    }
    function $(e, t) {
        return t <= e.length ? e : e + " ".repeat(t - e.length)
    }
    function E(e, t=(e=>0), n, s) {
        return new Promise(((r,a)=>{
            let i = 0;
            const o = ()=>{
                if (e())
                    return void r();
                i++;
                const l = t(i);
                null != n && i >= n ? a() : null != s ? s(o, l) : setTimeout(o, l)
            }
            ;
            o()
        }
        ))
    }
    function A(e, t) {
        let n = 1
          , s = -1;
        for (let t = 0; t < e.length; ++t)
            if (e[t] >= 0)
                n *= e[t];
            else if (-1 === e[t]) {
                if (-1 !== s)
                    throw Error(`Shapes can only have 1 implicit size. Found -1 at dim ${s} and dim ${t}`);
                s = t
            } else if (e[t] < 0)
                throw Error(`Shapes can not be < 0. Found ${e[t]} at dim ${t}`);
        if (-1 === s) {
            if (t > 0 && t !== n)
                throw Error(`Size(${t}) must match the product of shape ${e}`);
            return e
        }
        if (0 === n)
            throw Error(`Cannot infer the missing size in [${e}] when there are 0 elements`);
        if (t % n != 0)
            throw Error(`The implicit shape can't be a fractional number. Got ${t} / ${n}`);
        const r = e.slice();
        return r[s] = t / n,
        r
    }
    function R(e, t) {
        const n = t.length;
        return b((e = null == e ? t.map(((e,t)=>t)) : [].concat(e)).every((e=>e >= -n && e < n)), (()=>`All values in axis param must be in range [-${n}, ${n}) but got axis ${e}`)),
        b(e.every((e=>S(e))), (()=>`All values in axis param must be integers but got axis ${e}`)),
        e.map((e=>e < 0 ? n + e : e))
    }
    function F(e, t) {
        const n = []
          , s = []
          , r = null != t && Array.isArray(t) && 0 === t.length
          , a = null == t || r ? null : R(t, e).sort();
        let i = 0;
        for (let t = 0; t < e.length; ++t) {
            if (null != a) {
                if (a[i] === t && 1 !== e[t])
                    throw new Error(`Can't squeeze axis ${t} since its dim '${e[t]}' is not 1`);
                (null == a[i] || a[i] > t) && 1 === e[t] && (n.push(e[t]),
                s.push(t)),
                a[i] <= t && i++
            }
            1 !== e[t] && (n.push(e[t]),
            s.push(t))
        }
        return {
            newShape: n,
            keptDims: s
        }
    }
    function D(e, t) {
        let n = null;
        if (null == e || "float32" === e)
            n = new Float32Array(t);
        else if ("int32" === e)
            n = new Int32Array(t);
        else {
            if ("bool" !== e)
                throw new Error(`Unknown data type ${e}`);
            n = new Uint8Array(t)
        }
        return n
    }
    function _(e, t) {
        let n = null;
        if (null == e || "float32" === e)
            n = new Float32Array(t);
        else if ("int32" === e)
            n = new Int32Array(t);
        else if ("bool" === e)
            n = new Uint8Array(t);
        else {
            if ("string" !== e)
                throw new Error(`Unknown data type ${e}`);
            n = new Array(t)
        }
        return n
    }
    function O(e, t) {
        for (let n = 0; n < e.length; n++) {
            const s = e[n];
            if (isNaN(s) || !isFinite(s))
                throw Error(`A tensor of type ${t} being uploaded contains ${s}.`)
        }
    }
    function M(e) {
        return "bool" === e || "complex64" === e || "float32" === e || "int32" === e || "string" === e
    }
    function L(e, t) {
        return "complex64" !== t && (("float32" !== t || "complex64" === e) && (("int32" !== t || "float32" === e || "complex64" === e) && ("bool" !== t || "bool" !== e)))
    }
    function z(e) {
        if ("float32" === e || "int32" === e)
            return 4;
        if ("complex64" === e)
            return 8;
        if ("bool" === e)
            return 1;
        throw new Error(`Unknown dtype ${e}`)
    }
    function B(e) {
        if (null == e)
            return 0;
        let t = 0;
        return e.forEach((e=>t += e.length)),
        t
    }
    function P(e) {
        return "string" == typeof e || e instanceof String
    }
    function W(e) {
        return "boolean" == typeof e
    }
    function U(e) {
        return "number" == typeof e
    }
    function V(e) {
        return Array.isArray(e) ? V(e[0]) : e instanceof Float32Array ? "float32" : e instanceof Int32Array || e instanceof Uint8Array || e instanceof Uint8ClampedArray ? "int32" : U(e) ? "float32" : P(e) ? "string" : W(e) ? "bool" : "float32"
    }
    function G(e) {
        return !!(e && e.constructor && e.call && e.apply)
    }
    function H(e, t) {
        for (let n = t; n < e; ++n)
            if (e % n == 0)
                return n;
        return e
    }
    function j(e) {
        const t = e.length;
        if (t < 2)
            return [];
        const n = new Array(t - 1);
        n[t - 2] = e[t - 1];
        for (let s = t - 3; s >= 0; --s)
            n[s] = n[s + 1] * e[s + 1];
        return n
    }
    function q(e, t, n, s=!1) {
        const r = new Array;
        if (1 === t.length) {
            const a = t[0] * (s ? 2 : 1);
            for (let t = 0; t < a; t++)
                r[t] = n[e + t]
        } else {
            const a = t[0]
              , i = t.slice(1)
              , o = i.reduce(((e,t)=>e * t)) * (s ? 2 : 1);
            for (let t = 0; t < a; t++)
                r[t] = q(e + t * o, i, n, s)
        }
        return r
    }
    function K(e, t, n=!1) {
        if (0 === e.length)
            return t[0];
        const s = e.reduce(((e,t)=>e * t)) * (n ? 2 : 1);
        if (0 === s)
            return [];
        if (s !== t.length)
            throw new Error(`[${e}] does not match the input size ${t.length}${n ? " for a complex tensor" : ""}.`);
        return q(0, e, t, n)
    }
    function X(e, t) {
        if (Array.isArray(e))
            return e;
        if ("float32" === t)
            return e instanceof Float32Array ? e : new Float32Array(e);
        if ("int32" === t)
            return e instanceof Int32Array ? e : new Int32Array(e);
        if ("bool" === t || "string" === t)
            return Uint8Array.from(new Int32Array(e));
        throw new Error(`Unknown dtype ${t}`)
    }
    function Y(e, t) {
        const n = Z(e, t);
        for (let e = 0; e < n.length; e++)
            n[e] = 1;
        return n
    }
    function Z(e, t) {
        if (null == t || "float32" === t || "complex64" === t)
            return new Float32Array(e);
        if ("int32" === t)
            return new Int32Array(e);
        if ("bool" === t)
            return new Uint8Array(e);
        throw new Error(`Unknown data type ${t}`)
    }
    function J(e, t) {
        const n = e.reduce(((e,t)=>e * t), 1);
        if (null == t || "float32" === t)
            return K(e, new Float32Array(n));
        if ("int32" === t)
            return K(e, new Int32Array(n));
        if ("bool" === t)
            return K(e, new Uint8Array(n));
        throw new Error(`Unknown data type ${t}`)
    }
    function Q(e) {
        e.forEach((t=>{
            b(Number.isInteger(t) && t >= 0, (()=>`Tensor must have a shape comprised of positive integers but got shape [${e}].`))
        }
        ))
    }
    function ee(e, t, n) {
        if (0 === t)
            return 0;
        if (1 === t)
            return e[0];
        let s = e[e.length - 1];
        for (let t = 0; t < e.length - 1; ++t)
            s += n[t] * e[t];
        return s
    }
    function te(e, t, n) {
        if (0 === t)
            return [];
        if (1 === t)
            return [e];
        const s = new Array(t);
        for (let t = 0; t < s.length - 1; ++t)
            s[t] = Math.floor(e / n[t]),
            e -= s[t] * n[t];
        return s[s.length - 1] = e,
        s
    }
    function ne(e) {
        return e && e.then && "function" == typeof e.then
    }
    t(u, "shuffle", (()=>c)),
    t(u, "swap", (()=>f)),
    t(u, "shuffleCombo", (()=>h)),
    t(u, "clamp", (()=>p)),
    t(u, "nearestLargerEven", (()=>d)),
    t(u, "sum", (()=>m)),
    t(u, "randUniform", (()=>g)),
    t(u, "distSquared", (()=>y)),
    t(u, "assert", (()=>b)),
    t(u, "assertShapesMatch", (()=>x)),
    t(u, "arraysEqual", (()=>I)),
    t(u, "assertNonNull", (()=>w)),
    t(u, "sizeFromShape", (()=>v)),
    t(u, "isScalarShape", (()=>k)),
    t(u, "isInt", (()=>S)),
    t(u, "tanh", (()=>N)),
    t(u, "sizeToSquarishShape", (()=>T)),
    t(u, "createShuffledIndices", (()=>C)),
    t(u, "rightPad", (()=>$)),
    t(u, "repeatedTry", (()=>E)),
    t(u, "inferFromImplicitShape", (()=>A)),
    t(u, "parseAxisParam", (()=>R)),
    t(u, "squeezeShape", (()=>F)),
    t(u, "getTypedArrayFromDType", (()=>D)),
    t(u, "getArrayFromDType", (()=>_)),
    t(u, "checkConversionForErrors", (()=>O)),
    t(u, "isValidDtype", (()=>M)),
    t(u, "hasEncodingLoss", (()=>L)),
    t(u, "bytesPerElement", (()=>z)),
    t(u, "bytesFromStringArray", (()=>B)),
    t(u, "isString", (()=>P)),
    t(u, "isBoolean", (()=>W)),
    t(u, "isNumber", (()=>U)),
    t(u, "inferDtype", (()=>V)),
    t(u, "isFunction", (()=>G)),
    t(u, "nearestDivisor", (()=>H)),
    t(u, "computeStrides", (()=>j)),
    t(u, "toNestedArray", (()=>K)),
    t(u, "convertBackendValuesAndArrayBuffer", (()=>X)),
    t(u, "makeOnesTypedArray", (()=>Y)),
    t(u, "makeZerosTypedArray", (()=>Z)),
    t(u, "makeZerosNestedTypedArray", (()=>J)),
    t(u, "assertNonNegativeIntegerDimensions", (()=>Q)),
    t(u, "locToIndex", (()=>ee)),
    t(u, "indexToLoc", (()=>te)),
    t(u, "isPromise", (()=>ne));
    const se = "tfjsflags";
    class re {
        constructor(e) {
            this.global = e,
            this.flags = {},
            this.flagRegistry = {},
            this.urlFlags = {},
            this.getQueryParams = ae,
            this.populateURLFlags()
        }
        setPlatform(e, t) {
            null != this.platform && (ie().getBool("IS_TEST") || ie().getBool("PROD") || console.warn(`Platform ${this.platformName} has already been set. Overwriting the platform with ${e}.`)),
            this.platformName = e,
            this.platform = t
        }
        registerFlag(e, t, n) {
            if (this.flagRegistry[e] = {
                evaluationFn: t,
                setHook: n
            },
            null != this.urlFlags[e]) {
                const t = this.urlFlags[e];
                ie().getBool("IS_TEST") || ie().getBool("PROD") || console.warn(`Setting feature override from URL ${e}: ${t}.`),
                this.set(e, t)
            }
        }
        async getAsync(e) {
            return e in this.flags || (this.flags[e] = await this.evaluateFlag(e)),
            this.flags[e]
        }
        get(e) {
            if (e in this.flags)
                return this.flags[e];
            const t = this.evaluateFlag(e);
            if (ne(t))
                throw new Error(`Flag ${e} cannot be synchronously evaluated. Please use getAsync() instead.`);
            return this.flags[e] = t,
            this.flags[e]
        }
        getNumber(e) {
            return this.get(e)
        }
        getBool(e) {
            return this.get(e)
        }
        getFlags() {
            return this.flags
        }
        get features() {
            return this.flags
        }
        set(e, t) {
            if (null == this.flagRegistry[e])
                throw new Error(`Cannot set flag ${e} as it has not been registered.`);
            this.flags[e] = t,
            null != this.flagRegistry[e].setHook && this.flagRegistry[e].setHook(t)
        }
        evaluateFlag(e) {
            if (null == this.flagRegistry[e])
                throw new Error(`Cannot evaluate flag '${e}': no evaluation function found.`);
            return this.flagRegistry[e].evaluationFn()
        }
        setFlags(e) {
            this.flags = Object.assign({}, e)
        }
        reset() {
            this.flags = {},
            this.urlFlags = {},
            this.populateURLFlags()
        }
        populateURLFlags() {
            if (void 0 === this.global || void 0 === this.global.location || void 0 === this.global.location.search)
                return;
            const e = this.getQueryParams(this.global.location.search);
            if (se in e) {
                e.tfjsflags.split(",").forEach((e=>{
                    const [t,n] = e.split(":");
                    this.urlFlags[t] = function(e, t) {
                        if ("true" === (t = t.toLowerCase()) || "false" === t)
                            return "true" === t;
                        if ("" + +t === t)
                            return +t;
                        throw new Error(`Could not parse value flag value ${t} for flag ${e}.`)
                    }(t, n)
                }
                ))
            }
        }
    }
    function ae(e) {
        const t = {};
        return e.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, ((e,...n)=>(function(e, t, n) {
            e[decodeURIComponent(t)] = decodeURIComponent(n || "")
        }(t, n[0], n[1]),
        n.join("=")))),
        t
    }
    function ie() {
        return oe
    }
    let oe = null;
    var le, ue, ce = {}, he = ce = {};
    function pe() {
        throw new Error("setTimeout has not been defined")
    }
    function de() {
        throw new Error("clearTimeout has not been defined")
    }
    function fe(e) {
        if (le === setTimeout)
            return setTimeout(e, 0);
        if ((le === pe || !le) && setTimeout)
            return le = setTimeout,
            setTimeout(e, 0);
        try {
            return le(e, 0)
        } catch (t) {
            try {
                return le.call(null, e, 0)
            } catch (t) {
                return le.call(this, e, 0)
            }
        }
    }
    !function() {
        try {
            le = "function" == typeof setTimeout ? setTimeout : pe
        } catch (e) {
            le = pe
        }
        try {
            ue = "function" == typeof clearTimeout ? clearTimeout : de
        } catch (e) {
            ue = de
        }
    }();
    var me, ge = [], ye = !1, be = -1;
    function xe() {
        ye && me && (ye = !1,
        me.length ? ge = me.concat(ge) : be = -1,
        ge.length && we())
    }
    function we() {
        if (!ye) {
            var e = fe(xe);
            ye = !0;
            for (var t = ge.length; t; ) {
                for (me = ge,
                ge = []; ++be < t; )
                    me && me[be].run();
                be = -1,
                t = ge.length
            }
            me = null,
            ye = !1,
            function(e) {
                if (ue === clearTimeout)
                    return clearTimeout(e);
                if ((ue === de || !ue) && clearTimeout)
                    return ue = clearTimeout,
                    clearTimeout(e);
                try {
                    ue(e)
                } catch (t) {
                    try {
                        return ue.call(null, e)
                    } catch (t) {
                        return ue.call(this, e)
                    }
                }
            }(e)
        }
    }
    function ve(e, t) {
        this.fun = e,
        this.array = t
    }
    function ke() {}
    /**
 * @license
 * Copyright 2020 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
    let Ie;
    function Se() {
        if (null == Ie) {
            let t;
            if ("undefined" != typeof window)
                t = window;
            else if (void 0 !== e)
                t = e;
            else if (void 0 !== ce)
                t = ce;
            else {
                if ("undefined" == typeof self)
                    throw new Error("Could not find a global object");
                t = self
            }
            Ie = t
        }
        return Ie
    }
    function Ne(e, t) {
        const n = function() {
            const e = Se();
            return null == e._tfGlobals && (e._tfGlobals = new Map),
            e._tfGlobals
        }();
        if (n.has(e))
            return n.get(e);
        {
            const s = t();
            return n.set(e, s),
            n.get(e)
        }
    }
    he.nextTick = function(e) {
        var t = new Array(arguments.length - 1);
        if (arguments.length > 1)
            for (var n = 1; n < arguments.length; n++)
                t[n - 1] = arguments[n];
        ge.push(new ve(e,t)),
        1 !== ge.length || ye || fe(we)
    }
    ,
    ve.prototype.run = function() {
        this.fun.apply(null, this.array)
    }
    ,
    he.title = "browser",
    he.browser = !0,
    he.env = {},
    he.argv = [],
    he.version = "",
    he.versions = {},
    he.on = ke,
    he.addListener = ke,
    he.once = ke,
    he.off = ke,
    he.removeListener = ke,
    he.removeAllListeners = ke,
    he.emit = ke,
    he.prependListener = ke,
    he.prependOnceListener = ke,
    he.listeners = function(e) {
        return []
    }
    ,
    he.binding = function(e) {
        throw new Error("process.binding is not supported")
    }
    ,
    he.cwd = function() {
        return "/"
    }
    ,
    he.chdir = function(e) {
        throw new Error("process.chdir is not supported")
    }
    ,
    he.umask = function() {
        return 0
    }
    ;
    const Te = "Abs"
      , Ce = "Acos"
      , $e = "Acosh"
      , Ee = "Add"
      , Ae = "AddN"
      , Re = "All"
      , Fe = "Any"
      , De = "ArgMax"
      , _e = "ArgMin"
      , Oe = "Asin"
      , Me = "Asinh"
      , Le = "Atan"
      , ze = "Atanh"
      , Be = "Atan2"
      , Pe = "AvgPool"
      , We = "AvgPoolGrad"
      , Ue = "AvgPool3D"
      , Ve = "AvgPool3DGrad"
      , Ge = "BatchMatMul"
      , He = "BatchToSpaceND"
      , je = "Bincount"
      , qe = "BroadcastArgs"
      , Ke = "Cast"
      , Xe = "Ceil"
      , Ye = "ClipByValue"
      , Ze = "Complex"
      , Je = "ComplexAbs"
      , Qe = "Concat"
      , et = "Conv2D"
      , tt = "Conv2DBackpropFilter"
      , nt = "Conv2DBackpropInput"
      , st = "Conv3D"
      , rt = "Conv3DBackpropFilterV2"
      , at = "Conv3DBackpropInputV2"
      , it = "Cos"
      , ot = "Cosh"
      , lt = "Cumprod"
      , ut = "Cumsum"
      , ct = "CropAndResize"
      , ht = "DenseBincount"
      , pt = "DepthToSpace"
      , dt = "DepthwiseConv2dNative"
      , ft = "DepthwiseConv2dNativeBackpropFilter"
      , mt = "DepthwiseConv2dNativeBackpropInput"
      , gt = "Diag"
      , yt = "Dilation2D"
      , bt = "Dilation2DBackpropInput"
      , xt = "Dilation2DBackpropFilter"
      , wt = "RealDiv"
      , vt = "Einsum"
      , kt = "Elu"
      , It = "EluGrad"
      , St = "Erf"
      , Nt = "Equal"
      , Tt = "Exp"
      , Ct = "ExpandDims"
      , $t = "Expm1"
      , Et = "FFT"
      , At = "Fill"
      , Rt = "FlipLeftRight"
      , Ft = "Floor"
      , Dt = "FloorDiv"
      , _t = "FusedBatchNorm"
      , Ot = "GatherV2"
      , Mt = "GatherNd"
      , Lt = "Greater"
      , zt = "GreaterEqual"
      , Bt = "Identity"
      , Pt = "IFFT"
      , Wt = "Imag"
      , Ut = "IsFinite"
      , Vt = "IsInf"
      , Gt = "IsNan"
      , Ht = "LeakyRelu"
      , jt = "Less"
      , qt = "LessEqual"
      , Kt = "LinSpace"
      , Xt = "Log"
      , Yt = "Log1p"
      , Zt = "LogicalAnd"
      , Jt = "LogicalNot"
      , Qt = "LogicalOr"
      , en = "LRN"
      , tn = "LRNGrad"
      , nn = "Max"
      , sn = "Maximum"
      , rn = "MaxPool"
      , an = "MaxPoolGrad"
      , on = "MaxPool3D"
      , ln = "MaxPool3DGrad"
      , un = "MaxPoolWithArgmax"
      , cn = "Mean"
      , hn = "Min"
      , pn = "Minimum"
      , dn = "MirrorPad"
      , fn = "Mod"
      , mn = "Multinomial"
      , gn = "Multiply"
      , yn = "Neg"
      , bn = "NotEqual"
      , xn = "NonMaxSuppressionV3"
      , wn = "NonMaxSuppressionV4"
      , vn = "NonMaxSuppressionV5"
      , kn = "OnesLike"
      , In = "OneHot"
      , Sn = "Pack"
      , Nn = "PadV2"
      , Tn = "Pow"
      , Cn = "Prelu"
      , $n = "Prod"
      , En = "RaggedGather"
      , An = "RaggedRange"
      , Rn = "RaggedTensorToTensor"
      , Fn = "Range"
      , Dn = "Real"
      , _n = "Reciprocal"
      , On = "Relu"
      , Mn = "Reshape"
      , Ln = "ResizeNearestNeighbor"
      , zn = "ResizeNearestNeighborGrad"
      , Bn = "ResizeBilinear"
      , Pn = "ResizeBilinearGrad"
      , Wn = "Relu6"
      , Un = "Reverse"
      , Vn = "Round"
      , Gn = "Rsqrt"
      , Hn = "ScatterNd"
      , jn = "SearchSorted"
      , qn = "Select"
      , Kn = "Selu"
      , Xn = "Slice"
      , Yn = "Sin"
      , Zn = "Sinh"
      , Jn = "Sign"
      , Qn = "Sigmoid"
      , es = "Softplus"
      , ts = "Sqrt"
      , ns = "Sum"
      , ss = "SpaceToBatchND"
      , rs = "SplitV"
      , as = "Softmax"
      , is = "SparseFillEmptyRows"
      , os = "SparseReshape"
      , ls = "SparseSegmentMean"
      , us = "SparseSegmentSum"
      , cs = "SparseToDense"
      , hs = "SquaredDifference"
      , ps = "Square"
      , ds = "StridedSlice"
      , fs = "StringNGrams"
      , ms = "StringSplit"
      , gs = "StringToHashBucketFast"
      , ys = "Sub"
      , bs = "Tan"
      , xs = "Tanh"
      , ws = "Tile"
      , vs = "TopK"
      , ks = "Transform"
      , Is = "Transpose"
      , Ss = "Unique"
      , Ns = "Unpack"
      , Ts = "UnsortedSegmentSum"
      , Cs = "ZerosLike"
      , $s = "Step"
      , Es = "FromPixels"
      , As = "RotateWithOffset"
      , Rs = "_FusedMatMul"
      , Fs = "FusedConv2D"
      , Ds = "FusedDepthwiseConv2D";
    var _s = {};
    function Os(...e) {
        ie().getBool("IS_TEST") || ie().getBool("PROD") || console.warn(...e)
    }
    function Ms(...e) {
        ie().getBool("IS_TEST") || ie().getBool("PROD") || console.log(...e)
    }
    t(_s, "warn", (()=>Os)),
    t(_s, "log", (()=>Ms));
    const Ls = Ne("kernelRegistry", (()=>new Map))
      , zs = Ne("gradRegistry", (()=>new Map));
    function Bs(e, t) {
        const n = Gs(e, t);
        return Ls.get(n)
    }
    function Ps(e) {
        return zs.get(e)
    }
    function Ws(e) {
        const t = Ls.entries()
          , n = [];
        for (; ; ) {
            const {done: s, value: r} = t.next();
            if (s)
                break;
            const [a,i] = r
              , [o] = a.split("_");
            o === e && n.push(i)
        }
        return n
    }
    function Us(e) {
        const {kernelName: t, backendName: n} = e
          , s = Gs(t, n);
        Ls.has(s) && Os(`The kernel '${t}' for backend '${n}' is already registered`),
        Ls.set(s, e)
    }
    function Vs(e) {
        const {kernelName: t} = e;
        zs.has(t) && ie().getBool("DEBUG") && Os(`Overriding the gradient for '${t}'`),
        zs.set(t, e)
    }
    function Gs(e, t) {
        return `${t}_${e}`
    }
    var Hs = {};
    t(Hs, "createScalarValue", (()=>Rr)),
    t(Hs, "encodeString", (()=>Or)),
    t(Hs, "toTypedArray", (()=>Fr)),
    t(Hs, "flatten", (()=>zr)),
    t(Hs, "now", (()=>Dr)),
    t(Hs, "fetch", (()=>_r)),
    t(Hs, "decodeString", (()=>Mr)),
    t(Hs, "isTypedArray", (()=>Lr));
    var js = {};
    t(js, "hexToLong", (()=>xr)),
    t(js, "fingerPrint64", (()=>Ar));
    var qs;
    qs = Xs;
    var Ks = null;
    try {
        Ks = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 13, 2, 96, 0, 1, 127, 96, 4, 127, 127, 127, 127, 1, 127, 3, 7, 6, 0, 1, 1, 1, 1, 1, 6, 6, 1, 127, 1, 65, 0, 11, 7, 50, 6, 3, 109, 117, 108, 0, 1, 5, 100, 105, 118, 95, 115, 0, 2, 5, 100, 105, 118, 95, 117, 0, 3, 5, 114, 101, 109, 95, 115, 0, 4, 5, 114, 101, 109, 95, 117, 0, 5, 8, 103, 101, 116, 95, 104, 105, 103, 104, 0, 0, 10, 191, 1, 6, 4, 0, 35, 0, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 126, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 127, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 128, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 129, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 130, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11])),{}).exports
    } catch (e) {}
    function Xs(e, t, n) {
        this.low = 0 | e,
        this.high = 0 | t,
        this.unsigned = !!n
    }
    function Ys(e) {
        return !0 === (e && e.__isLong__)
    }
    Xs.prototype.__isLong__,
    Object.defineProperty(Xs.prototype, "__isLong__", {
        value: !0
    }),
    Xs.isLong = Ys;
    var Zs = {}
      , Js = {};
    function Qs(e, t) {
        var n, s, r;
        return t ? (r = 0 <= (e >>>= 0) && e < 256) && (s = Js[e]) ? s : (n = tr(e, (0 | e) < 0 ? -1 : 0, !0),
        r && (Js[e] = n),
        n) : (r = -128 <= (e |= 0) && e < 128) && (s = Zs[e]) ? s : (n = tr(e, e < 0 ? -1 : 0, !1),
        r && (Zs[e] = n),
        n)
    }
    function er(e, t) {
        if (isNaN(e))
            return t ? cr : ur;
        if (t) {
            if (e < 0)
                return cr;
            if (e >= ir)
                return mr
        } else {
            if (e <= -or)
                return gr;
            if (e + 1 >= or)
                return fr
        }
        return e < 0 ? er(-e, t).neg() : tr(e % ar | 0, e / ar | 0, t)
    }
    function tr(e, t, n) {
        return new Xs(e,t,n)
    }
    Xs.fromInt = Qs,
    Xs.fromNumber = er,
    Xs.fromBits = tr;
    var nr = Math.pow;
    function sr(e, t, n) {
        if (0 === e.length)
            throw Error("empty string");
        if ("NaN" === e || "Infinity" === e || "+Infinity" === e || "-Infinity" === e)
            return ur;
        if ("number" == typeof t ? (n = t,
        t = !1) : t = !!t,
        (n = n || 10) < 2 || 36 < n)
            throw RangeError("radix");
        var s;
        if ((s = e.indexOf("-")) > 0)
            throw Error("interior hyphen");
        if (0 === s)
            return sr(e.substring(1), t, n).neg();
        for (var r = er(nr(n, 8)), a = ur, i = 0; i < e.length; i += 8) {
            var o = Math.min(8, e.length - i)
              , l = parseInt(e.substring(i, i + o), n);
            if (o < 8) {
                var u = er(nr(n, o));
                a = a.mul(u).add(er(l))
            } else
                a = (a = a.mul(r)).add(er(l))
        }
        return a.unsigned = t,
        a
    }
    function rr(e, t) {
        return "number" == typeof e ? er(e, t) : "string" == typeof e ? sr(e, t) : tr(e.low, e.high, "boolean" == typeof t ? t : e.unsigned)
    }
    Xs.fromString = sr,
    Xs.fromValue = rr;
    var ar = 4294967296
      , ir = ar * ar
      , or = ir / 2
      , lr = Qs(16777216)
      , ur = Qs(0);
    Xs.ZERO = ur;
    var cr = Qs(0, !0);
    Xs.UZERO = cr;
    var hr = Qs(1);
    Xs.ONE = hr;
    var pr = Qs(1, !0);
    Xs.UONE = pr;
    var dr = Qs(-1);
    Xs.NEG_ONE = dr;
    var fr = tr(-1, 2147483647, !1);
    Xs.MAX_VALUE = fr;
    var mr = tr(-1, -1, !0);
    Xs.MAX_UNSIGNED_VALUE = mr;
    var gr = tr(0, -2147483648, !1);
    Xs.MIN_VALUE = gr;
    var yr = Xs.prototype;
    yr.toInt = function() {
        return this.unsigned ? this.low >>> 0 : this.low
    }
    ,
    yr.toNumber = function() {
        return this.unsigned ? (this.high >>> 0) * ar + (this.low >>> 0) : this.high * ar + (this.low >>> 0)
    }
    ,
    yr.toString = function(e) {
        if ((e = e || 10) < 2 || 36 < e)
            throw RangeError("radix");
        if (this.isZero())
            return "0";
        if (this.isNegative()) {
            if (this.eq(gr)) {
                var t = er(e)
                  , n = this.div(t)
                  , s = n.mul(t).sub(this);
                return n.toString(e) + s.toInt().toString(e)
            }
            return "-" + this.neg().toString(e)
        }
        for (var r = er(nr(e, 6), this.unsigned), a = this, i = ""; ; ) {
            var o = a.div(r)
              , l = (a.sub(o.mul(r)).toInt() >>> 0).toString(e);
            if ((a = o).isZero())
                return l + i;
            for (; l.length < 6; )
                l = "0" + l;
            i = "" + l + i
        }
    }
    ,
    yr.getHighBits = function() {
        return this.high
    }
    ,
    yr.getHighBitsUnsigned = function() {
        return this.high >>> 0
    }
    ,
    yr.getLowBits = function() {
        return this.low
    }
    ,
    yr.getLowBitsUnsigned = function() {
        return this.low >>> 0
    }
    ,
    yr.getNumBitsAbs = function() {
        if (this.isNegative())
            return this.eq(gr) ? 64 : this.neg().getNumBitsAbs();
        for (var e = 0 != this.high ? this.high : this.low, t = 31; t > 0 && 0 == (e & 1 << t); t--)
            ;
        return 0 != this.high ? t + 33 : t + 1
    }
    ,
    yr.isZero = function() {
        return 0 === this.high && 0 === this.low
    }
    ,
    yr.eqz = yr.isZero,
    yr.isNegative = function() {
        return !this.unsigned && this.high < 0
    }
    ,
    yr.isPositive = function() {
        return this.unsigned || this.high >= 0
    }
    ,
    yr.isOdd = function() {
        return 1 == (1 & this.low)
    }
    ,
    yr.isEven = function() {
        return 0 == (1 & this.low)
    }
    ,
    yr.equals = function(e) {
        return Ys(e) || (e = rr(e)),
        (this.unsigned === e.unsigned || this.high >>> 31 != 1 || e.high >>> 31 != 1) && (this.high === e.high && this.low === e.low)
    }
    ,
    yr.eq = yr.equals,
    yr.notEquals = function(e) {
        return !this.eq(e)
    }
    ,
    yr.neq = yr.notEquals,
    yr.ne = yr.notEquals,
    yr.lessThan = function(e) {
        return this.comp(e) < 0
    }
    ,
    yr.lt = yr.lessThan,
    yr.lessThanOrEqual = function(e) {
        return this.comp(e) <= 0
    }
    ,
    yr.lte = yr.lessThanOrEqual,
    yr.le = yr.lessThanOrEqual,
    yr.greaterThan = function(e) {
        return this.comp(e) > 0
    }
    ,
    yr.gt = yr.greaterThan,
    yr.greaterThanOrEqual = function(e) {
        return this.comp(e) >= 0
    }
    ,
    yr.gte = yr.greaterThanOrEqual,
    yr.ge = yr.greaterThanOrEqual,
    yr.compare = function(e) {
        if (Ys(e) || (e = rr(e)),
        this.eq(e))
            return 0;
        var t = this.isNegative()
          , n = e.isNegative();
        return t && !n ? -1 : !t && n ? 1 : this.unsigned ? e.high >>> 0 > this.high >>> 0 || e.high === this.high && e.low >>> 0 > this.low >>> 0 ? -1 : 1 : this.sub(e).isNegative() ? -1 : 1
    }
    ,
    yr.comp = yr.compare,
    yr.negate = function() {
        return !this.unsigned && this.eq(gr) ? gr : this.not().add(hr)
    }
    ,
    yr.neg = yr.negate,
    yr.add = function(e) {
        Ys(e) || (e = rr(e));
        var t = this.high >>> 16
          , n = 65535 & this.high
          , s = this.low >>> 16
          , r = 65535 & this.low
          , a = e.high >>> 16
          , i = 65535 & e.high
          , o = e.low >>> 16
          , l = 0
          , u = 0
          , c = 0
          , h = 0;
        return c += (h += r + (65535 & e.low)) >>> 16,
        u += (c += s + o) >>> 16,
        l += (u += n + i) >>> 16,
        l += t + a,
        tr((c &= 65535) << 16 | (h &= 65535), (l &= 65535) << 16 | (u &= 65535), this.unsigned)
    }
    ,
    yr.subtract = function(e) {
        return Ys(e) || (e = rr(e)),
        this.add(e.neg())
    }
    ,
    yr.sub = yr.subtract,
    yr.multiply = function(e) {
        if (this.isZero())
            return ur;
        if (Ys(e) || (e = rr(e)),
        Ks)
            return tr(Ks.mul(this.low, this.high, e.low, e.high), Ks.get_high(), this.unsigned);
        if (e.isZero())
            return ur;
        if (this.eq(gr))
            return e.isOdd() ? gr : ur;
        if (e.eq(gr))
            return this.isOdd() ? gr : ur;
        if (this.isNegative())
            return e.isNegative() ? this.neg().mul(e.neg()) : this.neg().mul(e).neg();
        if (e.isNegative())
            return this.mul(e.neg()).neg();
        if (this.lt(lr) && e.lt(lr))
            return er(this.toNumber() * e.toNumber(), this.unsigned);
        var t = this.high >>> 16
          , n = 65535 & this.high
          , s = this.low >>> 16
          , r = 65535 & this.low
          , a = e.high >>> 16
          , i = 65535 & e.high
          , o = e.low >>> 16
          , l = 65535 & e.low
          , u = 0
          , c = 0
          , h = 0
          , p = 0;
        return h += (p += r * l) >>> 16,
        c += (h += s * l) >>> 16,
        h &= 65535,
        c += (h += r * o) >>> 16,
        u += (c += n * l) >>> 16,
        c &= 65535,
        u += (c += s * o) >>> 16,
        c &= 65535,
        u += (c += r * i) >>> 16,
        u += t * l + n * o + s * i + r * a,
        tr((h &= 65535) << 16 | (p &= 65535), (u &= 65535) << 16 | (c &= 65535), this.unsigned)
    }
    ,
    yr.mul = yr.multiply,
    yr.divide = function(e) {
        if (Ys(e) || (e = rr(e)),
        e.isZero())
            throw Error("division by zero");
        var t, n, s;
        if (Ks)
            return this.unsigned || -2147483648 !== this.high || -1 !== e.low || -1 !== e.high ? tr((this.unsigned ? Ks.div_u : Ks.div_s)(this.low, this.high, e.low, e.high), Ks.get_high(), this.unsigned) : this;
        if (this.isZero())
            return this.unsigned ? cr : ur;
        if (this.unsigned) {
            if (e.unsigned || (e = e.toUnsigned()),
            e.gt(this))
                return cr;
            if (e.gt(this.shru(1)))
                return pr;
            s = cr
        } else {
            if (this.eq(gr))
                return e.eq(hr) || e.eq(dr) ? gr : e.eq(gr) ? hr : (t = this.shr(1).div(e).shl(1)).eq(ur) ? e.isNegative() ? hr : dr : (n = this.sub(e.mul(t)),
                s = t.add(n.div(e)));
            if (e.eq(gr))
                return this.unsigned ? cr : ur;
            if (this.isNegative())
                return e.isNegative() ? this.neg().div(e.neg()) : this.neg().div(e).neg();
            if (e.isNegative())
                return this.div(e.neg()).neg();
            s = ur
        }
        for (n = this; n.gte(e); ) {
            t = Math.max(1, Math.floor(n.toNumber() / e.toNumber()));
            for (var r = Math.ceil(Math.log(t) / Math.LN2), a = r <= 48 ? 1 : nr(2, r - 48), i = er(t), o = i.mul(e); o.isNegative() || o.gt(n); )
                o = (i = er(t -= a, this.unsigned)).mul(e);
            i.isZero() && (i = hr),
            s = s.add(i),
            n = n.sub(o)
        }
        return s
    }
    ,
    yr.div = yr.divide,
    yr.modulo = function(e) {
        return Ys(e) || (e = rr(e)),
        Ks ? tr((this.unsigned ? Ks.rem_u : Ks.rem_s)(this.low, this.high, e.low, e.high), Ks.get_high(), this.unsigned) : this.sub(this.div(e).mul(e))
    }
    ,
    yr.mod = yr.modulo,
    yr.rem = yr.modulo,
    yr.not = function() {
        return tr(~this.low, ~this.high, this.unsigned)
    }
    ,
    yr.and = function(e) {
        return Ys(e) || (e = rr(e)),
        tr(this.low & e.low, this.high & e.high, this.unsigned)
    }
    ,
    yr.or = function(e) {
        return Ys(e) || (e = rr(e)),
        tr(this.low | e.low, this.high | e.high, this.unsigned)
    }
    ,
    yr.xor = function(e) {
        return Ys(e) || (e = rr(e)),
        tr(this.low ^ e.low, this.high ^ e.high, this.unsigned)
    }
    ,
    yr.shiftLeft = function(e) {
        return Ys(e) && (e = e.toInt()),
        0 == (e &= 63) ? this : e < 32 ? tr(this.low << e, this.high << e | this.low >>> 32 - e, this.unsigned) : tr(0, this.low << e - 32, this.unsigned)
    }
    ,
    yr.shl = yr.shiftLeft,
    yr.shiftRight = function(e) {
        return Ys(e) && (e = e.toInt()),
        0 == (e &= 63) ? this : e < 32 ? tr(this.low >>> e | this.high << 32 - e, this.high >> e, this.unsigned) : tr(this.high >> e - 32, this.high >= 0 ? 0 : -1, this.unsigned)
    }
    ,
    yr.shr = yr.shiftRight,
    yr.shiftRightUnsigned = function(e) {
        if (Ys(e) && (e = e.toInt()),
        0 === (e &= 63))
            return this;
        var t = this.high;
        return e < 32 ? tr(this.low >>> e | t << 32 - e, t >>> e, this.unsigned) : tr(32 === e ? t : t >>> e - 32, 0, this.unsigned)
    }
    ,
    yr.shru = yr.shiftRightUnsigned,
    yr.shr_u = yr.shiftRightUnsigned,
    yr.toSigned = function() {
        return this.unsigned ? tr(this.low, this.high, !1) : this
    }
    ,
    yr.toUnsigned = function() {
        return this.unsigned ? this : tr(this.low, this.high, !0)
    }
    ,
    yr.toBytes = function(e) {
        return e ? this.toBytesLE() : this.toBytesBE()
    }
    ,
    yr.toBytesLE = function() {
        var e = this.high
          , t = this.low;
        return [255 & t, t >>> 8 & 255, t >>> 16 & 255, t >>> 24, 255 & e, e >>> 8 & 255, e >>> 16 & 255, e >>> 24]
    }
    ,
    yr.toBytesBE = function() {
        var e = this.high
          , t = this.low;
        return [e >>> 24, e >>> 16 & 255, e >>> 8 & 255, 255 & e, t >>> 24, t >>> 16 & 255, t >>> 8 & 255, 255 & t]
    }
    ,
    Xs.fromBytes = function(e, t, n) {
        return n ? Xs.fromBytesLE(e, t) : Xs.fromBytesBE(e, t)
    }
    ,
    Xs.fromBytesLE = function(e, t) {
        return new Xs(e[0] | e[1] << 8 | e[2] << 16 | e[3] << 24,e[4] | e[5] << 8 | e[6] << 16 | e[7] << 24,t)
    }
    ,
    Xs.fromBytesBE = function(e, t) {
        return new Xs(e[4] << 24 | e[5] << 16 | e[6] << 8 | e[7],e[0] << 24 | e[1] << 16 | e[2] << 8 | e[3],t)
    }
    ;
    const br = qs.default || qs;
    function xr(e) {
        return br.fromString(e, !0, 16)
    }
    const wr = xr("c3a5c85c97cb3127")
      , vr = xr("b492b66fbe98f273")
      , kr = xr("9ae16a3b2f90404f");
    function Ir(e) {
        return e.xor(e.shru(47))
    }
    function Sr(e, t, n) {
        const s = e.slice(t, t + n);
        return br.fromBytes(Array.from(s), !0, !0)
    }
    function Nr(e, t) {
        return Sr(e, t, 8)
    }
    function Tr(e, t) {
        return Sr(e, t, 4)
    }
    function Cr(e, t) {
        return 0 === t ? e : e.shru(t).or(e.shl(64 - t))
    }
    function $r(e, t, n=xr("9ddfea08eb382d69")) {
        let s = e.xor(t).mul(n);
        s = s.xor(s.shru(47));
        let r = t.xor(s).mul(n);
        return r = r.xor(r.shru(47)),
        r = r.mul(n),
        r
    }
    function Er(e, t, n, s) {
        return function(e, t, n, s, r, a) {
            r = r.add(e),
            a = Cr(a.add(r).add(s), 21);
            const i = r;
            return r = (r = r.add(t)).add(n),
            a = a.add(Cr(r, 44)),
            [r.add(s), a.add(i)]
        }(Nr(e, t), Nr(e, t + 8), Nr(e, t + 16), Nr(e, t + 24), n, s)
    }
    function Ar(e, t=e.length) {
        const n = br.fromNumber(81, !0);
        if (t <= 32)
            return t <= 16 ? function(e, t=e.length) {
                if (t >= 8) {
                    const n = kr.add(2 * t)
                      , s = Nr(e, 0).add(kr)
                      , r = Nr(e, t - 8);
                    return $r(Cr(r, 37).mul(n).add(s), Cr(s, 25).add(r).mul(n), n)
                }
                if (t >= 4) {
                    const n = kr.add(2 * t);
                    return $r(Tr(e, 0).shl(3).add(t), Tr(e, t - 4), n)
                }
                if (t > 0) {
                    const n = e[0] + (e[t >> 1] << 8)
                      , s = t + (e[t - 1] << 2);
                    return Ir(kr.mul(n).xor(wr.mul(s))).mul(kr)
                }
                return kr
            }(e, t) : function(e, t=e.length) {
                const n = kr.add(2 * t)
                  , s = Nr(e, 0).mul(vr)
                  , r = Nr(e, 8)
                  , a = Nr(e, t - 8).mul(n)
                  , i = Nr(e, t - 16).mul(kr);
                return $r(Cr(s.add(r), 43).add(Cr(a, 30)).add(i), s.add(Cr(r.add(kr), 18)).add(a), n)
            }(e, t);
        if (t <= 64)
            return function(e, t=e.length) {
                const n = kr.add(2 * t)
                  , s = Nr(e, 0).mul(kr)
                  , r = Nr(e, 8)
                  , a = Nr(e, t - 8).mul(n)
                  , i = Nr(e, t - 16).mul(kr)
                  , o = Cr(s.add(r), 43).add(Cr(a, 30)).add(i)
                  , l = $r(o, s.add(Cr(r.add(kr), 18)).add(a), n)
                  , u = Nr(e, 16).mul(n)
                  , c = Nr(e, 24)
                  , h = o.add(Nr(e, t - 32)).mul(n)
                  , p = l.add(Nr(e, t - 24)).mul(n);
                return $r(Cr(u.add(c), 43).add(Cr(h, 30)).add(p), u.add(Cr(c.add(s), 18)).add(h), n)
            }(e, t);
        let s = n
          , r = n.mul(vr).add(113)
          , a = Ir(r.mul(kr).add(113)).mul(kr)
          , i = [br.UZERO, br.UZERO]
          , o = [br.UZERO, br.UZERO];
        s = s.mul(kr).add(Nr(e, 0));
        let l = 0;
        const u = 64 * (t - 1 >> 6)
          , c = u + (t - 1 & 63) - 63;
        do {
            s = Cr(s.add(r).add(i[0]).add(Nr(e, l + 8)), 37).mul(vr),
            r = Cr(r.add(i[1]).add(Nr(e, l + 48)), 42).mul(vr),
            s = s.xor(o[1]),
            r = r.add(i[0]).add(Nr(e, l + 40)),
            a = Cr(a.add(o[0]), 33).mul(vr),
            i = Er(e, l, i[1].mul(vr), s.add(o[0])),
            o = Er(e, l + 32, a.add(o[1]), r.add(Nr(e, l + 16))),
            [a,s] = [s, a],
            l += 64
        } while (l !== u);
        const h = vr.add(a.and(255).shl(1));
        return l = c,
        o[0] = o[0].add(t - 1 & 63),
        i[0] = i[0].add(o[0]),
        o[0] = o[0].add(i[0]),
        s = Cr(s.add(r).add(i[0]).add(Nr(e, l + 8)), 37).mul(h),
        r = Cr(r.add(i[1]).add(Nr(e, l + 48)), 42).mul(h),
        s = s.xor(o[1].mul(9)),
        r = r.add(i[0].mul(9).add(Nr(e, l + 40))),
        a = Cr(a.add(o[0]), 33).mul(h),
        i = Er(e, l, i[1].mul(h), s.add(o[0])),
        o = Er(e, l + 32, a.add(o[1]), r.add(Nr(e, l + 16))),
        [a,s] = [s, a],
        $r($r(i[0], o[0], h).add(Ir(r).mul(wr)).add(a), $r(i[1], o[1], h).add(s), h)
    }
    function Rr(e, t) {
        return "string" === t ? Or(e) : Fr([e], t)
    }
    function Fr(e, t) {
        if ("string" === t)
            throw new Error("Cannot convert a string[] to a TypedArray");
        if (Array.isArray(e) && (e = zr(e)),
        ie().getBool("DEBUG") && O(e, t),
        function(e, t) {
            return e instanceof Float32Array && "float32" === t || e instanceof Int32Array && "int32" === t || e instanceof Uint8Array && "bool" === t
        }(e, t))
            return e;
        if (null == t || "float32" === t || "complex64" === t)
            return new Float32Array(e);
        if ("int32" === t)
            return new Int32Array(e);
        if ("bool" === t) {
            const t = new Uint8Array(e.length);
            for (let n = 0; n < t.length; ++n)
                0 !== Math.round(e[n]) && (t[n] = 1);
            return t
        }
        throw new Error(`Unknown data type ${t}`)
    }
    function Dr() {
        return ie().platform.now()
    }
    function _r(e, t) {
        return ie().platform.fetch(e, t)
    }
    function Or(e, t="utf-8") {
        return t = t || "utf-8",
        ie().platform.encode(e, t)
    }
    function Mr(e, t="utf-8") {
        return t = t || "utf-8",
        ie().platform.decode(e, t)
    }
    function Lr(e) {
        return ie().platform.isTypedArray(e)
    }
    function zr(e, t=[], n=!1) {
        if (null == t && (t = []),
        "boolean" == typeof e || "number" == typeof e || "string" == typeof e || ne(e) || null == e || Lr(e) && n)
            t.push(e);
        else if (Array.isArray(e) || Lr(e))
            for (let s = 0; s < e.length; ++s)
                zr(e[s], t, n);
        else {
            let s = -1;
            for (const t of Object.keys(e))
                /^([1-9]+[0-9]*|0)$/.test(t) && (s = Math.max(s, Number(t)));
            for (let r = 0; r <= s; r++)
                zr(e[r], t, n)
        }
        return t
    }
    n(Hs, u),
    n(Hs, js);
    class Br {
        constructor(e, t) {
            this.backendTimer = e,
            this.logger = t,
            null == t && (this.logger = new Wr)
        }
        profileKernel(e, t, n) {
            let s;
            const r = ()=>{
                s = n()
            }
            ;
            let a;
            const i = Dr();
            if (this.backendTimer.timerAvailable())
                a = this.backendTimer.time(r);
            else {
                r();
                for (const e of s)
                    e.dataSync();
                a = Promise.resolve({
                    kernelMs: Dr() - i
                })
            }
            if (ie().getBool("CHECK_COMPUTATION_FOR_ERRORS"))
                for (let t = 0; t < s.length; t++) {
                    const n = s[t];
                    n.data().then((t=>{
                        Pr(t, n.dtype, e)
                    }
                    ))
                }
            return {
                kernelName: e,
                outputs: s,
                inputs: t,
                timeMs: a.then((e=>e.kernelMs)),
                extraInfo: a.then((e=>null != e.getExtraProfileInfo ? e.getExtraProfileInfo() : ""))
            }
        }
        logKernelProfile(e) {
            const {kernelName: t, outputs: n, timeMs: s, inputs: r, extraInfo: a} = e;
            n.forEach((e=>{
                Promise.all([e.data(), s, a]).then((n=>{
                    this.logger.logKernelProfile(t, e, n[0], n[1], r, n[2])
                }
                ))
            }
            ))
        }
    }
    function Pr(e, t, n) {
        if ("float32" !== t)
            return !1;
        for (let t = 0; t < e.length; t++) {
            const s = e[t];
            if (isNaN(s) || !isFinite(s))
                return console.warn(`Found ${s} in the result of '${n}'`),
                !0
        }
        return !1
    }
    class Wr {
        logKernelProfile(e, t, n, s, r, a) {
            const i = "number" == typeof s ? $(`${s}ms`, 9) : s.error
              , o = $(e, 25)
              , l = t.rank
              , u = t.size
              , c = $(t.shape.toString(), 14);
            let h = "";
            for (const e in r) {
                const n = r[e];
                if (null != n) {
                    const s = n.shape || t.shape
                      , r = s.length;
                    h += `${e}: ${r}D ${r > 0 ? s : ""} `
                }
            }
            console.log(`%c${o}\t%c${i}\t%c${l}D ${c}\t%c${u}\t%c${h}\t%c${a}`, "font-weight:bold", "color:red", "color:blue", "color: orange", "color: green", "color: steelblue")
        }
    }
    function Ur(e, t, n, s) {
        const r = j(t)
          , a = function(e, t, n, s) {
            const r = v(t)
              , a = s[s.length - 1]
              , i = new Array(a).fill(0)
              , o = t.length
              , l = "complex64" === n ? jr(e) : e;
            if (o > 1)
                for (let e = 0; e < r / a; e++) {
                    const t = e * a;
                    for (let e = 0; e < a; e++)
                        i[e] = Math.max(i[e], Vr(l[t + e], 0, n).length)
                }
            return i
        }(e, t, n, r)
          , i = t.length
          , o = Hr(e, t, n, r, a)
          , l = ["Tensor"];
        return s && (l.push(`  dtype: ${n}`),
        l.push(`  rank: ${i}`),
        l.push(`  shape: [${t}]`),
        l.push("  values:")),
        l.push(o.map((e=>"    " + e)).join("\n")),
        l.join("\n")
    }
    function Vr(e, t, n) {
        let s;
        return s = Array.isArray(e) ? `${parseFloat(e[0].toFixed(7))} + ${parseFloat(e[1].toFixed(7))}j` : P(e) ? `'${e}'` : "bool" === n ? Gr(e) : parseFloat(e.toFixed(7)).toString(),
        $(s, t)
    }
    function Gr(e) {
        return 0 === e ? "false" : "true"
    }
    function Hr(e, t, n, s, r, a=!0) {
        const i = "complex64" === n ? 2 : 1
          , o = t[0]
          , l = t.length;
        if (0 === l) {
            if ("complex64" === n) {
                return [Vr(jr(e)[0], 0, n)]
            }
            return "bool" === n ? [Gr(e[0])] : [e[0].toString()]
        }
        if (1 === l) {
            if (o > 20) {
                const t = 3 * i;
                let s = Array.from(e.slice(0, t))
                  , a = Array.from(e.slice((o - 3) * i, o * i));
                return "complex64" === n && (s = jr(s),
                a = jr(a)),
                ["[" + s.map(((e,t)=>Vr(e, r[t], n))).join(", ") + ", ..., " + a.map(((e,t)=>Vr(e, r[o - 3 + t], n))).join(", ") + "]"]
            }
            return ["[" + ("complex64" === n ? jr(e) : Array.from(e)).map(((e,t)=>Vr(e, r[t], n))).join(", ") + "]"]
        }
        const u = t.slice(1)
          , c = s.slice(1)
          , h = s[0] * i
          , p = [];
        if (o > 20) {
            for (let t = 0; t < 3; t++) {
                const s = t * h
                  , a = s + h;
                p.push(...Hr(e.slice(s, a), u, n, c, r, !1))
            }
            p.push("...");
            for (let t = o - 3; t < o; t++) {
                const s = t * h
                  , a = s + h;
                p.push(...Hr(e.slice(s, a), u, n, c, r, t === o - 1))
            }
        } else
            for (let t = 0; t < o; t++) {
                const s = t * h
                  , a = s + h;
                p.push(...Hr(e.slice(s, a), u, n, c, r, t === o - 1))
            }
        const d = 2 === l ? "," : "";
        p[0] = "[" + (o > 0 ? p[0] + d : "");
        for (let e = 1; e < p.length - 1; e++)
            p[e] = " " + p[e] + d;
        let f = ",\n";
        for (let e = 2; e < l; e++)
            f += "\n";
        return p[p.length - 1] = " " + p[p.length - 1] + "]" + (a ? "" : f),
        p
    }
    function jr(e) {
        const t = [];
        for (let n = 0; n < e.length; n += 2)
            t.push([e[n], e[n + 1]]);
        return t
    }
    class qr {
        constructor(e, t, n) {
            if (this.dtype = t,
            this.shape = e.slice(),
            this.size = v(e),
            null != n) {
                const e = n.length;
                b(e === this.size, (()=>`Length of values '${e}' does not match the size inferred by the shape '${this.size}'.`))
            }
            if ("complex64" === t)
                throw new Error("complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).");
            this.values = n || _(t, this.size),
            this.strides = j(e)
        }
        set(e, ...t) {
            0 === t.length && (t = [0]),
            b(t.length === this.rank, (()=>`The number of provided coordinates (${t.length}) must match the rank (${this.rank})`));
            const n = this.locToIndex(t);
            this.values[n] = e
        }
        get(...e) {
            0 === e.length && (e = [0]);
            let t = 0;
            for (const n of e) {
                if (n < 0 || n >= this.shape[t]) {
                    const t = `Requested out of range element at ${e}.   Buffer shape=${this.shape}`;
                    throw new Error(t)
                }
                t++
            }
            let n = e[e.length - 1];
            for (let t = 0; t < e.length - 1; ++t)
                n += this.strides[t] * e[t];
            return this.values[n]
        }
        locToIndex(e) {
            if (0 === this.rank)
                return 0;
            if (1 === this.rank)
                return e[0];
            let t = e[e.length - 1];
            for (let n = 0; n < e.length - 1; ++n)
                t += this.strides[n] * e[n];
            return t
        }
        indexToLoc(e) {
            if (0 === this.rank)
                return [];
            if (1 === this.rank)
                return [e];
            const t = new Array(this.shape.length);
            for (let n = 0; n < t.length - 1; ++n)
                t[n] = Math.floor(e / this.strides[n]),
                e -= t[n] * this.strides[n];
            return t[t.length - 1] = e,
            t
        }
        get rank() {
            return this.shape.length
        }
        toTensor() {
            return Kr().makeTensor(this.values, this.shape, this.dtype)
        }
    }
    let Kr = null
      , Xr = null
      , Yr = null;
    class Zr {
        constructor(e, t, n, s) {
            this.kept = !1,
            this.isDisposedInternal = !1,
            this.shape = e.slice(),
            this.dtype = t || "float32",
            this.size = v(e),
            this.strides = j(e),
            this.dataId = n,
            this.id = s,
            this.rankType = this.rank < 5 ? this.rank.toString() : "higher"
        }
        get rank() {
            return this.shape.length
        }
        async buffer() {
            const e = await this.data();
            return Xr.buffer(this.shape, this.dtype, e)
        }
        bufferSync() {
            return Xr.buffer(this.shape, this.dtype, this.dataSync())
        }
        async array() {
            const e = await this.data();
            return K(this.shape, e, "complex64" === this.dtype)
        }
        arraySync() {
            return K(this.shape, this.dataSync(), "complex64" === this.dtype)
        }
        async data() {
            this.throwIfDisposed();
            const e = Kr().read(this.dataId);
            if ("string" === this.dtype) {
                const t = await e;
                try {
                    return t.map((e=>Mr(e)))
                } catch (e) {
                    throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().")
                }
            }
            return e
        }
        dataToGPU(e) {
            return this.throwIfDisposed(),
            Kr().readToGPU(this.dataId, e)
        }
        dataSync() {
            this.throwIfDisposed();
            const e = Kr().readSync(this.dataId);
            if ("string" === this.dtype)
                try {
                    return e.map((e=>Mr(e)))
                } catch (e) {
                    throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().")
                }
            return e
        }
        async bytes() {
            this.throwIfDisposed();
            const e = await Kr().read(this.dataId);
            return "string" === this.dtype ? e : new Uint8Array(e.buffer)
        }
        dispose() {
            this.isDisposed || (Kr().disposeTensor(this),
            this.isDisposedInternal = !0)
        }
        get isDisposed() {
            return this.isDisposedInternal
        }
        throwIfDisposed() {
            if (this.isDisposed)
                throw new Error("Tensor is disposed.")
        }
        print(e=!1) {
            return Xr.print(this, e)
        }
        clone() {
            return this.throwIfDisposed(),
            Xr.clone(this)
        }
        toString(e=!1) {
            return Ur(this.dataSync(), this.shape, this.dtype, e)
        }
        cast(e) {
            return this.throwIfDisposed(),
            Xr.cast(this, e)
        }
        variable(e=!0, t, n) {
            return this.throwIfDisposed(),
            Kr().makeVariable(this, e, t, n)
        }
    }
    function Jr() {
        return Ne("Tensor", (()=>Zr))
    }
    Object.defineProperty(Zr, Symbol.hasInstance, {
        value: e=>!!e && null != e.data && null != e.dataSync && null != e.throwIfDisposed
    }),
    Jr();
    class Qr extends Zr {
        constructor(e, t, n, s) {
            super(e.shape, e.dtype, e.dataId, s),
            this.trainable = t,
            this.name = n
        }
        assign(e) {
            if (e.dtype !== this.dtype)
                throw new Error(`dtype of the new value (${e.dtype}) and previous value (${this.dtype}) must match`);
            if (!I(e.shape, this.shape))
                throw new Error(`shape of the new value (${e.shape}) and previous value (${this.shape}) must match`);
            Kr().disposeTensor(this),
            this.dataId = e.dataId,
            Kr().incRef(this, null)
        }
        dispose() {
            Kr().disposeVariable(this),
            this.isDisposedInternal = !0
        }
    }
    Object.defineProperty(Qr, Symbol.hasInstance, {
        value: e=>e instanceof Zr && null != e.assign && e.assign instanceof Function
    });
    var ea, ta, na, sa, ra, aa, ia, oa, la, ua = {};
    t(ua, "makeTypesMatch", (()=>da)),
    t(ua, "assertTypesMatch", (()=>fa)),
    t(ua, "isTensorInList", (()=>ma)),
    t(ua, "getTensorsInContainer", (()=>ga)),
    function(e) {
        e.R0 = "R0",
        e.R1 = "R1",
        e.R2 = "R2",
        e.R3 = "R3",
        e.R4 = "R4",
        e.R5 = "R5",
        e.R6 = "R6"
    }(ea || (ea = {})),
    (na = ta || (ta = {})).float32 = "float32",
    na.int32 = "int32",
    na.bool = "int32",
    na.complex64 = "complex64",
    (ra = sa || (sa = {})).float32 = "float32",
    ra.int32 = "int32",
    ra.bool = "bool",
    ra.complex64 = "complex64",
    (ia = aa || (aa = {})).float32 = "float32",
    ia.int32 = "float32",
    ia.bool = "float32",
    ia.complex64 = "complex64",
    (la = oa || (oa = {})).float32 = "complex64",
    la.int32 = "complex64",
    la.bool = "complex64",
    la.complex64 = "complex64";
    const ca = {
        float32: aa,
        int32: ta,
        bool: sa,
        complex64: oa
    };
    function ha(e, t) {
        if ("string" === e || "string" === t) {
            if ("string" === e && "string" === t)
                return "string";
            throw new Error(`Can not upcast ${e} with ${t}`)
        }
        return ca[e][t]
    }
    function pa(e) {
        return ha(e, "int32")
    }
    function da(e, t) {
        if (e.dtype === t.dtype)
            return [e, t];
        const n = ha(e.dtype, t.dtype);
        return [e.cast(n), t.cast(n)]
    }
    function fa(e, t) {
        b(e.dtype === t.dtype, (()=>`The dtypes of the first(${e.dtype}) and second(${t.dtype}) input must match`))
    }
    function ma(e, t) {
        return t.some((t=>t.id === e.id))
    }
    function ga(e) {
        const t = [];
        return ya(e, t, new Set),
        t
    }
    function ya(e, t, n) {
        if (null == e)
            return;
        if (e instanceof Zr)
            return void t.push(e);
        if (s = e,
        !Array.isArray(s) && "object" != typeof s)
            return;
        var s;
        const r = e;
        for (const e in r) {
            const s = r[e];
            n.has(s) || (n.add(s),
            ya(s, t, n))
        }
    }
    function ba(e) {
        return null != e.kernelName
    }
    class xa {
        constructor() {
            this.registeredVariables = {},
            this.nextTapeNodeId = 0,
            this.numBytes = 0,
            this.numTensors = 0,
            this.numStringTensors = 0,
            this.numDataBuffers = 0,
            this.gradientDepth = 0,
            this.kernelDepth = 0,
            this.scopeStack = [],
            this.numDataMovesStack = [],
            this.nextScopeId = 0,
            this.tensorInfo = new WeakMap,
            this.profiling = !1,
            this.activeProfile = {
                newBytes: 0,
                newTensors: 0,
                peakBytes: 0,
                kernels: [],
                result: null,
                get kernelNames() {
                    return Array.from(new Set(this.kernels.map((e=>e.name))))
                }
            }
        }
        dispose() {
            for (const e in this.registeredVariables)
                this.registeredVariables[e].dispose()
        }
    }
    class wa {
        constructor(e) {
            this.ENV = e,
            this.registry = {},
            this.registryFactory = {},
            this.pendingBackendInitId = 0,
            this.state = new xa
        }
        async ready() {
            if (null != this.pendingBackendInit)
                return this.pendingBackendInit.then((()=>{}
                ));
            if (null != this.backendInstance)
                return;
            const e = this.getSortedBackends();
            for (let t = 0; t < e.length; t++) {
                const n = e[t];
                if (await this.initializeBackend(n).success)
                    return void await this.setBackend(n)
            }
            throw new Error("Could not initialize any backends, all backend initializations failed.")
        }
        get backend() {
            if (null != this.pendingBackendInit)
                throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
            if (null == this.backendInstance) {
                const {name: e, asyncInit: t} = this.initializeBackendsAndReturnBest();
                if (t)
                    throw new Error(`The highest priority backend '${e}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
                this.setBackend(e)
            }
            return this.backendInstance
        }
        backendNames() {
            return Object.keys(this.registryFactory)
        }
        findBackend(e) {
            if (!(e in this.registry)) {
                if (!(e in this.registryFactory))
                    return null;
                {
                    const {asyncInit: t} = this.initializeBackend(e);
                    if (t)
                        return null
                }
            }
            return this.registry[e]
        }
        findBackendFactory(e) {
            return e in this.registryFactory ? this.registryFactory[e].factory : null
        }
        registerBackend(e, t, n=1) {
            return e in this.registryFactory ? (Os(`${e} backend was already registered. Reusing existing backend factory.`),
            !1) : (this.registryFactory[e] = {
                factory: t,
                priority: n
            },
            !0)
        }
        async setBackend(e) {
            if (null == this.registryFactory[e])
                throw new Error(`Backend name '${e}' not found in registry`);
            if (this.backendName = e,
            null == this.registry[e]) {
                this.backendInstance = null;
                const {success: t, asyncInit: n} = this.initializeBackend(e);
                if (!(n ? await t : t))
                    return !1
            }
            return this.backendInstance = this.registry[e],
            this.setupRegisteredKernels(),
            this.profiler = new Br(this.backendInstance),
            !0
        }
        setupRegisteredKernels() {
            Ws(this.backendName).forEach((e=>{
                null != e.setupFunc && e.setupFunc(this.backendInstance)
            }
            ))
        }
        disposeRegisteredKernels(e) {
            Ws(e).forEach((t=>{
                null != t.disposeFunc && t.disposeFunc(this.registry[e])
            }
            ))
        }
        initializeBackend(e) {
            const t = this.registryFactory[e];
            if (null == t)
                throw new Error(`Cannot initialize backend ${e}, no registration found.`);
            try {
                const n = t.factory();
                if (!n || n instanceof o || "function" != typeof n.then)
                    return this.registry[e] = n,
                    {
                        success: !0,
                        asyncInit: !1
                    };
                {
                    const t = ++this.pendingBackendInitId
                      , s = n.then((n=>!(t < this.pendingBackendInitId) && (this.registry[e] = n,
                    this.pendingBackendInit = null,
                    !0))).catch((n=>(t < this.pendingBackendInitId || (this.pendingBackendInit = null,
                    Os(`Initialization of backend ${e} failed`),
                    Os(n.stack || n.message)),
                    !1)));
                    return this.pendingBackendInit = s,
                    {
                        success: s,
                        asyncInit: !0
                    }
                }
            } catch (t) {
                return Os(`Initialization of backend ${e} failed`),
                Os(t.stack || t.message),
                {
                    success: !1,
                    asyncInit: !1
                }
            }
        }
        removeBackend(e) {
            if (!(e in this.registryFactory))
                throw new Error(`${e} backend not found in registry`);
            this.backendName === e && null != this.pendingBackendInit && this.pendingBackendInitId++,
            e in this.registry && (this.disposeRegisteredKernels(e),
            this.registry[e].dispose(),
            delete this.registry[e]),
            delete this.registryFactory[e],
            this.backendName === e && (this.pendingBackendInit = null,
            this.backendName = null,
            this.backendInstance = null)
        }
        getSortedBackends() {
            if (0 === Object.keys(this.registryFactory).length)
                throw new Error("No backend found in registry.");
            return Object.keys(this.registryFactory).sort(((e,t)=>this.registryFactory[t].priority - this.registryFactory[e].priority))
        }
        initializeBackendsAndReturnBest() {
            const e = this.getSortedBackends();
            for (let t = 0; t < e.length; t++) {
                const n = e[t]
                  , {success: s, asyncInit: r} = this.initializeBackend(n);
                if (r || s)
                    return {
                        name: n,
                        asyncInit: r
                    }
            }
            throw new Error("Could not initialize any backends, all backend initializations failed.")
        }
        moveData(e, t) {
            const n = this.state.tensorInfo.get(t)
              , s = n.backend
              , r = this.readSync(t)
              , a = s.refCount(t);
            s.disposeData(t, !0),
            n.backend = e,
            e.move(t, r, n.shape, n.dtype, a),
            this.shouldCheckForMemLeaks() && this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++
        }
        tidy(e, t) {
            let n, s = null;
            if (null == t) {
                if ("function" != typeof e)
                    throw new Error("Please provide a function to tidy()");
                t = e
            } else {
                if ("string" != typeof e && !(e instanceof String))
                    throw new Error("When calling with two arguments, the first argument to tidy() must be a string");
                if ("function" != typeof t)
                    throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");
                s = e
            }
            return this.scopedRun((()=>this.startScope(s)), (()=>this.endScope(n)), (()=>(n = t(),
            n instanceof Promise && console.error("Cannot return a Promise inside of tidy."),
            n)))
        }
        scopedRun(e, t, n) {
            e();
            try {
                const e = n();
                return t(),
                e
            } catch (e) {
                throw t(),
                e
            }
        }
        nextTensorId() {
            return wa.nextTensorId++
        }
        nextVariableId() {
            return wa.nextVariableId++
        }
        clone(e) {
            const t = ka.runKernel(Bt, {
                x: e
            })
              , n = {
                x: e
            };
            return this.addTapeNode(this.state.activeScope.name, n, [t], (e=>({
                x: ()=>{
                    const t = {
                        x: e
                    }
                      , n = {
                        dtype: "float32"
                    };
                    return ka.runKernel(Ke, t, n)
                }
            })), [], {}),
            t
        }
        runKernel(e, t, n) {
            null == this.backendName && this.backend;
            if (!(null != Bs(e, this.backendName)))
                throw new Error(`Kernel '${e}' not registered for backend '${this.backendName}'`);
            return this.runKernelFunc({
                kernelName: e,
                inputs: t,
                attrs: n
            })
        }
        shouldCheckForMemLeaks() {
            return this.ENV.getBool("IS_TEST")
        }
        checkKernelForMemLeak(e, t, n) {
            const s = this.backend.numDataIds();
            let r = 0;
            n.forEach((e=>{
                r += "complex64" === e.dtype ? 3 : 1
            }
            ));
            const a = this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]
              , i = s - t - r - a;
            if (i > 0)
                throw new Error(`Backend '${this.backendName}' has an internal memory leak (${i} data ids) after running '${e}'`)
        }
        runKernelFunc(e) {
            let t, n = [];
            const s = this.isTapeOn()
              , r = this.state.numBytes
              , a = this.state.numTensors;
            let i, o;
            this.shouldCheckForMemLeaks() && this.state.numDataMovesStack.push(0),
            null == this.backendName && this.backend;
            const l = ba(e) ? e.kernelName : null != this.state.activeScope ? this.state.activeScope.name : "";
            if (ba(e)) {
                const {kernelName: t, inputs: r, attrs: a} = e;
                null == this.backendName && this.backend;
                const l = Bs(t, this.backendName);
                b(null != l, (()=>`Cannot find registered kernel '${t}' for backend '${this.backendName}'`)),
                i = ()=>{
                    const e = this.backend.numDataIds();
                    o = l.kernelFunc({
                        inputs: r,
                        attrs: a,
                        backend: this.backend
                    });
                    const i = Array.isArray(o) ? o : [o];
                    this.shouldCheckForMemLeaks() && this.checkKernelForMemLeak(t, e, i);
                    const u = i.map((e=>null != e.rank ? e : this.makeTensorFromTensorInfo(e)));
                    if (s) {
                        const e = this.getTensorsForGradient(t, r, u);
                        n = this.saveTensorsForBackwardMode(e)
                    }
                    return u
                }
            } else {
                const {forwardFunc: t} = e
                  , r = e=>{
                    s && (n = e.map((e=>this.keep(this.clone(e)))))
                }
                ;
                i = ()=>{
                    const e = this.backend.numDataIds();
                    o = this.tidy((()=>t(this.backend, r)));
                    const n = Array.isArray(o) ? o : [o];
                    return this.shouldCheckForMemLeaks() && this.checkKernelForMemLeak(l, e, n),
                    n
                }
            }
            const {inputs: u, attrs: c} = e
              , h = ba(e) ? null : e.backwardsFunc;
            let p;
            return this.scopedRun((()=>this.state.kernelDepth++), (()=>this.state.kernelDepth--), (()=>{
                this.ENV.getBool("DEBUG") || this.state.profiling ? (p = this.profiler.profileKernel(l, u, (()=>i())),
                this.ENV.getBool("DEBUG") && this.profiler.logKernelProfile(p),
                t = p.outputs) : t = i()
            }
            )),
            s && this.addTapeNode(l, u, t, h, n, c),
            this.state.profiling && this.state.activeProfile.kernels.push({
                name: l,
                bytesAdded: this.state.numBytes - r,
                totalBytesSnapshot: this.state.numBytes,
                tensorsAdded: this.state.numTensors - a,
                totalTensorsSnapshot: this.state.numTensors,
                inputShapes: Object.keys(u).map((e=>null != u[e] ? u[e].shape : null)),
                outputShapes: t.map((e=>e.shape)),
                kernelTimeMs: p.timeMs,
                extraInfo: p.extraInfo
            }),
            Array.isArray(o) ? t : t[0]
        }
        saveTensorsForBackwardMode(e) {
            return e.map((e=>this.keep(this.clone(e))))
        }
        getTensorsForGradient(e, t, n) {
            const s = Ps(e);
            if (null != s) {
                const e = s.inputsToSave || []
                  , r = s.outputsToSave || [];
                let a;
                s.saveAllInputs ? (b(Array.isArray(t), (()=>"saveAllInputs is true, expected inputs to be an array.")),
                a = Object.keys(t).map((e=>t[e]))) : a = e.map((e=>t[e]));
                const i = n.filter(((e,t)=>r[t]));
                return a.concat(i)
            }
            return []
        }
        makeTensor(e, t, n, s) {
            if (null == e)
                throw new Error("Values passed to engine.makeTensor() are null");
            n = n || "float32",
            s = s || this.backend;
            let r = e;
            "string" === n && P(e[0]) && (r = e.map((e=>Or(e))));
            const a = s.write(r, t, n)
              , i = new Zr(t,n,a,this.nextTensorId());
            if (this.trackTensor(i, s),
            "string" === n) {
                const e = this.state.tensorInfo.get(a)
                  , t = B(r);
                this.state.numBytes += t - e.bytes,
                e.bytes = t
            }
            return i
        }
        makeTensorFromDataId(e, t, n, s) {
            const r = {
                dataId: e,
                shape: t,
                dtype: n = n || "float32"
            };
            return this.makeTensorFromTensorInfo(r, s)
        }
        makeTensorFromTensorInfo(e, t) {
            const {dataId: n, shape: s, dtype: r} = e
              , a = new Zr(s,r,n,this.nextTensorId());
            return this.trackTensor(a, t),
            a
        }
        makeVariable(e, t=!0, n, s) {
            n = n || this.nextVariableId().toString(),
            null != s && s !== e.dtype && (e = e.cast(s));
            const r = new Qr(e,t,n,this.nextTensorId());
            if (null != this.state.registeredVariables[r.name])
                throw new Error(`Variable with name ${r.name} was already registered`);
            return this.state.registeredVariables[r.name] = r,
            this.incRef(r, this.backend),
            r
        }
        trackTensor(e, t) {
            this.state.numTensors++,
            "string" === e.dtype && this.state.numStringTensors++;
            let n = 0;
            "complex64" !== e.dtype && "string" !== e.dtype && (n = e.size * z(e.dtype)),
            this.state.numBytes += n,
            this.state.tensorInfo.has(e.dataId) || (this.state.numDataBuffers++,
            this.state.tensorInfo.set(e.dataId, {
                backend: t || this.backend,
                dtype: e.dtype,
                shape: e.shape,
                bytes: n
            })),
            e instanceof Qr || this.track(e)
        }
        incRef(e, t) {
            this.trackTensor(e, t),
            this.backend.incRef(e.dataId)
        }
        removeDataId(e, t) {
            this.state.tensorInfo.has(e) && this.state.tensorInfo.get(e).backend === t && (this.state.tensorInfo.delete(e),
            this.state.numDataBuffers--)
        }
        disposeTensor(e) {
            if (!this.state.tensorInfo.has(e.dataId))
                return;
            const t = this.state.tensorInfo.get(e.dataId);
            if (this.state.numTensors--,
            "string" === e.dtype && (this.state.numStringTensors--,
            this.state.numBytes -= t.bytes),
            "complex64" !== e.dtype && "string" !== e.dtype) {
                const t = e.size * z(e.dtype);
                this.state.numBytes -= t
            }
            t.backend.disposeData(e.dataId) && this.removeDataId(e.dataId, t.backend)
        }
        disposeVariables() {
            for (const e in this.state.registeredVariables) {
                const t = this.state.registeredVariables[e];
                this.disposeVariable(t)
            }
        }
        disposeVariable(e) {
            this.disposeTensor(e),
            null != this.state.registeredVariables[e.name] && delete this.state.registeredVariables[e.name]
        }
        memory() {
            const e = this.backend.memory();
            return e.numTensors = this.state.numTensors,
            e.numDataBuffers = this.state.numDataBuffers,
            e.numBytes = this.state.numBytes,
            this.state.numStringTensors > 0 && (e.unreliable = !0,
            null == e.reasons && (e.reasons = []),
            e.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)")),
            e
        }
        async profile(e) {
            this.state.profiling = !0;
            const t = this.state.numBytes
              , n = this.state.numTensors;
            this.state.activeProfile.kernels = [],
            this.state.activeProfile.result = await e(),
            this.state.profiling = !1,
            this.state.activeProfile.peakBytes = Math.max(...this.state.activeProfile.kernels.map((e=>e.totalBytesSnapshot))),
            this.state.activeProfile.newBytes = this.state.numBytes - t,
            this.state.activeProfile.newTensors = this.state.numTensors - n;
            for (const e of this.state.activeProfile.kernels)
                e.kernelTimeMs = await e.kernelTimeMs,
                e.extraInfo = await e.extraInfo;
            return this.state.activeProfile
        }
        isTapeOn() {
            return this.state.gradientDepth > 0 && 0 === this.state.kernelDepth
        }
        addTapeNode(e, t, n, s, r, a) {
            const i = {
                id: this.state.nextTapeNodeId++,
                kernelName: e,
                inputs: t,
                outputs: n,
                saved: r
            }
              , o = Ps(e);
            null != o && (s = o.gradFunc),
            null != s && (i.gradient = e=>(e = e.map(((e,t)=>{
                if (null == e) {
                    const e = n[t]
                      , s = Z(e.size, e.dtype);
                    return this.makeTensor(s, e.shape, e.dtype)
                }
                return e
            }
            )),
            s(e.length > 1 ? e : e[0], r, a))),
            this.state.activeTape.push(i)
        }
        keep(e) {
            return e.kept = !0,
            e
        }
        startTape() {
            0 === this.state.gradientDepth && (this.state.activeTape = []),
            this.state.gradientDepth++
        }
        endTape() {
            this.state.gradientDepth--
        }
        startScope(e) {
            const t = {
                track: [],
                name: "unnamed scope",
                id: this.state.nextScopeId++
            };
            e && (t.name = e),
            this.state.scopeStack.push(t),
            this.state.activeScope = t
        }
        endScope(e) {
            const t = ga(e)
              , n = new Set(t.map((e=>e.id)));
            for (let e = 0; e < this.state.activeScope.track.length; e++) {
                const t = this.state.activeScope.track[e];
                t.kept || n.has(t.id) || t.dispose()
            }
            const s = this.state.scopeStack.pop();
            this.state.activeScope = 0 === this.state.scopeStack.length ? null : this.state.scopeStack[this.state.scopeStack.length - 1],
            t.forEach((e=>{
                e.kept || e.scopeId !== s.id || this.track(e)
            }
            ))
        }
        gradients(e, t, n, s=!1) {
            if (b(t.length > 0, (()=>"gradients() received an empty list of xs.")),
            null != n && "float32" !== n.dtype)
                throw new Error(`dy must have 'float32' dtype, but has '${n.dtype}'`);
            const r = this.scopedRun((()=>this.startTape()), (()=>this.endTape()), (()=>this.tidy("forward", e)));
            b(r instanceof Zr, (()=>"The result y returned by f() must be a tensor."));
            const a = function(e, t, n) {
                const s = {}
                  , r = {};
                for (let e = 0; e < t.length; e++)
                    s[t[e].id] = !0;
                for (let n = 0; n < e.length; n++) {
                    const a = e[n]
                      , i = a.inputs;
                    for (const e in i) {
                        const n = i[e];
                        let o = !1;
                        for (let e = 0; e < t.length; e++)
                            if (s[n.id]) {
                                a.outputs.forEach((e=>s[e.id] = !0)),
                                o = !0,
                                r[a.id] = !0;
                                break
                            }
                        if (o)
                            break
                    }
                }
                const a = {};
                a[n.id] = !0;
                const i = {};
                for (let t = e.length - 1; t >= 0; t--) {
                    const n = e[t]
                      , s = n.inputs;
                    for (let e = 0; e < n.outputs.length; e++)
                        if (a[n.outputs[e].id]) {
                            for (const e in s)
                                a[s[e].id] = !0,
                                i[n.id] = !0;
                            break
                        }
                }
                const o = [];
                for (let t = 0; t < e.length; t++) {
                    const n = e[t];
                    if (r[n.id] && i[n.id]) {
                        const e = {};
                        for (const t in n.inputs) {
                            const r = n.inputs[t];
                            s[r.id] && (e[t] = r)
                        }
                        const t = Object.assign({}, n);
                        t.inputs = e,
                        t.outputs = n.outputs,
                        o.push(t)
                    }
                }
                return o
            }(this.state.activeTape, t, r);
            if (!s && 0 === a.length && t.length > 0)
                throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");
            return this.tidy("backward", (()=>{
                const e = {};
                e[r.id] = null == n ? function(e) {
                    const t = Y(v(e), "float32");
                    return ka.makeTensor(t, e, "float32")
                }(r.shape) : n,
                function(e, t, n, s) {
                    for (let r = t.length - 1; r >= 0; r--) {
                        const a = t[r]
                          , i = [];
                        if (a.outputs.forEach((t=>{
                            const n = e[t.id];
                            null != n ? i.push(n) : i.push(null)
                        }
                        )),
                        null == a.gradient)
                            throw new Error(`Cannot compute gradient: gradient function not found for ${a.kernelName}.`);
                        const o = a.gradient(i);
                        for (const t in a.inputs) {
                            if (!(t in o))
                                throw new Error(`Cannot backprop through input ${t}. Available gradients found: ${Object.keys(o)}.`);
                            const r = n((()=>o[t]()));
                            if ("float32" !== r.dtype)
                                throw new Error(`Error in gradient for op ${a.kernelName}. The gradient of input ${t} must have 'float32' dtype, but has '${r.dtype}'`);
                            const i = a.inputs[t];
                            if (!I(r.shape, i.shape))
                                throw new Error(`Error in gradient for op ${a.kernelName}. The gradient of input '${t}' has shape '${r.shape}', which does not match the shape of the input '${i.shape}'`);
                            if (null == e[i.id])
                                e[i.id] = r;
                            else {
                                const t = e[i.id];
                                e[i.id] = s(t, r),
                                t.dispose()
                            }
                        }
                    }
                }(e, a, (e=>this.tidy(e)), Ia);
                const s = t.map((t=>e[t.id]));
                return 0 === this.state.gradientDepth && (this.state.activeTape.forEach((e=>{
                    for (const t of e.saved)
                        t.dispose()
                }
                )),
                this.state.activeTape = null),
                {
                    value: r,
                    grads: s
                }
            }
            ))
        }
        customGrad(e) {
            return b(G(e), (()=>"The f passed in customGrad(f) must be a function.")),
            (...t)=>{
                let n;
                b(t.every((e=>e instanceof Zr)), (()=>"The args passed in customGrad(f)(x1, x2,...) must all be tensors"));
                const s = {};
                t.forEach(((e,t)=>{
                    s[t] = e
                }
                ));
                return this.runKernelFunc({
                    forwardFunc: (s,r)=>(n = e(...t, r),
                    b(n.value instanceof Zr, (()=>"The function f passed in customGrad(f) must return an object where `obj.value` is a tensor")),
                    b(G(n.gradFunc), (()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function.")),
                    n.value),
                    backwardsFunc: (e,s)=>{
                        const r = n.gradFunc(e, s)
                          , a = Array.isArray(r) ? r : [r];
                        b(a.length === t.length, (()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...).")),
                        b(a.every((e=>e instanceof Zr)), (()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors."));
                        const i = {};
                        return a.forEach(((e,t)=>{
                            i[t] = ()=>e
                        }
                        )),
                        i
                    }
                    ,
                    inputs: s
                })
            }
        }
        readSync(e) {
            return this.state.tensorInfo.get(e).backend.readSync(e)
        }
        read(e) {
            return this.state.tensorInfo.get(e).backend.read(e)
        }
        readToGPU(e, t) {
            return this.state.tensorInfo.get(e).backend.readToGPU(e, t)
        }
        async time(e) {
            const t = Dr()
              , n = await this.backend.time(e);
            return n.wallMs = Dr() - t,
            n
        }
        track(e) {
            return null != this.state.activeScope && (e.scopeId = this.state.activeScope.id,
            this.state.activeScope.track.push(e)),
            e
        }
        get registeredVariables() {
            return this.state.registeredVariables
        }
        reset() {
            this.pendingBackendInitId++,
            this.state.dispose(),
            this.ENV.reset(),
            this.state = new xa;
            for (const e in this.registry)
                this.disposeRegisteredKernels(e),
                this.registry[e].dispose(),
                delete this.registry[e];
            this.backendName = null,
            this.backendInstance = null,
            this.pendingBackendInit = null
        }
    }
    function va() {
        const e = Se();
        if (null == e._tfengine) {
            const t = new re(e);
            e._tfengine = new wa(t)
        }
        var t;
        return t = e._tfengine.ENV,
        oe = t,
        Kr = ()=>e._tfengine,
        e._tfengine
    }
    wa.nextTensorId = 0,
    wa.nextVariableId = 0;
    const ka = va();
    function Ia(e, t) {
        const n = {
            a: e,
            b: t
        };
        return ka.runKernel(Ee, n)
    }
    var Sa = {};
    let Na;
    function Ta(e) {
        Na = e
    }
    function Ca(e) {
        if (void 0 !== Na)
            return Na;
        if (e || "undefined" != typeof navigator && null != navigator) {
            if (e || (e = navigator),
            "ReactNative" === e.product)
                return !0;
            const t = e.userAgent || e.vendor || ("undefined" != typeof window ? window.opera : "");
            if (!t) {
                const t = e;
                return t.userAgentData && t.userAgentData.mobile
            }
            return /(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(t) || /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(t.substr(0, 4))
        }
        return !1
    }
    function $a() {
        return "undefined" != typeof window && null != window.document || "undefined" != typeof WorkerGlobalScope
    }
    t(Sa, "mockIsMobile", (()=>Ta)),
    t(Sa, "isMobile", (()=>Ca)),
    t(Sa, "isBrowser", (()=>$a));
    const Ea = ie();
    function Aa(e, t) {
        let n = e;
        if (Lr(e))
            return "string" === t ? [] : [e.length];
        if ("object" == typeof e) {
            if ("texture"in e) {
                const t = e.channels || "RGBA";
                return [e.height, e.width * t.length]
            }
            if ("buffer"in e && !(e.buffer instanceof ArrayBuffer))
                return [e.buffer.size / (null == t ? 4 : z(t))]
        }
        if (!Array.isArray(e))
            return [];
        const s = [];
        for (; Array.isArray(n) || Lr(n) && "string" !== t; )
            s.push(n.length),
            n = n[0];
        return Array.isArray(e) && ie().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY") && Ra(e, s, []),
        s
    }
    function Ra(e, t, n) {
        if (n = n || [],
        !Array.isArray(e) && !Lr(e))
            return void b(0 === t.length, (()=>`Element arr[${n.join("][")}] is a primitive, but should be an array/TypedArray of ${t[0]} elements`));
        b(t.length > 0, (()=>`Element arr[${n.join("][")}] should be a primitive, but is an array of ${e.length} elements`)),
        b(e.length === t[0], (()=>`Element arr[${n.join("][")}] should have ${t[0]} elements, but has ${e.length} elements`));
        const s = t.slice(1);
        for (let t = 0; t < e.length; ++t)
            Ra(e[t], s, n.concat(t))
    }
    function Fa(e, t, n, s) {
        if ("string_or_numeric" !== e) {
            if (null == e)
                throw new Error("Expected dtype cannot be null.");
            if ("numeric" !== e && e !== t || "numeric" === e && "string" === t)
                throw new Error(`Argument '${n}' passed to '${s}' must be ${e} tensor, but got ${t} tensor`)
        }
    }
    function Da(e, t, n, s="numeric") {
        if (e instanceof Zr)
            return Fa(s, e.dtype, t, n),
            e;
        let r = V(e);
        if ("string" !== r && ["bool", "int32", "float32"].indexOf(s) >= 0 && (r = s),
        Fa(s, r, t, n),
        null == e || !Lr(e) && !Array.isArray(e) && "number" != typeof e && "boolean" != typeof e && "string" != typeof e) {
            const s = null == e ? "null" : e.constructor.name;
            throw new Error(`Argument '${t}' passed to '${n}' must be a Tensor or TensorLike, but got '${s}'`)
        }
        const a = Aa(e, r);
        Lr(e) || Array.isArray(e) || (e = [e]);
        const i = "string" !== r ? Fr(e, r) : zr(e, [], !0);
        return ka.makeTensor(i, a, r)
    }
    function _a(e, t, n, s="numeric") {
        if (!Array.isArray(e))
            throw new Error(`Argument ${t} passed to ${n} must be a \`Tensor[]\` or \`TensorLike[]\``);
        return e.map(((e,r)=>Da(e, `${t}[${r}]`, n, s)))
    }
    Ea.registerFlag("DEBUG", (()=>!1), (e=>{
        e && console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.")
    }
    )),
    Ea.registerFlag("IS_BROWSER", (()=>$a())),
    Ea.registerFlag("IS_NODE", (()=>void 0 !== ce && void 0 !== ce.versions && void 0 !== ce.versions.node)),
    Ea.registerFlag("IS_CHROME", (()=>"undefined" != typeof navigator && null != navigator && null != navigator.userAgent && /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor))),
    Ea.registerFlag("PROD", (()=>!1)),
    Ea.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY", (()=>Ea.getBool("DEBUG"))),
    Ea.registerFlag("DEPRECATION_WARNINGS_ENABLED", (()=>!0)),
    Ea.registerFlag("IS_TEST", (()=>!1)),
    Ea.registerFlag("CHECK_COMPUTATION_FOR_ERRORS", (()=>!0)),
    Ea.registerFlag("WRAP_TO_IMAGEBITMAP", (()=>!1)),
    Ea.registerFlag("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU", (()=>!1)),
    Ea.registerFlag("USE_SETTIMEOUTCUSTOM", (()=>!1));
    const Oa = "__op";
    function Ma(e) {
        const t = Object.keys(e);
        if (1 !== t.length)
            throw new Error(`Please provide an object with a single key (operation name) mapping to a function. Got an object with ${t.length} keys.`);
        let n = t[0];
        const s = e[n];
        n.endsWith("_") && (n = n.substring(0, n.length - 1)),
        n += Oa;
        const r = (...e)=>{
            ka.startScope(n);
            try {
                const t = s(...e);
                return ne(t) && console.error("Cannot return a Promise inside of tidy."),
                ka.endScope(t),
                t
            } catch (e) {
                throw ka.endScope(null),
                e
            }
        }
        ;
        return Object.defineProperty(r, "name", {
            value: n,
            configurable: !0
        }),
        r
    }
    const La = Ma({
        complex_: function(e, t) {
            const n = Da(e, "real", "complex")
              , s = Da(t, "imag", "complex");
            x(n.shape, s.shape, `real and imag shapes, ${n.shape} and ${s.shape}, must match in call to tf.complex().`);
            const r = {
                real: n,
                imag: s
            };
            return ka.runKernel(Ze, r)
        }
    });
    function za(e, t, n, s) {
        if (null == s)
            s = V(e);
        else if ("complex64" === s)
            throw new Error("Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).");
        if ("object" == typeof e && ("texture"in e || "buffer"in e && !(e.buffer instanceof ArrayBuffer))) {
            if ("float32" !== s && "int32" !== s)
                throw new Error(`Creating tensor from GPU data only supports 'float32'|'int32' dtype, while the dtype is ${s}.`);
            return ka.backend.createTensorFromGPUData(e, t || n, s)
        }
        if (!Lr(e) && !Array.isArray(e) && "number" != typeof e && "boolean" != typeof e && "string" != typeof e)
            throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");
        if (null != t) {
            Q(t);
            const e = v(t)
              , s = v(n);
            b(e === s, (()=>`Based on the provided shape, [${t}], the tensor should have ${e} values but has ${s}`));
            for (let e = 0; e < n.length; ++e) {
                const s = n[e]
                  , r = e !== n.length - 1 || s !== v(t.slice(e));
                b(n[e] === t[e] || !r, (()=>`Error creating a new Tensor. Inferred shape (${n}) does not match the provided shape (${t}). `))
            }
        }
        return Lr(e) || Array.isArray(e) || (e = [e]),
        t = t || n,
        e = "string" !== s ? Fr(e, s) : zr(e, [], !0),
        ka.makeTensor(e, t, s)
    }
    function Ba(e, t, n) {
        return za(e, t, Aa(e, n), n)
    }
    const Pa = {
        float32: 4,
        float16: 2,
        int32: 4,
        uint16: 2,
        uint8: 1,
        bool: 1,
        complex64: 8
    };
    var Wa, Ua, Va;
    Ua = function(e) {
        var t, n, s = Ja(e), r = s[0], a = s[1], i = new Ka(function(e, t, n) {
            return 3 * (t + n) / 4 - n
        }(0, r, a)), o = 0, l = a > 0 ? r - 4 : r;
        for (n = 0; n < l; n += 4)
            t = qa[e.charCodeAt(n)] << 18 | qa[e.charCodeAt(n + 1)] << 12 | qa[e.charCodeAt(n + 2)] << 6 | qa[e.charCodeAt(n + 3)],
            i[o++] = t >> 16 & 255,
            i[o++] = t >> 8 & 255,
            i[o++] = 255 & t;
        2 === a && (t = qa[e.charCodeAt(n)] << 2 | qa[e.charCodeAt(n + 1)] >> 4,
        i[o++] = 255 & t);
        1 === a && (t = qa[e.charCodeAt(n)] << 10 | qa[e.charCodeAt(n + 1)] << 4 | qa[e.charCodeAt(n + 2)] >> 2,
        i[o++] = t >> 8 & 255,
        i[o++] = 255 & t);
        return i
    }
    ,
    Va = function(e) {
        for (var t, n = e.length, s = n % 3, r = [], a = 16383, i = 0, o = n - s; i < o; i += a)
            r.push(Qa(e, i, i + a > o ? o : i + a));
        1 === s ? (t = e[n - 1],
        r.push(ja[t >> 2] + ja[t << 4 & 63] + "==")) : 2 === s && (t = (e[n - 2] << 8) + e[n - 1],
        r.push(ja[t >> 10] + ja[t >> 4 & 63] + ja[t << 2 & 63] + "="));
        return r.join("")
    }
    /*! ieee754. BSD-3-Clause License. Feross Aboukhadijeh <https://feross.org/opensource> */
    ;
    for (var Ga, Ha, ja = [], qa = [], Ka = "undefined" != typeof Uint8Array ? Uint8Array : Array, Xa = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/", Ya = 0, Za = Xa.length; Ya < Za; ++Ya)
        ja[Ya] = Xa[Ya],
        qa[Xa.charCodeAt(Ya)] = Ya;
    function Ja(e) {
        var t = e.length;
        if (t % 4 > 0)
            throw new Error("Invalid string. Length must be a multiple of 4");
        var n = e.indexOf("=");
        return -1 === n && (n = t),
        [n, n === t ? 0 : 4 - n % 4]
    }
    function Qa(e, t, n) {
        for (var s, r, a = [], i = t; i < n; i += 3)
            s = (e[i] << 16 & 16711680) + (e[i + 1] << 8 & 65280) + (255 & e[i + 2]),
            a.push(ja[(r = s) >> 18 & 63] + ja[r >> 12 & 63] + ja[r >> 6 & 63] + ja[63 & r]);
        return a.join("")
    }
    qa["-".charCodeAt(0)] = 62,
    qa["_".charCodeAt(0)] = 63,
    Ga = function(e, t, n, s, r) {
        var a, i, o = 8 * r - s - 1, l = (1 << o) - 1, u = l >> 1, c = -7, h = n ? r - 1 : 0, p = n ? -1 : 1, d = e[t + h];
        for (h += p,
        a = d & (1 << -c) - 1,
        d >>= -c,
        c += o; c > 0; a = 256 * a + e[t + h],
        h += p,
        c -= 8)
            ;
        for (i = a & (1 << -c) - 1,
        a >>= -c,
        c += s; c > 0; i = 256 * i + e[t + h],
        h += p,
        c -= 8)
            ;
        if (0 === a)
            a = 1 - u;
        else {
            if (a === l)
                return i ? NaN : 1 / 0 * (d ? -1 : 1);
            i += Math.pow(2, s),
            a -= u
        }
        return (d ? -1 : 1) * i * Math.pow(2, a - s)
    }
    ,
    Ha = function(e, t, n, s, r, a) {
        var i, o, l, u = 8 * a - r - 1, c = (1 << u) - 1, h = c >> 1, p = 23 === r ? Math.pow(2, -24) - Math.pow(2, -77) : 0, d = s ? 0 : a - 1, f = s ? 1 : -1, m = t < 0 || 0 === t && 1 / t < 0 ? 1 : 0;
        for (t = Math.abs(t),
        isNaN(t) || t === 1 / 0 ? (o = isNaN(t) ? 1 : 0,
        i = c) : (i = Math.floor(Math.log(t) / Math.LN2),
        t * (l = Math.pow(2, -i)) < 1 && (i--,
        l *= 2),
        (t += i + h >= 1 ? p / l : p * Math.pow(2, 1 - h)) * l >= 2 && (i++,
        l /= 2),
        i + h >= c ? (o = 0,
        i = c) : i + h >= 1 ? (o = (t * l - 1) * Math.pow(2, r),
        i += h) : (o = t * Math.pow(2, h - 1) * Math.pow(2, r),
        i = 0)); r >= 8; e[n + d] = 255 & o,
        d += f,
        o /= 256,
        r -= 8)
            ;
        for (i = i << r | o,
        u += r; u > 0; e[n + d] = 255 & i,
        d += f,
        i /= 256,
        u -= 8)
            ;
        e[n + d - f] |= 128 * m
    }
    ;
    const ei = "function" == typeof Symbol && "function" == typeof Symbol.for ? Symbol.for("nodejs.util.inspect.custom") : null;
    Wa = si;
    const ti = 2147483647;
    function ni(e) {
        if (e > ti)
            throw new RangeError('The value "' + e + '" is invalid for option "size"');
        const t = new Uint8Array(e);
        return Object.setPrototypeOf(t, si.prototype),
        t
    }
    function si(e, t, n) {
        if ("number" == typeof e) {
            if ("string" == typeof t)
                throw new TypeError('The "string" argument must be of type string. Received type number');
            return ii(e)
        }
        return ri(e, t, n)
    }
    function ri(e, t, n) {
        if ("string" == typeof e)
            return function(e, t) {
                "string" == typeof t && "" !== t || (t = "utf8");
                if (!si.isEncoding(t))
                    throw new TypeError("Unknown encoding: " + t);
                const n = 0 | ci(e, t);
                let s = ni(n);
                const r = s.write(e, t);
                r !== n && (s = s.slice(0, r));
                return s
            }(e, t);
        if (ArrayBuffer.isView(e))
            return function(e) {
                if (Gi(e, Uint8Array)) {
                    const t = new Uint8Array(e);
                    return li(t.buffer, t.byteOffset, t.byteLength)
                }
                return oi(e)
            }(e);
        if (null == e)
            throw new TypeError("The first argument must be one of type string, Buffer, ArrayBuffer, Array, or Array-like Object. Received type " + typeof e);
        if (Gi(e, ArrayBuffer) || e && Gi(e.buffer, ArrayBuffer))
            return li(e, t, n);
        if ("undefined" != typeof SharedArrayBuffer && (Gi(e, SharedArrayBuffer) || e && Gi(e.buffer, SharedArrayBuffer)))
            return li(e, t, n);
        if ("number" == typeof e)
            throw new TypeError('The "value" argument must not be of type number. Received type number');
        const s = e.valueOf && e.valueOf();
        if (null != s && s !== e)
            return si.from(s, t, n);
        const r = function(e) {
            if (si.isBuffer(e)) {
                const t = 0 | ui(e.length)
                  , n = ni(t);
                return 0 === n.length || e.copy(n, 0, 0, t),
                n
            }
            if (void 0 !== e.length)
                return "number" != typeof e.length || Hi(e.length) ? ni(0) : oi(e);
            if ("Buffer" === e.type && Array.isArray(e.data))
                return oi(e.data)
        }(e);
        if (r)
            return r;
        if ("undefined" != typeof Symbol && null != Symbol.toPrimitive && "function" == typeof e[Symbol.toPrimitive])
            return si.from(e[Symbol.toPrimitive]("string"), t, n);
        throw new TypeError("The first argument must be one of type string, Buffer, ArrayBuffer, Array, or Array-like Object. Received type " + typeof e)
    }
    function ai(e) {
        if ("number" != typeof e)
            throw new TypeError('"size" argument must be of type number');
        if (e < 0)
            throw new RangeError('The value "' + e + '" is invalid for option "size"')
    }
    function ii(e) {
        return ai(e),
        ni(e < 0 ? 0 : 0 | ui(e))
    }
    function oi(e) {
        const t = e.length < 0 ? 0 : 0 | ui(e.length)
          , n = ni(t);
        for (let s = 0; s < t; s += 1)
            n[s] = 255 & e[s];
        return n
    }
    function li(e, t, n) {
        if (t < 0 || e.byteLength < t)
            throw new RangeError('"offset" is outside of buffer bounds');
        if (e.byteLength < t + (n || 0))
            throw new RangeError('"length" is outside of buffer bounds');
        let s;
        return s = void 0 === t && void 0 === n ? new Uint8Array(e) : void 0 === n ? new Uint8Array(e,t) : new Uint8Array(e,t,n),
        Object.setPrototypeOf(s, si.prototype),
        s
    }
    function ui(e) {
        if (e >= ti)
            throw new RangeError("Attempt to allocate Buffer larger than maximum size: 0x" + ti.toString(16) + " bytes");
        return 0 | e
    }
    function ci(e, t) {
        if (si.isBuffer(e))
            return e.length;
        if (ArrayBuffer.isView(e) || Gi(e, ArrayBuffer))
            return e.byteLength;
        if ("string" != typeof e)
            throw new TypeError('The "string" argument must be one of type string, Buffer, or ArrayBuffer. Received type ' + typeof e);
        const n = e.length
          , s = arguments.length > 2 && !0 === arguments[2];
        if (!s && 0 === n)
            return 0;
        let r = !1;
        for (; ; )
            switch (t) {
            case "ascii":
            case "latin1":
            case "binary":
                return n;
            case "utf8":
            case "utf-8":
                return Wi(e).length;
            case "ucs2":
            case "ucs-2":
            case "utf16le":
            case "utf-16le":
                return 2 * n;
            case "hex":
                return n >>> 1;
            case "base64":
                return Ui(e).length;
            default:
                if (r)
                    return s ? -1 : Wi(e).length;
                t = ("" + t).toLowerCase(),
                r = !0
            }
    }
    function hi(e, t, n) {
        let s = !1;
        if ((void 0 === t || t < 0) && (t = 0),
        t > this.length)
            return "";
        if ((void 0 === n || n > this.length) && (n = this.length),
        n <= 0)
            return "";
        if ((n >>>= 0) <= (t >>>= 0))
            return "";
        for (e || (e = "utf8"); ; )
            switch (e) {
            case "hex":
                return Ni(this, t, n);
            case "utf8":
            case "utf-8":
                return vi(this, t, n);
            case "ascii":
                return Ii(this, t, n);
            case "latin1":
            case "binary":
                return Si(this, t, n);
            case "base64":
                return wi(this, t, n);
            case "ucs2":
            case "ucs-2":
            case "utf16le":
            case "utf-16le":
                return Ti(this, t, n);
            default:
                if (s)
                    throw new TypeError("Unknown encoding: " + e);
                e = (e + "").toLowerCase(),
                s = !0
            }
    }
    function pi(e, t, n) {
        const s = e[t];
        e[t] = e[n],
        e[n] = s
    }
    function di(e, t, n, s, r) {
        if (0 === e.length)
            return -1;
        if ("string" == typeof n ? (s = n,
        n = 0) : n > 2147483647 ? n = 2147483647 : n < -2147483648 && (n = -2147483648),
        Hi(n = +n) && (n = r ? 0 : e.length - 1),
        n < 0 && (n = e.length + n),
        n >= e.length) {
            if (r)
                return -1;
            n = e.length - 1
        } else if (n < 0) {
            if (!r)
                return -1;
            n = 0
        }
        if ("string" == typeof t && (t = si.from(t, s)),
        si.isBuffer(t))
            return 0 === t.length ? -1 : fi(e, t, n, s, r);
        if ("number" == typeof t)
            return t &= 255,
            "function" == typeof Uint8Array.prototype.indexOf ? r ? Uint8Array.prototype.indexOf.call(e, t, n) : Uint8Array.prototype.lastIndexOf.call(e, t, n) : fi(e, [t], n, s, r);
        throw new TypeError("val must be string, number or Buffer")
    }
    function fi(e, t, n, s, r) {
        let a, i = 1, o = e.length, l = t.length;
        if (void 0 !== s && ("ucs2" === (s = String(s).toLowerCase()) || "ucs-2" === s || "utf16le" === s || "utf-16le" === s)) {
            if (e.length < 2 || t.length < 2)
                return -1;
            i = 2,
            o /= 2,
            l /= 2,
            n /= 2
        }
        function u(e, t) {
            return 1 === i ? e[t] : e.readUInt16BE(t * i)
        }
        if (r) {
            let s = -1;
            for (a = n; a < o; a++)
                if (u(e, a) === u(t, -1 === s ? 0 : a - s)) {
                    if (-1 === s && (s = a),
                    a - s + 1 === l)
                        return s * i
                } else
                    -1 !== s && (a -= a - s),
                    s = -1
        } else
            for (n + l > o && (n = o - l),
            a = n; a >= 0; a--) {
                let n = !0;
                for (let s = 0; s < l; s++)
                    if (u(e, a + s) !== u(t, s)) {
                        n = !1;
                        break
                    }
                if (n)
                    return a
            }
        return -1
    }
    function mi(e, t, n, s) {
        n = Number(n) || 0;
        const r = e.length - n;
        s ? (s = Number(s)) > r && (s = r) : s = r;
        const a = t.length;
        let i;
        for (s > a / 2 && (s = a / 2),
        i = 0; i < s; ++i) {
            const s = parseInt(t.substr(2 * i, 2), 16);
            if (Hi(s))
                return i;
            e[n + i] = s
        }
        return i
    }
    function gi(e, t, n, s) {
        return Vi(Wi(t, e.length - n), e, n, s)
    }
    function yi(e, t, n, s) {
        return Vi(function(e) {
            const t = [];
            for (let n = 0; n < e.length; ++n)
                t.push(255 & e.charCodeAt(n));
            return t
        }(t), e, n, s)
    }
    function bi(e, t, n, s) {
        return Vi(Ui(t), e, n, s)
    }
    function xi(e, t, n, s) {
        return Vi(function(e, t) {
            let n, s, r;
            const a = [];
            for (let i = 0; i < e.length && !((t -= 2) < 0); ++i)
                n = e.charCodeAt(i),
                s = n >> 8,
                r = n % 256,
                a.push(r),
                a.push(s);
            return a
        }(t, e.length - n), e, n, s)
    }
    function wi(e, t, n) {
        return 0 === t && n === e.length ? Va(e) : Va(e.slice(t, n))
    }
    function vi(e, t, n) {
        n = Math.min(e.length, n);
        const s = [];
        let r = t;
        for (; r < n; ) {
            const t = e[r];
            let a = null
              , i = t > 239 ? 4 : t > 223 ? 3 : t > 191 ? 2 : 1;
            if (r + i <= n) {
                let n, s, o, l;
                switch (i) {
                case 1:
                    t < 128 && (a = t);
                    break;
                case 2:
                    n = e[r + 1],
                    128 == (192 & n) && (l = (31 & t) << 6 | 63 & n,
                    l > 127 && (a = l));
                    break;
                case 3:
                    n = e[r + 1],
                    s = e[r + 2],
                    128 == (192 & n) && 128 == (192 & s) && (l = (15 & t) << 12 | (63 & n) << 6 | 63 & s,
                    l > 2047 && (l < 55296 || l > 57343) && (a = l));
                    break;
                case 4:
                    n = e[r + 1],
                    s = e[r + 2],
                    o = e[r + 3],
                    128 == (192 & n) && 128 == (192 & s) && 128 == (192 & o) && (l = (15 & t) << 18 | (63 & n) << 12 | (63 & s) << 6 | 63 & o,
                    l > 65535 && l < 1114112 && (a = l))
                }
            }
            null === a ? (a = 65533,
            i = 1) : a > 65535 && (a -= 65536,
            s.push(a >>> 10 & 1023 | 55296),
            a = 56320 | 1023 & a),
            s.push(a),
            r += i
        }
        return function(e) {
            const t = e.length;
            if (t <= ki)
                return String.fromCharCode.apply(String, e);
            let n = ""
              , s = 0;
            for (; s < t; )
                n += String.fromCharCode.apply(String, e.slice(s, s += ki));
            return n
        }(s)
    }
    si.TYPED_ARRAY_SUPPORT = function() {
        try {
            const e = new Uint8Array(1)
              , t = {
                foo: function() {
                    return 42
                }
            };
            return Object.setPrototypeOf(t, Uint8Array.prototype),
            Object.setPrototypeOf(e, t),
            42 === e.foo()
        } catch (e) {
            return !1
        }
    }(),
    si.TYPED_ARRAY_SUPPORT || "undefined" == typeof console || "function" != typeof console.error || console.error("This browser lacks typed array (Uint8Array) support which is required by `buffer` v5.x. Use `buffer` v4.x if you require old browser support."),
    Object.defineProperty(si.prototype, "parent", {
        enumerable: !0,
        get: function() {
            if (si.isBuffer(this))
                return this.buffer
        }
    }),
    Object.defineProperty(si.prototype, "offset", {
        enumerable: !0,
        get: function() {
            if (si.isBuffer(this))
                return this.byteOffset
        }
    }),
    si.poolSize = 8192,
    si.from = function(e, t, n) {
        return ri(e, t, n)
    }
    ,
    Object.setPrototypeOf(si.prototype, Uint8Array.prototype),
    Object.setPrototypeOf(si, Uint8Array),
    si.alloc = function(e, t, n) {
        return function(e, t, n) {
            return ai(e),
            e <= 0 ? ni(e) : void 0 !== t ? "string" == typeof n ? ni(e).fill(t, n) : ni(e).fill(t) : ni(e)
        }(e, t, n)
    }
    ,
    si.allocUnsafe = function(e) {
        return ii(e)
    }
    ,
    si.allocUnsafeSlow = function(e) {
        return ii(e)
    }
    ,
    si.isBuffer = function(e) {
        return null != e && !0 === e._isBuffer && e !== si.prototype
    }
    ,
    si.compare = function(e, t) {
        if (Gi(e, Uint8Array) && (e = si.from(e, e.offset, e.byteLength)),
        Gi(t, Uint8Array) && (t = si.from(t, t.offset, t.byteLength)),
        !si.isBuffer(e) || !si.isBuffer(t))
            throw new TypeError('The "buf1", "buf2" arguments must be one of type Buffer or Uint8Array');
        if (e === t)
            return 0;
        let n = e.length
          , s = t.length;
        for (let r = 0, a = Math.min(n, s); r < a; ++r)
            if (e[r] !== t[r]) {
                n = e[r],
                s = t[r];
                break
            }
        return n < s ? -1 : s < n ? 1 : 0
    }
    ,
    si.isEncoding = function(e) {
        switch (String(e).toLowerCase()) {
        case "hex":
        case "utf8":
        case "utf-8":
        case "ascii":
        case "latin1":
        case "binary":
        case "base64":
        case "ucs2":
        case "ucs-2":
        case "utf16le":
        case "utf-16le":
            return !0;
        default:
            return !1
        }
    }
    ,
    si.concat = function(e, t) {
        if (!Array.isArray(e))
            throw new TypeError('"list" argument must be an Array of Buffers');
        if (0 === e.length)
            return si.alloc(0);
        let n;
        if (void 0 === t)
            for (t = 0,
            n = 0; n < e.length; ++n)
                t += e[n].length;
        const s = si.allocUnsafe(t);
        let r = 0;
        for (n = 0; n < e.length; ++n) {
            let t = e[n];
            if (Gi(t, Uint8Array))
                r + t.length > s.length ? (si.isBuffer(t) || (t = si.from(t)),
                t.copy(s, r)) : Uint8Array.prototype.set.call(s, t, r);
            else {
                if (!si.isBuffer(t))
                    throw new TypeError('"list" argument must be an Array of Buffers');
                t.copy(s, r)
            }
            r += t.length
        }
        return s
    }
    ,
    si.byteLength = ci,
    si.prototype._isBuffer = !0,
    si.prototype.swap16 = function() {
        const e = this.length;
        if (e % 2 != 0)
            throw new RangeError("Buffer size must be a multiple of 16-bits");
        for (let t = 0; t < e; t += 2)
            pi(this, t, t + 1);
        return this
    }
    ,
    si.prototype.swap32 = function() {
        const e = this.length;
        if (e % 4 != 0)
            throw new RangeError("Buffer size must be a multiple of 32-bits");
        for (let t = 0; t < e; t += 4)
            pi(this, t, t + 3),
            pi(this, t + 1, t + 2);
        return this
    }
    ,
    si.prototype.swap64 = function() {
        const e = this.length;
        if (e % 8 != 0)
            throw new RangeError("Buffer size must be a multiple of 64-bits");
        for (let t = 0; t < e; t += 8)
            pi(this, t, t + 7),
            pi(this, t + 1, t + 6),
            pi(this, t + 2, t + 5),
            pi(this, t + 3, t + 4);
        return this
    }
    ,
    si.prototype.toString = function() {
        const e = this.length;
        return 0 === e ? "" : 0 === arguments.length ? vi(this, 0, e) : hi.apply(this, arguments)
    }
    ,
    si.prototype.toLocaleString = si.prototype.toString,
    si.prototype.equals = function(e) {
        if (!si.isBuffer(e))
            throw new TypeError("Argument must be a Buffer");
        return this === e || 0 === si.compare(this, e)
    }
    ,
    si.prototype.inspect = function() {
        let e = "";
        return e = this.toString("hex", 0, 50).replace(/(.{2})/g, "$1 ").trim(),
        this.length > 50 && (e += " ... "),
        "<Buffer " + e + ">"
    }
    ,
    ei && (si.prototype[ei] = si.prototype.inspect),
    si.prototype.compare = function(e, t, n, s, r) {
        if (Gi(e, Uint8Array) && (e = si.from(e, e.offset, e.byteLength)),
        !si.isBuffer(e))
            throw new TypeError('The "target" argument must be one of type Buffer or Uint8Array. Received type ' + typeof e);
        if (void 0 === t && (t = 0),
        void 0 === n && (n = e ? e.length : 0),
        void 0 === s && (s = 0),
        void 0 === r && (r = this.length),
        t < 0 || n > e.length || s < 0 || r > this.length)
            throw new RangeError("out of range index");
        if (s >= r && t >= n)
            return 0;
        if (s >= r)
            return -1;
        if (t >= n)
            return 1;
        if (this === e)
            return 0;
        let a = (r >>>= 0) - (s >>>= 0)
          , i = (n >>>= 0) - (t >>>= 0);
        const o = Math.min(a, i)
          , l = this.slice(s, r)
          , u = e.slice(t, n);
        for (let e = 0; e < o; ++e)
            if (l[e] !== u[e]) {
                a = l[e],
                i = u[e];
                break
            }
        return a < i ? -1 : i < a ? 1 : 0
    }
    ,
    si.prototype.includes = function(e, t, n) {
        return -1 !== this.indexOf(e, t, n)
    }
    ,
    si.prototype.indexOf = function(e, t, n) {
        return di(this, e, t, n, !0)
    }
    ,
    si.prototype.lastIndexOf = function(e, t, n) {
        return di(this, e, t, n, !1)
    }
    ,
    si.prototype.write = function(e, t, n, s) {
        if (void 0 === t)
            s = "utf8",
            n = this.length,
            t = 0;
        else if (void 0 === n && "string" == typeof t)
            s = t,
            n = this.length,
            t = 0;
        else {
            if (!isFinite(t))
                throw new Error("Buffer.write(string, encoding, offset[, length]) is no longer supported");
            t >>>= 0,
            isFinite(n) ? (n >>>= 0,
            void 0 === s && (s = "utf8")) : (s = n,
            n = void 0)
        }
        const r = this.length - t;
        if ((void 0 === n || n > r) && (n = r),
        e.length > 0 && (n < 0 || t < 0) || t > this.length)
            throw new RangeError("Attempt to write outside buffer bounds");
        s || (s = "utf8");
        let a = !1;
        for (; ; )
            switch (s) {
            case "hex":
                return mi(this, e, t, n);
            case "utf8":
            case "utf-8":
                return gi(this, e, t, n);
            case "ascii":
            case "latin1":
            case "binary":
                return yi(this, e, t, n);
            case "base64":
                return bi(this, e, t, n);
            case "ucs2":
            case "ucs-2":
            case "utf16le":
            case "utf-16le":
                return xi(this, e, t, n);
            default:
                if (a)
                    throw new TypeError("Unknown encoding: " + s);
                s = ("" + s).toLowerCase(),
                a = !0
            }
    }
    ,
    si.prototype.toJSON = function() {
        return {
            type: "Buffer",
            data: Array.prototype.slice.call(this._arr || this, 0)
        }
    }
    ;
    const ki = 4096;
    function Ii(e, t, n) {
        let s = "";
        n = Math.min(e.length, n);
        for (let r = t; r < n; ++r)
            s += String.fromCharCode(127 & e[r]);
        return s
    }
    function Si(e, t, n) {
        let s = "";
        n = Math.min(e.length, n);
        for (let r = t; r < n; ++r)
            s += String.fromCharCode(e[r]);
        return s
    }
    function Ni(e, t, n) {
        const s = e.length;
        (!t || t < 0) && (t = 0),
        (!n || n < 0 || n > s) && (n = s);
        let r = "";
        for (let s = t; s < n; ++s)
            r += ji[e[s]];
        return r
    }
    function Ti(e, t, n) {
        const s = e.slice(t, n);
        let r = "";
        for (let e = 0; e < s.length - 1; e += 2)
            r += String.fromCharCode(s[e] + 256 * s[e + 1]);
        return r
    }
    function Ci(e, t, n) {
        if (e % 1 != 0 || e < 0)
            throw new RangeError("offset is not uint");
        if (e + t > n)
            throw new RangeError("Trying to access beyond buffer length")
    }
    function $i(e, t, n, s, r, a) {
        if (!si.isBuffer(e))
            throw new TypeError('"buffer" argument must be a Buffer instance');
        if (t > r || t < a)
            throw new RangeError('"value" argument is out of bounds');
        if (n + s > e.length)
            throw new RangeError("Index out of range")
    }
    function Ei(e, t, n, s, r) {
        Li(t, s, r, e, n, 7);
        let a = Number(t & BigInt(4294967295));
        e[n++] = a,
        a >>= 8,
        e[n++] = a,
        a >>= 8,
        e[n++] = a,
        a >>= 8,
        e[n++] = a;
        let i = Number(t >> BigInt(32) & BigInt(4294967295));
        return e[n++] = i,
        i >>= 8,
        e[n++] = i,
        i >>= 8,
        e[n++] = i,
        i >>= 8,
        e[n++] = i,
        n
    }
    function Ai(e, t, n, s, r) {
        Li(t, s, r, e, n, 7);
        let a = Number(t & BigInt(4294967295));
        e[n + 7] = a,
        a >>= 8,
        e[n + 6] = a,
        a >>= 8,
        e[n + 5] = a,
        a >>= 8,
        e[n + 4] = a;
        let i = Number(t >> BigInt(32) & BigInt(4294967295));
        return e[n + 3] = i,
        i >>= 8,
        e[n + 2] = i,
        i >>= 8,
        e[n + 1] = i,
        i >>= 8,
        e[n] = i,
        n + 8
    }
    function Ri(e, t, n, s, r, a) {
        if (n + s > e.length)
            throw new RangeError("Index out of range");
        if (n < 0)
            throw new RangeError("Index out of range")
    }
    function Fi(e, t, n, s, r) {
        return t = +t,
        n >>>= 0,
        r || Ri(e, 0, n, 4),
        Ha(e, t, n, s, 23, 4),
        n + 4
    }
    function Di(e, t, n, s, r) {
        return t = +t,
        n >>>= 0,
        r || Ri(e, 0, n, 8),
        Ha(e, t, n, s, 52, 8),
        n + 8
    }
    si.prototype.slice = function(e, t) {
        const n = this.length;
        (e = ~~e) < 0 ? (e += n) < 0 && (e = 0) : e > n && (e = n),
        (t = void 0 === t ? n : ~~t) < 0 ? (t += n) < 0 && (t = 0) : t > n && (t = n),
        t < e && (t = e);
        const s = this.subarray(e, t);
        return Object.setPrototypeOf(s, si.prototype),
        s
    }
    ,
    si.prototype.readUintLE = si.prototype.readUIntLE = function(e, t, n) {
        e >>>= 0,
        t >>>= 0,
        n || Ci(e, t, this.length);
        let s = this[e]
          , r = 1
          , a = 0;
        for (; ++a < t && (r *= 256); )
            s += this[e + a] * r;
        return s
    }
    ,
    si.prototype.readUintBE = si.prototype.readUIntBE = function(e, t, n) {
        e >>>= 0,
        t >>>= 0,
        n || Ci(e, t, this.length);
        let s = this[e + --t]
          , r = 1;
        for (; t > 0 && (r *= 256); )
            s += this[e + --t] * r;
        return s
    }
    ,
    si.prototype.readUint8 = si.prototype.readUInt8 = function(e, t) {
        return e >>>= 0,
        t || Ci(e, 1, this.length),
        this[e]
    }
    ,
    si.prototype.readUint16LE = si.prototype.readUInt16LE = function(e, t) {
        return e >>>= 0,
        t || Ci(e, 2, this.length),
        this[e] | this[e + 1] << 8
    }
    ,
    si.prototype.readUint16BE = si.prototype.readUInt16BE = function(e, t) {
        return e >>>= 0,
        t || Ci(e, 2, this.length),
        this[e] << 8 | this[e + 1]
    }
    ,
    si.prototype.readUint32LE = si.prototype.readUInt32LE = function(e, t) {
        return e >>>= 0,
        t || Ci(e, 4, this.length),
        (this[e] | this[e + 1] << 8 | this[e + 2] << 16) + 16777216 * this[e + 3]
    }
    ,
    si.prototype.readUint32BE = si.prototype.readUInt32BE = function(e, t) {
        return e >>>= 0,
        t || Ci(e, 4, this.length),
        16777216 * this[e] + (this[e + 1] << 16 | this[e + 2] << 8 | this[e + 3])
    }
    ,
    si.prototype.readBigUInt64LE = qi((function(e) {
        zi(e >>>= 0, "offset");
        const t = this[e]
          , n = this[e + 7];
        void 0 !== t && void 0 !== n || Bi(e, this.length - 8);
        const s = t + 256 * this[++e] + 65536 * this[++e] + this[++e] * 2 ** 24
          , r = this[++e] + 256 * this[++e] + 65536 * this[++e] + n * 2 ** 24;
        return BigInt(s) + (BigInt(r) << BigInt(32))
    }
    )),
    si.prototype.readBigUInt64BE = qi((function(e) {
        zi(e >>>= 0, "offset");
        const t = this[e]
          , n = this[e + 7];
        void 0 !== t && void 0 !== n || Bi(e, this.length - 8);
        const s = t * 2 ** 24 + 65536 * this[++e] + 256 * this[++e] + this[++e]
          , r = this[++e] * 2 ** 24 + 65536 * this[++e] + 256 * this[++e] + n;
        return (BigInt(s) << BigInt(32)) + BigInt(r)
    }
    )),
    si.prototype.readIntLE = function(e, t, n) {
        e >>>= 0,
        t >>>= 0,
        n || Ci(e, t, this.length);
        let s = this[e]
          , r = 1
          , a = 0;
        for (; ++a < t && (r *= 256); )
            s += this[e + a] * r;
        return r *= 128,
        s >= r && (s -= Math.pow(2, 8 * t)),
        s
    }
    ,
    si.prototype.readIntBE = function(e, t, n) {
        e >>>= 0,
        t >>>= 0,
        n || Ci(e, t, this.length);
        let s = t
          , r = 1
          , a = this[e + --s];
        for (; s > 0 && (r *= 256); )
            a += this[e + --s] * r;
        return r *= 128,
        a >= r && (a -= Math.pow(2, 8 * t)),
        a
    }
    ,
    si.prototype.readInt8 = function(e, t) {
        return e >>>= 0,
        t || Ci(e, 1, this.length),
        128 & this[e] ? -1 * (255 - this[e] + 1) : this[e]
    }
    ,
    si.prototype.readInt16LE = function(e, t) {
        e >>>= 0,
        t || Ci(e, 2, this.length);
        const n = this[e] | this[e + 1] << 8;
        return 32768 & n ? 4294901760 | n : n
    }
    ,
    si.prototype.readInt16BE = function(e, t) {
        e >>>= 0,
        t || Ci(e, 2, this.length);
        const n = this[e + 1] | this[e] << 8;
        return 32768 & n ? 4294901760 | n : n
    }
    ,
    si.prototype.readInt32LE = function(e, t) {
        return e >>>= 0,
        t || Ci(e, 4, this.length),
        this[e] | this[e + 1] << 8 | this[e + 2] << 16 | this[e + 3] << 24
    }
    ,
    si.prototype.readInt32BE = function(e, t) {
        return e >>>= 0,
        t || Ci(e, 4, this.length),
        this[e] << 24 | this[e + 1] << 16 | this[e + 2] << 8 | this[e + 3]
    }
    ,
    si.prototype.readBigInt64LE = qi((function(e) {
        zi(e >>>= 0, "offset");
        const t = this[e]
          , n = this[e + 7];
        void 0 !== t && void 0 !== n || Bi(e, this.length - 8);
        const s = this[e + 4] + 256 * this[e + 5] + 65536 * this[e + 6] + (n << 24);
        return (BigInt(s) << BigInt(32)) + BigInt(t + 256 * this[++e] + 65536 * this[++e] + this[++e] * 2 ** 24)
    }
    )),
    si.prototype.readBigInt64BE = qi((function(e) {
        zi(e >>>= 0, "offset");
        const t = this[e]
          , n = this[e + 7];
        void 0 !== t && void 0 !== n || Bi(e, this.length - 8);
        const s = (t << 24) + 65536 * this[++e] + 256 * this[++e] + this[++e];
        return (BigInt(s) << BigInt(32)) + BigInt(this[++e] * 2 ** 24 + 65536 * this[++e] + 256 * this[++e] + n)
    }
    )),
    si.prototype.readFloatLE = function(e, t) {
        return e >>>= 0,
        t || Ci(e, 4, this.length),
        Ga(this, e, !0, 23, 4)
    }
    ,
    si.prototype.readFloatBE = function(e, t) {
        return e >>>= 0,
        t || Ci(e, 4, this.length),
        Ga(this, e, !1, 23, 4)
    }
    ,
    si.prototype.readDoubleLE = function(e, t) {
        return e >>>= 0,
        t || Ci(e, 8, this.length),
        Ga(this, e, !0, 52, 8)
    }
    ,
    si.prototype.readDoubleBE = function(e, t) {
        return e >>>= 0,
        t || Ci(e, 8, this.length),
        Ga(this, e, !1, 52, 8)
    }
    ,
    si.prototype.writeUintLE = si.prototype.writeUIntLE = function(e, t, n, s) {
        if (e = +e,
        t >>>= 0,
        n >>>= 0,
        !s) {
            $i(this, e, t, n, Math.pow(2, 8 * n) - 1, 0)
        }
        let r = 1
          , a = 0;
        for (this[t] = 255 & e; ++a < n && (r *= 256); )
            this[t + a] = e / r & 255;
        return t + n
    }
    ,
    si.prototype.writeUintBE = si.prototype.writeUIntBE = function(e, t, n, s) {
        if (e = +e,
        t >>>= 0,
        n >>>= 0,
        !s) {
            $i(this, e, t, n, Math.pow(2, 8 * n) - 1, 0)
        }
        let r = n - 1
          , a = 1;
        for (this[t + r] = 255 & e; --r >= 0 && (a *= 256); )
            this[t + r] = e / a & 255;
        return t + n
    }
    ,
    si.prototype.writeUint8 = si.prototype.writeUInt8 = function(e, t, n) {
        return e = +e,
        t >>>= 0,
        n || $i(this, e, t, 1, 255, 0),
        this[t] = 255 & e,
        t + 1
    }
    ,
    si.prototype.writeUint16LE = si.prototype.writeUInt16LE = function(e, t, n) {
        return e = +e,
        t >>>= 0,
        n || $i(this, e, t, 2, 65535, 0),
        this[t] = 255 & e,
        this[t + 1] = e >>> 8,
        t + 2
    }
    ,
    si.prototype.writeUint16BE = si.prototype.writeUInt16BE = function(e, t, n) {
        return e = +e,
        t >>>= 0,
        n || $i(this, e, t, 2, 65535, 0),
        this[t] = e >>> 8,
        this[t + 1] = 255 & e,
        t + 2
    }
    ,
    si.prototype.writeUint32LE = si.prototype.writeUInt32LE = function(e, t, n) {
        return e = +e,
        t >>>= 0,
        n || $i(this, e, t, 4, 4294967295, 0),
        this[t + 3] = e >>> 24,
        this[t + 2] = e >>> 16,
        this[t + 1] = e >>> 8,
        this[t] = 255 & e,
        t + 4
    }
    ,
    si.prototype.writeUint32BE = si.prototype.writeUInt32BE = function(e, t, n) {
        return e = +e,
        t >>>= 0,
        n || $i(this, e, t, 4, 4294967295, 0),
        this[t] = e >>> 24,
        this[t + 1] = e >>> 16,
        this[t + 2] = e >>> 8,
        this[t + 3] = 255 & e,
        t + 4
    }
    ,
    si.prototype.writeBigUInt64LE = qi((function(e, t=0) {
        return Ei(this, e, t, BigInt(0), BigInt("0xffffffffffffffff"))
    }
    )),
    si.prototype.writeBigUInt64BE = qi((function(e, t=0) {
        return Ai(this, e, t, BigInt(0), BigInt("0xffffffffffffffff"))
    }
    )),
    si.prototype.writeIntLE = function(e, t, n, s) {
        if (e = +e,
        t >>>= 0,
        !s) {
            const s = Math.pow(2, 8 * n - 1);
            $i(this, e, t, n, s - 1, -s)
        }
        let r = 0
          , a = 1
          , i = 0;
        for (this[t] = 255 & e; ++r < n && (a *= 256); )
            e < 0 && 0 === i && 0 !== this[t + r - 1] && (i = 1),
            this[t + r] = (e / a >> 0) - i & 255;
        return t + n
    }
    ,
    si.prototype.writeIntBE = function(e, t, n, s) {
        if (e = +e,
        t >>>= 0,
        !s) {
            const s = Math.pow(2, 8 * n - 1);
            $i(this, e, t, n, s - 1, -s)
        }
        let r = n - 1
          , a = 1
          , i = 0;
        for (this[t + r] = 255 & e; --r >= 0 && (a *= 256); )
            e < 0 && 0 === i && 0 !== this[t + r + 1] && (i = 1),
            this[t + r] = (e / a >> 0) - i & 255;
        return t + n
    }
    ,
    si.prototype.writeInt8 = function(e, t, n) {
        return e = +e,
        t >>>= 0,
        n || $i(this, e, t, 1, 127, -128),
        e < 0 && (e = 255 + e + 1),
        this[t] = 255 & e,
        t + 1
    }
    ,
    si.prototype.writeInt16LE = function(e, t, n) {
        return e = +e,
        t >>>= 0,
        n || $i(this, e, t, 2, 32767, -32768),
        this[t] = 255 & e,
        this[t + 1] = e >>> 8,
        t + 2
    }
    ,
    si.prototype.writeInt16BE = function(e, t, n) {
        return e = +e,
        t >>>= 0,
        n || $i(this, e, t, 2, 32767, -32768),
        this[t] = e >>> 8,
        this[t + 1] = 255 & e,
        t + 2
    }
    ,
    si.prototype.writeInt32LE = function(e, t, n) {
        return e = +e,
        t >>>= 0,
        n || $i(this, e, t, 4, 2147483647, -2147483648),
        this[t] = 255 & e,
        this[t + 1] = e >>> 8,
        this[t + 2] = e >>> 16,
        this[t + 3] = e >>> 24,
        t + 4
    }
    ,
    si.prototype.writeInt32BE = function(e, t, n) {
        return e = +e,
        t >>>= 0,
        n || $i(this, e, t, 4, 2147483647, -2147483648),
        e < 0 && (e = 4294967295 + e + 1),
        this[t] = e >>> 24,
        this[t + 1] = e >>> 16,
        this[t + 2] = e >>> 8,
        this[t + 3] = 255 & e,
        t + 4
    }
    ,
    si.prototype.writeBigInt64LE = qi((function(e, t=0) {
        return Ei(this, e, t, -BigInt("0x8000000000000000"), BigInt("0x7fffffffffffffff"))
    }
    )),
    si.prototype.writeBigInt64BE = qi((function(e, t=0) {
        return Ai(this, e, t, -BigInt("0x8000000000000000"), BigInt("0x7fffffffffffffff"))
    }
    )),
    si.prototype.writeFloatLE = function(e, t, n) {
        return Fi(this, e, t, !0, n)
    }
    ,
    si.prototype.writeFloatBE = function(e, t, n) {
        return Fi(this, e, t, !1, n)
    }
    ,
    si.prototype.writeDoubleLE = function(e, t, n) {
        return Di(this, e, t, !0, n)
    }
    ,
    si.prototype.writeDoubleBE = function(e, t, n) {
        return Di(this, e, t, !1, n)
    }
    ,
    si.prototype.copy = function(e, t, n, s) {
        if (!si.isBuffer(e))
            throw new TypeError("argument should be a Buffer");
        if (n || (n = 0),
        s || 0 === s || (s = this.length),
        t >= e.length && (t = e.length),
        t || (t = 0),
        s > 0 && s < n && (s = n),
        s === n)
            return 0;
        if (0 === e.length || 0 === this.length)
            return 0;
        if (t < 0)
            throw new RangeError("targetStart out of bounds");
        if (n < 0 || n >= this.length)
            throw new RangeError("Index out of range");
        if (s < 0)
            throw new RangeError("sourceEnd out of bounds");
        s > this.length && (s = this.length),
        e.length - t < s - n && (s = e.length - t + n);
        const r = s - n;
        return this === e && "function" == typeof Uint8Array.prototype.copyWithin ? this.copyWithin(t, n, s) : Uint8Array.prototype.set.call(e, this.subarray(n, s), t),
        r
    }
    ,
    si.prototype.fill = function(e, t, n, s) {
        if ("string" == typeof e) {
            if ("string" == typeof t ? (s = t,
            t = 0,
            n = this.length) : "string" == typeof n && (s = n,
            n = this.length),
            void 0 !== s && "string" != typeof s)
                throw new TypeError("encoding must be a string");
            if ("string" == typeof s && !si.isEncoding(s))
                throw new TypeError("Unknown encoding: " + s);
            if (1 === e.length) {
                const t = e.charCodeAt(0);
                ("utf8" === s && t < 128 || "latin1" === s) && (e = t)
            }
        } else
            "number" == typeof e ? e &= 255 : "boolean" == typeof e && (e = Number(e));
        if (t < 0 || this.length < t || this.length < n)
            throw new RangeError("Out of range index");
        if (n <= t)
            return this;
        let r;
        if (t >>>= 0,
        n = void 0 === n ? this.length : n >>> 0,
        e || (e = 0),
        "number" == typeof e)
            for (r = t; r < n; ++r)
                this[r] = e;
        else {
            const a = si.isBuffer(e) ? e : si.from(e, s)
              , i = a.length;
            if (0 === i)
                throw new TypeError('The value "' + e + '" is invalid for argument "value"');
            for (r = 0; r < n - t; ++r)
                this[r + t] = a[r % i]
        }
        return this
    }
    ;
    const _i = {};
    function Oi(e, t, n) {
        _i[e] = class extends n {
            constructor() {
                super(),
                Object.defineProperty(this, "message", {
                    value: t.apply(this, arguments),
                    writable: !0,
                    configurable: !0
                }),
                this.name = `${this.name} [${e}]`,
                this.stack,
                delete this.name
            }
            get code() {
                return e
            }
            set code(e) {
                Object.defineProperty(this, "code", {
                    configurable: !0,
                    enumerable: !0,
                    value: e,
                    writable: !0
                })
            }
            toString() {
                return `${this.name} [${e}]: ${this.message}`
            }
        }
    }
    function Mi(e) {
        let t = ""
          , n = e.length;
        const s = "-" === e[0] ? 1 : 0;
        for (; n >= s + 4; n -= 3)
            t = `_${e.slice(n - 3, n)}${t}`;
        return `${e.slice(0, n)}${t}`
    }
    function Li(e, t, n, s, r, a) {
        if (e > n || e < t) {
            const s = "bigint" == typeof t ? "n" : "";
            let r;
            throw r = a > 3 ? 0 === t || t === BigInt(0) ? `>= 0${s} and < 2${s} ** ${8 * (a + 1)}${s}` : `>= -(2${s} ** ${8 * (a + 1) - 1}${s}) and < 2 ** ${8 * (a + 1) - 1}${s}` : `>= ${t}${s} and <= ${n}${s}`,
            new _i.ERR_OUT_OF_RANGE("value",r,e)
        }
        !function(e, t, n) {
            zi(t, "offset"),
            void 0 !== e[t] && void 0 !== e[t + n] || Bi(t, e.length - (n + 1))
        }(s, r, a)
    }
    function zi(e, t) {
        if ("number" != typeof e)
            throw new _i.ERR_INVALID_ARG_TYPE(t,"number",e)
    }
    function Bi(e, t, n) {
        if (Math.floor(e) !== e)
            throw zi(e, n),
            new _i.ERR_OUT_OF_RANGE(n || "offset","an integer",e);
        if (t < 0)
            throw new _i.ERR_BUFFER_OUT_OF_BOUNDS;
        throw new _i.ERR_OUT_OF_RANGE(n || "offset",`>= ${n ? 1 : 0} and <= ${t}`,e)
    }
    Oi("ERR_BUFFER_OUT_OF_BOUNDS", (function(e) {
        return e ? `${e} is outside of buffer bounds` : "Attempt to access memory outside buffer bounds"
    }
    ), RangeError),
    Oi("ERR_INVALID_ARG_TYPE", (function(e, t) {
        return `The "${e}" argument must be of type number. Received type ${typeof t}`
    }
    ), TypeError),
    Oi("ERR_OUT_OF_RANGE", (function(e, t, n) {
        let s = `The value of "${e}" is out of range.`
          , r = n;
        return Number.isInteger(n) && Math.abs(n) > 2 ** 32 ? r = Mi(String(n)) : "bigint" == typeof n && (r = String(n),
        (n > BigInt(2) ** BigInt(32) || n < -(BigInt(2) ** BigInt(32))) && (r = Mi(r)),
        r += "n"),
        s += ` It must be ${t}. Received ${r}`,
        s
    }
    ), RangeError);
    const Pi = /[^+/0-9A-Za-z-_]/g;
    function Wi(e, t) {
        let n;
        t = t || 1 / 0;
        const s = e.length;
        let r = null;
        const a = [];
        for (let i = 0; i < s; ++i) {
            if (n = e.charCodeAt(i),
            n > 55295 && n < 57344) {
                if (!r) {
                    if (n > 56319) {
                        (t -= 3) > -1 && a.push(239, 191, 189);
                        continue
                    }
                    if (i + 1 === s) {
                        (t -= 3) > -1 && a.push(239, 191, 189);
                        continue
                    }
                    r = n;
                    continue
                }
                if (n < 56320) {
                    (t -= 3) > -1 && a.push(239, 191, 189),
                    r = n;
                    continue
                }
                n = 65536 + (r - 55296 << 10 | n - 56320)
            } else
                r && (t -= 3) > -1 && a.push(239, 191, 189);
            if (r = null,
            n < 128) {
                if ((t -= 1) < 0)
                    break;
                a.push(n)
            } else if (n < 2048) {
                if ((t -= 2) < 0)
                    break;
                a.push(n >> 6 | 192, 63 & n | 128)
            } else if (n < 65536) {
                if ((t -= 3) < 0)
                    break;
                a.push(n >> 12 | 224, n >> 6 & 63 | 128, 63 & n | 128)
            } else {
                if (!(n < 1114112))
                    throw new Error("Invalid code point");
                if ((t -= 4) < 0)
                    break;
                a.push(n >> 18 | 240, n >> 12 & 63 | 128, n >> 6 & 63 | 128, 63 & n | 128)
            }
        }
        return a
    }
    function Ui(e) {
        return Ua(function(e) {
            if ((e = (e = e.split("=")[0]).trim().replace(Pi, "")).length < 2)
                return "";
            for (; e.length % 4 != 0; )
                e += "=";
            return e
        }(e))
    }
    function Vi(e, t, n, s) {
        let r;
        for (r = 0; r < s && !(r + n >= t.length || r >= e.length); ++r)
            t[r + n] = e[r];
        return r
    }
    function Gi(e, t) {
        return e instanceof t || null != e && null != e.constructor && null != e.constructor.name && e.constructor.name === t.name
    }
    function Hi(e) {
        return e != e
    }
    const ji = function() {
        const e = "0123456789abcdef"
          , t = new Array(256);
        for (let n = 0; n < 16; ++n) {
            const s = 16 * n;
            for (let r = 0; r < 16; ++r)
                t[s + r] = e[n] + e[r]
        }
        return t
    }();
    function qi(e) {
        return "undefined" == typeof BigInt ? Ki : e
    }
    function Ki() {
        throw new Error("BigInt not supported")
    }
    var Xi = Wa;
    async function Yi(e, t) {
        const n = []
          , s = []
          , r = Array.isArray(e) ? e.map((e=>e.name)) : Object.keys(e);
        for (let a = 0; a < r.length; ++a) {
            const i = r[a]
              , o = Array.isArray(e) ? e[a].tensor : e[i];
            if ("float32" !== o.dtype && "int32" !== o.dtype && "bool" !== o.dtype && "string" !== o.dtype && "complex64" !== o.dtype)
                throw new Error(`Unsupported dtype in weight '${i}': ${o.dtype}`);
            const l = {
                name: i,
                shape: o.shape,
                dtype: o.dtype
            };
            if ("string" === o.dtype) {
                const e = new Promise((async e=>{
                    const t = await o.bytes()
                      , n = t.reduce(((e,t)=>e + t.length), 0) + 4 * t.length
                      , s = new Uint8Array(n);
                    let r = 0;
                    for (let e = 0; e < t.length; e++) {
                        const n = t[e]
                          , a = new Uint8Array(new Uint32Array([n.length]).buffer);
                        s.set(a, r),
                        r += 4,
                        s.set(n, r),
                        r += n.length
                    }
                    e(s)
                }
                ));
                s.push(e)
            } else
                s.push(o.data());
            null != t && (l.group = t),
            n.push(l)
        }
        return {
            data: Ji(await Promise.all(s)),
            specs: n
        }
    }
    function Zi(e, t) {
        const n = {};
        let s, r = 0;
        for (const a of t) {
            const t = a.name
              , i = a.dtype
              , o = a.shape
              , l = v(o);
            let u;
            if ("quantization"in a) {
                const n = a.quantization;
                if ("uint8" === n.dtype || "uint16" === n.dtype) {
                    if (!("min"in n) || !("scale"in n))
                        throw new Error(`Weight ${a.name} with quantization ${n.dtype} doesn't have corresponding metadata min and scale.`)
                } else {
                    if ("float16" !== n.dtype)
                        throw new Error(`Weight ${a.name} has unknown quantization dtype ${n.dtype}. Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.`);
                    if ("float32" !== i)
                        throw new Error(`Weight ${a.name} is quantized with ${n.dtype} which only supports weights of type float32 not ${i}.`)
                }
                const o = Pa[n.dtype]
                  , c = e.slice(r, r + l * o)
                  , h = "uint8" === n.dtype ? new Uint8Array(c) : new Uint16Array(c);
                if ("float32" === i)
                    if ("uint8" === n.dtype || "uint16" === n.dtype) {
                        u = new Float32Array(h.length);
                        for (let e = 0; e < h.length; e++) {
                            const t = h[e];
                            u[e] = t * n.scale + n.min
                        }
                    } else {
                        if ("float16" !== n.dtype)
                            throw new Error(`Unsupported quantization type ${n.dtype} for weight type float32.`);
                        void 0 === s && (s = lo()),
                        u = s(h)
                    }
                else {
                    if ("int32" !== i)
                        throw new Error(`Unsupported dtype in weight '${t}': ${i}`);
                    if ("uint8" !== n.dtype && "uint16" !== n.dtype)
                        throw new Error(`Unsupported quantization type ${n.dtype} for weight type int32.`);
                    u = new Int32Array(h.length);
                    for (let e = 0; e < h.length; e++) {
                        const t = h[e];
                        u[e] = Math.round(t * n.scale + n.min)
                    }
                }
                r += l * o
            } else if ("string" === i) {
                const t = v(a.shape);
                u = [];
                for (let n = 0; n < t; n++) {
                    const t = new Uint32Array(e.slice(r, r + 4))[0];
                    r += 4;
                    const n = new Uint8Array(e.slice(r, r + t));
                    u.push(n),
                    r += t
                }
            } else {
                const s = Pa[i]
                  , a = e.slice(r, r + l * s);
                if ("float32" === i)
                    u = new Float32Array(a);
                else if ("int32" === i)
                    u = new Int32Array(a);
                else if ("bool" === i)
                    u = new Uint8Array(a);
                else {
                    if ("complex64" !== i)
                        throw new Error(`Unsupported dtype in weight '${t}': ${i}`);
                    {
                        u = new Float32Array(a);
                        const e = new Float32Array(u.length / 2)
                          , s = new Float32Array(u.length / 2);
                        for (let t = 0; t < e.length; t++)
                            e[t] = u[2 * t],
                            s[t] = u[2 * t + 1];
                        const r = Ba(e, o, "float32")
                          , i = Ba(s, o, "float32");
                        n[t] = La(r, i),
                        r.dispose(),
                        i.dispose()
                    }
                }
                r += l * s
            }
            "complex64" !== i && (n[t] = Ba(u, o, i))
        }
        return n
    }
    function Ji(e) {
        if (null === e)
            throw new Error(`Invalid input value: ${JSON.stringify(e)}`);
        let t = 0;
        const n = [];
        e.forEach((e=>{
            if (t += e.byteLength,
            n.push(e.byteLength === e.buffer.byteLength ? e : new e.constructor(e)),
            !(e instanceof Float32Array || e instanceof Int32Array || e instanceof Uint8Array))
                throw new Error(`Unsupported TypedArray subtype: ${e.constructor.name}`)
        }
        ));
        const s = new Uint8Array(t);
        let r = 0;
        return n.forEach((e=>{
            s.set(new Uint8Array(e.buffer), r),
            r += e.byteLength
        }
        )),
        s.buffer
    }
    const Qi = void 0 !== Xi && ("undefined" == typeof Blob || "undefined" == typeof atob || "undefined" == typeof btoa);
    function eo(e) {
        return Qi ? Xi.byteLength(e) : new Blob([e]).size
    }
    function to(e) {
        if (1 === e.length)
            return e[0];
        let t = 0;
        e.forEach((e=>{
            t += e.byteLength
        }
        ));
        const n = new Uint8Array(t);
        let s = 0;
        return e.forEach((e=>{
            n.set(new Uint8Array(e), s),
            s += e.byteLength
        }
        )),
        n.buffer
    }
    function no(e) {
        for (e = e.trim(); e.endsWith("/"); )
            e = e.slice(0, e.length - 1);
        const t = e.split("/");
        return t[t.length - 1]
    }
    function so(e, t) {
        const n = {
            modelTopology: e.modelTopology,
            format: e.format,
            generatedBy: e.generatedBy,
            convertedBy: e.convertedBy,
            weightsManifest: t
        };
        return null != e.signature && (n.signature = e.signature),
        null != e.userDefinedMetadata && (n.userDefinedMetadata = e.userDefinedMetadata),
        null != e.modelInitializer && (n.modelInitializer = e.modelInitializer),
        null != e.initializerSignature && (n.initializerSignature = e.initializerSignature),
        null != e.trainingConfig && (n.trainingConfig = e.trainingConfig),
        n
    }
    function ro(e, t, n) {
        const s = {
            modelTopology: e.modelTopology,
            format: e.format,
            generatedBy: e.generatedBy,
            convertedBy: e.convertedBy
        };
        if (null != e.trainingConfig && (s.trainingConfig = e.trainingConfig),
        null != e.weightsManifest) {
            if (!t)
                throw new Error("modelJSON has weightsManifest but weightSpecs is null");
            if (!n)
                throw new Error("modelJSON has weightsManifest but weightData is null");
            s.weightSpecs = t,
            s.weightData = n
        }
        return null != e.signature && (s.signature = e.signature),
        null != e.userDefinedMetadata && (s.userDefinedMetadata = e.userDefinedMetadata),
        null != e.modelInitializer && (s.modelInitializer = e.modelInitializer),
        null != e.initializerSignature && (s.initializerSignature = e.initializerSignature),
        s
    }
    async function ao(e, t) {
        let n, s;
        return null != e.weightsManifest && ([n,s] = await t(e.weightsManifest)),
        ro(e, n, s)
    }
    function io(e) {
        if (e.modelTopology instanceof ArrayBuffer)
            throw new Error("Expected JSON model topology, received ArrayBuffer.");
        return {
            dateSaved: new Date,
            modelTopologyType: "JSON",
            modelTopologyBytes: null == e.modelTopology ? 0 : eo(JSON.stringify(e.modelTopology)),
            weightSpecsBytes: null == e.weightSpecs ? 0 : eo(JSON.stringify(e.weightSpecs)),
            weightDataBytes: null == e.weightData ? 0 : e.weightData.byteLength
        }
    }
    function oo(e) {
        const t = [];
        for (const n of e)
            t.push(...n.weights);
        return t
    }
    function lo() {
        const e = function() {
            const e = e=>{
                let t = e << 13
                  , n = 0;
                for (; 0 == (8388608 & t); )
                    n -= 8388608,
                    t <<= 1;
                return t &= -8388609,
                n += 947912704,
                t | n
            }
              , t = new Uint32Array(2048);
            t[0] = 0;
            for (let n = 1; n < 1024; n++)
                t[n] = e(n);
            for (let e = 1024; e < 2048; e++)
                t[e] = 939524096 + (e - 1024 << 13);
            return t
        }()
          , t = function() {
            const e = new Uint32Array(64);
            e[0] = 0,
            e[31] = 1199570944,
            e[32] = 2147483648,
            e[63] = 3347054592;
            for (let t = 1; t < 31; t++)
                e[t] = t << 23;
            for (let t = 33; t < 63; t++)
                e[t] = 2147483648 + (t - 32 << 23);
            return e
        }()
          , n = function() {
            const e = new Uint32Array(64);
            for (let t = 0; t < 64; t++)
                e[t] = 1024;
            return e[0] = e[32] = 0,
            e
        }();
        return s=>{
            const r = new ArrayBuffer(4 * s.length)
              , a = new Uint32Array(r);
            for (let r = 0; r < s.length; r++) {
                const i = s[r]
                  , o = e[n[i >> 10] + (1023 & i)] + t[i >> 10];
                a[r] = o
            }
            return new Float32Array(r)
        }
    }
    class uo {
        constructor() {
            this.saveRouters = [],
            this.loadRouters = []
        }
        static getInstance() {
            return null == uo.instance && (uo.instance = new uo),
            uo.instance
        }
        static registerSaveRouter(e) {
            uo.getInstance().saveRouters.push(e)
        }
        static registerLoadRouter(e) {
            uo.getInstance().loadRouters.push(e)
        }
        static getSaveHandlers(e) {
            return uo.getHandlers(e, "save")
        }
        static getLoadHandlers(e, t) {
            return uo.getHandlers(e, "load", t)
        }
        static getHandlers(e, t, n) {
            const s = [];
            return ("load" === t ? uo.getInstance().loadRouters : uo.getInstance().saveRouters).forEach((t=>{
                const r = t(e, n);
                null !== r && s.push(r)
            }
            )),
            s
        }
    }
    const co = e=>uo.registerSaveRouter(e)
      , ho = e=>uo.registerLoadRouter(e)
      , po = e=>uo.getSaveHandlers(e)
      , fo = (e,t)=>uo.getLoadHandlers(e, t)
      , mo = "tensorflowjs"
      , go = "models_store"
      , yo = "model_info_store";
    function bo() {
        if (!ie().getBool("IS_BROWSER"))
            throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");
        const e = "undefined" == typeof window ? self : window
          , t = e.indexedDB || e.mozIndexedDB || e.webkitIndexedDB || e.msIndexedDB || e.shimIndexedDB;
        if (null == t)
            throw new Error("The current browser does not appear to support IndexedDB.");
        return t
    }
    function xo(e) {
        const t = e.result;
        t.createObjectStore(go, {
            keyPath: "modelPath"
        }),
        t.createObjectStore(yo, {
            keyPath: "modelPath"
        })
    }
    class wo {
        constructor(e) {
            if (this.indexedDB = bo(),
            null == e || !e)
                throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");
            this.modelPath = e
        }
        async save(e) {
            if (e.modelTopology instanceof ArrayBuffer)
                throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
            return this.databaseAction(this.modelPath, e)
        }
        async load() {
            return this.databaseAction(this.modelPath)
        }
        databaseAction(e, t) {
            return new Promise(((e,n)=>{
                const s = this.indexedDB.open(mo, 1);
                s.onupgradeneeded = ()=>xo(s),
                s.onsuccess = ()=>{
                    const r = s.result;
                    if (null == t) {
                        const t = r.transaction(go, "readonly")
                          , s = t.objectStore(go).get(this.modelPath);
                        s.onsuccess = ()=>{
                            if (null == s.result)
                                return r.close(),
                                n(new Error(`Cannot find model with path '${this.modelPath}' in IndexedDB.`));
                            e(s.result.modelArtifacts)
                        }
                        ,
                        s.onerror = e=>(r.close(),
                        n(s.error)),
                        t.oncomplete = ()=>r.close()
                    } else {
                        const s = io(t)
                          , a = r.transaction(yo, "readwrite");
                        let i = a.objectStore(yo);
                        const o = i.put({
                            modelPath: this.modelPath,
                            modelArtifactsInfo: s
                        });
                        let l;
                        o.onsuccess = ()=>{
                            l = r.transaction(go, "readwrite");
                            const o = l.objectStore(go).put({
                                modelPath: this.modelPath,
                                modelArtifacts: t,
                                modelArtifactsInfo: s
                            });
                            o.onsuccess = ()=>e({
                                modelArtifactsInfo: s
                            }),
                            o.onerror = e=>{
                                i = a.objectStore(yo);
                                const t = i.delete(this.modelPath);
                                t.onsuccess = ()=>(r.close(),
                                n(o.error)),
                                t.onerror = e=>(r.close(),
                                n(o.error))
                            }
                        }
                        ,
                        o.onerror = e=>(r.close(),
                        n(o.error)),
                        a.oncomplete = ()=>{
                            null == l ? r.close() : l.oncomplete = ()=>r.close()
                        }
                    }
                }
                ,
                s.onerror = e=>n(s.error)
            }
            ))
        }
    }
    wo.URL_SCHEME = "indexeddb://";
    const vo = e=>{
        return ie().getBool("IS_BROWSER") && !Array.isArray(e) && e.startsWith(wo.URL_SCHEME) ? (t = e.slice(wo.URL_SCHEME.length),
        new wo(t)) : null;
        var t
    }
    ;
    uo.registerSaveRouter(vo),
    uo.registerLoadRouter(vo);
    class ko {
        constructor() {
            this.indexedDB = bo()
        }
        async listModels() {
            return new Promise(((e,t)=>{
                const n = this.indexedDB.open(mo, 1);
                n.onupgradeneeded = ()=>xo(n),
                n.onsuccess = ()=>{
                    const s = n.result
                      , r = s.transaction(yo, "readonly")
                      , a = r.objectStore(yo).getAll();
                    a.onsuccess = ()=>{
                        const t = {};
                        for (const e of a.result)
                            t[e.modelPath] = e.modelArtifactsInfo;
                        e(t)
                    }
                    ,
                    a.onerror = e=>(s.close(),
                    t(a.error)),
                    r.oncomplete = ()=>s.close()
                }
                ,
                n.onerror = e=>t(n.error)
            }
            ))
        }
        async removeModel(e) {
            var t;
            return e = (t = e).startsWith(wo.URL_SCHEME) ? t.slice(wo.URL_SCHEME.length) : t,
            new Promise(((t,n)=>{
                const s = this.indexedDB.open(mo, 1);
                s.onupgradeneeded = ()=>xo(s),
                s.onsuccess = ()=>{
                    const r = s.result
                      , a = r.transaction(yo, "readwrite")
                      , i = a.objectStore(yo)
                      , o = i.get(e);
                    let l;
                    o.onsuccess = ()=>{
                        if (null == o.result)
                            return r.close(),
                            n(new Error(`Cannot find model with path '${e}' in IndexedDB.`));
                        {
                            const s = i.delete(e)
                              , a = ()=>{
                                l = r.transaction(go, "readwrite");
                                const s = l.objectStore(go).delete(e);
                                s.onsuccess = ()=>t(o.result.modelArtifactsInfo),
                                s.onerror = e=>n(o.error)
                            }
                            ;
                            s.onsuccess = a,
                            s.onerror = e=>(a(),
                            r.close(),
                            n(o.error))
                        }
                    }
                    ,
                    o.onerror = e=>(r.close(),
                    n(o.error)),
                    a.oncomplete = ()=>{
                        null == l ? r.close() : l.oncomplete = ()=>r.close()
                    }
                }
                ,
                s.onerror = e=>n(s.error)
            }
            ))
        }
    }
    const Io = "/"
      , So = "tensorflowjs_models"
      , No = "info"
      , To = "model_topology"
      , Co = "weight_specs"
      , $o = "weight_data"
      , Eo = "model_metadata";
    function Ao(e) {
        return {
            info: [So, e, No].join(Io),
            topology: [So, e, To].join(Io),
            weightSpecs: [So, e, Co].join(Io),
            weightData: [So, e, $o].join(Io),
            modelMetadata: [So, e, Eo].join(Io)
        }
    }
    function Ro(e) {
        for (const t of Object.values(e))
            window.localStorage.removeItem(t)
    }
    function Fo(e) {
        const t = e.split(Io);
        if (t.length < 3)
            throw new Error(`Invalid key format: ${e}`);
        return t.slice(1, t.length - 1).join(Io)
    }
    class Do {
        constructor(e) {
            if (!ie().getBool("IS_BROWSER") || "undefined" == typeof window || void 0 === window.localStorage)
                throw new Error("The current environment does not support local storage.");
            if (this.LS = window.localStorage,
            null == e || !e)
                throw new Error("For local storage, modelPath must not be null, undefined or empty.");
            this.modelPath = e,
            this.keys = Ao(this.modelPath)
        }
        async save(e) {
            if (e.modelTopology instanceof ArrayBuffer)
                throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
            {
                const t = JSON.stringify(e.modelTopology)
                  , n = JSON.stringify(e.weightSpecs)
                  , s = io(e);
                try {
                    this.LS.setItem(this.keys.info, JSON.stringify(s)),
                    this.LS.setItem(this.keys.topology, t),
                    this.LS.setItem(this.keys.weightSpecs, n),
                    this.LS.setItem(this.keys.weightData, function(e) {
                        if (Qi)
                            return Xi.from(e).toString("base64");
                        const t = new Uint8Array(e);
                        let n = "";
                        for (let e = 0, s = t.length; e < s; e++)
                            n += String.fromCharCode(t[e]);
                        return btoa(n)
                    }(e.weightData));
                    const r = {
                        format: e.format,
                        generatedBy: e.generatedBy,
                        convertedBy: e.convertedBy,
                        signature: null != e.signature ? e.signature : void 0,
                        userDefinedMetadata: null != e.userDefinedMetadata ? e.userDefinedMetadata : void 0,
                        modelInitializer: null != e.modelInitializer ? e.modelInitializer : void 0,
                        initializerSignature: null != e.initializerSignature ? e.initializerSignature : void 0,
                        trainingConfig: null != e.trainingConfig ? e.trainingConfig : void 0
                    };
                    return this.LS.setItem(this.keys.modelMetadata, JSON.stringify(r)),
                    {
                        modelArtifactsInfo: s
                    }
                } catch (e) {
                    throw Ro(this.keys),
                    new Error(`Failed to save model '${this.modelPath}' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=${s.modelTopologyBytes}, weightSpecsBytes=${s.weightSpecsBytes}, weightDataBytes=${s.weightDataBytes}.`)
                }
            }
        }
        async load() {
            const e = JSON.parse(this.LS.getItem(this.keys.info));
            if (null == e)
                throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);
            if ("JSON" !== e.modelTopologyType)
                throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");
            const t = {}
              , n = JSON.parse(this.LS.getItem(this.keys.topology));
            if (null == n)
                throw new Error(`In local storage, the topology of model '${this.modelPath}' is missing.`);
            t.modelTopology = n;
            const s = JSON.parse(this.LS.getItem(this.keys.weightSpecs));
            if (null == s)
                throw new Error(`In local storage, the weight specs of model '${this.modelPath}' are missing.`);
            t.weightSpecs = s;
            const r = this.LS.getItem(this.keys.modelMetadata);
            if (null != r) {
                const e = JSON.parse(r);
                t.format = e.format,
                t.generatedBy = e.generatedBy,
                t.convertedBy = e.convertedBy,
                null != e.signature && (t.signature = e.signature),
                null != e.userDefinedMetadata && (t.userDefinedMetadata = e.userDefinedMetadata),
                null != e.modelInitializer && (t.modelInitializer = e.modelInitializer),
                null != e.initializerSignature && (t.initializerSignature = e.initializerSignature),
                null != e.trainingConfig && (t.trainingConfig = e.trainingConfig)
            }
            const a = this.LS.getItem(this.keys.weightData);
            if (null == a)
                throw new Error(`In local storage, the binary weight values of model '${this.modelPath}' are missing.`);
            return t.weightData = function(e) {
                if (Qi) {
                    const t = Xi.from(e, "base64");
                    return t.buffer.slice(t.byteOffset, t.byteOffset + t.byteLength)
                }
                const t = atob(e)
                  , n = new Uint8Array(t.length);
                for (let e = 0; e < t.length; ++e)
                    n.set([t.charCodeAt(e)], e);
                return n.buffer
            }(a),
            t
        }
    }
    Do.URL_SCHEME = "localstorage://";
    const _o = e=>{
        return ie().getBool("IS_BROWSER") && !Array.isArray(e) && e.startsWith(Do.URL_SCHEME) ? (t = e.slice(Do.URL_SCHEME.length),
        new Do(t)) : null;
        var t
    }
    ;
    uo.registerSaveRouter(_o),
    uo.registerLoadRouter(_o);
    class Oo {
        constructor() {
            b(ie().getBool("IS_BROWSER"), (()=>"Current environment is not a web browser")),
            b("undefined" == typeof window || void 0 !== window.localStorage, (()=>"Current browser does not appear to support localStorage")),
            this.LS = window.localStorage
        }
        async listModels() {
            const e = {}
              , t = So + Io
              , n = Io + No;
            for (let s = 0; s < this.LS.length; ++s) {
                const r = this.LS.key(s);
                if (r.startsWith(t) && r.endsWith(n)) {
                    e[Fo(r)] = JSON.parse(this.LS.getItem(r))
                }
            }
            return e
        }
        async removeModel(e) {
            var t;
            const n = Ao(e = (t = e).startsWith(Do.URL_SCHEME) ? t.slice(Do.URL_SCHEME.length) : t);
            if (null == this.LS.getItem(n.info))
                throw new Error(`Cannot find model at path '${e}'`);
            const s = JSON.parse(this.LS.getItem(n.info));
            return Ro(n),
            s
        }
    }
    const Mo = "://";
    class Lo {
        constructor() {
            this.managers = {}
        }
        static getInstance() {
            return null == Lo.instance && (Lo.instance = new Lo),
            Lo.instance
        }
        static registerManager(e, t) {
            b(null != e, (()=>"scheme must not be undefined or null.")),
            e.endsWith(Mo) && (e = e.slice(0, e.indexOf(Mo))),
            b(e.length > 0, (()=>"scheme must not be an empty string."));
            const n = Lo.getInstance();
            b(null == n.managers[e], (()=>`A model store manager is already registered for scheme '${e}'.`)),
            n.managers[e] = t
        }
        static getManager(e) {
            const t = Lo.getInstance().managers[e];
            if (null == t)
                throw new Error(`Cannot find model manager for scheme '${e}'`);
            return t
        }
        static getSchemes() {
            return Object.keys(Lo.getInstance().managers)
        }
    }
    function zo(e) {
        if (-1 === e.indexOf(Mo))
            throw new Error(`The url string provided does not contain a scheme. Supported schemes are: ${Lo.getSchemes().join(",")}`);
        return {
            scheme: e.split(Mo)[0],
            path: e.split(Mo)[1]
        }
    }
    async function Bo(e, t, n=!1) {
        b(e !== t, (()=>`Old path and new path are the same: '${e}'`));
        const s = uo.getLoadHandlers(e);
        b(s.length > 0, (()=>`Copying failed because no load handler is found for source URL ${e}.`)),
        b(s.length < 2, (()=>`Copying failed because more than one (${s.length}) load handlers for source URL ${e}.`));
        const r = s[0]
          , a = uo.getSaveHandlers(t);
        b(a.length > 0, (()=>`Copying failed because no save handler is found for destination URL ${t}.`)),
        b(a.length < 2, (()=>`Copying failed because more than one (${s.length}) save handlers for destination URL ${t}.`));
        const i = a[0]
          , o = zo(e).scheme
          , l = zo(e).path
          , u = o === zo(e).scheme
          , c = await r.load();
        n && u && await Lo.getManager(o).removeModel(l);
        const h = await i.save(c);
        return n && !u && await Lo.getManager(o).removeModel(l),
        h.modelArtifactsInfo
    }
    async function Po() {
        const e = Lo.getSchemes()
          , t = {};
        for (const n of e) {
            const e = await Lo.getManager(n).listModels();
            for (const s in e) {
                t[n + Mo + s] = e[s]
            }
        }
        return t
    }
    async function Wo(e) {
        const t = zo(e);
        return Lo.getManager(t.scheme).removeModel(t.path)
    }
    async function Uo(e, t) {
        return Bo(e, t, !1)
    }
    async function Vo(e, t) {
        return Bo(e, t, !0)
    }
    class Go {
        constructor() {
            this.messageName = "setTimeoutCustom",
            this.functionRefs = [],
            this.handledMessageCount = 0,
            this.hasEventListener = !1
        }
        fetch(e, t) {
            return fetch(e, t)
        }
        now() {
            return performance.now()
        }
        encode(e, t) {
            if ("utf-8" !== t && "utf8" !== t)
                throw new Error(`Browser's encoder only supports utf-8, but got ${t}`);
            return null == this.textEncoder && (this.textEncoder = new TextEncoder),
            this.textEncoder.encode(e)
        }
        decode(e, t) {
            return new TextDecoder(t).decode(e)
        }
        setTimeoutCustom(e, t) {
            "undefined" != typeof window && ie().getBool("USE_SETTIMEOUTCUSTOM") ? (this.functionRefs.push(e),
            setTimeout((()=>{
                window.postMessage({
                    name: this.messageName,
                    index: this.functionRefs.length - 1
                }, "*")
            }
            ), t),
            this.hasEventListener || (this.hasEventListener = !0,
            window.addEventListener("message", (e=>{
                if (e.source === window && e.data.name === this.messageName) {
                    e.stopPropagation();
                    (0,
                    this.functionRefs[e.data.index])(),
                    this.handledMessageCount++,
                    this.handledMessageCount === this.functionRefs.length && (this.functionRefs = [],
                    this.handledMessageCount = 0)
                }
            }
            ), !0))) : setTimeout(e, t)
        }
        isTypedArray(e) {
            return e instanceof Float32Array || e instanceof Int32Array || e instanceof Uint8Array || e instanceof Uint8ClampedArray
        }
    }
    if (ie().get("IS_BROWSER")) {
        ie().setPlatform("browser", new Go);
        try {
            Lo.registerManager(Do.URL_SCHEME, new Oo)
        } catch (e) {}
        try {
            Lo.registerManager(wo.URL_SCHEME, new ko)
        } catch (e) {}
    }
    const Ho = ()=>a("foUwZ");
    let jo;
    function qo(e, t="float32", n) {
        return t = t || "float32",
        Q(e),
        new qr(e,t,n)
    }
    ie().get("IS_NODE") && !ie().get("IS_BROWSER") && ie().setPlatform("node", new class {
        constructor() {
            this.util = a("foUwZ"),
            this.textEncoder = new this.util.TextEncoder
        }
        fetch(e, t) {
            return null != ie().global.fetch ? ie().global.fetch(e, t) : (null == jo && (jo = Ho()),
            jo(e, t))
        }
        now() {
            const e = ce.hrtime();
            return 1e3 * e[0] + e[1] / 1e6
        }
        encode(e, t) {
            if ("utf-8" !== t && "utf8" !== t)
                throw new Error(`Node built-in encoder only supports utf-8, but got ${t}`);
            return this.textEncoder.encode(e)
        }
        decode(e, t) {
            return 0 === e.length ? "" : new this.util.TextDecoder(t).decode(e)
        }
        isTypedArray(e) {
            return this.util.types.isFloat32Array(e) || this.util.types.isInt32Array(e) || this.util.types.isUint8Array(e) || this.util.types.isUint8ClampedArray(e)
        }
    }
    );
    const Ko = Ma({
        cast_: function(e, t) {
            const n = Da(e, "x", "cast");
            if (!M(t))
                throw new Error(`Failed to cast to unknown dtype ${t}`);
            if ("string" === t && "string" !== n.dtype || "string" !== t && "string" === n.dtype)
                throw new Error("Only strings can be casted to strings");
            const s = {
                x: n
            }
              , r = {
                dtype: t
            };
            return ka.runKernel(Ke, s, r)
        }
    });
    const Xo = Ma({
        clone_: function(e) {
            const t = {
                x: Da(e, "x", "clone", "string_or_numeric")
            };
            return ka.runKernel(Bt, t)
        }
    });
    function Yo(e, t=!1) {
        console.log(e.toString(t))
    }
    va();
    function Zo() {
        return ka
    }
    function Jo() {
        return ka.memory()
    }
    function Qo(e, t) {
        return ka.tidy(e, t)
    }
    function el(e) {
        ga(e).forEach((e=>e.dispose()))
    }
    function tl(e) {
        return ka.keep(e)
    }
    function nl(e, t, n=1) {
        return ka.registerBackend(e, t, n)
    }
    Xr = {
        buffer: qo,
        cast: Ko,
        clone: Xo,
        print: Yo
    },
    Yr = function(e) {
        ie().getBool("DEPRECATION_WARNINGS_ENABLED") && console.warn(e + " You can disable deprecation warnings with tf.disableDeprecationWarnings().")
    }
    ;
    const sl = Ma({
        add_: function(e, t) {
            let n = Da(e, "a", "add")
              , s = Da(t, "b", "add");
            [n,s] = da(n, s);
            const r = {
                a: n,
                b: s
            };
            return ka.runKernel(Ee, r)
        }
    });
    const rl = Ma({
        floorDiv_: function(e, t) {
            let n = Da(e, "a", "floorDiv")
              , s = Da(t, "b", "floorDiv");
            [n,s] = da(n, s);
            const r = {
                a: n,
                b: s
            };
            return ka.runKernel(Dt, r)
        }
    });
    const al = Ma({
        div_: function(e, t) {
            let n = Da(e, "a", "div")
              , s = Da(t, "b", "div");
            if ([n,s] = da(n, s),
            "int32" === n.dtype && "int32" === s.dtype)
                return rl(n, s);
            const r = {
                a: n,
                b: s
            };
            return ka.runKernel(wt, r, {})
        }
    });
    const il = Ma({
        mul_: function(e, t) {
            let n = Da(e, "a", "mul")
              , s = Da(t, "b", "mul");
            [n,s] = da(n, s);
            const r = {
                a: n,
                b: s
            };
            return ka.runKernel(gn, r)
        }
    });
    var ol = {};
    t(ol, "spectral", (()=>ef)),
    t(ol, "signal", (()=>tf)),
    t(ol, "image", (()=>nf)),
    t(ol, "linalg", (()=>sf)),
    t(ol, "losses", (()=>rf)),
    t(ol, "sparse", (()=>af)),
    t(ol, "string", (()=>of)),
    t(ol, "abs", (()=>uc)),
    t(ol, "acos", (()=>oh)),
    t(ol, "acosh", (()=>lh)),
    t(ol, "add", (()=>sl)),
    t(ol, "addN", (()=>uh)),
    t(ol, "all", (()=>ch)),
    t(ol, "any", (()=>hh)),
    t(ol, "argMax", (()=>ph)),
    t(ol, "argMin", (()=>dh)),
    t(ol, "asin", (()=>fh)),
    t(ol, "asinh", (()=>mh)),
    t(ol, "atan", (()=>gh)),
    t(ol, "atan2", (()=>yh)),
    t(ol, "atanh", (()=>bh)),
    t(ol, "avgPool", (()=>xh)),
    t(ol, "avgPool3d", (()=>wh)),
    t(ol, "basicLSTMCell", (()=>kh)),
    t(ol, "batchToSpaceND", (()=>Ih)),
    t(ol, "batchNorm", (()=>Sh)),
    t(ol, "batchNorm2d", (()=>Nh)),
    t(ol, "batchNorm3d", (()=>Th)),
    t(ol, "batchNorm4d", (()=>Ch)),
    t(ol, "bincount", (()=>qu)),
    t(ol, "broadcastArgs", (()=>$h)),
    t(ol, "broadcastTo", (()=>Ju)),
    t(ol, "buffer", (()=>qo)),
    t(ol, "cast", (()=>Ko)),
    t(ol, "ceil", (()=>Eh)),
    t(ol, "clipByValue", (()=>Ah)),
    t(ol, "clone", (()=>Xo)),
    t(ol, "complex", (()=>La)),
    t(ol, "concat", (()=>ll)),
    t(ol, "concat1d", (()=>Rh)),
    t(ol, "concat2d", (()=>Fh)),
    t(ol, "concat3d", (()=>Dh)),
    t(ol, "concat4d", (()=>_h)),
    t(ol, "conv1d", (()=>Oh)),
    t(ol, "conv2d", (()=>Hl)),
    t(ol, "conv2dTranspose", (()=>Mh)),
    t(ol, "conv3d", (()=>Lh)),
    t(ol, "conv3dTranspose", (()=>Bh)),
    t(ol, "cos", (()=>Ph)),
    t(ol, "cosh", (()=>Wh)),
    t(ol, "cumprod", (()=>Uh)),
    t(ol, "cumsum", (()=>Vh)),
    t(ol, "denseBincount", (()=>Gh)),
    t(ol, "depthToSpace", (()=>Hh)),
    t(ol, "depthwiseConv2d", (()=>lu)),
    t(ol, "diag", (()=>jh)),
    t(ol, "dilation2d", (()=>qh)),
    t(ol, "div", (()=>al)),
    t(ol, "divNoNan", (()=>Xh)),
    t(ol, "dot", (()=>Yh)),
    t(ol, "einsum", (()=>Zh)),
    t(ol, "elu", (()=>Xl)),
    t(ol, "equal", (()=>Kh)),
    t(ol, "erf", (()=>Jh)),
    t(ol, "euclideanNorm", (()=>Qh)),
    t(ol, "exp", (()=>Xc)),
    t(ol, "expandDims", (()=>$c)),
    t(ol, "expm1", (()=>ep)),
    t(ol, "eye", (()=>Ec)),
    t(ol, "fill", (()=>wu)),
    t(ol, "floor", (()=>tp)),
    t(ol, "floorDiv", (()=>rl)),
    t(ol, "gather", (()=>np)),
    t(ol, "greater", (()=>Xu)),
    t(ol, "greaterEqual", (()=>sc)),
    t(ol, "imag", (()=>ul)),
    t(ol, "isFinite", (()=>sp)),
    t(ol, "isInf", (()=>rp)),
    t(ol, "isNaN", (()=>ap)),
    t(ol, "leakyRelu", (()=>Yl)),
    t(ol, "less", (()=>ip)),
    t(ol, "lessEqual", (()=>Ku)),
    t(ol, "linspace", (()=>op)),
    t(ol, "localResponseNormalization", (()=>lp)),
    t(ol, "log", (()=>Hc)),
    t(ol, "log1p", (()=>Yc)),
    t(ol, "logSigmoid", (()=>cp)),
    t(ol, "logSoftmax", (()=>hp)),
    t(ol, "logSumExp", (()=>Jc)),
    t(ol, "logicalAnd", (()=>rc)),
    t(ol, "logicalNot", (()=>pp)),
    t(ol, "logicalOr", (()=>dp)),
    t(ol, "logicalXor", (()=>fp)),
    t(ol, "lowerBound", (()=>bp)),
    t(ol, "matMul", (()=>pu)),
    t(ol, "max", (()=>xc)),
    t(ol, "maxPool", (()=>xp)),
    t(ol, "maxPool3d", (()=>wp)),
    t(ol, "maxPoolWithArgmax", (()=>vp)),
    t(ol, "maximum", (()=>kp)),
    t(ol, "mean", (()=>Mc)),
    t(ol, "meshgrid", (()=>Ip)),
    t(ol, "min", (()=>wc)),
    t(ol, "minimum", (()=>Vc)),
    t(ol, "mirrorPad", (()=>Sp)),
    t(ol, "mod", (()=>Np)),
    t(ol, "moments", (()=>Tp)),
    t(ol, "mul", (()=>il)),
    t(ol, "multiRNNCell", (()=>Cp)),
    t(ol, "multinomial", (()=>$p)),
    t(ol, "neg", (()=>Ac)),
    t(ol, "notEqual", (()=>Lc)),
    t(ol, "oneHot", (()=>Ep)),
    t(ol, "ones", (()=>zc)),
    t(ol, "onesLike", (()=>Ap)),
    t(ol, "outerProduct", (()=>Rp)),
    t(ol, "pad", (()=>Fp)),
    t(ol, "pad1d", (()=>Dp)),
    t(ol, "pad2d", (()=>_p)),
    t(ol, "pad3d", (()=>Op)),
    t(ol, "pad4d", (()=>Mp)),
    t(ol, "pool", (()=>zp)),
    t(ol, "pow", (()=>vc)),
    t(ol, "prelu", (()=>Zl)),
    t(ol, "print", (()=>Yo)),
    t(ol, "prod", (()=>Bp)),
    t(ol, "raggedGather", (()=>Pp)),
    t(ol, "raggedRange", (()=>Wp)),
    t(ol, "raggedTensorToTensor", (()=>Up)),
    t(ol, "rand", (()=>Vp)),
    t(ol, "randomGamma", (()=>td)),
    t(ol, "randomNormal", (()=>nd)),
    t(ol, "randomStandardNormal", (()=>sd)),
    t(ol, "randomUniform", (()=>rd)),
    t(ol, "range", (()=>ec)),
    t(ol, "real", (()=>cl)),
    t(ol, "reciprocal", (()=>ad)),
    t(ol, "relu", (()=>Jl)),
    t(ol, "relu6", (()=>Ql)),
    t(ol, "reshape", (()=>hl)),
    t(ol, "reverse", (()=>xl)),
    t(ol, "reverse1d", (()=>id)),
    t(ol, "reverse2d", (()=>od)),
    t(ol, "reverse3d", (()=>ld)),
    t(ol, "reverse4d", (()=>ud)),
    t(ol, "round", (()=>Zu)),
    t(ol, "rsqrt", (()=>cd)),
    t(ol, "scalar", (()=>wl)),
    t(ol, "selu", (()=>hd)),
    t(ol, "separableConv2d", (()=>pd)),
    t(ol, "setdiff1dAsync", (()=>dd)),
    t(ol, "sigmoid", (()=>eu)),
    t(ol, "sign", (()=>fd)),
    t(ol, "sin", (()=>md)),
    t(ol, "sinh", (()=>gd)),
    t(ol, "slice", (()=>pl)),
    t(ol, "slice1d", (()=>yd)),
    t(ol, "slice2d", (()=>bd)),
    t(ol, "slice3d", (()=>xd)),
    t(ol, "slice4d", (()=>wd)),
    t(ol, "softmax", (()=>vd)),
    t(ol, "softplus", (()=>up)),
    t(ol, "spaceToBatchND", (()=>Lp)),
    t(ol, "fft", (()=>gl)),
    t(ol, "ifft", (()=>bl)),
    t(ol, "irfft", (()=>vl)),
    t(ol, "rfft", (()=>yl)),
    t(ol, "split", (()=>dl)),
    t(ol, "sqrt", (()=>kc)),
    t(ol, "square", (()=>Ic)),
    t(ol, "squaredDifference", (()=>qc)),
    t(ol, "squeeze", (()=>Tc)),
    t(ol, "stack", (()=>ac)),
    t(ol, "step", (()=>tu)),
    t(ol, "stridedSlice", (()=>kd)),
    t(ol, "sub", (()=>Yu)),
    t(ol, "sum", (()=>nu)),
    t(ol, "tan", (()=>Id)),
    t(ol, "tanh", (()=>vh)),
    t(ol, "tensor", (()=>Ba)),
    t(ol, "tensor1d", (()=>mu)),
    t(ol, "tensor2d", (()=>vu)),
    t(ol, "tensor3d", (()=>Sd)),
    t(ol, "tensor4d", (()=>Nd)),
    t(ol, "tensor5d", (()=>Td)),
    t(ol, "tensor6d", (()=>Cd)),
    t(ol, "tile", (()=>Tu)),
    t(ol, "topk", (()=>$d)),
    t(ol, "truncatedNormal", (()=>Ed)),
    t(ol, "unique", (()=>Ad)),
    t(ol, "unsortedSegmentSum", (()=>Rd)),
    t(ol, "unstack", (()=>ic)),
    t(ol, "upperBound", (()=>Fd)),
    t(ol, "variable", (()=>Dd)),
    t(ol, "where", (()=>Qu)),
    t(ol, "whereAsync", (()=>Od)),
    t(ol, "zeros", (()=>fl)),
    t(ol, "zerosLike", (()=>ml)),
    t(ol, "op", (()=>Ma)),
    t(ol, "OP_SCOPE_SUFFIX", (()=>Oa)),
    t(ol, "fused", (()=>kl));
    const ll = Ma({
        concat_: function(e, t=0) {
            b(e.length >= 1, (()=>"Pass at least one tensor to concat"));
            const n = _a(e, "tensors", "concat", "string_or_numeric");
            if ("complex64" === n[0].dtype && n.forEach((e=>{
                if ("complex64" !== e.dtype)
                    throw new Error(`Cannot concatenate complex64 tensors with a tensor\n          with dtype ${e.dtype}. `)
            }
            )),
            1 === n.length)
                return Xo(n[0]);
            const s = n
              , r = {
                axis: t
            };
            return ka.runKernel(Qe, s, r)
        }
    });
    const ul = Ma({
        imag_: function(e) {
            const t = {
                input: Da(e, "input", "imag")
            };
            return ka.runKernel(Wt, t)
        }
    });
    const cl = Ma({
        real_: function(e) {
            const t = {
                input: Da(e, "input", "real")
            };
            return ka.runKernel(Dn, t)
        }
    });
    const hl = Ma({
        reshape_: function(e, t) {
            const n = {
                x: Da(e, "x", "reshape", "string_or_numeric")
            }
              , s = {
                shape: t
            };
            return ka.runKernel(Mn, n, s)
        }
    });
    const pl = Ma({
        slice_: function(e, t, n) {
            const s = Da(e, "x", "slice", "string_or_numeric");
            if (0 === s.rank)
                throw new Error("Slicing scalar is not possible");
            const r = {
                x: s
            }
              , a = {
                begin: t,
                size: n
            };
            return ka.runKernel(Xn, r, a)
        }
    });
    const dl = Ma({
        split_: function(e, t, n=0) {
            const s = {
                x: Da(e, "x", "split")
            }
              , r = {
                numOrSizeSplits: t,
                axis: n
            };
            return ka.runKernel(rs, s, r)
        }
    });
    function fl(e, t="float32") {
        if (Q(e),
        "complex64" === t) {
            const t = fl(e, "float32")
              , n = fl(e, "float32");
            return La(t, n)
        }
        const n = Z(v(e), t);
        return ka.makeTensor(n, e, t)
    }
    const ml = Ma({
        zerosLike_: function(e) {
            const t = {
                x: Da(e, "x", "zerosLike")
            };
            return ka.runKernel(Cs, t)
        }
    });
    const gl = Ma({
        fft_: function(e) {
            b("complex64" === e.dtype, (()=>`The dtype for tf.spectral.fft() must be complex64 but got ${e.dtype}.`));
            const t = {
                input: e
            };
            return ka.runKernel(Et, t)
        }
    });
    const yl = Ma({
        rfft_: function(e, t) {
            b("float32" === e.dtype, (()=>`The dtype for rfft() must be real value but got ${e.dtype}`));
            let n = e.shape[e.shape.length - 1];
            const s = e.size / n;
            let r;
            if (null != t && t < n) {
                const s = e.shape.map((e=>0))
                  , a = e.shape.map((e=>e));
                a[e.shape.length - 1] = t,
                r = pl(e, s, a),
                n = t
            } else if (null != t && t > n) {
                const s = e.shape.map((e=>e));
                s[e.shape.length - 1] = t - n,
                r = ll([e, fl(s)], e.shape.length - 1),
                n = t
            } else
                r = e;
            const a = ml(r)
              , i = hl(La(r, a), [s, n])
              , o = gl(i)
              , l = Math.floor(n / 2) + 1
              , u = cl(o)
              , c = ul(o)
              , h = dl(u, [l, n - l], u.shape.length - 1)
              , p = dl(c, [l, n - l], c.shape.length - 1)
              , d = r.shape.slice();
            return d[r.shape.length - 1] = l,
            hl(La(h[0], p[0]), d)
        }
    });
    const bl = Ma({
        ifft_: function(e) {
            b("complex64" === e.dtype, (()=>`The dtype for tf.spectral.ifft() must be complex64 but got ${e.dtype}.`));
            const t = {
                input: e
            };
            return ka.runKernel(Pt, t)
        }
    });
    const xl = Ma({
        reverse_: function(e, t) {
            const n = {
                x: Da(e, "x", "reverse")
            }
              , s = {
                dims: t
            };
            return ka.runKernel(Un, n, s)
        }
    });
    function wl(e, t) {
        if ((Lr(e) && "string" !== t || Array.isArray(e)) && "complex64" !== t)
            throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");
        if ("string" === t && Lr(e) && !(e instanceof Uint8Array))
            throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");
        return za(e, [], [], t)
    }
    const vl = Ma({
        irfft_: function(e) {
            const t = e.shape[e.shape.length - 1]
              , n = e.size / t;
            let s;
            if (t <= 2) {
                const r = hl(e, [n, t]);
                s = bl(r)
            } else {
                const r = [n, 2 * (t - 1)]
                  , a = hl(cl(e), [n, t])
                  , i = hl(ul(e), [n, t])
                  , o = xl(pl(a, [0, 1], [n, t - 2]), 1)
                  , l = il(xl(pl(i, [0, 1], [n, t - 2]), 1), wl(-1))
                  , u = ll([a, o], 1)
                  , c = ll([i, l], 1)
                  , h = hl(La(u, c), [r[0], r[1]]);
                s = bl(h)
            }
            if (s = cl(s),
            3 === e.rank && 0 !== e.shape[0]) {
                const t = s
                  , n = e.shape[0];
                s = hl(s, [n, s.shape[0] / n, s.shape[1]]),
                t.dispose()
            }
            return s
        }
    });
    var kl = {};
    function Il(e, t) {
        b(G(e), (()=>"The f passed in variableGrads(f) must be a function")),
        b(null == t || Array.isArray(t) && t.every((e=>e instanceof Qr)), (()=>"The varList passed in variableGrads(f, varList) must be an array of variables"));
        const n = null != t;
        if (!n) {
            t = [];
            for (const e in ka.registeredVariables)
                t.push(ka.registeredVariables[e])
        }
        const s = n ? t.filter((e=>!e.trainable)) : null
          , r = t.length;
        b((t = t.filter((e=>e.trainable))).length > 0, (()=>`variableGrads() expects at least one of the input variables to be trainable, but none of the ${r} variables is trainable.`));
        const {value: a, grads: i} = ka.gradients(e, t, null, !0);
        b(i.some((e=>null != e)), (()=>"Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize().")),
        b(0 === a.rank, (()=>`The f passed in variableGrads(f) must return a scalar, but it returned a rank-${a.rank} tensor`));
        const o = {};
        return t.forEach(((e,t)=>{
            null != i[t] && (o[e.name] = i[t])
        }
        )),
        null != s && s.forEach((e=>o[e.name] = null)),
        {
            value: a,
            grads: o
        }
    }
    function Sl(e) {
        return ka.customGrad(e)
    }
    t(kl, "conv2d", (()=>ou)),
    t(kl, "depthwiseConv2d", (()=>hu)),
    t(kl, "matMul", (()=>du));
    var Nl = {};
    function Tl(e, t) {
        const n = e.length
          , s = [];
        for (let r = 0; r < n; r++) {
            const a = n - 1 - r
              , i = e[a] || 1;
            (t[t.length - 1 - r] || 1) > 1 && 1 === i && s.unshift(a)
        }
        return s
    }
    function Cl(e, t) {
        const n = [];
        for (let s = 0; s < t.length; s++) {
            const r = e[e.length - s - 1]
              , a = t.length - s - 1
              , i = t[a];
            (null == r || 1 === r && i > 1) && n.unshift(a)
        }
        return n
    }
    function $l(e, t) {
        const n = []
          , s = Math.max(e.length, t.length);
        for (let r = 0; r < s; r++) {
            let s = e[e.length - r - 1];
            null == s && (s = 1);
            let a = t[t.length - r - 1];
            if (null == a && (a = 1),
            1 === s)
                n.unshift(a);
            else if (1 === a)
                n.unshift(s);
            else {
                if (s !== a) {
                    throw Error(`Operands could not be broadcast together with shapes ${e} and ${t}.`)
                }
                n.unshift(s)
            }
        }
        return n
    }
    t(Nl, "getBroadcastDims", (()=>Tl)),
    t(Nl, "getReductionAxes", (()=>Cl)),
    t(Nl, "assertAndGetBroadcastShape", (()=>$l));
    var El = {};
    function Al(e, t, n, s, r="NHWC", a) {
        return Dl(e, [...t, e[3]], n, a, s, null, null, Vl(r))
    }
    function Rl(e, t, n, s, r, a, i="channelsLast") {
        const [o,l] = Ml(t);
        let u;
        if ("channelsLast" === i)
            u = [o, l, e[3], e[3]];
        else {
            if ("channelsFirst" !== i)
                throw new Error(`Unknown dataFormat ${i}`);
            u = [o, l, e[1], e[1]]
        }
        return Dl(e, u, n, s, r, a, !1, i)
    }
    function Fl(e, t, n, s, r, a, i="NDHWC") {
        const [o,l,u] = Ll(t);
        let c, h;
        if ("NDHWC" === i)
            h = "channelsLast",
            c = [o, l, u, e[4], e[4]];
        else {
            if ("NCDHW" !== i)
                throw new Error(`Unknown dataFormat ${i}`);
            h = "channelsFirst",
            c = [o, l, u, e[1], e[1]]
        }
        return _l(e, c, n, s, r, !1, h, a)
    }
    function Dl(e, t, n, s, r, a, i=!1, o="channelsLast") {
        let[l,u,c,h] = [-1, -1, -1, -1];
        if ("channelsLast" === o)
            [l,u,c,h] = e;
        else {
            if ("channelsFirst" !== o)
                throw new Error(`Unknown dataFormat ${o}`);
            [l,h,u,c] = e
        }
        const [p,d,,f] = t
          , [m,g] = Ml(n)
          , [y,b] = Ml(s)
          , x = zl(p, y)
          , w = zl(d, b)
          , {padInfo: v, outHeight: k, outWidth: I} = function(e, t, n, s, r, a, i, o, l) {
            let u, c, h;
            if ("number" == typeof e) {
                u = {
                    top: e,
                    bottom: e,
                    left: e,
                    right: e,
                    type: 0 === e ? "VALID" : "NUMBER"
                };
                const r = function(e, t, n, s, r) {
                    null == s && (s = Ol(e, t, n));
                    const a = e[0]
                      , i = e[1]
                      , o = Bl((a - t + 2 * s) / n + 1, r)
                      , l = Bl((i - t + 2 * s) / n + 1, r);
                    return [o, l]
                }([t, n], a, s, e, o);
                c = r[0],
                h = r[1]
            } else if ("same" === e) {
                c = Math.ceil(t / s),
                h = Math.ceil(n / r);
                const e = Math.max(0, (c - 1) * s + a - t)
                  , o = Math.max(0, (h - 1) * r + i - n)
                  , l = Math.floor(e / 2)
                  , p = e - l
                  , d = Math.floor(o / 2);
                u = {
                    top: l,
                    bottom: p,
                    left: d,
                    right: o - d,
                    type: "SAME"
                }
            } else if ("valid" === e)
                u = {
                    top: 0,
                    bottom: 0,
                    left: 0,
                    right: 0,
                    type: "VALID"
                },
                c = Math.ceil((t - a + 1) / s),
                h = Math.ceil((n - i + 1) / r);
            else {
                if ("object" != typeof e)
                    throw Error(`Unknown padding parameter: ${e}`);
                {
                    const p = "channelsLast" === l ? e[1][0] : e[2][0]
                      , d = "channelsLast" === l ? e[1][1] : e[2][1]
                      , f = "channelsLast" === l ? e[2][0] : e[3][0]
                      , m = "channelsLast" === l ? e[2][1] : e[3][1];
                    u = {
                        top: p,
                        bottom: d,
                        left: f,
                        right: m,
                        type: 0 === p && 0 === d && 0 === f && 0 === m ? "VALID" : "EXPLICIT"
                    },
                    c = Bl((t - a + p + d) / s + 1, o),
                    h = Bl((n - i + f + m) / r + 1, o)
                }
            }
            return {
                padInfo: u,
                outHeight: c,
                outWidth: h
            }
        }(r, u, c, m, g, x, w, a, o)
          , S = i ? f * h : f;
        let N;
        return "channelsFirst" === o ? N = [l, S, k, I] : "channelsLast" === o && (N = [l, k, I, S]),
        {
            batchSize: l,
            dataFormat: o,
            inHeight: u,
            inWidth: c,
            inChannels: h,
            outHeight: k,
            outWidth: I,
            outChannels: S,
            padInfo: v,
            strideHeight: m,
            strideWidth: g,
            filterHeight: p,
            filterWidth: d,
            effectiveFilterHeight: x,
            effectiveFilterWidth: w,
            dilationHeight: y,
            dilationWidth: b,
            inShape: e,
            outShape: N,
            filterShape: t
        }
    }
    function _l(e, t, n, s, r, a=!1, i="channelsLast", o) {
        let[l,u,c,h,p] = [-1, -1, -1, -1, -1];
        if ("channelsLast" === i)
            [l,u,c,h,p] = e;
        else {
            if ("channelsFirst" !== i)
                throw new Error(`Unknown dataFormat ${i}`);
            [l,p,u,c,h] = e
        }
        const [d,f,m,,g] = t
          , [y,b,x] = Ll(n)
          , [w,v,k] = Ll(s)
          , I = zl(d, w)
          , S = zl(f, v)
          , N = zl(m, k)
          , {padInfo: T, outDepth: C, outHeight: $, outWidth: E} = function(e, t, n, s, r, a, i, o, l, u, c) {
            let h, p, d, f;
            "valid" === e && (e = 0);
            if ("number" == typeof e) {
                h = {
                    top: e,
                    bottom: e,
                    left: e,
                    right: e,
                    front: e,
                    back: e,
                    type: 0 === e ? "VALID" : "NUMBER"
                };
                const m = function(e, t, n, s, r, a) {
                    null == r && (r = Ol(e, t[0], s[0]));
                    const i = [0, 0, 0, n];
                    for (let n = 0; n < 3; n++)
                        e[n] + 2 * r >= t[n] && (i[n] = Bl((e[n] - t[n] + 2 * r) / s[n] + 1, a));
                    return i
                }([t, n, s, 1], [o, l, u], 1, [r, a, i], e, c);
                p = m[0],
                d = m[1],
                f = m[2]
            } else {
                if ("same" !== e)
                    throw Error(`Unknown padding parameter: ${e}`);
                {
                    p = Math.ceil(t / r),
                    d = Math.ceil(n / a),
                    f = Math.ceil(s / i);
                    const e = (p - 1) * r + o - t
                      , c = (d - 1) * a + l - n
                      , m = (f - 1) * i + u - s
                      , g = Math.floor(e / 2)
                      , y = e - g
                      , b = Math.floor(c / 2)
                      , x = c - b
                      , w = Math.floor(m / 2);
                    h = {
                        top: b,
                        bottom: x,
                        left: w,
                        right: m - w,
                        front: g,
                        back: y,
                        type: "SAME"
                    }
                }
            }
            return {
                padInfo: h,
                outDepth: p,
                outHeight: d,
                outWidth: f
            }
        }(r, u, c, h, y, b, x, I, S, N, o)
          , A = a ? g * p : g;
        let R;
        return "channelsFirst" === i ? R = [l, A, C, $, E] : "channelsLast" === i && (R = [l, C, $, E, A]),
        {
            batchSize: l,
            dataFormat: i,
            inDepth: u,
            inHeight: c,
            inWidth: h,
            inChannels: p,
            outDepth: C,
            outHeight: $,
            outWidth: E,
            outChannels: A,
            padInfo: T,
            strideDepth: y,
            strideHeight: b,
            strideWidth: x,
            filterDepth: d,
            filterHeight: f,
            filterWidth: m,
            effectiveFilterDepth: I,
            effectiveFilterHeight: S,
            effectiveFilterWidth: N,
            dilationDepth: w,
            dilationHeight: v,
            dilationWidth: k,
            inShape: e,
            outShape: R,
            filterShape: t
        }
    }
    function Ol(e, t, n, s=1) {
        const r = zl(t, s);
        return Math.floor((e[0] * (n - 1) - n + r) / 2)
    }
    function Ml(e) {
        return "number" == typeof e ? [e, e, e] : 2 === e.length ? [e[0], e[1], 1] : e
    }
    function Ll(e) {
        return "number" == typeof e ? [e, e, e] : e
    }
    function zl(e, t) {
        return t <= 1 ? e : e + (e - 1) * (t - 1)
    }
    function Bl(e, t) {
        if (!t)
            return Math.trunc(e);
        switch (t) {
        case "round":
            return Math.round(e);
        case "ceil":
            return Math.ceil(e);
        case "floor":
            return Math.floor(e);
        default:
            throw new Error(`Unknown roundingMode ${t}`)
        }
    }
    function Pl(e) {
        const [t,n,s] = Ml(e);
        return 1 === t && 1 === n && 1 === s
    }
    function Wl(e, t) {
        return Pl(e) || Pl(t)
    }
    function Ul(e) {
        return Ml(e).every((e=>e > 0))
    }
    function Vl(e) {
        if ("NHWC" === e)
            return "channelsLast";
        if ("NCHW" === e)
            return "channelsFirst";
        throw new Error(`Unknown dataFormat ${e}`)
    }
    function Gl(e, t, n) {
        if (null != n) {
            if ("string" == typeof t)
                throw Error(`Error in ${e}: pad must be an integer when using dimRoundingMode ${n} but got pad ${t}.`);
            if ("number" == typeof t)
                b(S(t), (()=>`Error in ${e}: pad must be an integer when using dimRoundingMode ${n} but got pad ${t}.`));
            else {
                if ("object" != typeof t)
                    throw Error(`Error in ${e}: Unknown padding parameter: ${t}`);
                t.forEach((t=>{
                    t.forEach((t=>{
                        b(S(t), (()=>`Error in ${e}: pad must be an integer when using dimRoundingMode ${n} but got pad ${t}.`))
                    }
                    ))
                }
                ))
            }
        }
    }
    t(El, "computeDilation2DInfo", (()=>Al)),
    t(El, "convertConv2DDataFormat", (()=>Vl)),
    t(El, "computeConv2DInfo", (()=>Dl)),
    t(El, "computePool2DInfo", (()=>Rl)),
    t(El, "computePool3DInfo", (()=>Fl)),
    t(El, "computeConv3DInfo", (()=>_l)),
    t(El, "computeDefaultPad", (()=>Ol)),
    t(El, "tupleValuesAreOne", (()=>Pl)),
    t(El, "eitherStridesOrDilationsAreOne", (()=>Wl)),
    t(El, "stridesOrDilationsArePositive", (()=>Ul)),
    t(El, "checkPadOnDimRoundingMode", (()=>Gl));
    const Hl = Ma({
        conv2d_: function(e, t, n, s, r="NHWC", a=[1, 1], i) {
            const o = Da(e, "x", "conv2d", "float32")
              , l = Da(t, "filter", "conv2d", "float32");
            let u = o
              , c = !1;
            3 === o.rank && (c = !0,
            u = hl(o, [1, o.shape[0], o.shape[1], o.shape[2]])),
            b(4 === u.rank, (()=>`Error in conv2d: input must be rank 4, but got rank ${u.rank}.`)),
            b(4 === l.rank, (()=>`Error in conv2d: filter must be rank 4, but got rank ${l.rank}.`)),
            Gl("conv2d", s, i);
            const h = "NHWC" === r ? u.shape[3] : u.shape[1];
            b(h === l.shape[2], (()=>`Error in conv2d: depth of input (${h}) must match input depth for filter ${l.shape[2]}.`)),
            b(Wl(n, a), (()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`)),
            b(Ul(a), (()=>"Error in conv2D: Dilated rates should be larger than 0.")),
            b(Ul(n), (()=>"Error in conv2D: Strides should be larger than 0."));
            const p = {
                x: u,
                filter: l
            }
              , d = {
                strides: n,
                pad: s,
                dataFormat: r,
                dilations: a,
                dimRoundingMode: i
            }
              , f = ka.runKernel(et, p, d);
            return c ? hl(f, [f.shape[1], f.shape[2], f.shape[3]]) : f
        }
    });
    const jl = Ma({
        conv2DBackpropFilter_: function(e, t, n, s, r, a="NHWC", i) {
            let o = e;
            3 === e.rank && (o = hl(e, [1, e.shape[0], e.shape[1], e.shape[2]]));
            let l = t;
            3 === l.rank && (l = hl(t, [1, t.shape[0], t.shape[1], t.shape[2]])),
            b(4 === o.rank, (()=>`Error in conv2dDerFilter: input must be rank 4, but got shape ${o.shape}.`)),
            b(4 === l.rank, (()=>`Error in conv2dDerFilter: dy must be rank 4, but got shape ${l.shape}.`)),
            b(4 === n.length, (()=>`Error in conv2dDerFilter: filterShape must be length 4, but got ${n}.`));
            const u = "NHWC" === a ? o.shape[3] : o.shape[1]
              , c = "NHWC" === a ? l.shape[3] : l.shape[1];
            b(u === n[2], (()=>`Error in conv2dDerFilter: depth of input ${u}) must match input depth in filter (${n[2]}.`)),
            b(c === n[3], (()=>`Error in conv2dDerFilter: depth of dy (${c}) must match output depth for filter (${n[3]}).`)),
            Gl("conv2dDerFilter", r, i);
            const h = {
                x: o,
                dy: l
            }
              , p = {
                strides: s,
                pad: r,
                dataFormat: a,
                dimRoundingMode: i,
                filterShape: n
            };
            return ka.runKernel(tt, h, p)
        }
    });
    const ql = Ma({
        conv2DBackpropInput_: function(e, t, n, s, r, a="NHWC", i) {
            b(e.length === t.rank, (()=>`Length of inShape (${e.length}) and rank of dy (${t.rank}) must match`));
            let o = e
              , l = t
              , u = !1;
            3 === t.rank && (u = !0,
            l = hl(t, [1, t.shape[0], t.shape[1], t.shape[2]]),
            o = [1, e[0], e[1], e[2]]),
            b(4 === o.length, (()=>`Error in conv2dDerInput: inShape must be length 4, but got length ${o.length}.`)),
            b(4 === l.rank, (()=>`Error in conv2dDerInput: dy must be rank 4, but got rank ${l.rank}`)),
            b(4 === n.rank, (()=>`Error in conv2dDerInput: filter must be rank 4, but got rank ${n.rank}`));
            const c = "NHWC" === a ? o[3] : o[1]
              , h = "NHWC" === a ? l.shape[3] : l.shape[1];
            b(c === n.shape[2], (()=>`Error in conv2dDerInput: depth of input (${c}) must match input depth for filter ${n.shape[2]}.`)),
            b(h === n.shape[3], (()=>`Error in conv2dDerInput: depth of output (${h}) must match output depth for filter ${n.shape[3]}.`)),
            Gl("conv2dDerInput", r, i);
            const p = {
                dy: l,
                filter: n
            }
              , d = {
                strides: s,
                pad: r,
                dataFormat: a,
                dimRoundingMode: i,
                inputShape: o
            }
              , f = ka.runKernel(nt, p, d);
            return u ? hl(f, [f.shape[1], f.shape[2], f.shape[3]]) : f
        }
    });
    var Kl = {};
    t(Kl, "getFusedDyActivation", (()=>su)),
    t(Kl, "getFusedBiasGradient", (()=>ru)),
    t(Kl, "applyActivation", (()=>au)),
    t(Kl, "shouldFuse", (()=>iu));
    const Xl = Ma({
        elu_: function(e) {
            const t = {
                x: Da(e, "x", "elu", "float32")
            };
            return ka.runKernel(kt, t)
        }
    });
    const Yl = Ma({
        leakyRelu_: function(e, t=.2) {
            const n = {
                x: Da(e, "x", "leakyRelu")
            }
              , s = {
                alpha: t
            };
            return ka.runKernel(Ht, n, s)
        }
    });
    const Zl = Ma({
        prelu_: function(e, t) {
            const n = {
                x: Da(e, "x", "prelu"),
                alpha: Da(t, "alpha", "prelu")
            };
            return ka.runKernel(Cn, n)
        }
    });
    const Jl = Ma({
        relu_: function(e) {
            const t = {
                x: Da(e, "x", "relu")
            };
            return ka.runKernel(On, t)
        }
    });
    const Ql = Ma({
        relu6_: function(e) {
            const t = {
                x: Da(e, "x", "relu6")
            };
            return ka.runKernel(Wn, t)
        }
    });
    const eu = Ma({
        sigmoid_: function(e) {
            const t = {
                x: Da(e, "x", "sigmoid", "float32")
            };
            return ka.runKernel(Qn, t)
        }
    });
    const tu = Ma({
        step_: function(e, t=0) {
            const n = {
                x: Da(e, "x", "step")
            }
              , s = {
                alpha: t
            };
            return ka.runKernel($s, n, s)
        }
    });
    const nu = Ma({
        sum_: function(e, t=null, n=!1) {
            let s = Da(e, "x", "sum");
            "bool" === s.dtype && (s = Ko(s, "int32"));
            const r = {
                x: s
            }
              , a = {
                axis: t,
                keepDims: n
            };
            return ka.runKernel(ns, r, a)
        }
    });
    function su(e, t, n) {
        if (null == n || "linear" === n)
            return e;
        if ("relu" === n)
            return il(e, tu(t));
        throw new Error(`Cannot compute gradient for fused activation ${n}.`)
    }
    function ru(e, t) {
        let n = t;
        const s = Cl(e.shape, t.shape);
        return s.length > 0 && (n = nu(n, s)),
        hl(n, e.shape)
    }
    function au(e, t, n, s) {
        if ("linear" === t)
            return e;
        if ("relu" === t)
            return Jl(e);
        if ("elu" === t)
            return Xl(e);
        if ("relu6" === t)
            return Ql(e);
        if ("prelu" === t)
            return Zl(e, n);
        if ("leakyrelu" === t)
            return Yl(e, s);
        if ("sigmoid" === t)
            return eu(e);
        throw new Error(`Unknown fused activation ${t}.`)
    }
    const iu = (e,t)=>!(e > 0) || "linear" === t;
    const ou = Ma({
        fusedConv2d_: function({x: e, filter: t, strides: n, pad: s, dataFormat: r="NHWC", dilations: a=[1, 1], dimRoundingMode: i, bias: o, activation: l="linear", preluActivationWeights: u, leakyreluAlpha: c}) {
            if (l = l || "linear",
            !1 === iu(ka.state.gradientDepth, l)) {
                b("NHWC" === r, (()=>`Error in fused conv2d: got dataFormat of ${r} but only NHWC is currently supported for the case of gradient depth is 0 and the activation is not linear.`));
                let h = Hl(e, t, n, s, r, a, i);
                return null != o && (h = sl(h, o)),
                au(h, l, u, c)
            }
            const h = Da(e, "x", "conv2d", "float32")
              , p = Da(t, "filter", "conv2d", "float32");
            let d = h
              , f = !1;
            3 === h.rank && (f = !0,
            d = hl(h, [1, h.shape[0], h.shape[1], h.shape[2]])),
            b(4 === d.rank, (()=>`Error in fused conv2d: input must be rank 4, but got rank ${d.rank}.`)),
            b(4 === p.rank, (()=>`Error in fused conv2d: filter must be rank 4, but got rank ${p.rank}.`)),
            Gl("fused conv2d", s, i);
            const m = "NHWC" === r ? d.shape[3] : d.shape[1];
            b(p.shape[2] === m, (()=>`Error in conv2d: depth of input (${m}) must match input depth for filter ${p.shape[2]}.`)),
            b(Wl(n, a), (()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`));
            const g = Dl(d.shape, p.shape, n, a, s, i);
            let y, x;
            if (null != o && (y = Da(o, "bias", "fused conv2d"),
            [y] = da(y, h),
            "NHWC" === r ? $l(g.outShape, y.shape) : (b(y.shape.length <= 1, (()=>`Error in fused conv2d: only supports scalar or 1-D Tensor bias for NCHW format but got the bias of rank-${y.shape.length}.`)),
            b(0 === y.shape.length || y.shape[0] === g.outChannels || 1 === y.shape[0], (()=>`Error in fused conv2d: bias shape (${y.shape}) is not compatible with the number of output channels (${g.outChannels})`)))),
            null != u) {
                const e = u.shape;
                if (b(e.length <= 1 || 3 === e.length, (()=>`Error in fused conv2d: only supports scalar, 1-D Tensor or 3-D Tensor PReLU activation weights but got a tensor of rank-${e.length}.`)),
                1 === e.length)
                    b(1 === e[0] || e[0] === g.outChannels, (()=>`Error in fused conv2d: PReLU activation weights (${e}) is not compatible with the number of output channels (${g.outChannels}).`));
                else if (3 === e.length)
                    try {
                        $l(e, g.outShape)
                    } catch (t) {
                        const n = `Error in fused conv2d: PReLU activation weights (${e}) is not compatible with the output shape of the conv2d (${g.outShape}).`;
                        throw Error(n)
                    }
                x = Da(u, "prelu weights", "fused conv2d")
            }
            const w = (e,t)=>{
                b("NHWC" === r, (()=>`Error in gradient of fused conv2D: got dataFormat of ${r} but only NHWC is currently supported.`));
                const [i,o,u,c] = t
                  , h = su(e, u, l);
                b(Pl(a), (()=>`Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${a}'`));
                const p = [ql(o.shape, h, i, n, s), jl(o, h, i.shape, n, s)];
                if (null != c) {
                    const e = ru(c, h);
                    p.push(e)
                }
                return p
            }
              , v = {
                x: d,
                filter: p,
                bias: y,
                preluActivationWeights: x
            }
              , k = {
                strides: n,
                pad: s,
                dataFormat: r,
                dilations: a,
                dimRoundingMode: i,
                activation: l,
                leakyreluAlpha: c
            };
            if (null == o) {
                return Sl(((e,t,n)=>{
                    let s = ka.runKernel(Fs, v, k);
                    return n([t, e, s]),
                    f && (s = hl(s, [s.shape[1], s.shape[2], s.shape[3]])),
                    {
                        value: s,
                        gradFunc: w
                    }
                }
                ))(d, p)
            }
            return Sl(((e,t,n,s)=>{
                let r = ka.runKernel(Fs, v, k);
                return s([t, e, r, n]),
                f && (r = hl(r, [r.shape[1], r.shape[2], r.shape[3]])),
                {
                    value: r,
                    gradFunc: w
                }
            }
            ))(d, p, y)
        }
    });
    const lu = Ma({
        depthwiseConv2d_: function(e, t, n, s, r="NHWC", a=[1, 1], i) {
            const o = Da(e, "x", "depthwiseConv2d", "float32")
              , l = Da(t, "filter", "depthwiseConv2d", "float32");
            let u = o
              , c = !1;
            3 === o.rank && (c = !0,
            u = hl(o, [1, o.shape[0], o.shape[1], o.shape[2]])),
            b(4 === u.rank, (()=>`Error in depthwiseConv2d: input must be rank 4, but got rank ${u.rank}.`)),
            b(4 === l.rank, (()=>`Error in depthwiseConv2d: filter must be rank 4, but got rank ${l.rank}.`));
            const h = "NHWC" === r ? u.shape[3] : u.shape[1];
            b(h === l.shape[2], (()=>`Error in depthwiseConv2d: number of input channels (${h}) must match the inChannels dimension in filter ${l.shape[2]}.`)),
            Gl("depthwiseConv2d", s, i);
            const p = {
                x: u,
                filter: l
            }
              , d = {
                strides: n,
                pad: s,
                dataFormat: r,
                dilations: a,
                dimRoundingMode: i
            }
              , f = ka.runKernel(dt, p, d);
            return c ? hl(f, [f.shape[1], f.shape[2], f.shape[3]]) : f
        }
    });
    const uu = Ma({
        depthwiseConv2dNativeBackpropFilter_: function(e, t, n, s, r, a=[1, 1], i) {
            let o = e;
            3 === e.rank && (o = hl(e, [1, e.shape[0], e.shape[1], e.shape[2]]));
            let l = t;
            3 === l.rank && (l = hl(t, [1, t.shape[0], t.shape[1], t.shape[2]]));
            const u = {
                x: o,
                dy: l
            }
              , c = {
                strides: s,
                pad: r,
                dimRoundingMode: i,
                dilations: a,
                filterShape: n
            };
            return ka.runKernel(ft, u, c)
        }
    });
    const cu = Ma({
        depthwiseConv2dNativeBackpropInput_: function(e, t, n, s, r, a=[1, 1], i) {
            let o = t
              , l = !1;
            3 === t.rank && (l = !0,
            o = hl(t, [1, t.shape[0], t.shape[1], t.shape[2]]));
            const u = {
                dy: o,
                filter: n
            }
              , c = {
                strides: s,
                pad: r,
                dimRoundingMode: i,
                dilations: a,
                inputShape: e
            }
              , h = ka.runKernel(mt, u, c);
            return l ? hl(h, [h.shape[1], h.shape[2], h.shape[3]]) : h
        }
    });
    const hu = Ma({
        fusedDepthwiseConv2d_: function({x: e, filter: t, strides: n, pad: s, dataFormat: r="NHWC", dilations: a=[1, 1], dimRoundingMode: i, bias: o, activation: l="linear", preluActivationWeights: u, leakyreluAlpha: c}) {
            if (!1 === iu(ka.state.gradientDepth, l)) {
                let h = lu(e, t, n, s, r, a, i);
                return null != o && (h = sl(h, o)),
                au(h, l, u, c)
            }
            const h = Da(e, "x", "depthwiseConv2d", "float32")
              , p = Da(t, "filter", "depthwiseConv2d", "float32");
            let d = h
              , f = !1;
            3 === h.rank && (f = !0,
            d = hl(h, [1, h.shape[0], h.shape[1], h.shape[2]])),
            b(4 === d.rank, (()=>`Error in fused depthwiseConv2d: input must be rank 4, but got rank ${d.rank}.`)),
            b(4 === p.rank, (()=>`Error in fused depthwiseConv2d: filter must be rank 4, but got rank ${p.rank}.`)),
            b(d.shape[3] === p.shape[2], (()=>`Error in fused depthwiseConv2d: number of input channels (${d.shape[3]}) must match the inChannels dimension in filter ${p.shape[2]}.`)),
            null == a && (a = [1, 1]),
            b(Wl(n, a), (()=>`Error in fused depthwiseConv2d: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`)),
            Gl("fused depthwiseConv2d", s, i);
            const m = Dl(d.shape, p.shape, n, a, s, i, !0);
            let g, y;
            null != o && (g = Da(o, "bias", "fused conv2d"),
            [g] = da(g, h),
            $l(m.outShape, g.shape)),
            null != u && (y = Da(u, "prelu weights", "fused depthwiseConv2d"));
            const x = (e,t)=>{
                b(Pl(a), (()=>`Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '${a}'`));
                const [r,o,u,c] = t
                  , h = su(e, u, l)
                  , p = cu(o.shape, h, r, n, s, a, i)
                  , d = uu(o, h, r.shape, n, s, a, i);
                if (null != c) {
                    return [p, d, ru(g, h)]
                }
                return [p, d]
            }
              , w = {
                x: d,
                filter: p,
                bias: g,
                preluActivationWeights: y
            }
              , v = {
                strides: n,
                pad: s,
                dataFormat: r,
                dilations: a,
                dimRoundingMode: i,
                activation: l,
                leakyreluAlpha: c
            };
            if (null == o) {
                return Sl(((e,t,n)=>{
                    let s = ka.runKernel(Ds, w, v);
                    return n([t, e, s]),
                    f && (s = hl(s, [s.shape[1], s.shape[2], s.shape[3]])),
                    {
                        value: s,
                        gradFunc: x
                    }
                }
                ))(d, p)
            }
            return Sl(((e,t,n,s)=>{
                let r = ka.runKernel(Ds, w, v);
                return s([t, e, r, n]),
                f && (r = hl(r, [r.shape[1], r.shape[2], r.shape[3]])),
                {
                    value: r,
                    gradFunc: x
                }
            }
            ))(d, p, g)
        }
    });
    const pu = Ma({
        matMul_: function(e, t, n=!1, s=!1) {
            let r = Da(e, "a", "matMul")
              , a = Da(t, "b", "matMul");
            [r,a] = da(r, a);
            const i = {
                a: r,
                b: a
            }
              , o = {
                transposeA: n,
                transposeB: s
            };
            return ka.runKernel(Ge, i, o)
        }
    });
    const du = Ma({
        fusedMatMul_: function({a: e, b: t, transposeA: n=!1, transposeB: s=!1, bias: r, activation: a="linear", preluActivationWeights: i, leakyreluAlpha: o=.2}) {
            if (!1 === iu(ka.state.gradientDepth, a)) {
                let l = pu(e, t, n, s);
                return null != r && (l = sl(l, r)),
                au(l, a, i, o)
            }
            let l = Da(e, "a", "fused matMul")
              , u = Da(t, "b", "fused matMul");
            [l,u] = da(l, u);
            const c = n ? l.shape[l.rank - 2] : l.shape[l.rank - 1]
              , h = s ? u.shape[u.rank - 1] : u.shape[u.rank - 2]
              , p = n ? l.shape[l.rank - 1] : l.shape[l.rank - 2]
              , d = s ? u.shape[u.rank - 2] : u.shape[u.rank - 1]
              , f = l.shape.slice(0, -2)
              , m = u.shape.slice(0, -2)
              , g = v(f)
              , y = v(m);
            b(c === h, (()=>`Error in fused matMul: inner shapes (${c}) and (${h}) of Tensors with shapes ${l.shape} and ${u.shape} and transposeA=${n} and transposeB=${s} must match.`));
            const x = $l(l.shape.slice(0, -2), u.shape.slice(0, -2)).concat([p, d])
              , w = hl(l, n ? [g, c, p] : [g, p, c])
              , k = hl(u, s ? [y, d, h] : [y, h, d]);
            let I, S;
            null != r && (I = Da(r, "bias", "fused matMul"),
            [I] = da(I, l),
            $l(x, I.shape)),
            null != i && (S = Da(i, "prelu weights", "fused matMul"));
            const N = (e,t)=>{
                const [i,o,l,u] = t
                  , c = su(hl(e, l.shape), l, a);
                let h, p;
                if (n || s ? !n && s ? (h = pu(c, o, !1, !1),
                p = pu(c, i, !0, !1)) : n && !s ? (h = pu(o, c, !1, !0),
                p = pu(i, c, !1, !1)) : (h = pu(o, c, !0, !0),
                p = pu(c, i, !0, !0)) : (h = pu(c, o, !1, !0),
                p = pu(i, c, !0, !1)),
                null != r) {
                    return [h, p, ru(u, c)]
                }
                return [h, p]
            }
              , T = {
                a: w,
                b: k,
                bias: I,
                preluActivationWeights: S
            }
              , C = {
                transposeA: n,
                transposeB: s,
                activation: a,
                leakyreluAlpha: o
            };
            if (null == r) {
                return Sl(((e,t,n)=>{
                    const s = ka.runKernel(Rs, T, C);
                    return n([e, t, s]),
                    {
                        value: hl(s, x),
                        gradFunc: N
                    }
                }
                ))(w, k)
            }
            return Sl(((e,t,n,s)=>{
                const r = ka.runKernel(Rs, T, C);
                return s([e, t, r, n]),
                {
                    value: hl(r, x),
                    gradFunc: N
                }
            }
            ))(w, k, I)
        }
    });
    var fu = {};
    function mu(e, t) {
        w(e);
        const n = Aa(e, t);
        if (1 !== n.length)
            throw new Error("tensor1d() requires values to be a flat/TypedArray");
        return za(e, null, n, t)
    }
    function gu(e) {
        return Math.floor(Math.pow(2, Math.ceil(Math.log(e) / Math.log(2))))
    }
    function yu(e, t, n) {
        const s = 1 - e % 2
          , r = new Float32Array(e);
        for (let a = 0; a < e; ++a) {
            const i = 2 * Math.PI * a / (e + s - 1);
            r[a] = t - n * Math.cos(i)
        }
        return mu(r, "float32")
    }
    t(fu, "enclosingPowerOfTwo", (()=>gu)),
    t(fu, "cosineWindow", (()=>yu));
    const bu = Ma({
        hammingWindow_: function(e) {
            return yu(e, .54, .46)
        }
    });
    const xu = Ma({
        hannWindow_: function(e) {
            return yu(e, .5, .5)
        }
    });
    function wu(e, t, n) {
        Q(e);
        const s = {
            shape: e,
            value: t,
            dtype: n
        };
        return ka.runKernel(At, {}, s)
    }
    function vu(e, t, n) {
        if (w(e),
        null != t && 2 !== t.length)
            throw new Error("tensor2d() requires shape to have two numbers");
        const s = Aa(e, n);
        if (2 !== s.length && 1 !== s.length)
            throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");
        if (1 === s.length && null == t)
            throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");
        return za(e, t, s, n)
    }
    const ku = Ma({
        frame_: function(e, t, n, s=!1, r=0) {
            let a = 0;
            const i = [];
            for (; a + t <= e.size; )
                i.push(pl(e, a, t)),
                a += n;
            if (s)
                for (; a < e.size; ) {
                    const s = a + t - e.size
                      , o = ll([pl(e, a, t - s), wu([s], r)]);
                    i.push(o),
                    a += n
                }
            return 0 === i.length ? vu([], [0, t]) : hl(ll(i), [i.length, t])
        }
    });
    const Iu = Ma({
        stft_: function(e, t, n, s, r=xu) {
            null == s && (s = gu(t));
            const a = ku(e, t, n)
              , i = il(a, r(t));
            return yl(i, s)
        }
    });
    const Su = Ma({
        cropAndResize_: function(e, t, n, s, r="bilinear", a=0) {
            const i = Da(e, "image", "cropAndResize")
              , o = Da(t, "boxes", "cropAndResize", "float32")
              , l = Da(n, "boxInd", "cropAndResize", "int32")
              , u = o.shape[0];
            b(4 === i.rank, (()=>`Error in cropAndResize: image must be rank 4,but got rank ${i.rank}.`)),
            b(2 === o.rank && 4 === o.shape[1], (()=>`Error in cropAndResize: boxes must be have size [${u},4] but had shape ${o.shape}.`)),
            b(1 === l.rank && l.shape[0] === u, (()=>`Error in cropAndResize: boxInd must be have size [${u}] but had shape ${o.shape}.`)),
            b(2 === s.length, (()=>`Error in cropAndResize: cropSize must be of length 2, but got length ${s.length}.`)),
            b(s[0] >= 1 && s[1] >= 1, (()=>`cropSize must be atleast [1,1], but was ${s}`)),
            b("bilinear" === r || "nearest" === r, (()=>`method must be bilinear or nearest, but was ${r}`));
            const c = {
                image: i,
                boxes: o,
                boxInd: l
            }
              , h = {
                method: r,
                extrapolationValue: a,
                cropSize: s
            };
            return ka.runKernel(ct, c, h)
        }
    });
    const Nu = Ma({
        flipLeftRight_: function(e) {
            const t = Da(e, "image", "flipLeftRight", "float32");
            b(4 === t.rank, (()=>`Error in flipLeftRight: image must be rank 4,but got rank ${t.rank}.`));
            const n = {
                image: t
            };
            return ka.runKernel(Rt, n, {})
        }
    });
    const Tu = Ma({
        tile_: function(e, t) {
            const n = Da(e, "x", "tile", "string_or_numeric");
            b(n.rank === t.length, (()=>`Error in transpose: rank of input ${n.rank} must match length of reps ${t}.`));
            const s = {
                x: n
            }
              , r = {
                reps: t
            };
            return ka.runKernel(ws, s, r)
        }
    });
    const Cu = Ma({
        grayscaleToRGB_: function(e) {
            const t = Da(e, "image", "grayscaleToRGB")
              , n = t.rank - 1
              , s = t.shape[n];
            b(t.rank >= 2, (()=>`Error in grayscaleToRGB: images must be at least rank 2, but got rank ${t.rank}.`)),
            b(1 === s, (()=>`Error in grayscaleToRGB: last dimension of a grayscale image should be size 1, but got size ${s}.`));
            const r = new Array(t.rank);
            return r.fill(1, 0, n),
            r[n] = 3,
            Tu(t, r)
        }
    });
    const $u = Ma({
        rotateWithOffset_: function(e, t, n=0, s=.5) {
            const r = Da(e, "image", "rotateWithOffset", "float32");
            b(4 === r.rank, (()=>`Error in rotateWithOffset: image must be rank 4,but got rank ${r.rank}.`));
            const a = {
                image: r
            }
              , i = {
                radians: t,
                fillValue: n,
                center: s
            };
            return ka.runKernel(As, a, i)
        }
    });
    function Eu(e, t, n, s, r, a) {
        null == s && (s = .5),
        null == r && (r = Number.NEGATIVE_INFINITY),
        null == a && (a = 0);
        const i = e.shape[0];
        return n = Math.min(n, i),
        b(0 <= s && s <= 1, (()=>`iouThreshold must be in [0, 1], but was '${s}'`)),
        b(2 === e.rank, (()=>`boxes must be a 2D tensor, but was of rank '${e.rank}'`)),
        b(4 === e.shape[1], (()=>`boxes must have 4 columns, but 2nd dimension was ${e.shape[1]}`)),
        b(1 === t.rank, (()=>"scores must be a 1D tensor")),
        b(t.shape[0] === i, (()=>`scores has incompatible shape with boxes. Expected ${i}, but was ${t.shape[0]}`)),
        b(0 <= a && a <= 1, (()=>`softNmsSigma must be in [0, 1], but was '${a}'`)),
        {
            maxOutputSize: n,
            iouThreshold: s,
            scoreThreshold: r,
            softNmsSigma: a
        }
    }
    const Au = Ma({
        nonMaxSuppression_: function(e, t, n, s=.5, r=Number.NEGATIVE_INFINITY) {
            const a = Da(e, "boxes", "nonMaxSuppression", "float32")
              , i = Da(t, "scores", "nonMaxSuppression", "float32")
              , o = Eu(a, i, n, s, r)
              , l = {
                maxOutputSize: n = o.maxOutputSize,
                iouThreshold: s = o.iouThreshold,
                scoreThreshold: r = o.scoreThreshold
            };
            return ka.runKernel(xn, {
                boxes: a,
                scores: i
            }, l)
        }
    });
    function Ru(e, t, n) {
        const s = function(e, t, n) {
            return function(e, t, n) {
                let s = 0
                  , r = e.length
                  , a = 0
                  , i = !1;
                for (; s < r; ) {
                    a = s + (r - s >>> 1);
                    const o = n(t, e[a]);
                    o > 0 ? s = a + 1 : (r = a,
                    i = !o)
                }
                return i ? s : -s - 1
            }(e, t, n || Fu)
        }(e, t, n)
          , r = s < 0 ? -(s + 1) : s;
        e.splice(r, 0, t)
    }
    function Fu(e, t) {
        return e > t ? 1 : e < t ? -1 : 0
    }
    function Du(e, t, n, s, r) {
        return Mu(e, t, n, s, r, 0)
    }
    function _u(e, t, n, s, r, a) {
        return Mu(e, t, n, s, r, 0, !1, a, !0)
    }
    function Ou(e, t, n, s, r, a) {
        return Mu(e, t, n, s, r, a, !0)
    }
    function Mu(e, t, n, s, r, a, i=!1, o=!1, l=!1) {
        const u = [];
        for (let e = 0; e < t.length; e++)
            t[e] > r && u.push({
                score: t[e],
                boxIndex: e,
                suppressBeginIndex: 0
            });
        u.sort(Bu);
        const c = a > 0 ? -.5 / a : 0
          , h = []
          , p = [];
        for (; h.length < n && u.length > 0; ) {
            const t = u.pop()
              , {score: n, boxIndex: a, suppressBeginIndex: i} = t;
            if (n < r)
                break;
            let o = !1;
            for (let n = h.length - 1; n >= i; --n) {
                const i = Lu(e, a, h[n]);
                if (i >= s) {
                    o = !0;
                    break
                }
                if (t.score = t.score * zu(s, c, i),
                t.score <= r)
                    break
            }
            t.suppressBeginIndex = h.length,
            o || (t.score === n ? (h.push(a),
            p.push(t.score)) : t.score > r && Ru(u, t, Bu))
        }
        const d = h.length
          , f = n - d;
        o && f > 0 && (h.push(...new Array(f).fill(0)),
        p.push(...new Array(f).fill(0)));
        const m = {
            selectedIndices: h
        };
        return i && (m.selectedScores = p),
        l && (m.validOutputs = d),
        m
    }
    function Lu(e, t, n) {
        const s = e.subarray(4 * t, 4 * t + 4)
          , r = e.subarray(4 * n, 4 * n + 4)
          , a = Math.min(s[0], s[2])
          , i = Math.min(s[1], s[3])
          , o = Math.max(s[0], s[2])
          , l = Math.max(s[1], s[3])
          , u = Math.min(r[0], r[2])
          , c = Math.min(r[1], r[3])
          , h = Math.max(r[0], r[2])
          , p = Math.max(r[1], r[3])
          , d = (o - a) * (l - i)
          , f = (h - u) * (p - c);
        if (d <= 0 || f <= 0)
            return 0;
        const m = Math.max(a, u)
          , g = Math.max(i, c)
          , y = Math.min(o, h)
          , b = Math.min(l, p)
          , x = Math.max(y - m, 0) * Math.max(b - g, 0);
        return x / (d + f - x)
    }
    function zu(e, t, n) {
        const s = Math.exp(t * n * n);
        return n <= e ? s : 0
    }
    function Bu(e, t) {
        return e.score - t.score || e.score === t.score && t.boxIndex - e.boxIndex
    }
    const Pu = async function(e, t, n, s=.5, r=Number.NEGATIVE_INFINITY) {
        const a = Da(e, "boxes", "nonMaxSuppressionAsync")
          , i = Da(t, "scores", "nonMaxSuppressionAsync")
          , o = Eu(a, i, n, s, r);
        n = o.maxOutputSize,
        s = o.iouThreshold,
        r = o.scoreThreshold;
        const l = await Promise.all([a.data(), i.data()])
          , u = l[0]
          , c = l[1]
          , {selectedIndices: h} = Du(u, c, n, s, r);
        return a !== e && a.dispose(),
        i !== t && i.dispose(),
        mu(h, "int32")
    };
    const Wu = Ma({
        nonMaxSuppressionWithScore_: function(e, t, n, s=.5, r=Number.NEGATIVE_INFINITY, a=0) {
            const i = Da(e, "boxes", "nonMaxSuppression")
              , o = Da(t, "scores", "nonMaxSuppression")
              , l = Eu(i, o, n, s, r, a)
              , u = {
                boxes: i,
                scores: o
            }
              , c = {
                maxOutputSize: n = l.maxOutputSize,
                iouThreshold: s = l.iouThreshold,
                scoreThreshold: r = l.scoreThreshold,
                softNmsSigma: a = l.softNmsSigma
            }
              , h = ka.runKernel(vn, u, c);
            return {
                selectedIndices: h[0],
                selectedScores: h[1]
            }
        }
    });
    const Uu = async function(e, t, n, s=.5, r=Number.NEGATIVE_INFINITY, a=0) {
        const i = Da(e, "boxes", "nonMaxSuppressionAsync")
          , o = Da(t, "scores", "nonMaxSuppressionAsync")
          , l = Eu(i, o, n, s, r, a);
        n = l.maxOutputSize,
        s = l.iouThreshold,
        r = l.scoreThreshold,
        a = l.softNmsSigma;
        const u = await Promise.all([i.data(), o.data()])
          , c = u[0]
          , h = u[1]
          , {selectedIndices: p, selectedScores: d} = Ou(c, h, n, s, r, a);
        return i !== e && i.dispose(),
        o !== t && o.dispose(),
        {
            selectedIndices: mu(p, "int32"),
            selectedScores: mu(d)
        }
    };
    const Vu = Ma({
        nonMaxSuppressionPadded_: function(e, t, n, s=.5, r=Number.NEGATIVE_INFINITY, a=!1) {
            const i = Da(e, "boxes", "nonMaxSuppression")
              , o = Da(t, "scores", "nonMaxSuppression")
              , l = Eu(i, o, n, s, r, null)
              , u = {
                boxes: i,
                scores: o
            }
              , c = {
                maxOutputSize: l.maxOutputSize,
                iouThreshold: l.iouThreshold,
                scoreThreshold: l.scoreThreshold,
                padToMaxOutputSize: a
            }
              , h = ka.runKernel(wn, u, c);
            return {
                selectedIndices: h[0],
                validOutputs: h[1]
            }
        }
    });
    const Gu = async function(e, t, n, s=.5, r=Number.NEGATIVE_INFINITY, a=!1) {
        const i = Da(e, "boxes", "nonMaxSuppressionAsync")
          , o = Da(t, "scores", "nonMaxSuppressionAsync")
          , l = Eu(i, o, n, s, r, null)
          , u = l.maxOutputSize
          , c = l.iouThreshold
          , h = l.scoreThreshold
          , [p,d] = await Promise.all([i.data(), o.data()])
          , {selectedIndices: f, validOutputs: m} = _u(p, d, u, c, h, a);
        return i !== e && i.dispose(),
        o !== t && o.dispose(),
        {
            selectedIndices: mu(f, "int32"),
            validOutputs: wl(m, "int32")
        }
    };
    const Hu = Ma({
        resizeBilinear_: function(e, t, n=!1, s=!1) {
            const r = Da(e, "images", "resizeBilinear");
            b(3 === r.rank || 4 === r.rank, (()=>`Error in resizeBilinear: x must be rank 3 or 4, but got rank ${r.rank}.`)),
            b(2 === t.length, (()=>`Error in resizeBilinear: new shape must 2D, but got shape ${t}.`)),
            b(!1 === s || !1 === n, (()=>"Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false."));
            let a = r
              , i = !1;
            3 === r.rank && (i = !0,
            a = hl(r, [1, r.shape[0], r.shape[1], r.shape[2]]));
            const [] = t
              , o = {
                images: a
            }
              , l = {
                alignCorners: n,
                halfPixelCenters: s,
                size: t
            }
              , u = ka.runKernel(Bn, o, l);
            return i ? hl(u, [u.shape[1], u.shape[2], u.shape[3]]) : u
        }
    });
    const ju = Ma({
        resizeNearestNeighbor_: function(e, t, n=!1, s=!1) {
            const r = Da(e, "images", "resizeNearestNeighbor");
            b(3 === r.rank || 4 === r.rank, (()=>`Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${r.rank}.`)),
            b(2 === t.length, (()=>`Error in resizeNearestNeighbor: new shape must 2D, but got shape ${t}.`)),
            b("float32" === r.dtype || "int32" === r.dtype, (()=>"`images` must have `int32` or `float32` as dtype")),
            b(!1 === s || !1 === n, (()=>"Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false."));
            let a = r
              , i = !1;
            3 === r.rank && (i = !0,
            a = hl(r, [1, r.shape[0], r.shape[1], r.shape[2]]));
            const [] = t
              , o = {
                images: a
            }
              , l = {
                alignCorners: n,
                halfPixelCenters: s,
                size: t
            }
              , u = ka.runKernel(Ln, o, l);
            return i ? hl(u, [u.shape[1], u.shape[2], u.shape[3]]) : u
        }
    });
    const qu = Ma({
        bincount_: function(e, t, n) {
            const s = Da(e, "x", "bincount")
              , r = Da(t, "weights", "bincount");
            b("int32" === s.dtype, (()=>`Error in bincount: input dtype must be int32, but got ${s.dtype}`)),
            b(n >= 0, (()=>`size must be non-negative, but got ${n}.`)),
            b(r.size === s.size || 0 === r.size, (()=>`Error in bincount: weights must have the same size as input or0-length, but got input shape: ${s.shape}, weights shape: ${r.shape}.`));
            const a = {
                x: s,
                weights: r
            }
              , i = {
                size: n
            };
            return ka.runKernel(je, a, i)
        }
    });
    const Ku = Ma({
        lessEqual_: function(e, t) {
            let n = Da(e, "a", "lessEqual", "string_or_numeric")
              , s = Da(t, "b", "lessEqual", "string_or_numeric");
            [n,s] = da(n, s),
            $l(n.shape, s.shape);
            const r = {
                a: n,
                b: s
            };
            return ka.runKernel(qt, r)
        }
    });
    const Xu = Ma({
        greater_: function(e, t) {
            let n = Da(e, "a", "greater", "string_or_numeric")
              , s = Da(t, "b", "greater", "string_or_numeric");
            [n,s] = da(n, s),
            $l(n.shape, s.shape);
            const r = {
                a: n,
                b: s
            };
            return ka.runKernel(Lt, r)
        }
    });
    const Yu = Ma({
        sub_: function(e, t) {
            let n = Da(e, "a", "sub")
              , s = Da(t, "b", "sub");
            [n,s] = da(n, s);
            const r = {
                a: n,
                b: s
            };
            return ka.runKernel(ys, r)
        }
    });
    const Zu = Ma({
        round_: function(e) {
            const t = {
                x: Da(e, "x", "round")
            };
            return ka.runKernel(Vn, t)
        }
    });
    const Ju = Ma({
        broadcastTo_: function(e, t) {
            let n = Da(e, "broadcastTo", "x");
            const s = n.shape;
            if (Q(t),
            t.length < n.rank)
                throw new Error(`broadcastTo(): shape.length=${t.length} < input.rank=${n.rank}.`);
            if (t.length > n.rank) {
                const e = n.shape.slice();
                for (; e.length < t.length; )
                    e.unshift(1);
                n = hl(n, e)
            }
            const r = n.shape
              , a = Array.from(t);
            for (let e = t.length - 1; e >= 0; e--)
                if (r[e] === t[e])
                    a[e] = 1;
                else if (1 !== n.shape[e])
                    throw new Error(`broadcastTo(): [${s}] cannot be broadcast to [${t}].`);
            if (0 === a.map(((e,t)=>e > 1 ? t : -1)).filter((e=>e >= 0)).length)
                return Xo(n);
            const i = {
                x: n
            }
              , o = {
                reps: a
            };
            return ka.runKernel(ws, i, o)
        }
    });
    const Qu = Ma({
        where_: function(e, t, n) {
            const s = Da(t, "a", "where")
              , r = Da(n, "b", "where")
              , a = Da(e, "condition", "where", "bool")
              , i = $l($l(a.shape, s.shape), r.shape)
              , o = {
                condition: Ju(a, i),
                t: Ju(s, i),
                e: Ju(r, i)
            };
            return ka.runKernel(qn, o)
        }
    });
    function ec(e, t, n=1, s="float32") {
        if (0 === n)
            throw new Error("Cannot have a step of zero");
        const r = {
            start: e,
            stop: t,
            step: n,
            dtype: s
        };
        return ka.runKernel(Fn, {}, r)
    }
    const tc = Ma({
        threshold_: function(e, t="binary", n=!1, s=.5) {
            const r = Da(e, "image", "threshold")
              , a = r.shape[0] * r.shape[1];
            let i, o, l, u, c = il(mu([s]), 255);
            if (b(3 === r.rank, (()=>`Error in threshold: image must be rank 3,but got rank ${r.rank}.`)),
            b(3 === r.shape[2] || 1 === r.shape[2], (()=>`Error in threshold: image color channel must be equal to 3 or 1but got ${r.shape[2]}.`)),
            b("int32" === r.dtype || "float32" === r.dtype, (()=>`Error in dtype: image dtype must be int32 or float32,but got dtype ${r.dtype}.`)),
            b("otsu" === t || "binary" === t, (()=>`Method must be binary or otsu, but was ${t}`)),
            3 === r.shape[2]) {
                [i,o,l] = dl(r, [1, 1, 1], -1);
                const e = il(i, .2989)
                  , t = il(o, .587)
                  , n = il(l, .114);
                u = sl(sl(e, t), n)
            } else
                u = e;
            if ("otsu" === t) {
                c = function(e, t) {
                    let n, s, r, a, i, o, l = mu([-1]), u = mu([0]), c = mu([0]);
                    for (let h = 0; h < e.size - 1; h++) {
                        n = pl(e, 0, h + 1),
                        s = pl(e, h + 1),
                        i = al(nu(n), t),
                        o = al(nu(s), t);
                        const p = nu(il(n, ec(0, n.size)));
                        r = al(p, nu(n));
                        const d = wu(s.shape, n.size)
                          , f = sl(ec(0, s.size), d)
                          , m = il(s, f);
                        a = al(nu(m), nu(s));
                        const g = Yu(r, a)
                          , y = Yu(r, a)
                          , b = il(i, o);
                        c = il(il(b, g), y);
                        const x = Xu(c, u);
                        u = Qu(x, c, u),
                        l = Qu(x, mu([h]), l)
                    }
                    return l
                }(qu(Ko(Zu(u), "int32"), Ba([]), 256), a)
            }
            const h = n ? Ku(u, c) : Xu(u, c);
            return Ko(il(h, 255), "int32")
        }
    });
    const nc = Ma({
        transform_: function(e, t, n="nearest", s="constant", r=0, a) {
            const i = Da(e, "image", "transform", "float32")
              , o = Da(t, "transforms", "transform", "float32");
            b(4 === i.rank, (()=>`Error in transform: image must be rank 4,but got rank ${i.rank}.`)),
            b(2 === o.rank && (o.shape[0] === i.shape[0] || 1 === o.shape[0]) && 8 === o.shape[1], (()=>"Error in transform: Input transform should be batch x 8 or 1 x 8")),
            b(null == a || 2 === a.length, (()=>`Error in transform: outputShape must be [height, width] or null, but got ${a}.`));
            const l = {
                image: i,
                transforms: o
            }
              , u = {
                interpolation: n,
                fillMode: s,
                fillValue: r,
                outputShape: a
            };
            return ka.runKernel(ks, l, u)
        }
    });
    const sc = Ma({
        greaterEqual_: function(e, t) {
            let n = Da(e, "a", "greaterEqual", "string_or_numeric")
              , s = Da(t, "b", "greaterEqual", "string_or_numeric");
            [n,s] = da(n, s),
            $l(n.shape, s.shape);
            const r = {
                a: n,
                b: s
            };
            return ka.runKernel(zt, r)
        }
    });
    const rc = Ma({
        logicalAnd_: function(e, t) {
            const n = Da(e, "a", "logicalAnd", "bool")
              , s = Da(t, "b", "logicalAnd", "bool");
            $l(n.shape, s.shape);
            const r = {
                a: n,
                b: s
            };
            return ka.runKernel(Zt, r)
        }
    });
    const ac = Ma({
        stack_: function(e, t=0) {
            const n = _a(e, "tensors", "stack", "string_or_numeric");
            b(n.length >= 1, (()=>"Pass at least one tensor to tf.stack")),
            n.length > 0 && b(t <= n[0].rank, (()=>"Axis must be <= rank of the tensor"));
            const s = n
              , r = {
                axis: t
            };
            return ka.runKernel(Sn, s, r)
        }
    });
    const ic = Ma({
        unstack_: function(e, t=0) {
            const n = Da(e, "x", "unstack", "string_or_numeric");
            b(t >= -n.shape.length && t < n.shape.length, (()=>`Axis = ${t} is not in [-${n.shape.length}, ${n.shape.length})`));
            const s = {
                value: n
            }
              , r = {
                axis: t
            };
            return ka.runKernel(Ns, s, r)
        }
    });
    const oc = Ma({
        bandPart_: function(e, t, n) {
            b(t % 1 == 0, (()=>`bandPart(): numLower must be an integer, got ${t}.`)),
            b(n % 1 == 0, (()=>`bandPart(): numUpper must be an integer, got ${n}.`));
            const s = Da(e, "a", "bandPart");
            b(s.rank >= 2, (()=>`bandPart(): Rank must be at least 2, got ${s.rank}.`));
            const r = s.shape
              , [a,i] = s.shape.slice(-2);
            if (!(t <= a))
                throw new Error(`bandPart(): numLower (${t}) must not be greater than the number of rows (${a}).`);
            if (!(n <= i))
                throw new Error(`bandPart(): numUpper (${n}) must not be greater than the number of columns (${i}).`);
            t < 0 && (t = a),
            n < 0 && (n = i);
            const o = hl(ec(0, a, 1, "int32"), [-1, 1])
              , l = ec(0, i, 1, "int32")
              , u = Yu(o, l)
              , c = rc(Ku(u, wl(+t, "int32")), sc(u, wl(-n, "int32")))
              , h = fl([a, i], s.dtype);
            return hl(ac(ic(hl(s, [-1, a, i])).map((e=>Qu(c, e, h)))), r)
        }
    });
    var lc = {};
    t(lc, "norm", (()=>Nc));
    const uc = Ma({
        abs_: function(e) {
            const t = Da(e, "x", "abs");
            if ("complex64" === t.dtype) {
                const e = {
                    x: t
                };
                return ka.runKernel(Je, e)
            }
            {
                const e = {
                    x: t
                };
                return ka.runKernel(Te, e)
            }
        }
    });
    var cc = {};
    function hc(e, t) {
        for (let n = 0; n < e.length; ++n)
            if (e[e.length - n - 1] !== t - 1 - n)
                return !1;
        return !0
    }
    function pc(e, t, n) {
        const s = e.length + t.length
          , r = [];
        let a = 0
          , i = 0;
        for (let o = 0; o < s; o++)
            -1 === n.indexOf(o) ? r.push(e[a++]) : r.push(t[i++]);
        return r
    }
    function dc(e, t) {
        const n = []
          , s = e.length;
        for (let r = 0; r < s; r++)
            -1 === t.indexOf(r) && n.push(e[r]);
        return [n, t.map((t=>e[t]))]
    }
    function fc(e, t) {
        return pc(e, t.map((e=>1)), t)
    }
    function mc(e, t, n) {
        b(hc(t, n), (()=>`${e} supports only inner-most axes for now. Got axes ${t} and rank-${n} input.`))
    }
    function gc(e, t) {
        if (hc(e, t))
            return null;
        const n = [];
        for (let s = 0; s < t; ++s)
            -1 === e.indexOf(s) && n.push(s);
        return e.forEach((e=>n.push(e))),
        n
    }
    function yc(e) {
        return e.map(((e,t)=>[t, e])).sort(((e,t)=>e[1] - t[1])).map((e=>e[0]))
    }
    function bc(e, t) {
        const n = [];
        for (let s = t - e; s < t; ++s)
            n.push(s);
        return n
    }
    t(cc, "axesAreInnerMostDims", (()=>hc)),
    t(cc, "combineLocations", (()=>pc)),
    t(cc, "computeOutAndReduceShapes", (()=>dc)),
    t(cc, "expandShapeToKeepDim", (()=>fc)),
    t(cc, "assertAxesAreInnerMostDims", (()=>mc)),
    t(cc, "getAxesPermutation", (()=>gc)),
    t(cc, "getUndoAxesPermutation", (()=>yc)),
    t(cc, "getInnerMostAxes", (()=>bc));
    const xc = Ma({
        max_: function(e, t=null, n=!1) {
            const s = {
                x: Da(e, "x", "max")
            }
              , r = {
                reductionIndices: t,
                keepDims: n
            };
            return ka.runKernel(nn, s, r)
        }
    });
    const wc = Ma({
        min_: function(e, t=null, n=!1) {
            const s = {
                x: Da(e, "x", "min")
            }
              , r = {
                axis: t,
                keepDims: n
            };
            return ka.runKernel(hn, s, r)
        }
    });
    const vc = Ma({
        pow_: function(e, t) {
            let n = Da(e, "base", "pow")
              , s = Da(t, "exp", "pow");
            [n,s] = da(n, s);
            const r = {
                a: n,
                b: s
            };
            return ka.runKernel(Tn, r)
        }
    });
    const kc = Ma({
        sqrt_: function(e) {
            const t = {
                x: Da(e, "x", "sqrt", "float32")
            };
            return ka.runKernel(ts, t)
        }
    });
    const Ic = Ma({
        square_: function(e) {
            const t = Da(e, "x", "square");
            return ka.runKernel("Square", {
                x: t
            }, {})
        }
    });
    function Sc(e, t, n=null) {
        if (0 === e.rank)
            return uc(e);
        if (1 !== e.rank && null === n)
            return Sc(hl(e, [-1]), t, n);
        if (1 === e.rank || "number" == typeof n || Array.isArray(n) && 1 === n.length) {
            if (1 === t)
                return nu(uc(e), n);
            if (t === 1 / 0)
                return xc(uc(e), n);
            if (t === -1 / 0)
                return wc(uc(e), n);
            if ("euclidean" === t || 2 === t)
                return kc(nu(vc(uc(e), wl(2, "int32")), n));
            throw new Error(`Error in norm: invalid ord value: ${t}`)
        }
        if (Array.isArray(n) && 2 === n.length) {
            if (1 === t)
                return xc(nu(uc(e), n[0]), n[1] - 1);
            if (t === 1 / 0)
                return xc(nu(uc(e), n[1]), n[0]);
            if (t === -1 / 0)
                return wc(nu(uc(e), n[1]), n[0]);
            if ("fro" === t || "euclidean" === t)
                return kc(nu(Ic(e), n));
            throw new Error(`Error in norm: invalid ord value: ${t}`)
        }
        throw new Error(`Error in norm: invalid axis: ${n}`)
    }
    const Nc = Ma({
        norm_: function(e, t="euclidean", n=null, s=!1) {
            const r = Sc(e = Da(e, "x", "norm"), t, n);
            let a = r.shape;
            if (s) {
                const t = R(n, e.shape);
                a = fc(r.shape, t)
            }
            return hl(r, a)
        }
    });
    const Tc = Ma({
        squeeze_: function(e, t) {
            const n = Da(e, "x", "squeeze", "string_or_numeric");
            return hl(n, F(n.shape, t).newShape)
        }
    });
    const Cc = Ma({
        gramSchmidt_: function(e) {
            let t;
            if (Array.isArray(e)) {
                t = !1,
                b(null != e && e.length > 0, (()=>"Gram-Schmidt process: input must not be null, undefined, or empty"));
                const n = e[0].shape[0];
                for (let t = 1; t < e.length; ++t)
                    b(e[t].shape[0] === n, (()=>`Gram-Schmidt: Non-unique lengths found in the input vectors: (${e[t].shape[0]} vs. ${n})`))
            } else
                t = !0,
                e = dl(e, e.shape[0], 0).map((e=>Tc(e, [0])));
            b(e.length <= e[0].shape[0], (()=>`Gram-Schmidt: Number of vectors (${e.length}) exceeds number of dimensions (${e[0].shape[0]}).`));
            const n = []
              , s = e;
            for (let t = 0; t < e.length; ++t)
                n.push(ka.tidy((()=>{
                    let e = s[t];
                    if (t > 0)
                        for (let s = 0; s < t; ++s) {
                            const t = il(nu(il(n[s], e)), n[s]);
                            e = Yu(e, t)
                        }
                    return al(e, Nc(e, "euclidean"))
                }
                )));
            return t ? ac(n, 0) : n
        }
    });
    const $c = Ma({
        expandDims_: function(e, t=0) {
            const n = Da(e, "x", "expandDims", "string_or_numeric");
            b(t <= n.rank, (()=>"Axis must be <= rank of the tensor"));
            const s = {
                input: n
            }
              , r = {
                dim: t
            };
            return ka.runKernel(Ct, s, r)
        }
    });
    const Ec = Ma({
        eye_: function(e, t, n, s="float32") {
            null == t && (t = e);
            const r = qo([e, t], s)
              , a = e <= t ? e : t;
            for (let e = 0; e < a; ++e)
                r.set(1, e, e);
            const i = hl(r.toTensor(), [e, t]);
            if (null == n)
                return i;
            if (1 === n.length)
                return Tu($c(i, 0), [n[0], 1, 1]);
            if (2 === n.length)
                return Tu($c($c(i, 0), 0), [n[0], n[1], 1, 1]);
            if (3 === n.length)
                return Tu($c($c($c(i, 0), 0), 0), [n[0], n[1], n[2], 1, 1]);
            throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${n.length}D.`)
        }
    });
    const Ac = Ma({
        neg_: function(e) {
            const t = {
                x: Da(e, "x", "neg")
            };
            return ka.runKernel(yn, t)
        }
    });
    var Rc = {};
    t(Rc, "transpose", (()=>Fc));
    const Fc = Ma({
        transpose_: function(e, t, n) {
            const s = Da(e, "x", "transpose");
            if (null == t && (t = s.shape.map(((e,t)=>t)).reverse()),
            b(s.rank === t.length, (()=>`Error in transpose: rank of input ${s.rank} must match length of perm ${t}.`)),
            t.forEach((e=>{
                b(e >= 0 && e < s.rank, (()=>"All entries in 'perm' must be between 0 and " + (s.rank - 1) + ` but got ${t}`))
            }
            )),
            s.rank <= 1)
                return s.clone();
            const r = {
                x: s
            }
              , a = {
                perm: t
            };
            return "complex64" === s.dtype ? Qo((()=>{
                let e = cl(s)
                  , t = ul(s);
                return e = ka.runKernel(Is, {
                    x: e
                }, a),
                t = ka.runKernel(Is, {
                    x: t
                }, a),
                n && (t = Ac(t)),
                La(e, t)
            }
            )) : ka.runKernel(Is, r, a)
        }
    });
    function Dc(e, t=!1) {
        return ka.tidy((()=>{
            b(2 === e.shape.length, (()=>`qr2d() requires a 2D Tensor, but got a ${e.shape.length}D Tensor.`));
            const n = e.shape[0]
              , s = e.shape[1];
            let r = Ec(n)
              , a = Xo(e);
            const i = vu([[1]], [1, 1]);
            let o = Xo(i);
            const l = n >= s ? s : n;
            for (let e = 0; e < l; ++e) {
                const t = a
                  , l = o
                  , u = r;
                [o,a,r] = ka.tidy((()=>{
                    const t = pl(a, [e, e], [n - e, 1])
                      , l = Nc(t)
                      , u = pl(a, [e, e], [1, 1])
                      , c = Qu(Xu(u, 0), vu([[-1]]), vu([[1]]))
                      , h = Yu(u, il(c, l))
                      , p = al(t, h);
                    o = 1 === p.shape[0] ? Xo(i) : ll([i, pl(p, [1, 0], [p.shape[0] - 1, p.shape[1]])], 0);
                    const d = Ac(al(pu(c, h), l))
                      , f = pl(a, [e, 0], [n - e, s])
                      , m = il(d, o)
                      , g = Fc(o);
                    if (0 === e)
                        a = Yu(f, pu(m, pu(g, f)));
                    else {
                        const t = Yu(f, pu(m, pu(g, f)));
                        a = ll([pl(a, [0, 0], [e, s]), t], 0)
                    }
                    const y = Fc(m)
                      , b = pl(r, [0, e], [n, r.shape[1] - e]);
                    if (0 === e)
                        r = Yu(b, pu(pu(b, o), y));
                    else {
                        const t = Yu(b, pu(pu(b, o), y));
                        r = ll([pl(r, [0, 0], [n, e]), t], 1)
                    }
                    return [o, a, r]
                }
                )),
                el([t, l, u])
            }
            return !t && n > s && (r = pl(r, [0, 0], [n, s]),
            a = pl(a, [0, 0], [s, s])),
            [r, a]
        }
        ))
    }
    const _c = Ma({
        qr_: function(e, t=!1) {
            if (b(e.rank >= 2, (()=>`qr() requires input tensor to have a rank >= 2, but got rank ${e.rank}`)),
            2 === e.rank)
                return Dc(e, t);
            {
                const n = e.shape.slice(0, e.shape.length - 2).reduce(((e,t)=>e * t))
                  , s = ic(hl(e, [n, e.shape[e.shape.length - 2], e.shape[e.shape.length - 1]]), 0)
                  , r = []
                  , a = [];
                s.forEach((e=>{
                    const [n,s] = Dc(e, t);
                    r.push(n),
                    a.push(s)
                }
                ));
                return [hl(ac(r, 0), e.shape), hl(ac(a, 0), e.shape)]
            }
        }
    });
    var Oc;
    !function(e) {
        e[e.NONE = 0] = "NONE",
        e[e.MEAN = 1] = "MEAN",
        e[e.SUM = 2] = "SUM",
        e[e.SUM_BY_NONZERO_WEIGHTS = 3] = "SUM_BY_NONZERO_WEIGHTS"
    }(Oc || (Oc = {}));
    const Mc = Ma({
        mean_: function(e, t=null, n=!1) {
            const s = {
                x: Da(e, "x", "mean")
            }
              , r = {
                axis: t,
                keepDims: n
            };
            return ka.runKernel(cn, s, r)
        }
    });
    const Lc = Ma({
        notEqual_: function(e, t) {
            let n = Da(e, "a", "notEqual", "string_or_numeric")
              , s = Da(t, "b", "notEqual", "string_or_numeric");
            [n,s] = da(n, s),
            $l(n.shape, s.shape);
            const r = {
                a: n,
                b: s
            };
            return ka.runKernel(bn, r)
        }
    });
    function zc(e, t="float32") {
        if (Q(e),
        "complex64" === t) {
            const t = zc(e, "float32")
              , n = fl(e, "float32");
            return La(t, n)
        }
        const n = Y(v(e), t);
        return ka.makeTensor(n, e, t)
    }
    const Bc = Ma({
        computeWeightedLoss_: function(e, t, n=Oc.SUM_BY_NONZERO_WEIGHTS) {
            const s = Da(e, "losses", "computeWeightedLoss");
            let r = null;
            null != t && (r = Da(t, "weights", "computeWeightedLoss"));
            const a = null == r ? s : il(s, r);
            if (n === Oc.NONE)
                return a;
            if (n === Oc.SUM)
                return nu(a);
            if (n === Oc.MEAN) {
                if (null == r)
                    return Mc(a);
                {
                    const e = s.size / r.size
                      , t = al(nu(a), nu(r));
                    return e > 1 ? al(t, wl(e)) : t
                }
            }
            if (n === Oc.SUM_BY_NONZERO_WEIGHTS) {
                if (null == r)
                    return al(nu(a), wl(s.size));
                {
                    const e = il(r, zc(s.shape))
                      , t = Ko(nu(Lc(e, wl(0))), "float32");
                    return al(nu(a), t)
                }
            }
            throw Error(`Unknown reduction: ${n}`)
        }
    });
    const Pc = Ma({
        absoluteDifference_: function(e, t, n, s=Oc.SUM_BY_NONZERO_WEIGHTS) {
            const r = Da(e, "labels", "absoluteDifference")
              , a = Da(t, "predictions", "absoluteDifference");
            let i = null;
            null != n && (i = Da(n, "weights", "absoluteDifference")),
            x(r.shape, a.shape, "Error in absoluteDifference: ");
            const o = uc(Yu(r, a));
            return Bc(o, i, s)
        }
    });
    const Wc = Ma({
        cosineDistance_: function(e, t, n, s, r=Oc.SUM_BY_NONZERO_WEIGHTS) {
            const a = Da(e, "labels", "cosineDistance")
              , i = Da(t, "predictions", "cosineDistance");
            let o = null;
            null != s && (o = Da(s, "weights", "cosineDistance")),
            x(a.shape, i.shape, "Error in cosineDistance: ");
            const l = wl(1)
              , u = Yu(l, nu(il(a, i), n, !0));
            return Bc(u, o, r)
        }
    });
    const Uc = Ma({
        hingeLoss_: function(e, t, n, s=Oc.SUM_BY_NONZERO_WEIGHTS) {
            let r = Da(e, "labels", "hingeLoss");
            const a = Da(t, "predictions", "hingeLoss");
            let i = null;
            null != n && (i = Da(n, "weights", "hingeLoss")),
            x(r.shape, a.shape, "Error in hingeLoss: ");
            const o = wl(1);
            r = Yu(il(wl(2), r), o);
            const l = Jl(Yu(o, il(r, a)));
            return Bc(l, i, s)
        }
    });
    const Vc = Ma({
        minimum_: function(e, t) {
            let n = Da(e, "a", "minimum")
              , s = Da(t, "b", "minimum");
            [n,s] = da(n, s),
            "bool" === n.dtype && (n = Ko(n, "int32"),
            s = Ko(s, "int32")),
            $l(n.shape, s.shape);
            const r = {
                a: n,
                b: s
            };
            return ka.runKernel(pn, r)
        }
    });
    const Gc = Ma({
        huberLoss_: function(e, t, n, s=1, r=Oc.SUM_BY_NONZERO_WEIGHTS) {
            const a = Da(e, "labels", "huberLoss")
              , i = Da(t, "predictions", "huberLoss");
            let o = null;
            null != n && (o = Da(n, "weights", "huberLoss")),
            x(a.shape, i.shape, "Error in huberLoss: ");
            const l = wl(s)
              , u = uc(Yu(i, a))
              , c = Vc(u, l)
              , h = Yu(u, c)
              , p = sl(il(wl(.5), Ic(c)), il(l, h));
            return Bc(p, o, r)
        }
    });
    const Hc = Ma({
        log_: function(e) {
            const t = {
                x: Da(e, "x", "log", "float32")
            };
            return ka.runKernel(Xt, t)
        }
    });
    const jc = Ma({
        logLoss_: function(e, t, n, s=1e-7, r=Oc.SUM_BY_NONZERO_WEIGHTS) {
            const a = Da(e, "labels", "logLoss")
              , i = Da(t, "predictions", "logLoss");
            let o = null;
            null != n && (o = Da(n, "weights", "logLoss")),
            x(a.shape, i.shape, "Error in logLoss: ");
            const l = wl(1)
              , u = wl(s)
              , c = Ac(il(a, Hc(sl(i, u))))
              , h = il(Yu(l, a), Hc(sl(Yu(l, i), u)))
              , p = Yu(c, h);
            return Bc(p, o, r)
        }
    });
    const qc = Ma({
        squaredDifference_: function(e, t) {
            let n = Da(e, "a", "squaredDifference")
              , s = Da(t, "b", "squaredDifference");
            [n,s] = da(n, s),
            $l(n.shape, s.shape);
            const r = {
                a: n,
                b: s
            };
            return ka.runKernel(hs, r, {})
        }
    });
    const Kc = Ma({
        meanSquaredError_: function(e, t, n, s=Oc.SUM_BY_NONZERO_WEIGHTS) {
            const r = Da(e, "labels", "meanSquaredError")
              , a = Da(t, "predictions", "meanSquaredError");
            let i = null;
            null != n && (i = Da(n, "weights", "meanSquaredError")),
            x(r.shape, a.shape, "Error in meanSquaredError: ");
            const o = qc(r, a);
            return Bc(o, i, s)
        }
    });
    const Xc = Ma({
        exp_: function(e) {
            const t = {
                x: Da(e, "x", "exp")
            };
            return ka.runKernel(Tt, t)
        }
    });
    const Yc = Ma({
        log1p_: function(e) {
            const t = {
                x: Da(e, "x", "log1p")
            };
            return ka.runKernel(Yt, t)
        }
    });
    const Zc = Ma({
        sigmoidCrossEntropy_: function(e, t, n, s=0, r=Oc.SUM_BY_NONZERO_WEIGHTS) {
            let a = Da(e, "multiClassLabels", "sigmoidCrossEntropy");
            const i = Da(t, "logits", "sigmoidCrossEntropy");
            let o = null;
            if (null != n && (o = Da(n, "weights", "sigmoidCrossEntropy")),
            x(a.shape, i.shape, "Error in sigmoidCrossEntropy: "),
            s > 0) {
                const e = wl(s)
                  , t = wl(1)
                  , n = wl(.5);
                a = sl(il(a, Yu(t, e)), il(n, e))
            }
            const l = function(e, t) {
                const n = Da(e, "labels", "sigmoidCrossEntropyWithLogits")
                  , s = Da(t, "logits", "sigmoidCrossEntropyWithLogits");
                x(n.shape, s.shape, "Error in sigmoidCrossEntropyWithLogits: ");
                const r = Jl(s)
                  , a = il(s, n)
                  , i = Yc(Xc(Ac(uc(s))));
                return sl(Yu(r, a), i)
            }(a, i);
            return Bc(l, o, r)
        }
    });
    const Jc = Ma({
        logSumExp_: function(e, t=null, n=!1) {
            const s = Da(e, "x", "logSumExp")
              , r = R(t, s.shape)
              , a = xc(s, r, !0)
              , i = Yu(s, a)
              , o = Xc(i)
              , l = nu(o, r)
              , u = Hc(l)
              , c = sl(hl(a, u.shape), u);
            if (n) {
                const e = fc(c.shape, r);
                return hl(c, e)
            }
            return c
        }
    });
    const Qc = Ma({
        softmaxCrossEntropy_: function(e, t, n, s=0, r=Oc.SUM_BY_NONZERO_WEIGHTS) {
            let a = Da(e, "onehotLabels", "softmaxCrossEntropy");
            const i = Da(t, "logits", "softmaxCrossEntropy");
            let o = null;
            if (null != n && (o = Da(n, "weights", "softmaxCrossEntropy")),
            x(a.shape, i.shape, "Error in softmaxCrossEntropy: "),
            s > 0) {
                const e = wl(s)
                  , t = wl(1)
                  , n = wl(a.shape[1]);
                a = sl(il(a, Yu(t, e)), al(e, n))
            }
            const l = function(e, t, n=-1) {
                if (-1 === n && (n = t.rank - 1),
                n !== t.rank - 1)
                    throw Error(`Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank ${t.rank} and dim was ${n}`);
                return Sl(((e,t,s)=>{
                    const r = Jc(t, [n], !0)
                      , a = Yu(Ko(t, "float32"), r);
                    s([e, a]);
                    const i = Ac(il(a, e));
                    return {
                        value: nu(i, [n]),
                        gradFunc: (e,t)=>{
                            const [s,r] = t
                              , a = fc(e.shape, [n]);
                            return [il(hl(e, a), Yu(Ko(s, "float32"), Xc(r))), il(hl(e, a), Yu(Xc(r), Ko(s, "float32")))]
                        }
                    }
                }
                ))(e, t)
            }(a, i);
            return Bc(l, o, r)
        }
    });
    const eh = Ma({
        sparseFillEmptyRows_: function(e, t, n, s) {
            const r = Da(e, "indices", "sparseFillEmptyRows", "int32")
              , a = Da(t, "values", "sparseFillEmptyRows")
              , i = Da(n, "denseShape", "sparseFillEmptyRows", "int32")
              , o = Da(s, "defaultValue", "sparseFillEmptyRows", a.dtype);
            if (2 !== r.rank)
                throw new Error(`Indices should be Tensor2D but received shape\n        ${r.shape}`);
            if (1 !== a.rank)
                throw new Error(`Values should be Tensor1D but received shape ${a.shape}`);
            if (1 !== i.rank)
                throw new Error(`Dense shape should be Tensor1D but received shape ${i.shape}`);
            if (0 !== o.rank)
                throw new Error(`Default value should be a scalar but received shape ${o.shape}`);
            const l = {
                indices: r,
                values: a,
                denseShape: i,
                defaultValue: o
            }
              , u = ka.runKernel(is, l);
            return {
                outputIndices: u[0],
                outputValues: u[1],
                emptyRowIndicator: u[2],
                reverseIndexMap: u[3]
            }
        }
    });
    const th = Ma({
        sparseReshape_: function(e, t, n) {
            const s = Da(e, "inputIndices", "sparseReshape", "int32")
              , r = Da(t, "inputShape", "sparseReshape", "int32")
              , a = Da(n, "newShape", "sparseReshape", "int32");
            if (2 !== s.rank)
                throw new Error(`Input indices should be Tensor2D but received shape\n        ${s.shape}`);
            if (1 !== r.rank)
                throw new Error(`Input shape should be Tensor1D but received shape ${r.shape}`);
            if (1 !== a.rank)
                throw new Error(`New shape should be Tensor1D but received shape ${a.shape}`);
            const i = {
                inputIndices: s,
                inputShape: r,
                newShape: a
            }
              , o = ka.runKernel(os, i);
            return {
                outputIndices: o[0],
                outputShape: o[1]
            }
        }
    });
    const nh = Ma({
        sparseSegmentMean_: function(e, t, n) {
            const s = Da(e, "data", "sparseSegmentMean")
              , r = Da(t, "indices", "sparseSegmentMean", "int32")
              , a = Da(n, "segmentIds", "sparseSegmentMean", "int32");
            if (s.rank < 1)
                throw new Error("Data should be at least 1 dimensional but received scalar");
            if (1 !== r.rank)
                throw new Error(`Indices should be Tensor1D but received shape\n          ${r.shape}`);
            if (1 !== a.rank)
                throw new Error(`Segment ids should be Tensor1D but received shape\n          ${a.shape}`);
            const i = {
                data: s,
                indices: r,
                segmentIds: a
            };
            return ka.runKernel(ls, i)
        }
    });
    const sh = Ma({
        sparseSegmentSum_: function(e, t, n) {
            const s = Da(e, "data", "sparseSegmentSum")
              , r = Da(t, "indices", "sparseSegmentSum", "int32")
              , a = Da(n, "segmentIds", "sparseSegmentSum", "int32");
            if (s.rank < 1)
                throw new Error("Data should be at least 1 dimensional but received scalar");
            if (1 !== r.rank)
                throw new Error(`Indices should be Tensor1D but received shape\n         ${r.shape}`);
            if (1 !== a.rank)
                throw new Error(`Segment ids should be Tensor1D but received shape\n         ${a.shape}`);
            const i = {
                data: s,
                indices: r,
                segmentIds: a
            };
            return ka.runKernel(us, i)
        }
    });
    const rh = Ma({
        stringNGrams_: function(e, t, n, s, r, a, i, o) {
            const l = Da(e, "data", "stringNGrams", "string");
            if ("string" !== l.dtype)
                throw new Error("Data must be of datatype string");
            if (1 !== l.shape.length)
                throw new Error(`Data must be a vector, saw: ${l.shape}`);
            const u = Da(t, "dataSplits", "stringNGrams");
            if ("int32" !== u.dtype)
                throw new Error("Data splits must be of datatype int32");
            const c = {
                separator: n,
                nGramWidths: s,
                leftPad: r,
                rightPad: a,
                padWidth: i,
                preserveShortSequences: o
            }
              , h = {
                data: l,
                dataSplits: u
            }
              , p = ka.runKernel(fs, h, c);
            return {
                nGrams: p[0],
                nGramsSplits: p[1]
            }
        }
    });
    const ah = Ma({
        stringSplit_: function(e, t, n=!0) {
            const s = Da(e, "input", "stringSplit", "string")
              , r = Da(t, "delimiter", "stringSplit", "string");
            if (1 !== s.rank)
                throw new Error(`Input should be Tensor1D but received shape ${s.shape}`);
            if (0 !== r.rank)
                throw new Error(`Delimiter should be a scalar but received shape ${r.shape}`);
            const a = {
                skipEmpty: n
            }
              , i = {
                input: s,
                delimiter: r
            }
              , o = ka.runKernel(ms, i, a);
            return {
                indices: o[0],
                values: o[1],
                shape: o[2]
            }
        }
    });
    const ih = Ma({
        stringToHashBucketFast_: function(e, t) {
            const n = Da(e, "input", "stringToHashBucketFast", "string")
              , s = {
                numBuckets: t
            };
            if (t <= 0)
                throw new Error("Number of buckets must be at least 1");
            const r = {
                input: n
            };
            return ka.runKernel(gs, r, s)
        }
    });
    const oh = Ma({
        acos_: function(e) {
            const t = {
                x: Da(e, "x", "acos")
            };
            return ka.runKernel(Ce, t)
        }
    });
    const lh = Ma({
        acosh_: function(e) {
            const t = {
                x: Da(e, "x", "acosh")
            };
            return ka.runKernel($e, t)
        }
    });
    const uh = Ma({
        addN_: function(e) {
            b(Array.isArray(e), (()=>"The argument passed to tf.addN() must be a list of tensors")),
            b(e.length >= 1, (()=>`Must pass at least one tensor to tf.addN(), but got ${e.length}`));
            const t = e.map(((e,t)=>Da(e, `tensors${t}`, "addN")))
              , n = t[0];
            t.forEach((e=>{
                if (e.dtype !== n.dtype)
                    throw new Error("All tensors passed to tf.addN() must have the same dtype")
            }
            )),
            t.forEach((e=>{
                if (!I(e.shape, n.shape))
                    throw new Error("All tensors passed to tf.addN() must have the same shape")
            }
            ));
            const s = t;
            return ka.runKernel(Ae, s)
        }
    });
    const ch = Ma({
        all_: function(e, t=null, n=!1) {
            const s = {
                x: Da(e, "x", "all", "bool")
            }
              , r = {
                axis: t,
                keepDims: n
            };
            return ka.runKernel(Re, s, r)
        }
    });
    const hh = Ma({
        any_: function(e, t=null, n=!1) {
            const s = {
                x: Da(e, "x", "any", "bool")
            }
              , r = {
                axis: t,
                keepDims: n
            };
            return ka.runKernel(Fe, s, r)
        }
    });
    const ph = Ma({
        argMax_: function(e, t=0) {
            const n = {
                x: Da(e, "x", "argMax")
            }
              , s = {
                axis: t
            };
            return ka.runKernel(De, n, s)
        }
    });
    const dh = Ma({
        argMin_: function(e, t=0) {
            const n = {
                x: Da(e, "x", "argMin")
            }
              , s = {
                axis: t
            };
            return ka.runKernel(_e, n, s)
        }
    });
    const fh = Ma({
        asin_: function(e) {
            const t = {
                x: Da(e, "x", "asin")
            };
            return ka.runKernel(Oe, t)
        }
    });
    const mh = Ma({
        asinh_: function(e) {
            const t = {
                x: Da(e, "x", "asinh")
            };
            return ka.runKernel(Me, t)
        }
    });
    const gh = Ma({
        atan_: function(e) {
            const t = {
                x: Da(e, "x", "atan")
            };
            return ka.runKernel(Le, t)
        }
    });
    const yh = Ma({
        atan2_: function(e, t) {
            let n = Da(e, "a", "atan2")
              , s = Da(t, "b", "atan2");
            [n,s] = da(n, s);
            const r = {
                a: n,
                b: s
            };
            return ka.runKernel(Be, r)
        }
    });
    const bh = Ma({
        atanh_: function(e) {
            const t = {
                x: Da(e, "x", "atanh")
            };
            return ka.runKernel(ze, t)
        }
    });
    const xh = Ma({
        avgPool_: function(e, t, n, s, r) {
            const a = Da(e, "x", "avgPool", "float32");
            b(Wl(n, 1), (()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`));
            let i = a
              , o = !1;
            3 === a.rank && (o = !0,
            i = hl(a, [1, a.shape[0], a.shape[1], a.shape[2]])),
            b(4 === i.rank, (()=>`Error in avgPool: x must be rank 4 but got rank ${i.rank}.`)),
            Gl("avgPool", s, r);
            const l = {
                x: i
            }
              , u = {
                filterSize: t,
                strides: n,
                pad: s,
                dimRoundingMode: r
            };
            let c = ka.runKernel(Pe, l, u);
            return c = Ko(c, a.dtype),
            o ? hl(c, [c.shape[1], c.shape[2], c.shape[3]]) : c
        }
    });
    const wh = Ma({
        avgPool3d_: function(e, t, n, s, r, a="NDHWC") {
            const i = Da(e, "x", "avgPool3d", "float32");
            let o = i
              , l = !1;
            4 === i.rank && (l = !0,
            o = hl(i, [1, i.shape[0], i.shape[1], i.shape[2], i.shape[3]])),
            b(5 === o.rank, (()=>`Error in avgPool3d: x must be rank 5 but got rank ${o.rank}.`)),
            b("NDHWC" === a, (()=>`Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ${a}`)),
            b("number" == typeof n && n > 0 || Array.isArray(n) && n[0] > 0 && n[1] > 0 && n[2] > 0, (()=>`Error in avgPool3d: Stride must be > 0, but got '${n}'`)),
            Gl("avgPool3d", s, r);
            const u = {
                x: o
            }
              , c = {
                filterSize: t,
                strides: n,
                pad: s,
                dimRoundingMode: r,
                dataFormat: a
            };
            let h = ka.runKernel(Ue, u, c);
            return h = Ko(h, o.dtype),
            l ? hl(h, [h.shape[1], h.shape[2], h.shape[3], h.shape[4]]) : h
        }
    });
    const vh = Ma({
        tanh_: function(e) {
            const t = {
                x: Da(e, "x", "tanh", "float32")
            };
            return ka.runKernel(xs, t)
        }
    });
    const kh = Ma({
        basicLSTMCell_: function(e, t, n, s, r, a) {
            const i = Da(e, "forgetBias", "basicLSTMCell")
              , o = Da(t, "lstmKernel", "basicLSTMCell")
              , l = Da(n, "lstmBias", "basicLSTMCell")
              , u = Da(s, "data", "basicLSTMCell")
              , c = Da(r, "c", "basicLSTMCell")
              , h = Da(a, "h", "basicLSTMCell")
              , p = ll([u, h], 1)
              , d = pu(p, o)
              , f = sl(d, l)
              , m = f.shape[0]
              , g = f.shape[1] / 4
              , y = [m, g]
              , b = pl(f, [0, 0], y)
              , x = pl(f, [0, g], y)
              , w = pl(f, [0, 2 * g], y)
              , v = pl(f, [0, 3 * g], y)
              , k = sl(il(eu(b), vh(x)), il(c, eu(sl(i, w))));
            return [k, il(vh(k), eu(v))]
        }
    });
    const Ih = Ma({
        batchToSpaceND_: function(e, t, n) {
            const s = Da(e, "x", "batchToSpaceND")
              , r = t.reduce(((e,t)=>e * t));
            b(s.rank >= 1 + t.length, (()=>`input rank is ${s.rank} but should be > than blockShape.length ${t.length}`)),
            b(n.length === t.length, (()=>`crops.length is ${n.length} but should be equal to blockShape.length  ${t.length}`)),
            b(s.shape[0] % r == 0, (()=>`input tensor batch is ${s.shape[0]} but is not divisible by the product of the elements of blockShape ${t.join(" * ")} === ${r}`));
            const a = {
                x: s
            }
              , i = {
                blockShape: t,
                crops: n
            };
            return ka.runKernel(He, a, i)
        }
    });
    const Sh = Ma({
        batchNorm_: function(e, t, n, s, r, a) {
            null == a && (a = .001);
            const i = Da(e, "x", "batchNorm")
              , o = Da(t, "mean", "batchNorm")
              , l = Da(n, "variance", "batchNorm");
            let u, c;
            null != r && (u = Da(r, "scale", "batchNorm")),
            null != s && (c = Da(s, "offset", "batchNorm")),
            b(o.rank === l.rank, (()=>"Batch normalization gradient requires mean and variance to have equal ranks.")),
            b(null == c || o.rank === c.rank, (()=>"Batch normalization gradient requires mean and offset to have equal ranks.")),
            b(null == u || o.rank === u.rank, (()=>"Batch normalization gradient requires mean and scale to have equal ranks."));
            const h = function(e) {
                let t;
                return t = 0 === e.rank || 1 === e.rank ? hl(e, [1, 1, 1, e.size]) : 2 === e.rank ? hl(e, [1, 1, e.shape[0], e.shape[1]]) : 3 === e.rank ? hl(e, [1, e.shape[0], e.shape[1], e.shape[2]]) : e,
                t
            }(i)
              , p = {
                x: h,
                scale: u,
                offset: c,
                mean: o,
                variance: l
            }
              , d = {
                varianceEpsilon: a
            }
              , f = ka.runKernel(_t, p, d);
            return hl(f, i.shape)
        }
    });
    const Nh = Ma({
        batchNorm2d_: function(e, t, n, s, r, a) {
            const i = Da(e, "x", "batchNorm")
              , o = Da(t, "mean", "batchNorm")
              , l = Da(n, "variance", "batchNorm");
            let u, c;
            return null != r && (u = Da(r, "scale", "batchNorm")),
            null != s && (c = Da(s, "offset", "batchNorm")),
            b(2 === i.rank, (()=>`Error in batchNorm2D: x must be rank 2 but got rank ${i.rank}.`)),
            b(2 === o.rank || 1 === o.rank, (()=>`Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${o.rank}.`)),
            b(2 === l.rank || 1 === l.rank, (()=>`Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${l.rank}.`)),
            null != u && b(2 === u.rank || 1 === u.rank, (()=>`Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${u.rank}.`)),
            null != c && b(2 === c.rank || 1 === c.rank, (()=>`Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${c.rank}.`)),
            Sh(i, o, l, c, u, a)
        }
    });
    const Th = Ma({
        batchNorm3d_: function(e, t, n, s, r, a) {
            const i = Da(e, "x", "batchNorm")
              , o = Da(t, "mean", "batchNorm")
              , l = Da(n, "variance", "batchNorm");
            let u, c;
            return null != r && (u = Da(r, "scale", "batchNorm")),
            null != s && (c = Da(s, "offset", "batchNorm")),
            b(3 === i.rank, (()=>`Error in batchNorm3D: x must be rank 3 but got rank ${i.rank}.`)),
            b(3 === o.rank || 1 === o.rank, (()=>`Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${o.rank}.`)),
            b(3 === l.rank || 1 === l.rank, (()=>`Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${l.rank}.`)),
            null != u && b(3 === u.rank || 1 === u.rank, (()=>`Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${u.rank}.`)),
            null != c && b(3 === c.rank || 1 === c.rank, (()=>`Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${c.rank}.`)),
            Sh(i, o, l, c, u, a)
        }
    });
    const Ch = Ma({
        batchNorm4d_: function(e, t, n, s, r, a) {
            const i = Da(e, "x", "batchNorm")
              , o = Da(t, "mean", "batchNorm")
              , l = Da(n, "variance", "batchNorm");
            let u, c;
            return null != r && (u = Da(r, "scale", "batchNorm")),
            null != s && (c = Da(s, "offset", "batchNorm")),
            b(4 === i.rank, (()=>`Error in batchNorm4D: x must be rank 4 but got rank ${i.rank}.`)),
            b(4 === o.rank || 1 === o.rank, (()=>`Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${o.rank}.`)),
            b(4 === l.rank || 1 === l.rank, (()=>`Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${l.rank}.`)),
            null != u && b(4 === u.rank || 1 === u.rank, (()=>`Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${u.rank}.`)),
            null != c && b(4 === c.rank || 1 === c.rank, (()=>`Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${c.rank}.`)),
            Sh(i, o, l, c, u, a)
        }
    });
    const $h = Ma({
        broadcastArgs_: function(e, t) {
            const n = Da(e, "s0", "broadcastArgs", "int32")
              , s = Da(t, "s1", "broadcastArgs", "int32");
            if (1 !== n.rank)
                throw new Error(`broadcastArgs(): first input must be a vector (rank=1). Has rank ${n.rank}`);
            if (1 !== s.rank)
                throw new Error(`broadcastArgs(): second input must be a vector (rank=1). Has rank ${s.rank}`);
            const r = {
                s0: n,
                s1: s
            };
            return ka.runKernel(qe, r)
        }
    });
    const Eh = Ma({
        ceil_: function(e) {
            const t = {
                x: Da(e, "x", "ceil", "float32")
            };
            return ka.runKernel(Xe, t)
        }
    });
    const Ah = Ma({
        clipByValue_: function(e, t, n) {
            const s = Da(e, "x", "clipByValue");
            if (b(t <= n, (()=>`Error in clip: min (${t}) must be less than or equal to max (${n}).`)),
            t === n)
                return wu(s.shape, t, s.dtype);
            const r = {
                x: s
            }
              , a = {
                clipValueMin: t,
                clipValueMax: n
            };
            return ka.runKernel(Ye, r, a)
        }
    });
    const Rh = Ma({
        concat1d_: function(e) {
            return ll(e, 0)
        }
    });
    const Fh = Ma({
        concat2d_: function(e, t) {
            return ll(e, t)
        }
    });
    const Dh = Ma({
        concat3d_: function(e, t) {
            return ll(e, t)
        }
    });
    const _h = Ma({
        concat4d_: function(e, t) {
            return ll(e, t)
        }
    });
    const Oh = Ma({
        conv1d_: function(e, t, n, s, r="NWC", a=1, i) {
            const o = Da(e, "x", "conv1d")
              , l = Da(t, "filter", "conv1d");
            let u = o
              , c = !1;
            2 === o.rank && (c = !0,
            u = hl(o, [1, o.shape[0], o.shape[1]])),
            b(3 === u.rank, (()=>`Error in conv1d: input must be rank 3, but got rank ${u.rank}.`)),
            b(3 === l.rank, (()=>`Error in conv1d: filter must be rank 3, but got rank ${l.rank}.`)),
            Gl("conv1d", s, i),
            b(u.shape[2] === l.shape[1], (()=>`Error in conv1d: depth of input (${u.shape[2]}) must match input depth for filter ${l.shape[1]}.`)),
            b(Wl(n, a), (()=>`Error in conv1D: Either stride or dilation must be 1. Got stride ${n} and dilation '${a}'`)),
            b(Ul(a), (()=>"Error in conv1D: Dilated rates should be larger than 0.")),
            b(Ul(n), (()=>"Error in conv1D: Stride should be larger than 0.")),
            b("NWC" === r, (()=>`Error in conv1d: got dataFormat of ${r} but only NWC is currently supported.`));
            const h = hl(l, [1, l.shape[0], l.shape[1], l.shape[2]])
              , p = hl(u, [u.shape[0], 1, u.shape[1], u.shape[2]])
              , d = Hl(p, h, [1, n], s, "NHWC", [1, a], i);
            return hl(d, c ? [d.shape[2], d.shape[3]] : [d.shape[0], d.shape[2], d.shape[3]])
        }
    });
    const Mh = Ma({
        conv2dTranspose_: function(e, t, n, s, r, a) {
            const i = Da(e, "x", "conv2dTranspose")
              , o = Da(t, "filter", "conv2dTranspose");
            return ql(n, i, o, s, r, "NHWC", a)
        }
    });
    const Lh = Ma({
        conv3d_: function(e, t, n, s, r="NDHWC", a=[1, 1, 1]) {
            const i = Da(e, "x", "conv3d")
              , o = Da(t, "filter", "conv3d");
            let l = i
              , u = !1;
            4 === i.rank && (u = !0,
            l = hl(i, [1, i.shape[0], i.shape[1], i.shape[2], i.shape[3]])),
            b(5 === l.rank, (()=>`Error in conv3d: input must be rank 5, but got rank ${l.rank}.`)),
            b(5 === o.rank, (()=>`Error in conv3d: filter must be rank 5, but got rank ${o.rank}.`)),
            b(l.shape[4] === o.shape[3], (()=>`Error in conv3d: depth of input (${l.shape[4]}) must match input depth for filter ${o.shape[3]}.`)),
            b(Wl(n, a), (()=>`Error in conv3D: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`)),
            b("NDHWC" === r, (()=>`Error in conv3d: got dataFormat of ${r} but only NDHWC is currently supported.`)),
            b(Ul(a), (()=>"Error in conv3D: Dilated rates should be larger than 0.")),
            b(Ul(n), (()=>"Error in conv3D: Strides should be larger than 0."));
            const c = {
                x: l,
                filter: o
            }
              , h = {
                strides: n,
                pad: s,
                dataFormat: r,
                dilations: a
            }
              , p = ka.runKernel(st, c, h);
            return u ? hl(p, [p.shape[1], p.shape[2], p.shape[3], p.shape[4]]) : p
        }
    });
    const zh = Ma({
        conv3DBackpropInput_: function(e, t, n, s, r) {
            b(e.length === t.rank, (()=>`Length of inShape (${e.length}) and rank of dy (${t.rank}) must match`));
            let a = e
              , i = t
              , o = !1;
            4 === t.rank && (o = !0,
            i = hl(t, [1, t.shape[0], t.shape[1], t.shape[2], t.shape[3]]),
            a = [1, e[0], e[1], e[2], e[3]]);
            const l = a[4]
              , u = i.shape[4];
            b(5 === a.length, (()=>`Error in conv3dDerInput: inShape must be length 5, but got length ${a.length}.`)),
            b(5 === i.rank, (()=>`Error in conv3dDerInput: dy must be rank 5, but got rank ${i.rank}`)),
            b(5 === n.rank, (()=>`Error in conv3dDerInput: filter must be rank 5, but got rank ${n.rank}`)),
            b(l === n.shape[3], (()=>`Error in conv3dDerInput: depth of input (${l}) must match input depth for filter ${n.shape[3]}.`)),
            b(u === n.shape[4], (()=>`Error in conv3dDerInput: depth of output (${u}) must match output depth for filter ${n.shape[4]}.`));
            const c = {
                dy: i,
                filter: n
            }
              , h = {
                pad: r,
                strides: s,
                inputShape: a
            }
              , p = ka.runKernel(at, c, h);
            return o ? hl(p, [p.shape[1], p.shape[2], p.shape[3], p.shape[4]]) : p
        }
    });
    const Bh = Ma({
        conv3dTranspose_: function(e, t, n, s, r) {
            const a = Da(e, "x", "conv3dTranspose")
              , i = Da(t, "filter", "conv3dTranspose");
            return zh(n, a, i, s, r)
        }
    });
    const Ph = Ma({
        cos_: function(e) {
            const t = {
                x: Da(e, "x", "cos", "float32")
            };
            return ka.runKernel(it, t)
        }
    });
    const Wh = Ma({
        cosh_: function(e) {
            const t = {
                x: Da(e, "x", "cosh", "float32")
            };
            return ka.runKernel(ot, t)
        }
    });
    const Uh = Ma({
        cumprod_: function(e, t=0, n=!1, s=!1) {
            const r = {
                x: Da(e, "x", "cumprod")
            }
              , a = {
                axis: t,
                exclusive: n,
                reverse: s
            };
            return ka.runKernel(lt, r, a)
        }
    });
    const Vh = Ma({
        cumsum_: function(e, t=0, n=!1, s=!1) {
            const r = {
                x: Da(e, "x", "cumsum")
            }
              , a = {
                axis: t,
                exclusive: n,
                reverse: s
            };
            return ka.runKernel(ut, r, a)
        }
    });
    const Gh = Ma({
        denseBincount_: function(e, t, n, s=!1) {
            const r = Da(e, "x", "denseBincount")
              , a = Da(t, "weights", "denseBincount");
            b("int32" === r.dtype, (()=>`Error in denseBincount: input dtype must be int32, but got ${r.dtype}`)),
            b(r.rank <= 2, (()=>`Error in denseBincount: input must be at most rank 2, but got rank ${r.rank}.`)),
            b(n >= 0, (()=>`size must be non-negative, but got ${n}.`)),
            b(a.size === r.size || 0 === a.size, (()=>`Error in denseBincount: weights must have the same shape as x or 0-length, but got x shape: ${r.shape}, weights shape: ${a.shape}.`));
            const i = {
                x: r,
                weights: a
            }
              , o = {
                size: n,
                binaryOutput: s
            };
            return ka.runKernel(ht, i, o)
        }
    });
    const Hh = Ma({
        depthToSpace_: function(e, t, n="NHWC") {
            const s = Da(e, "x", "depthToSpace", "float32")
              , r = "NHWC" === n ? s.shape[1] : s.shape[2]
              , a = "NHWC" === n ? s.shape[2] : s.shape[3]
              , i = "NHWC" === n ? s.shape[3] : s.shape[1];
            b(t > 1, (()=>`blockSize should be > 1 for depthToSpace, but was: ${t}`)),
            b(r * t >= 0, (()=>`Negative dimension size caused by overflow when multiplying\n    ${r} and ${t}  for depthToSpace with input shape\n    ${s.shape}`)),
            b(a * t >= 0, (()=>`Negative dimension size caused by overflow when multiplying\n    ${a} and ${t} for depthToSpace with input shape\n        ${s.shape}`)),
            b(i % (t * t) == 0, (()=>`Dimension size must be evenly divisible by ${t * t} but is ${i} for depthToSpace with input shape ${s.shape}`));
            const o = {
                x: s
            }
              , l = {
                blockSize: t,
                dataFormat: n
            };
            return ka.runKernel(pt, o, l)
        }
    });
    const jh = Ma({
        diag_: function(e) {
            const t = {
                x: Da(e, "x", "diag")
            };
            return ka.runKernel(gt, t)
        }
    });
    const qh = Ma({
        dilation2d_: function(e, t, n, s, r=[1, 1], a="NHWC") {
            const i = Da(e, "x", "dilation2d")
              , o = Da(t, "filter", "dilation2d");
            b(3 === i.rank || 4 === i.rank, (()=>`Error in dilation2d: input must be rank 3 or 4, but got rank ${i.rank}.`)),
            b(3 === o.rank, (()=>`Error in dilation2d: filter must be rank 3, but got rank ${o.rank}.`)),
            b("NHWC" === a, (()=>`Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ${a}`));
            let l = i
              , u = !1;
            3 === i.rank && (l = hl(i, [1, i.shape[0], i.shape[1], i.shape[2]]),
            u = !0),
            b(l.shape[3] === o.shape[2], (()=>`Error in dilation2d:  input and filter must have the same depth: ${l.shape[3]} vs ${o.shape[2]}`));
            const c = {
                x: l,
                filter: o
            }
              , h = {
                strides: n,
                pad: s,
                dilations: r
            }
              , p = ka.runKernel(yt, c, h);
            return u ? hl(p, [p.shape[1], p.shape[2], p.shape[3]]) : p
        }
    });
    const Kh = Ma({
        equal_: function(e, t) {
            let n = Da(e, "a", "equal", "string_or_numeric")
              , s = Da(t, "b", "equal", "string_or_numeric");
            [n,s] = da(n, s),
            $l(n.shape, s.shape);
            const r = {
                a: n,
                b: s
            };
            return ka.runKernel(Nt, r)
        }
    });
    const Xh = Ma({
        divNoNan_: function(e, t) {
            let n = Da(e, "a", "div")
              , s = Da(t, "b", "div");
            [n,s] = da(n, s);
            const r = al(n, s)
              , a = ml(r)
              , i = Kh(s, a);
            return Qu(i, a, r)
        }
    });
    const Yh = Ma({
        dot_: function(e, t) {
            const n = Da(e, "t1", "dot")
              , s = Da(t, "t2", "dot");
            b(!(1 !== n.rank && 2 !== n.rank || 1 !== s.rank && 2 !== s.rank), (()=>`Error in dot: inputs must all be rank 1 or 2, but got ranks ${n.rank} and ${s.rank}.`));
            const r = 1 === n.rank ? n.size : n.shape[1]
              , a = 1 === s.rank ? s.size : s.shape[0];
            if (b(r === a, (()=>`Error in dot: inner dimensions of inputs must match, but got ${r} and ${a}.`)),
            1 === n.rank && 1 === s.rank) {
                const e = hl(n, [1, -1])
                  , t = hl(s, [-1, 1])
                  , r = pu(e, t);
                return hl(r, [])
            }
            if (1 === n.rank && 2 === s.rank) {
                const e = hl(n, [1, -1])
                  , t = hl(s, [s.shape[0], s.shape[1]])
                  , r = pu(e, t);
                return hl(r, [r.size])
            }
            if (2 === n.rank && 1 === s.rank) {
                const e = hl(s, [-1, 1])
                  , t = pu(n, e);
                return hl(t, [t.size])
            }
            {
                const e = hl(s, [s.shape[0], s.shape[1]]);
                return pu(n, e)
            }
        }
    });
    const Zh = Ma({
        einsum_: function(e, ...t) {
            const n = t.map(((e,t)=>Da(e, `tensors${t}`, "einsum")))
              , s = {
                equation: e
            };
            return ka.runKernel(vt, n, s)
        }
    });
    const Jh = Ma({
        erf_: function(e) {
            let t = Da(e, "x", "erf");
            b("int32" === t.dtype || "float32" === t.dtype, (()=>"Input dtype must be `int32` or `float32`.")),
            "int32" === t.dtype && (t = Ko(t, "float32"));
            const n = {
                x: t
            };
            return ka.runKernel(St, n)
        }
    });
    const Qh = Ma({
        euclideanNorm_: function(e, t=null, n=!1) {
            return Nc(e, "euclidean", t, n)
        }
    });
    const ep = Ma({
        expm1_: function(e) {
            const t = {
                x: Da(e, "x", "expm1")
            };
            return ka.runKernel($t, t)
        }
    });
    const tp = Ma({
        floor_: function(e) {
            const t = {
                x: Da(e, "x", "floor", "float32")
            };
            return ka.runKernel(Ft, t)
        }
    });
    const np = Ma({
        gather_: function(e, t, n=0, s=0) {
            const r = {
                x: Da(e, "x", "gather"),
                indices: Da(t, "indices", "gather", "int32")
            }
              , a = {
                axis: n,
                batchDims: s
            };
            return ka.runKernel(Ot, r, a)
        }
    });
    const sp = Ma({
        isFinite_: function(e) {
            const t = {
                x: Da(e, "x", "isFinite")
            };
            return ka.runKernel(Ut, t)
        }
    });
    const rp = Ma({
        isInf_: function(e) {
            const t = {
                x: Da(e, "x", "isInf")
            };
            return ka.runKernel(Vt, t)
        }
    });
    const ap = Ma({
        isNaN_: function(e) {
            const t = {
                x: Da(e, "x", "isNaN")
            };
            return ka.runKernel(Gt, t)
        }
    });
    const ip = Ma({
        less_: function(e, t) {
            let n = Da(e, "a", "less", "string_or_numeric")
              , s = Da(t, "b", "less", "string_or_numeric");
            [n,s] = da(n, s),
            $l(n.shape, s.shape);
            const r = {
                a: n,
                b: s
            };
            return ka.runKernel(jt, r)
        }
    });
    function op(e, t, n) {
        if (n <= 0)
            throw new Error("The number of values should be positive.");
        const s = {
            start: e,
            stop: t,
            num: n
        };
        return ka.runKernel(Kt, {}, s)
    }
    const lp = Ma({
        localResponseNormalization_: function(e, t=5, n=1, s=1, r=.5) {
            const a = Da(e, "x", "localResponseNormalization");
            b(4 === a.rank || 3 === a.rank, (()=>`Error in localResponseNormalization: x must be rank 3 or 4 but got\n               rank ${a.rank}.`)),
            b(S(t), (()=>`Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${t}.`));
            let i = a
              , o = !1;
            3 === a.rank && (o = !0,
            i = hl(a, [1, a.shape[0], a.shape[1], a.shape[2]]));
            const l = {
                x: i
            }
              , u = {
                depthRadius: t,
                bias: n,
                alpha: s,
                beta: r
            }
              , c = ka.runKernel(en, l, u);
            return o ? hl(c, [c.shape[1], c.shape[2], c.shape[3]]) : c
        }
    });
    const up = Ma({
        softplus_: function(e) {
            const t = {
                x: Da(e, "x", "softplus")
            };
            return ka.runKernel(es, t)
        }
    });
    const cp = Ma({
        logSigmoid_: function(e) {
            const t = Da(e, "x", "logSigmoid");
            return Sl((e=>({
                value: Ac(up(Ac(e))),
                gradFunc: t=>il(t, eu(Ac(e)))
            })))(t)
        }
    });
    const hp = Ma({
        logSoftmax_: function(e, t=-1) {
            const n = Da(e, "logits", "logSoftmax");
            if (-1 === t && (t = n.rank - 1),
            t !== n.rank - 1)
                throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and axis was ${t}`);
            return Sl(((e,n)=>{
                const s = xc(e, t, !0)
                  , r = Yu(e, s)
                  , a = Yu(Ko(r, "float32"), Hc(nu(Xc(r), t, !0)));
                n([a]);
                return {
                    value: a,
                    gradFunc: (e,n)=>{
                        const [s] = n
                          , r = Xc(s);
                        return Yu(e, il(nu(e, t, !0), r))
                    }
                }
            }
            ))(n)
        }
    });
    const pp = Ma({
        logicalNot_: function(e) {
            const t = {
                x: Da(e, "x", "logicalNot", "bool")
            };
            return ka.runKernel(Jt, t)
        }
    });
    const dp = Ma({
        logicalOr_: function(e, t) {
            const n = Da(e, "a", "logicalOr", "bool")
              , s = Da(t, "b", "logicalOr", "bool");
            $l(n.shape, s.shape);
            const r = {
                a: n,
                b: s
            };
            return ka.runKernel(Qt, r)
        }
    });
    const fp = Ma({
        logicalXor_: function(e, t) {
            const n = Da(e, "a", "logicalXor", "bool")
              , s = Da(t, "b", "logicalXor", "bool");
            return $l(n.shape, s.shape),
            rc(dp(e, t), pp(rc(e, t)))
        }
    });
    var mp = {};
    t(mp, "searchSorted", (()=>yp));
    const gp = 2147483648;
    const yp = Ma({
        searchSorted_: function(e, t, n="left") {
            const s = Da(e, "sortedSequence", "searchSorted")
              , r = Da(t, "values", "searchSorted")
              , a = s.shape[s.shape.length - 1]
              , i = r.shape[r.shape.length - 1]
              , o = hl(s, [-1, a])
              , l = hl(r, [-1, i]);
            if (o.rank < 2)
                throw new Error("Sorted input argument must be at least 2-dimensional");
            if (o.shape[0] !== l.shape[0])
                throw new Error("Leading dimension of 'sortedSequence' and 'values' must match.");
            if (v(l.shape) >= gp)
                throw new Error("values tensor size must less than 2147483648");
            if (o.shape[1] >= gp)
                throw new Error(`trailing dim_size must less than 2147483648 for int32 output type, was ${o.shape[1]}`);
            const u = {
                sortedSequence: o,
                values: l
            }
              , c = {
                side: n
            };
            return ka.runKernel(jn, u, c)
        }
    });
    function bp(e, t) {
        return yp(e, t, "left")
    }
    const xp = Ma({
        maxPool_: function(e, t, n, s, r) {
            const a = Da(e, "x", "maxPool");
            let i = a
              , o = !1;
            3 === a.rank && (o = !0,
            i = hl(a, [1, a.shape[0], a.shape[1], a.shape[2]])),
            b(4 === i.rank, (()=>`Error in maxPool: input must be rank 4 but got rank ${i.rank}.`)),
            b(Wl(n, 1), (()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`)),
            Gl("maxPool", s, r);
            const l = {
                x: i
            }
              , u = {
                filterSize: t,
                strides: n,
                pad: s,
                dimRoundingMode: r
            }
              , c = ka.runKernel(rn, l, u);
            return o ? hl(c, [c.shape[1], c.shape[2], c.shape[3]]) : c
        }
    });
    const wp = Ma({
        maxPool3d_: function(e, t=[1, 1, 1], n, s, r, a="NDHWC") {
            const i = Da(e, "x", "maxPool3d");
            let o = i
              , l = !1;
            4 === i.rank && (l = !0,
            o = hl(i, [1, i.shape[0], i.shape[1], i.shape[2], i.shape[3]])),
            b(5 === o.rank, (()=>`Error in maxPool3d: x must be rank 5 but got rank ${o.rank}.`)),
            b("NDHWC" === a, (()=>`Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ${a}`)),
            Gl("maxPool3d", s, r);
            const u = {
                x: o
            }
              , c = {
                filterSize: t,
                strides: n,
                pad: s,
                dimRoundingMode: r,
                dataFormat: a
            }
              , h = ka.runKernel(on, u, c);
            return l ? hl(h, [h.shape[1], h.shape[2], h.shape[3], h.shape[4]]) : h
        }
    });
    const vp = Ma({
        maxPoolWithArgmax_: function(e, t, n, s, r=!1) {
            const a = {
                x: Da(e, "x", "maxPoolWithArgmax")
            }
              , i = {
                filterSize: t,
                strides: n,
                pad: s,
                includeBatchInIndex: r
            }
              , o = ka.runKernel(un, a, i);
            return {
                result: o[0],
                indexes: o[1]
            }
        }
    });
    const kp = Ma({
        maximum_: function(e, t) {
            let n = Da(e, "a", "maximum")
              , s = Da(t, "b", "maximum");
            [n,s] = da(n, s),
            "bool" === n.dtype && (n = Ko(n, "int32"),
            s = Ko(s, "int32")),
            $l(n.shape, s.shape);
            const r = {
                a: n,
                b: s
            };
            return ka.runKernel(sn, r)
        }
    });
    function Ip(e, t, {indexing: n="xy"}={}) {
        if ("xy" !== n && "ij" !== n)
            throw new TypeError(`${n} is not a valid third argument to meshgrid`);
        if (void 0 === e)
            return [];
        let s = Da(e, "x", "meshgrid", e instanceof Zr ? e.dtype : "float32");
        if (void 0 === t)
            return [s];
        let r = Da(t, "y", "meshgrid", t instanceof Zr ? t.dtype : "float32");
        const a = v(s.shape)
          , i = v(r.shape);
        return "xy" === n ? (s = hl(s, [1, -1]),
        r = hl(r, [-1, 1]),
        [pu(zc([i, 1], s.dtype), s), pu(r, zc([1, a], r.dtype))]) : (s = hl(s, [-1, 1]),
        r = hl(r, [1, -1]),
        [pu(s, zc([1, i], s.dtype)), pu(zc([a, 1], r.dtype), r)])
    }
    const Sp = Ma({
        mirrorPad_: function(e, t, n) {
            b("reflect" === n || "symmetric" === n, (()=>`Invalid mode. Mode must be either reflect or symmetric. Got ${n}.`));
            const s = Da(e, "x", "mirrorPad");
            if (0 === s.rank)
                throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");
            b(t.length === s.rank, (()=>`Padding doesn't match input. Must be ${s.rank}. Got ${t.length}.`));
            const r = "reflect" === n ? 1 : 0;
            for (let e = 0; e < s.rank; e++)
                b(2 === t[e].length, (()=>"Invalid number of paddings. Must be length of 2 each.")),
                b(t[e][0] >= 0 && t[e][0] <= s.shape[e] - r && t[e][1] >= 0 && t[e][1] <= s.shape[e] - r, (()=>`Padding in dimension ${e} cannot be greater than or equal to ${s.shape[e] - r} or less than 0 for input of shape ${s.shape}`));
            const a = {
                paddings: t,
                mode: n
            }
              , i = {
                x: s
            };
            return ka.runKernel(dn, i, a)
        }
    });
    const Np = Ma({
        mod_: function(e, t) {
            let n = Da(e, "a", "mod")
              , s = Da(t, "b", "mod");
            [n,s] = da(n, s);
            const r = {
                a: n,
                b: s
            };
            return ka.runKernel(fn, r)
        }
    });
    const Tp = Ma({
        moments_: function(e, t=null, n=!1) {
            const s = R(t, (e = Da(e, "x", "moments")).shape)
              , r = Mc(e, s, n);
            let a = r.shape;
            n || (a = fc(r.shape, s));
            const i = Ic(Yu(Ko(e, "float32"), hl(r, a)));
            return {
                mean: r,
                variance: Mc(i, s, n)
            }
        }
    });
    const Cp = Ma({
        multiRNNCell_: function(e, t, n, s) {
            const r = Da(t, "data", "multiRNNCell")
              , a = _a(n, "c", "multiRNNCell")
              , i = _a(s, "h", "multiRNNCell");
            let o = r;
            const l = [];
            for (let t = 0; t < e.length; t++) {
                const n = e[t](o, a[t], i[t]);
                l.push(n[0]),
                l.push(n[1]),
                o = n[1]
            }
            const u = []
              , c = [];
            for (let e = 0; e < l.length; e += 2)
                u.push(l[e]),
                c.push(l[e + 1]);
            return [u, c]
        }
    });
    const $p = Ma({
        multinomial_: function(e, t, n, s=!1) {
            const r = Da(e, "logits", "multinomial")
              , a = r.size
              , i = r.rank;
            if (a < 2)
                throw new Error(`Error in multinomial: you need at least 2 outcomes, but got ${a}.`);
            if (i > 2)
                throw new Error(`Rank of probabilities must be 1 or 2, but is ${i}`);
            n = n || Math.random();
            const o = {
                logits: 1 === i ? hl(r, [1, -1]) : r
            }
              , l = {
                numSamples: t,
                seed: n,
                normalized: s
            }
              , u = ka.runKernel(mn, o, l);
            return 1 === i ? hl(u, [u.size]) : u
        }
    });
    const Ep = Ma({
        oneHot_: function(e, t, n=1, s=0, r="int32") {
            if (t < 2)
                throw new Error(`Error in oneHot: depth must be >=2, but it is ${t}`);
            const a = {
                indices: Da(e, "indices", "oneHot", "int32")
            }
              , i = {
                dtype: r,
                depth: t,
                onValue: n,
                offValue: s
            };
            return ka.runKernel(In, a, i)
        }
    });
    const Ap = Ma({
        onesLike_: function(e) {
            const t = {
                x: Da(e, "x", "onesLike")
            };
            return ka.runKernel(kn, t)
        }
    });
    const Rp = Ma({
        outerProduct_: function(e, t) {
            const n = Da(e, "v1", "outerProduct")
              , s = Da(t, "v2", "outerProduct");
            b(1 === n.rank && 1 === s.rank, (()=>`Error in outerProduct: inputs must be rank 1, but got ranks ${n.rank} and ${s.rank}.`));
            const r = hl(n, [-1, 1])
              , a = hl(s, [1, -1]);
            return pu(r, a)
        }
    });
    const Fp = Ma({
        pad_: function(e, t, n=0) {
            const s = Da(e, "x", "pad");
            if (0 === s.rank)
                throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");
            const r = {
                paddings: t,
                constantValue: n
            }
              , a = {
                x: s
            };
            return ka.runKernel(Nn, a, r)
        }
    });
    const Dp = Ma({
        pad1d_: function(e, t, n=0) {
            return b(2 === t.length, (()=>"Invalid number of paddings. Must be length of 2.")),
            Fp(e, [t], n)
        }
    });
    const _p = Ma({
        pad2d_: function(e, t, n=0) {
            return b(2 === t.length && 2 === t[0].length && 2 === t[1].length, (()=>"Invalid number of paddings. Must be length of 2 each.")),
            Fp(e, t, n)
        }
    });
    const Op = Ma({
        pad3d_: function(e, t, n=0) {
            return b(3 === t.length && 2 === t[0].length && 2 === t[1].length && 2 === t[2].length, (()=>"Invalid number of paddings. Must be length of 2 each.")),
            Fp(e, t, n)
        }
    });
    const Mp = Ma({
        pad4d_: function(e, t, n=0) {
            return b(4 === t.length && 2 === t[0].length && 2 === t[1].length && 2 === t[2].length && 2 === t[3].length, (()=>"Invalid number of paddings. Must be length of 2 each.")),
            Fp(e, t, n)
        }
    });
    const Lp = Ma({
        spaceToBatchND_: function(e, t, n) {
            const s = Da(e, "x", "spaceToBatchND");
            b(s.rank >= 1 + t.length, (()=>`input rank ${s.rank} should be > than [blockShape] ${t.length}`)),
            b(n.length === t.length, (()=>`paddings.shape[0] ${n.length} must be equal to [blockShape] ${t.length}`)),
            b(s.shape.reduce(((e,s,r)=>r > 0 && r <= t.length ? e && (s + n[r - 1][0] + n[r - 1][1]) % t[r - 1] == 0 : e), !0), (()=>`input spatial dimensions ${s.shape.slice(1)} with paddings ${n.toString()} must be divisible by blockShapes ${t.toString()}`));
            const r = {
                x: s
            }
              , a = {
                blockShape: t,
                paddings: n
            };
            return ka.runKernel(ss, r, a)
        }
    });
    const zp = Ma({
        pool_: function(e, t, n, s, r, a, i) {
            null == r && (r = [1, 1]),
            null == a && (a = 1),
            0 === s && (s = "valid");
            const o = Da(e, "x", "maxPool");
            let l = o
              , u = !1;
            3 === o.rank && (u = !0,
            l = hl(o, [1, o.shape[0], o.shape[1], o.shape[2]])),
            b(Wl(a, r), (()=>`Error in pool: Either strides or dilations must be 1. Got strides ${a} and dilations '${r}'`));
            const c = Rl(l.shape, t, a, r, s)
              , h = [c.dilationHeight, c.dilationWidth];
            let p;
            p = "same" === s ? function(e, t) {
                const n = e.map(((e,n)=>e + (e - 1) * (t[n] - 1))).map((e=>e - 1))
                  , s = n.map((e=>Math.floor(e / 2)))
                  , r = n.map(((e,t)=>e - s[t]));
                return n.map(((e,t)=>[s[t], r[t]]))
            }([c.filterHeight, c.filterWidth], h) : [[0, 0], [0, 0]];
            const d = 1 === h[0] && 1 === h[1]
              , [f,m] = function(e, t, n) {
                const s = n.map((e=>e[0]))
                  , r = n.map((e=>e[1]))
                  , a = e.concat(s, r)
                  , i = t.map(((e,t)=>(e - a[t] % e) % e))
                  , o = r.map(((e,t)=>e + i[t]))
                  , l = t.map(((e,t)=>[s[t], o[t]]))
                  , u = t.map(((e,t)=>[0, i[t]]));
                return [l, u]
            }([c.inHeight, c.inWidth], h, p)
              , g = d ? s : "valid"
              , y = d ? l : Lp(l, h, f)
              , x = ("avg" === n ? ()=>xh(y, t, a, g, i) : ()=>xp(y, t, a, g, i))()
              , w = d ? x : Ih(x, h, m);
            return u ? hl(w, [w.shape[1], w.shape[2], w.shape[3]]) : w
        }
    });
    const Bp = Ma({
        prod_: function(e, t=null, n=!1) {
            let s = Da(e, "x", "prod");
            "bool" === s.dtype && (s = Ko(s, "int32"));
            const r = {
                x: s
            }
              , a = {
                axis: t,
                keepDims: n
            };
            return ka.runKernel($n, r, a)
        }
    });
    const Pp = Ma({
        raggedGather_: function(e, t, n, s) {
            const r = {
                paramsNestedSplits: e.map(((e,t)=>Da(e, `tensors${t}`, "raggedGather", "int32"))),
                paramsDenseValues: Da(t, "paramsDenseValues", "raggedGather"),
                indices: Da(n, "indices", "raggedGather", "int32")
            }
              , a = {
                outputRaggedRank: s
            }
              , i = ka.runKernel(En, r, a);
            return {
                outputNestedSplits: i.slice(0, i.length - 1),
                outputDenseValues: i[i.length - 1]
            }
        }
    });
    const Wp = Ma({
        raggedRange_: function(e, t, n) {
            const s = Da(e, "starts", "raggedRange")
              , r = {
                starts: s,
                limits: Da(t, "limits", "raggedRange", s.dtype),
                deltas: Da(n, "deltas", "raggedRange", s.dtype)
            }
              , a = ka.runKernel(An, r);
            return {
                rtNestedSplits: a[0],
                rtDenseValues: a[1]
            }
        }
    });
    const Up = Ma({
        raggedTensorToTensor_: function(e, t, n, s, r) {
            const a = Da(e, "shape", "raggedTensorToTensor", "int32")
              , i = Da(t, "values", "raggedTensorToTensor")
              , o = {
                shape: a,
                values: i,
                defaultValue: Da(n, "defaultValue", "raggedTensorToTensor", i.dtype),
                rowPartitionTensors: s.map(((e,t)=>Da(e, `tensors${t}`, "raggedTensorToTensor", "int32")))
            }
              , l = {
                rowPartitionTypes: r
            };
            return ka.runKernel(Rn, o, l)
        }
    });
    const Vp = Ma({
        rand_: function(e, t, n) {
            Q(e);
            const s = v(e);
            let r = null;
            if (null == n || "float32" === n)
                r = new Float32Array(s);
            else if ("int32" === n)
                r = new Int32Array(s);
            else {
                if ("bool" !== n)
                    throw new Error(`Unknown data type ${n}`);
                r = new Uint8Array(s)
            }
            for (let e = 0; e < s; e++)
                r[e] = t();
            return ka.makeTensor(r, e, n)
        }
    });
    var Gp = {}
      , Hp = a("gj6Et")
      , jp = a("4gDjz")
      , qp = a("HLBv4")
      , Kp = a("ktaoY")
      , Xp = a("gBs5C")
      , Yp = a("ktLSh")
      , Zp = {};
    !function(e, t, n) {
        var s, r = 256, i = n.pow(r, 6), o = n.pow(2, 52), l = 2 * o, u = 255;
        function c(a, u, c) {
            var g = []
              , y = f(d((u = 1 == u ? {
                entropy: !0
            } : u || {}).entropy ? [a, m(t)] : null == a ? function() {
                try {
                    var n;
                    return s && (n = s.randomBytes) ? n = n(r) : (n = new Uint8Array(r),
                    (e.crypto || e.msCrypto).getRandomValues(n)),
                    m(n)
                } catch (n) {
                    var a = e.navigator
                      , i = a && a.plugins;
                    return [+new Date, e, i, e.screen, m(t)]
                }
            }() : a, 3), g)
              , b = new h(g)
              , x = function() {
                for (var e = b.g(6), t = i, n = 0; e < o; )
                    e = (e + n) * r,
                    t *= r,
                    n = b.g(1);
                for (; e >= l; )
                    e /= 2,
                    t /= 2,
                    n >>>= 1;
                return (e + n) / t
            };
            return x.int32 = function() {
                return 0 | b.g(4)
            }
            ,
            x.quick = function() {
                return b.g(4) / 4294967296
            }
            ,
            x.double = x,
            f(m(b.S), t),
            (u.pass || c || function(e, t, s, r) {
                return r && (r.S && p(r, b),
                e.state = function() {
                    return p(b, {})
                }
                ),
                s ? (n.random = e,
                t) : e
            }
            )(x, y, "global"in u ? u.global : this == n, u.state)
        }
        function h(e) {
            var t, n = e.length, s = this, a = 0, i = s.i = s.j = 0, o = s.S = [];
            for (n || (e = [n++]); a < r; )
                o[a] = a++;
            for (a = 0; a < r; a++)
                o[a] = o[i = u & i + e[a % n] + (t = o[a])],
                o[i] = t;
            (s.g = function(e) {
                for (var t, n = 0, a = s.i, i = s.j, o = s.S; e--; )
                    t = o[a = u & a + 1],
                    n = n * r + o[u & (o[a] = o[i = u & i + t]) + (o[i] = t)];
                return s.i = a,
                s.j = i,
                n
            }
            )(r)
        }
        function p(e, t) {
            return t.i = e.i,
            t.j = e.j,
            t.S = e.S.slice(),
            t
        }
        function d(e, t) {
            var n, s = [], r = typeof e;
            if (t && "object" == r)
                for (n in e)
                    try {
                        s.push(d(e[n], t - 1))
                    } catch (e) {}
            return s.length ? s : "string" == r ? e : e + "\0"
        }
        function f(e, t) {
            for (var n, s = e + "", r = 0; r < s.length; )
                t[u & r] = u & (n ^= 19 * t[u & r]) + s.charCodeAt(r++);
            return m(t)
        }
        function m(e) {
            return String.fromCharCode.apply(0, e)
        }
        if (f(n.random(), t),
        Zp) {
            Zp = c;
            try {
                s = a("foUwZ")
            } catch (e) {}
        } else
            "function" == typeof define && define.amd ? define((function() {
                return c
            }
            )) : n.seedrandom = c
    }("undefined" != typeof self ? self : Zp, [], Math),
    Zp.alea = Hp,
    Zp.xor128 = jp,
    Zp.xorwow = qp,
    Zp.xorshift7 = Kp,
    Zp.xor4096 = Xp,
    Zp.tychei = Yp,
    Gp = Zp;
    class Jp {
        constructor(e, t, n, s, r) {
            this.mean = e,
            this.stdDev = t,
            this.dtype = n,
            this.nextVal = NaN,
            this.truncated = s,
            this.truncated && (this.upper = this.mean + 2 * this.stdDev,
            this.lower = this.mean - 2 * this.stdDev);
            const a = r || Math.random();
            this.random = Gp.alea(a.toString())
        }
        nextValue() {
            if (!isNaN(this.nextVal)) {
                const e = this.nextVal;
                return this.nextVal = NaN,
                e
            }
            let e, t, n = !1;
            for (; !n; ) {
                let s, r, a;
                do {
                    s = 2 * this.random() - 1,
                    r = 2 * this.random() - 1,
                    a = s * s + r * r
                } while (a >= 1 || 0 === a);
                const i = Math.sqrt(-2 * Math.log(a) / a);
                e = this.mean + this.stdDev * s * i,
                t = this.mean + this.stdDev * r * i,
                this.truncated && !this.isValidTruncated(e) || (n = !0)
            }
            return this.truncated && !this.isValidTruncated(t) || (this.nextVal = this.convertValue(t)),
            this.convertValue(e)
        }
        convertValue(e) {
            return null == this.dtype || "float32" === this.dtype ? e : Math.round(e)
        }
        isValidTruncated(e) {
            return e <= this.upper && e >= this.lower
        }
    }
    class Qp {
        constructor(e, t, n, s) {
            this.alpha = e,
            this.beta = 1 / t,
            this.dtype = n;
            const r = s || Math.random();
            this.randu = Gp.alea(r.toString()),
            this.randn = new Jp(0,1,n,!1,this.randu()),
            this.d = e < 1 ? e + 2 / 3 : e - 1 / 3,
            this.c = 1 / Math.sqrt(9 * this.d)
        }
        nextValue() {
            let e, t, n, s, r, a;
            for (; ; ) {
                do {
                    s = this.randn.nextValue(),
                    a = 1 + this.c * s
                } while (a <= 0);
                if (a *= a * a,
                e = s * s,
                t = 1 - .331 * e * e,
                n = .5 * e + this.d * (1 - a + Math.log(a)),
                r = this.randu(),
                r < t || Math.log(r) < n)
                    break
            }
            return a = 1 / this.beta * this.d * a,
            this.alpha < 1 && (a *= Math.pow(this.randu(), 1 / this.alpha)),
            this.convertValue(a)
        }
        convertValue(e) {
            return "float32" === this.dtype ? e : Math.round(e)
        }
    }
    class ed {
        constructor(e=0, t=1, n, s) {
            if (this.canReturnFloat = ()=>null == this.dtype || "float32" === this.dtype,
            this.min = e,
            this.range = t - e,
            this.dtype = n,
            null == s && (s = Math.random()),
            "number" == typeof s && (s = s.toString()),
            !this.canReturnFloat() && this.range <= 1)
                throw new Error(`The difference between ${e} - ${t} <= 1 and dtype is not float`);
            this.random = Gp.alea(s)
        }
        convertValue(e) {
            return this.canReturnFloat() ? e : Math.round(e)
        }
        nextValue() {
            return this.convertValue(this.min + this.range * this.random())
        }
    }
    const td = Ma({
        randomGamma_: function(e, t, n=1, s="float32", r) {
            if (Q(e),
            null == n && (n = 1),
            null == s && (s = "float32"),
            "float32" !== s && "int32" !== s)
                throw new Error(`Unsupported data type ${s}`);
            const a = new Qp(t,n,s,r)
              , i = qo(e, s);
            for (let e = 0; e < i.values.length; e++)
                i.values[e] = a.nextValue();
            return i.toTensor()
        }
    });
    const nd = Ma({
        randomNormal_: function(e, t=0, n=1, s, r) {
            if (Q(e),
            null != s && "bool" === s)
                throw new Error(`Unsupported data type ${s}`);
            const a = new Jp(t,n,s,!1,r)
              , i = qo(e, s);
            for (let e = 0; e < i.values.length; e++)
                i.values[e] = a.nextValue();
            return i.toTensor()
        }
    });
    const sd = Ma({
        randomStandardNormal_: function(e, t, n) {
            if (null != t && "bool" === t)
                throw new Error(`Unsupported data type ${t}`);
            return nd(e, 0, 1, t, n)
        }
    });
    const rd = Ma({
        randomUniform_: function(e, t=0, n=1, s="float32", r) {
            Q(e);
            const a = qo(e, s)
              , i = new ed(t,n,null,r);
            for (let e = 0; e < a.values.length; e++)
                a.values[e] = i.nextValue();
            return a.toTensor()
        }
    });
    const ad = Ma({
        reciprocal_: function(e) {
            const t = {
                x: Da(e, "x", "reciprocal")
            };
            return ka.runKernel(_n, t)
        }
    });
    const id = Ma({
        reverse1d_: function(e) {
            const t = Da(e, "x", "reverse");
            return b(1 === t.rank, (()=>`Error in reverse1D: x must be rank 1 but got rank ${t.rank}.`)),
            xl(t, 0)
        }
    });
    const od = Ma({
        reverse2d_: function(e, t) {
            const n = Da(e, "x", "reverse");
            return b(2 === n.rank, (()=>`Error in reverse2D: x must be rank 2 but got rank ${n.rank}.`)),
            xl(n, t)
        }
    });
    const ld = Ma({
        reverse3d_: function(e, t) {
            const n = Da(e, "x", "reverse");
            return b(3 === n.rank, (()=>`Error in reverse3D: x must be rank 3 but got rank ${n.rank}.`)),
            xl(n, t)
        }
    });
    const ud = Ma({
        reverse4d_: function(e, t) {
            const n = Da(e, "x", "reverse");
            return b(4 === n.rank, (()=>`Error in reverse4D: x must be rank 4 but got rank ${n.rank}.`)),
            xl(n, t)
        }
    });
    const cd = Ma({
        rsqrt_: function(e) {
            const t = {
                x: Da(e, "x", "rsqrt", "float32")
            };
            return ka.runKernel(Gn, t)
        }
    });
    const hd = Ma({
        selu_: function(e) {
            const t = {
                x: Da(e, "x", "selu")
            };
            return ka.runKernel(Kn, t)
        }
    });
    const pd = Ma({
        separableConv2d_: function(e, t, n, s, r, a=[1, 1], i="NHWC") {
            const o = Da(e, "x", "separableConv2d")
              , l = Da(t, "depthwiseFilter", "separableConv2d")
              , u = Da(n, "pointwiseFilter", "separableConv2d");
            let c = o
              , h = !1;
            if (3 === o.rank && (h = !0,
            c = hl(o, [1, o.shape[0], o.shape[1], o.shape[2]])),
            "NCHW" === i)
                throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");
            b(4 === c.rank, (()=>`Error in separableConv2d: input must be rank 4, but got rank ${c.rank}.`)),
            b(4 === l.rank, (()=>`Error in separableConv2d: depthwise filter must be rank 4, but got rank ${l.rank}.`)),
            b(4 === u.rank, (()=>`Error in separableConv2d: pointwise filter must be rank 4, but got rank ${l.rank}.`)),
            b(1 === u.shape[0], (()=>`Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ${u.shape[0]}.`)),
            b(1 === u.shape[1], (()=>`Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ${u.shape[1]}.`));
            const p = l.shape[2]
              , d = l.shape[3];
            b(u.shape[2] === p * d, (()=>`Error in separableConv2d: the third dimension of pointwise filter must be ${p * d}, but got ${u.shape[2]}.`));
            const f = lu(c, l, s, r, i, a)
              , m = Hl(f, u, 1, "valid", i);
            return h ? hl(m, [m.shape[1], m.shape[2], m.shape[3]]) : m
        }
    });
    const dd = async function(e, t) {
        const n = Da(e, "x", "setdiff1d")
          , s = Da(t, "y", "setdiff1d");
        b(n.dtype === s.dtype, (()=>`x and y should have the same dtype, but got x (${n.dtype}) and y (${s.dtype}).`)),
        b(1 === n.rank, (()=>`x should be 1D tensor, but got x (${n.shape}).`)),
        b(1 === s.rank, (()=>`y should be 1D tensor, but got y (${s.shape}).`));
        const r = await n.data()
          , a = await s.data()
          , i = new Set(a);
        let o = 0;
        for (let e = 0; e < r.length; e++)
            i.has(r[e]) || o++;
        const l = new qr([o],n.dtype)
          , u = new qr([o],"int32");
        for (let e = 0, t = 0; e < r.length; e++)
            i.has(r[e]) || (l.values[t] = r[e],
            u.values[t] = e,
            t++);
        return [l.toTensor(), u.toTensor()]
    };
    const fd = Ma({
        sign_: function(e) {
            const t = {
                x: Da(e, "x", "sign")
            };
            return ka.runKernel(Jn, t)
        }
    });
    const md = Ma({
        sin_: function(e) {
            const t = {
                x: Da(e, "x", "sin", "float32")
            };
            return ka.runKernel(Yn, t)
        }
    });
    const gd = Ma({
        sinh_: function(e) {
            const t = {
                x: Da(e, "x", "sinh")
            };
            return ka.runKernel(Zn, t)
        }
    });
    const yd = Ma({
        slice1d_: function(e, t, n) {
            const s = Da(e, "x", "slice1d");
            return b(1 === s.rank, (()=>`slice1d expects a rank-1 tensor, but got a rank-${s.rank} tensor`)),
            pl(s, [t], [n])
        }
    });
    const bd = Ma({
        slice2d_: function(e, t, n) {
            const s = Da(e, "x", "slice2d");
            return b(2 === s.rank, (()=>`slice2d expects a rank-2 tensor, but got a rank-${s.rank} tensor`)),
            pl(s, t, n)
        }
    });
    const xd = Ma({
        slice3d_: function(e, t, n) {
            const s = Da(e, "x", "slice3d");
            return b(3 === s.rank, (()=>`slice3d expects a rank-3 tensor, but got a rank-${s.rank} tensor`)),
            pl(s, t, n)
        }
    });
    const wd = Ma({
        slice4d_: function(e, t, n) {
            const s = Da(e, "x", "slice4d");
            return b(4 === s.rank, (()=>`slice4d expects a rank-4 tensor, but got a rank-${s.rank} tensor`)),
            pl(s, t, n)
        }
    });
    const vd = Ma({
        softmax_: function(e, t=-1) {
            const n = Da(e, "logits", "softmax", "float32");
            if (-1 === t && (t = n.rank - 1),
            t !== n.rank - 1)
                throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and dim was ${t}`);
            const s = {
                logits: n
            }
              , r = {
                dim: t
            };
            return ka.runKernel(as, s, r)
        }
    });
    const kd = Ma({
        stridedSlice_: function(e, t, n, s, r=0, a=0, i=0, o=0, l=0) {
            const u = {
                x: Da(e, "x", "stridedSlice", "string_or_numeric")
            }
              , c = {
                begin: t,
                end: n,
                strides: s,
                beginMask: r,
                endMask: a,
                ellipsisMask: i,
                newAxisMask: o,
                shrinkAxisMask: l
            };
            return ka.runKernel(ds, u, c)
        }
    });
    const Id = Ma({
        tan_: function(e) {
            const t = {
                x: Da(e, "x", "tan", "float32")
            };
            return ka.runKernel(bs, t)
        }
    });
    function Sd(e, t, n) {
        if (w(e),
        null != t && 3 !== t.length)
            throw new Error("tensor3d() requires shape to have three numbers");
        const s = Aa(e, n);
        if (3 !== s.length && 1 !== s.length)
            throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");
        if (1 === s.length && null == t)
            throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");
        return za(e, t, s, n)
    }
    function Nd(e, t, n) {
        if (w(e),
        null != t && 4 !== t.length)
            throw new Error("tensor4d() requires shape to have four numbers");
        const s = Aa(e, n);
        if (4 !== s.length && 1 !== s.length)
            throw new Error("tensor4d() requires values to be number[][][][] or flat/TypedArray");
        if (1 === s.length && null == t)
            throw new Error("tensor4d() requires shape to be provided when `values` are a flat array");
        return za(e, t, s, n)
    }
    function Td(e, t, n) {
        if (w(e),
        null != t && 5 !== t.length)
            throw new Error("tensor5d() requires shape to have five numbers");
        const s = Aa(e, n);
        if (5 !== s.length && 1 !== s.length)
            throw new Error("tensor5d() requires values to be number[][][][][] or flat/TypedArray");
        if (1 === s.length && null == t)
            throw new Error("tensor5d() requires shape to be provided when `values` are a flat array");
        return za(e, t, s, n)
    }
    function Cd(e, t, n) {
        if (w(e),
        null != t && 6 !== t.length)
            throw new Error("tensor6d() requires shape to have six numbers");
        const s = Aa(e, n);
        if (6 !== s.length && 1 !== s.length)
            throw new Error("tensor6d() requires values to be number[][][][][][] or flat/TypedArray");
        if (1 === s.length && null == t)
            throw new Error("tensor6d() requires shape to be provided when `values` are a flat array");
        return za(e, t = t || s, s, n)
    }
    const $d = Ma({
        topk_: function(e, t=1, n=!0) {
            const s = Da(e, "x", "topk");
            if (0 === s.rank)
                throw new Error("topk() expects the input to be of rank 1 or higher");
            const r = s.shape[s.shape.length - 1];
            if (t < 0)
                throw new Error(`'k' passed to topk() must be >= 0 but got ${t}`);
            if (t > r)
                throw new Error(`'k' passed to topk() must be <= the last dimension (${r}) but got ${t}`);
            const a = {
                x: s
            }
              , i = {
                k: t,
                sorted: n
            }
              , [o,l] = ka.runKernel(vs, a, i);
            return {
                values: o,
                indices: l
            }
        }
    });
    const Ed = Ma({
        truncatedNormal_: function(e, t=0, n=1, s, r) {
            if (Q(e),
            null != s && "bool" === s)
                throw new Error("Unsupported data type $ { dtype }");
            const a = new Jp(t,n,s,!0,r)
              , i = qo(e, s);
            for (let e = 0; e < i.values.length; e++)
                i.values[e] = a.nextValue();
            return i.toTensor()
        }
    });
    const Ad = Ma({
        unique_: function(e, t=0) {
            const n = Da(e, "x", "unique", "string_or_numeric");
            b(n.rank > 0, (()=>"The input tensor must be at least 1D"));
            const s = {
                x: n
            }
              , r = {
                axis: t
            }
              , [a,i] = ka.runKernel(Ss, s, r);
            return {
                values: a,
                indices: i
            }
        }
    });
    const Rd = Ma({
        unsortedSegmentSum_: function(e, t, n) {
            const s = Da(e, "x", "unsortedSegmentSum")
              , r = Da(t, "segmentIds", "unsortedSegmentSum", "int32");
            b(S(n), (()=>"numSegments must be of dtype int"));
            const a = {
                x: s,
                segmentIds: r
            }
              , i = {
                numSegments: n
            };
            return ka.runKernel(Ts, a, i)
        }
    });
    function Fd(e, t) {
        return yp(e, t, "right")
    }
    function Dd(e, t=!0, n, s) {
        return ka.makeVariable(e, t, n, s)
    }
    function _d(e, t) {
        const n = [];
        for (let e = 0; e < t.length; e++)
            t[e] && n.push(e);
        const s = qo(e, "int32")
          , r = qo([n.length, e.length], "int32");
        for (let t = 0; t < n.length; t++) {
            const a = s.indexToLoc(n[t])
              , i = t * e.length;
            r.values.set(a, i)
        }
        return r.toTensor()
    }
    const Od = async function(e) {
        const t = Da(e, "condition", "whereAsync", "bool")
          , n = await t.data()
          , s = _d(t.shape, n);
        return e !== t && t.dispose(),
        s
    };
    var Md = {};
    t(Md, "booleanMaskAsync", (()=>Ld));
    const Ld = async function(e, t, n) {
        const s = Da(e, "tensor", "boolMask")
          , r = Da(t, "mask", "boolMask", "bool")
          , a = null == n ? 0 : n
          , i = r.rank
          , o = s.shape;
        b(i > 0, (()=>"mask cannot be scalar")),
        x(o.slice(a, a + i), r.shape, "mask's shape must match the first K dimensions of tensor's shape,");
        let l = 1;
        for (let e = a; e < a + i; e++)
            l *= o[e];
        const u = o.slice(0, a).concat([l], o.slice(a + i))
          , c = hl(s, u)
          , h = hl(r, [-1])
          , p = await Od(h)
          , d = Tc(p, [1])
          , f = np(c, d, a);
        return e !== s && s.dispose(),
        t !== r && r.dispose(),
        d.dispose(),
        c.dispose(),
        h.dispose(),
        p.dispose(),
        f
    };
    var zd = {};
    t(zd, "movingAverage", (()=>Bd));
    const Bd = Ma({
        movingAverage_: function(e, t, n, s, r=!0) {
            const a = Da(e, "v", "movingAverage")
              , i = Da(t, "x", "movingAverage")
              , o = Da(n, "decay", "movingAverage");
            fa(a, i),
            b(I(a.shape, i.shape), (()=>"Shape mismatch in v and x"));
            const l = wl(1)
              , u = Yu(l, o);
            let c = il(Yu(i, a), u);
            if (r) {
                b(null != s, (()=>"When using zeroDebias: true, step is required."));
                const e = Da(s, "step", "movingAverage");
                c = al(c, Yu(l, vc(o, e)))
            }
            return sl(a, c)
        }
    });
    var Pd = {};
    t(Pd, "scatterND", (()=>Hd));
    var Wd = {};
    function Ud(e, t, n) {
        const s = t.rank > 1 ? t.shape[t.rank - 1] : 1
          , r = t.rank > 1 ? t.rank - 1 : 1
          , a = `Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: ${n.shape}, indices.shape: ${t.shape}, shape: ${e}, sliceDim: ${s}, and batchDim: ${r}.`;
        if (n.rank < r)
            throw new Error(a + ` update.rank < ${r}. `);
        if (e.length < s + (n.rank - r))
            throw new Error(a + ` Output shape length < ${s + (n.rank - r)}`);
        if (n.rank !== r + e.length - s)
            throw new Error(a + " update.rank != " + (r + e.length - s));
        for (let e = 0; e < r; ++e)
            if (n.shape[e] !== t.shape[e])
                throw new Error(a + ` updates.shape[${e}] (${n.shape[e]}) != indices.shape[${e}] (${t.shape[e]}).`);
        for (let t = 0; t < n.rank - r; ++t)
            if (n.shape[t + r] !== e[t + s])
                throw new Error(a + ` updates.shape[${t + r}] (${n.shape[t + r]}) != shape[${t + r}] (${e[t + r]})`)
    }
    function Vd(e, t, n) {
        if (t.rank < 1)
            throw new Error(`tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ${t.rank}.`);
        if (e.rank < 1)
            throw new Error(`tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ${e.rank}.`);
        if ("int32" !== t.dtype)
            throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${t.dtype}`);
        if (n.length < 1)
            throw new Error(`Output rank must be greater or equal to 1, but got shape: ${n}`);
        if (0 === n.length) {
            if (0 === t.size)
                throw new Error(`Indices specified for empty output. indices shape: ${t.shape}`);
            if (0 === e.size)
                throw new Error(`Updates specified for empty output. updates shape: ${e.shape}`)
        }
        Ud(n, t, e)
    }
    function Gd(e, t, n) {
        const s = t.shape.length
          , r = s > 1 ? t.shape[s - 1] : 1
          , a = n.length;
        let i = 1;
        for (let e = r; e < a; ++e)
            i *= n[e];
        const o = r < 1 ? 1 : r;
        return {
            sliceRank: r,
            numUpdates: v(t.shape) / o,
            sliceSize: i,
            strides: [...j(n.slice(0, r)), 1],
            outputSize: v(n)
        }
    }
    t(Wd, "validateUpdateShape", (()=>Ud)),
    t(Wd, "validateInput", (()=>Vd)),
    t(Wd, "calculateShapes", (()=>Gd));
    const Hd = Ma({
        scatterND_: function(e, t, n) {
            Q(n);
            const s = Da(e, "indices", "scatterND", "int32")
              , r = Da(t, "updates", "scatterND");
            Vd(r, s, n);
            const a = {
                indices: s,
                updates: r
            }
              , i = {
                shape: n
            };
            return ka.runKernel(Hn, a, i)
        }
    });
    var jd = {};
    t(jd, "sparseToDense", (()=>qd));
    const qd = Ma({
        sparseToDense_: function(e, t, n, s=0) {
            Q(n);
            const r = Da(e, "sparseIndices", "sparseToDense", "int32")
              , a = Da(t, "sparseValues", "sparseToDense", "string_or_numeric")
              , i = Da(s, "defaultValue", "sparseToDense", a.dtype);
            !function(e, t, n, s) {
                if ("int32" !== e.dtype)
                    throw new Error(`tf.sparseToDense() expects the indices to be int32 type, but the dtype was ${e.dtype}.`);
                if (e.rank > 2)
                    throw new Error(`sparseIndices should be a scalar, vector, or matrix, but got shape ${e.shape}.`);
                const r = e.rank > 0 ? e.shape[0] : 1
                  , a = e.rank > 1 ? e.shape[1] : 1;
                if (n.length !== a)
                    throw new Error(`outputShape has incorrect number of elements:, ${n.length}, should be: ${a}.`);
                const i = t.size;
                if (0 !== t.rank && (1 !== t.rank || i !== r))
                    throw new Error(`sparseValues has incorrect shape ${t.shape}, should be [] or [${r}]`);
                if (t.dtype !== s.dtype)
                    throw new Error("sparseValues.dtype must match defaultValues.dtype")
            }(r, a, n, i);
            const o = {
                sparseIndices: r,
                sparseValues: a,
                defaultValue: i
            }
              , l = {
                outputShape: n
            };
            return ka.runKernel(cs, o, l)
        }
    });
    var Kd = {};
    t(Kd, "gatherND", (()=>Xd));
    const Xd = Ma({
        gatherND_: function(e, t) {
            const n = Da(t, "indices", "gatherND", "int32")
              , s = {
                params: Da(e, "x", "gatherND", "string_or_numeric"),
                indices: n
            };
            return ka.runKernel(Mt, s)
        }
    });
    var Yd = {};
    t(Yd, "dropout", (()=>Zd));
    const Zd = Ma({
        dropout_: function(e, t, n, s) {
            const r = Da(e, "x", "dropout");
            if (b("float32" === r.dtype, (()=>`x has to be a floating point tensor since it's going to be scaled, but got a ${r.dtype} tensor instead.`)),
            b(t >= 0 && t < 1, (()=>`rate must be a float in the range [0, 1), but got ${t}.`)),
            0 === t)
                return e instanceof Zr ? r.clone() : r;
            const a = function(e, t) {
                if (null == t)
                    return e.shape.slice();
                if (I(e.shape, t))
                    return t;
                if (e.shape.length === t.length) {
                    const n = [];
                    for (let s = 0; s < e.shape.length; s++)
                        null == t[s] && null != e.shape[s] ? n.push(e.shape[s]) : n.push(t[s]);
                    return n
                }
                return t
            }(r, n)
              , i = 1 - t
              , o = al(tp(sl(rd(a, 0, 1, "float32", s), i)), i);
            return il(r, o)
        }
    });
    var Jd = {};
    t(Jd, "inTopKAsync", (()=>Qd));
    const Qd = async function(e, t, n=1) {
        const s = Da(e, "predictions", "inTopK")
          , r = Da(t, "targets", "inTopK");
        b(s.rank > 1, (()=>`inTopK() expects the predictions to be of rank 2 or higher, but got ${s.rank}`)),
        b(s.rank - 1 === r.rank, (()=>`predictions rank should be 1 larger than targets rank, but got predictions rank ${s.rank} and targets rank ${r.rank}`)),
        x(s.shape.slice(0, s.shape.length - 1), r.shape, "predictions's shape should be align with the targets' shape, except the last dimension.");
        const a = s.shape[s.shape.length - 1];
        b(n > 0 && n <= a, (()=>`'k' passed to inTopK() must be > 0 && <= the predictions last dimension (${a}), but got ${n}`));
        const i = await s.data()
          , o = await r.data()
          , [l,u] = [i.length / a, a]
          , c = D("bool", l);
        for (let e = 0; e < l; e++) {
            const t = e * u
              , s = i.subarray(t, t + u)
              , r = [];
            for (let e = 0; e < s.length; e++)
                r.push({
                    value: s[e],
                    index: e
                });
            r.sort(((e,t)=>t.value - e.value)),
            c[e] = 0;
            for (let t = 0; t < n; t++)
                if (r[t].index === o[e]) {
                    c[e] = 1;
                    break
                }
        }
        return e !== s && s.dispose(),
        t !== r && r.dispose(),
        Ba(c, r.shape, "bool")
    }
      , ef = {
        fft: gl,
        ifft: bl,
        rfft: yl,
        irfft: vl
    }
      , tf = {
        hammingWindow: bu,
        hannWindow: xu,
        frame: ku,
        stft: Iu
    }
      , nf = {
        flipLeftRight: Nu,
        grayscaleToRGB: Cu,
        resizeNearestNeighbor: ju,
        resizeBilinear: Hu,
        rotateWithOffset: $u,
        cropAndResize: Su,
        nonMaxSuppression: Au,
        nonMaxSuppressionAsync: Pu,
        nonMaxSuppressionWithScore: Wu,
        nonMaxSuppressionWithScoreAsync: Uu,
        nonMaxSuppressionPadded: Vu,
        nonMaxSuppressionPaddedAsync: Gu,
        threshold: tc,
        transform: nc
    }
      , sf = {
        bandPart: oc,
        gramSchmidt: Cc,
        qr: _c
    }
      , rf = {
        absoluteDifference: Pc,
        computeWeightedLoss: Bc,
        cosineDistance: Wc,
        hingeLoss: Uc,
        huberLoss: Gc,
        logLoss: jc,
        meanSquaredError: Kc,
        sigmoidCrossEntropy: Zc,
        softmaxCrossEntropy: Qc
    }
      , af = {
        sparseFillEmptyRows: eh,
        sparseReshape: th,
        sparseSegmentMean: nh,
        sparseSegmentSum: sh
    }
      , of = {
        stringNGrams: rh,
        stringSplit: ah,
        stringToHashBucketFast: ih
    };
    n(ol, Md),
    n(ol, Rc),
    n(ol, lc),
    n(ol, zd),
    n(ol, Pd),
    n(ol, jd),
    n(ol, Kd),
    n(ol, Yd),
    n(ol, fu),
    n(ol, Jd),
    n(ol, mp);
    var lf = {};
    t(lf, "Serializable", (()=>uf)),
    t(lf, "SerializationMap", (()=>cf)),
    t(lf, "registerClass", (()=>hf));
    class uf {
        getClassName() {
            return this.constructor.className
        }
        static fromConfig(e, t) {
            return new e(t)
        }
    }
    class cf {
        constructor() {
            this.classNameMap = {}
        }
        static getMap() {
            return null == cf.instance && (cf.instance = new cf),
            cf.instance
        }
        static register(e) {
            cf.getMap().classNameMap[e.className] = [e, e.fromConfig]
        }
    }
    function hf(e) {
        b(null != e.className, (()=>"Class being registered does not have the static className property defined.")),
        b("string" == typeof e.className, (()=>"className is required to be a string, but got type " + typeof e.className)),
        b(e.className.length > 0, (()=>"Class being registered has an empty-string as its className, which is disallowed.")),
        cf.register(e)
    }
    class pf extends uf {
        minimize(e, t=!1, n) {
            const {value: s, grads: r} = this.computeGradients(e, n);
            if (null != n) {
                const e = n.map((e=>({
                    name: e.name,
                    tensor: r[e.name]
                })));
                this.applyGradients(e)
            } else
                this.applyGradients(r);
            return el(r),
            t ? s : (s.dispose(),
            null)
        }
        get iterations() {
            return null == this.iterations_ && (this.iterations_ = 0),
            this.iterations_
        }
        incrementIterations() {
            this.iterations_ = this.iterations + 1
        }
        computeGradients(e, t) {
            return Il(e, t)
        }
        dispose() {
            null != this.iterations_ && el(this.iterations_)
        }
        async saveIterations() {
            return null == this.iterations_ && (this.iterations_ = 0),
            {
                name: "iter",
                tensor: wl(this.iterations_, "int32")
            }
        }
        async getWeights() {
            throw new Error("getWeights() is not implemented for this optimizer yet.")
        }
        async setWeights(e) {
            throw new Error(`setWeights() is not implemented for this optimizer class ${this.getClassName()}`)
        }
        async extractIterations(e) {
            return this.iterations_ = (await e[0].tensor.data())[0],
            e.slice(1)
        }
    }
    Object.defineProperty(pf, Symbol.hasInstance, {
        value: e=>null != e.minimize && null != e.computeGradients && null != e.applyGradients
    });
    class df extends pf {
        constructor(e, t, n=null) {
            super(),
            this.learningRate = e,
            this.rho = t,
            this.epsilon = n,
            this.accumulatedGrads = [],
            this.accumulatedUpdates = [],
            null == n && (this.epsilon = ka.backend.epsilon())
        }
        static get className() {
            return "Adadelta"
        }
        applyGradients(e) {
            (Array.isArray(e) ? e.map((e=>e.name)) : Object.keys(e)).forEach(((t,n)=>{
                const s = ka.registeredVariables[t];
                null == this.accumulatedGrads[n] && (this.accumulatedGrads[n] = {
                    originalName: `${t}/accum_grad`,
                    variable: Qo((()=>ml(s).variable(false)))
                }),
                null == this.accumulatedUpdates[n] && (this.accumulatedUpdates[n] = {
                    originalName: `${t}/accum_var`,
                    variable: Qo((()=>ml(s).variable(false)))
                });
                const r = Array.isArray(e) ? e[n].tensor : e[t];
                if (null == r)
                    return;
                const a = this.accumulatedGrads[n].variable
                  , i = this.accumulatedUpdates[n].variable;
                Qo((()=>{
                    const e = sl(il(a, this.rho), il(Ic(r), 1 - this.rho))
                      , t = il(al(kc(sl(i, this.epsilon)), kc(sl(a, this.epsilon))), r)
                      , n = sl(il(i, this.rho), il(Ic(t), 1 - this.rho));
                    a.assign(e),
                    i.assign(n);
                    const o = sl(il(t, -this.learningRate), s);
                    s.assign(o)
                }
                ))
            }
            )),
            this.incrementIterations()
        }
        dispose() {
            null != this.accumulatedUpdates && (el(this.accumulatedGrads.map((e=>e.variable))),
            el(this.accumulatedUpdates.map((e=>e.variable))))
        }
        async getWeights() {
            const e = [...this.accumulatedGrads, ...this.accumulatedUpdates];
            return [await this.saveIterations()].concat(e.map((e=>({
                name: e.originalName,
                tensor: e.variable
            }))))
        }
        async setWeights(e) {
            const t = (e = await this.extractIterations(e)).length / 2;
            this.accumulatedGrads = e.slice(0, t).map((e=>({
                originalName: e.name,
                variable: e.tensor.variable(false)
            }))),
            this.accumulatedUpdates = e.slice(t, 2 * t).map((e=>({
                originalName: e.name,
                variable: e.tensor.variable(false)
            })))
        }
        getConfig() {
            return {
                learningRate: this.learningRate,
                rho: this.rho,
                epsilon: this.epsilon
            }
        }
        static fromConfig(e, t) {
            return new e(t.learningRate,t.rho,t.epsilon)
        }
    }
    class ff extends pf {
        constructor(e, t=.1) {
            super(),
            this.learningRate = e,
            this.initialAccumulatorValue = t,
            this.accumulatedGrads = []
        }
        static get className() {
            return "Adagrad"
        }
        applyGradients(e) {
            (Array.isArray(e) ? e.map((e=>e.name)) : Object.keys(e)).forEach(((t,n)=>{
                const s = ka.registeredVariables[t];
                if (null == this.accumulatedGrads[n]) {
                    const e = !1;
                    this.accumulatedGrads[n] = {
                        originalName: `${t}/accumulator`,
                        variable: Qo((()=>wu(s.shape, this.initialAccumulatorValue).variable(e)))
                    }
                }
                const r = Array.isArray(e) ? e[n].tensor : e[t];
                if (null == r)
                    return;
                const a = this.accumulatedGrads[n].variable;
                Qo((()=>{
                    const e = sl(a, Ic(r));
                    a.assign(e);
                    const t = sl(il(al(r, kc(sl(e, ka.backend.epsilon()))), -this.learningRate), s);
                    s.assign(t)
                }
                ))
            }
            )),
            this.incrementIterations()
        }
        dispose() {
            null != this.accumulatedGrads && el(this.accumulatedGrads.map((e=>e.variable)))
        }
        async getWeights() {
            return [await this.saveIterations()].concat(this.accumulatedGrads.map((e=>({
                name: e.originalName,
                tensor: e.variable
            }))))
        }
        async setWeights(e) {
            e = await this.extractIterations(e);
            this.accumulatedGrads = e.map((e=>({
                originalName: e.name,
                variable: e.tensor.variable(false)
            })))
        }
        getConfig() {
            return {
                learningRate: this.learningRate,
                initialAccumulatorValue: this.initialAccumulatorValue
            }
        }
        static fromConfig(e, t) {
            return new e(t.learningRate,t.initialAccumulatorValue)
        }
    }
    class mf extends pf {
        constructor(e, t, n, s=null) {
            super(),
            this.learningRate = e,
            this.beta1 = t,
            this.beta2 = n,
            this.epsilon = s,
            this.accumulatedFirstMoment = [],
            this.accumulatedSecondMoment = [],
            Qo((()=>{
                this.accBeta1 = wl(t).variable(),
                this.accBeta2 = wl(n).variable()
            }
            )),
            null == s && (this.epsilon = ka.backend.epsilon())
        }
        static get className() {
            return "Adam"
        }
        applyGradients(e) {
            const t = Array.isArray(e) ? e.map((e=>e.name)) : Object.keys(e);
            Qo((()=>{
                const n = Yu(1, this.accBeta1)
                  , s = Yu(1, this.accBeta2);
                t.forEach(((t,r)=>{
                    const a = ka.registeredVariables[t];
                    null == this.accumulatedFirstMoment[r] && (this.accumulatedFirstMoment[r] = {
                        originalName: `${t}/m`,
                        variable: Qo((()=>ml(a).variable(false)))
                    }),
                    null == this.accumulatedSecondMoment[r] && (this.accumulatedSecondMoment[r] = {
                        originalName: `${t}/v`,
                        variable: Qo((()=>ml(a).variable(false)))
                    });
                    const i = Array.isArray(e) ? e[r].tensor : e[t];
                    if (null == i)
                        return;
                    const o = this.accumulatedFirstMoment[r].variable
                      , l = this.accumulatedSecondMoment[r].variable
                      , u = sl(il(o, this.beta1), il(i, 1 - this.beta1))
                      , c = sl(il(l, this.beta2), il(Ic(i), 1 - this.beta2))
                      , h = al(u, n)
                      , p = al(c, s);
                    o.assign(u),
                    l.assign(c);
                    const d = sl(il(al(h, sl(kc(p), this.epsilon)), -this.learningRate), a);
                    a.assign(d)
                }
                )),
                this.accBeta1.assign(il(this.accBeta1, this.beta1)),
                this.accBeta2.assign(il(this.accBeta2, this.beta2))
            }
            )),
            this.incrementIterations()
        }
        dispose() {
            this.accBeta1.dispose(),
            this.accBeta2.dispose(),
            null != this.accumulatedFirstMoment && el(this.accumulatedFirstMoment.map((e=>e.variable))),
            null != this.accumulatedSecondMoment && el(this.accumulatedSecondMoment.map((e=>e.variable)))
        }
        async getWeights() {
            const e = [...this.accumulatedFirstMoment, ...this.accumulatedSecondMoment];
            return [await this.saveIterations()].concat(e.map((e=>({
                name: e.originalName,
                tensor: e.variable
            }))))
        }
        async setWeights(e) {
            e = await this.extractIterations(e),
            Qo((()=>{
                this.accBeta1.assign(vc(this.beta1, this.iterations_ + 1)),
                this.accBeta2.assign(vc(this.beta2, this.iterations_ + 1))
            }
            ));
            const t = e.length / 2;
            this.accumulatedFirstMoment = e.slice(0, t).map((e=>({
                originalName: e.name,
                variable: e.tensor.variable(false)
            }))),
            this.accumulatedSecondMoment = e.slice(t, 2 * t).map((e=>({
                originalName: e.name,
                variable: e.tensor.variable(false)
            })))
        }
        getConfig() {
            return {
                learningRate: this.learningRate,
                beta1: this.beta1,
                beta2: this.beta2,
                epsilon: this.epsilon
            }
        }
        static fromConfig(e, t) {
            return new e(t.learningRate,t.beta1,t.beta2,t.epsilon)
        }
    }
    class gf extends pf {
        constructor(e, t, n, s=null, r=0) {
            super(),
            this.learningRate = e,
            this.beta1 = t,
            this.beta2 = n,
            this.epsilon = s,
            this.decay = r,
            this.accumulatedFirstMoment = [],
            this.accumulatedWeightedInfNorm = [],
            Qo((()=>{
                this.iteration = wl(0).variable(),
                this.accBeta1 = wl(t).variable()
            }
            )),
            null == s && (this.epsilon = ka.backend.epsilon())
        }
        static get className() {
            return "Adamax"
        }
        applyGradients(e) {
            const t = Array.isArray(e) ? e.map((e=>e.name)) : Object.keys(e);
            Qo((()=>{
                const n = Yu(1, this.accBeta1)
                  , s = al(-this.learningRate, sl(il(this.iteration, this.decay), 1));
                t.forEach(((t,r)=>{
                    const a = ka.registeredVariables[t];
                    null == this.accumulatedFirstMoment[r] && (this.accumulatedFirstMoment[r] = {
                        originalName: `${t}/m`,
                        variable: ml(a).variable(false)
                    }),
                    null == this.accumulatedWeightedInfNorm[r] && (this.accumulatedWeightedInfNorm[r] = {
                        originalName: `${t}/v`,
                        variable: ml(a).variable(false)
                    });
                    const i = Array.isArray(e) ? e[r].tensor : e[t];
                    if (null == i)
                        return;
                    const o = this.accumulatedFirstMoment[r].variable
                      , l = this.accumulatedWeightedInfNorm[r].variable
                      , u = sl(il(o, this.beta1), il(i, 1 - this.beta1))
                      , c = il(l, this.beta2)
                      , h = uc(i)
                      , p = kp(c, h);
                    o.assign(u),
                    l.assign(p);
                    const d = sl(il(al(s, n), al(u, sl(p, this.epsilon))), a);
                    a.assign(d)
                }
                )),
                this.iteration.assign(sl(this.iteration, 1)),
                this.accBeta1.assign(il(this.accBeta1, this.beta1))
            }
            )),
            this.incrementIterations()
        }
        dispose() {
            this.accBeta1.dispose(),
            this.iteration.dispose(),
            null != this.accumulatedFirstMoment && el(this.accumulatedFirstMoment.map((e=>e.variable))),
            null != this.accumulatedWeightedInfNorm && el(this.accumulatedWeightedInfNorm.map((e=>e.variable)))
        }
        async getWeights() {
            throw new Error("getWeights() is not implemented for Adamax yet.")
        }
        async setWeights(e) {
            throw new Error("setWeights() is not implemented for Adamax yet.")
        }
        getConfig() {
            return {
                learningRate: this.learningRate,
                beta1: this.beta1,
                beta2: this.beta2,
                epsilon: this.epsilon,
                decay: this.decay
            }
        }
        static fromConfig(e, t) {
            return new e(t.learningRate,t.beta1,t.beta2,t.epsilon,t.decay)
        }
    }
    class yf extends pf {
        constructor(e) {
            super(),
            this.learningRate = e,
            this.setLearningRate(e)
        }
        static get className() {
            return "SGD"
        }
        applyGradients(e) {
            (Array.isArray(e) ? e.map((e=>e.name)) : Object.keys(e)).forEach(((t,n)=>{
                const s = Array.isArray(e) ? e[n].tensor : e[t];
                if (null == s)
                    return;
                const r = ka.registeredVariables[t];
                Qo((()=>{
                    const e = sl(il(this.c, s), r);
                    r.assign(e)
                }
                ))
            }
            )),
            this.incrementIterations()
        }
        setLearningRate(e) {
            this.learningRate = e,
            null != this.c && this.c.dispose(),
            this.c = tl(wl(-e))
        }
        dispose() {
            this.c.dispose()
        }
        async getWeights() {
            return [await this.saveIterations()]
        }
        async setWeights(e) {
            if (0 !== (e = await this.extractIterations(e)).length)
                throw new Error("SGD optimizer does not have settable weights.")
        }
        getConfig() {
            return {
                learningRate: this.learningRate
            }
        }
        static fromConfig(e, t) {
            return new e(t.learningRate)
        }
    }
    class bf extends yf {
        constructor(e, t, n=!1) {
            super(e),
            this.learningRate = e,
            this.momentum = t,
            this.useNesterov = n,
            this.accumulations = [],
            this.m = wl(this.momentum)
        }
        static get className() {
            return "Momentum"
        }
        applyGradients(e) {
            (Array.isArray(e) ? e.map((e=>e.name)) : Object.keys(e)).forEach(((t,n)=>{
                const s = ka.registeredVariables[t];
                if (null == this.accumulations[n]) {
                    const e = !1;
                    this.accumulations[n] = {
                        originalName: `${t}/momentum`,
                        variable: Qo((()=>ml(s).variable(e)))
                    }
                }
                const r = this.accumulations[n].variable
                  , a = Array.isArray(e) ? e[n].tensor : e[t];
                null != a && Qo((()=>{
                    let e;
                    const t = sl(il(this.m, r), a);
                    e = this.useNesterov ? sl(il(this.c, sl(a, il(t, this.m))), s) : sl(il(this.c, t), s),
                    r.assign(t),
                    s.assign(e)
                }
                ))
            }
            )),
            this.incrementIterations()
        }
        dispose() {
            this.m.dispose(),
            null != this.accumulations && el(this.accumulations.map((e=>e.variable)))
        }
        setMomentum(e) {
            this.momentum = e
        }
        async getWeights() {
            return [await this.saveIterations()].concat(this.accumulations.map((e=>({
                name: e.originalName,
                tensor: e.variable
            }))))
        }
        async setWeights(e) {
            e = await this.extractIterations(e);
            this.accumulations = e.map((e=>({
                originalName: e.name,
                variable: e.tensor.variable(false)
            })))
        }
        getConfig() {
            return {
                learningRate: this.learningRate,
                momentum: this.momentum,
                useNesterov: this.useNesterov
            }
        }
        static fromConfig(e, t) {
            return new e(t.learningRate,t.momentum,t.useNesterov)
        }
    }
    class xf extends pf {
        constructor(e, t=.9, n=0, s=null, r=!1) {
            if (super(),
            this.learningRate = e,
            this.decay = t,
            this.momentum = n,
            this.epsilon = s,
            this.accumulatedMeanSquares = [],
            this.accumulatedMoments = [],
            this.accumulatedMeanGrads = [],
            this.centered = r,
            null == s && (this.epsilon = ka.backend.epsilon()),
            null == e)
                throw new Error("learningRate for RMSPropOptimizer must be defined.")
        }
        static get className() {
            return "RMSProp"
        }
        applyGradients(e) {
            (Array.isArray(e) ? e.map((e=>e.name)) : Object.keys(e)).forEach(((t,n)=>{
                const s = ka.registeredVariables[t]
                  , r = !1;
                null == this.accumulatedMeanSquares[n] && (this.accumulatedMeanSquares[n] = {
                    originalName: `${t}/rms`,
                    variable: Qo((()=>ml(s).variable(r)))
                }),
                null == this.accumulatedMoments[n] && (this.accumulatedMoments[n] = {
                    originalName: `${t}/momentum`,
                    variable: Qo((()=>ml(s).variable(r)))
                }),
                null == this.accumulatedMeanGrads[n] && this.centered && (this.accumulatedMeanGrads[n] = {
                    originalName: `${t}/mg`,
                    variable: Qo((()=>ml(s).variable(r)))
                });
                const a = Array.isArray(e) ? e[n].tensor : e[t];
                if (null == a)
                    return;
                const i = this.accumulatedMeanSquares[n].variable
                  , o = this.accumulatedMoments[n].variable;
                Qo((()=>{
                    const e = sl(il(i, this.decay), il(Ic(a), 1 - this.decay));
                    if (this.centered) {
                        const t = this.accumulatedMeanGrads[n].variable
                          , r = sl(il(t, this.decay), il(a, 1 - this.decay))
                          , l = al(il(a, this.learningRate), kc(Yu(e, sl(Ic(r), this.epsilon))))
                          , u = sl(il(o, this.momentum), l);
                        i.assign(e),
                        t.assign(r),
                        o.assign(u);
                        const c = Yu(s, u);
                        s.assign(c)
                    } else {
                        const e = sl(il(i, this.decay), il(Ic(a), 1 - this.decay))
                          , t = sl(il(o, this.momentum), al(il(a, this.learningRate), kc(sl(e, this.epsilon))));
                        i.assign(e),
                        o.assign(t);
                        const n = Yu(s, t);
                        s.assign(n)
                    }
                }
                ))
            }
            )),
            this.incrementIterations()
        }
        dispose() {
            null != this.accumulatedMeanSquares && el(this.accumulatedMeanSquares.map((e=>e.variable))),
            null != this.accumulatedMeanGrads && this.centered && el(this.accumulatedMeanGrads.map((e=>e.variable))),
            null != this.accumulatedMoments && el(this.accumulatedMoments.map((e=>e.variable)))
        }
        async getWeights() {
            const e = [...this.accumulatedMeanSquares, ...this.accumulatedMoments];
            return this.centered && e.push(...this.accumulatedMeanGrads),
            [await this.saveIterations()].concat(e.map((e=>({
                name: e.originalName,
                tensor: e.variable
            }))))
        }
        async setWeights(e) {
            e = await this.extractIterations(e);
            const t = this.centered ? e.length / 3 : e.length / 2
              , n = !1;
            this.accumulatedMeanSquares = e.slice(0, t).map((e=>({
                originalName: e.name,
                variable: e.tensor.variable(n)
            }))),
            this.accumulatedMoments = e.slice(t, 2 * t).map((e=>({
                originalName: e.name,
                variable: e.tensor.variable(n)
            }))),
            this.centered && (this.accumulatedMeanGrads = e.slice(2 * t, 3 * t).map((e=>({
                originalName: e.name,
                variable: e.tensor.variable(n)
            }))))
        }
        getConfig() {
            return {
                learningRate: this.learningRate,
                decay: this.decay,
                momentum: this.momentum,
                epsilon: this.epsilon,
                centered: this.centered
            }
        }
        static fromConfig(e, t) {
            return new e(t.learningRate,t.decay,t.momentum,t.epsilon,t.centered)
        }
    }
    const wf = [df, ff, mf, gf, bf, xf, yf];
    var vf = {};
    t(vf, "copyModel", (()=>Uo)),
    t(vf, "listModels", (()=>Po)),
    t(vf, "moveModel", (()=>Vo)),
    t(vf, "removeModel", (()=>Wo)),
    t(vf, "browserFiles", (()=>Nf)),
    t(vf, "browserHTTPRequest", (()=>_f)),
    t(vf, "concatenateArrayBuffers", (()=>to)),
    t(vf, "decodeWeights", (()=>Zi)),
    t(vf, "encodeWeights", (()=>Yi)),
    t(vf, "fromMemory", (()=>zf)),
    t(vf, "fromMemorySync", (()=>Bf)),
    t(vf, "getLoadHandlers", (()=>fo)),
    t(vf, "getModelArtifactsForJSON", (()=>ao)),
    t(vf, "getModelArtifactsForJSONSync", (()=>ro)),
    t(vf, "getModelArtifactsInfoForJSON", (()=>io)),
    t(vf, "getSaveHandlers", (()=>po)),
    t(vf, "getWeightSpecs", (()=>oo)),
    t(vf, "http", (()=>Df)),
    t(vf, "isHTTPScheme", (()=>Rf)),
    t(vf, "loadWeights", (()=>$f)),
    t(vf, "registerLoadRouter", (()=>ho)),
    t(vf, "registerSaveRouter", (()=>co)),
    t(vf, "weightsLoaderFactory", (()=>Ef)),
    t(vf, "withSaveHandler", (()=>Pf)),
    t(vf, "withSaveHandlerSync", (()=>Wf));
    function kf(e) {
        return new Promise((e=>setTimeout(e))).then(e)
    }
    class If {
        constructor(e) {
            if (!ie().getBool("IS_BROWSER"))
                throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");
            e.startsWith(If.URL_SCHEME) && (e = e.slice(If.URL_SCHEME.length)),
            null != e && 0 !== e.length || (e = "model"),
            this.modelJsonFileName = e + ".json",
            this.weightDataFileName = e + ".weights.bin"
        }
        async save(e) {
            if ("undefined" == typeof document)
                throw new Error("Browser downloads are not supported in this environment since `document` is not present");
            const t = window.URL.createObjectURL(new Blob([e.weightData],{
                type: "application/octet-stream"
            }));
            if (e.modelTopology instanceof ArrayBuffer)
                throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");
            {
                const n = so(e, [{
                    paths: ["./" + this.weightDataFileName],
                    weights: e.weightSpecs
                }])
                  , s = window.URL.createObjectURL(new Blob([JSON.stringify(n)],{
                    type: "application/json"
                }))
                  , r = null == this.modelJsonAnchor ? document.createElement("a") : this.modelJsonAnchor;
                if (r.download = this.modelJsonFileName,
                r.href = s,
                await kf((()=>r.dispatchEvent(new MouseEvent("click")))),
                null != e.weightData) {
                    const e = null == this.weightDataAnchor ? document.createElement("a") : this.weightDataAnchor;
                    e.download = this.weightDataFileName,
                    e.href = t,
                    await kf((()=>e.dispatchEvent(new MouseEvent("click"))))
                }
                return {
                    modelArtifactsInfo: io(e)
                }
            }
        }
    }
    If.URL_SCHEME = "downloads://";
    class Sf {
        constructor(e) {
            if (null == e || e.length < 1)
                throw new Error(`When calling browserFiles, at least 1 file is required, but received ${e}`);
            this.jsonFile = e[0],
            this.weightsFiles = e.slice(1)
        }
        async load() {
            return new Promise(((e,t)=>{
                const n = new FileReader;
                n.onload = n=>{
                    const s = JSON.parse(n.target.result)
                      , r = s.modelTopology;
                    if (null == r)
                        return void t(new Error(`modelTopology field is missing from file ${this.jsonFile.name}`));
                    if (null == s.weightsManifest)
                        return void t(new Error(`weightManifest field is missing from file ${this.jsonFile.name}`));
                    if (0 === this.weightsFiles.length)
                        return void e({
                            modelTopology: r
                        });
                    const a = ao(s, (e=>this.loadWeights(e)));
                    e(a)
                }
                ,
                n.onerror = e=>t(`Failed to read model topology and weights manifest JSON from file '${this.jsonFile.name}'. BrowserFiles supports loading Keras-style tf.Model artifacts only.`),
                n.readAsText(this.jsonFile)
            }
            ))
        }
        loadWeights(e) {
            const t = []
              , n = [];
            for (const s of e)
                t.push(...s.weights),
                n.push(...s.paths);
            const s = this.checkManifestAndWeightFiles(e)
              , r = n.map((e=>this.loadWeightsFile(e, s[e])));
            return Promise.all(r).then((e=>[t, to(e)]))
        }
        loadWeightsFile(e, t) {
            return new Promise(((n,s)=>{
                const r = new FileReader;
                r.onload = e=>{
                    const t = e.target.result;
                    n(t)
                }
                ,
                r.onerror = t=>s(`Failed to weights data from file of path '${e}'.`),
                r.readAsArrayBuffer(t)
            }
            ))
        }
        checkManifestAndWeightFiles(e) {
            const t = []
              , n = this.weightsFiles.map((e=>no(e.name)))
              , s = {};
            for (const r of e)
                r.paths.forEach((e=>{
                    const r = no(e);
                    if (-1 !== t.indexOf(r))
                        throw new Error(`Duplicate file basename found in weights manifest: '${r}'`);
                    if (t.push(r),
                    -1 === n.indexOf(r))
                        throw new Error(`Weight file with basename '${r}' is not provided.`);
                    s[e] = this.weightsFiles[n.indexOf(r)]
                }
                ));
            if (t.length !== this.weightsFiles.length)
                throw new Error(`Mismatch in the number of files in weights manifest (${t.length}) and the number of weight files provided (${this.weightsFiles.length}).`);
            return s
        }
    }
    function Nf(e) {
        return new Sf(e)
    }
    function Tf(e, t, n, s) {
        var r, a, i;
        b(null != (r = e) && Array.isArray(r) && r.length > 0, (()=>"promises must be a none empty array")),
        i = s = null == s ? 1 : s,
        b((a = n = null == n ? 0 : n) >= 0 && a <= 1, (()=>`Progress fraction must be in range [0, 1], but got startFraction ${a}`)),
        b(i >= 0 && i <= 1, (()=>`Progress fraction must be in range [0, 1], but got endFraction ${i}`)),
        b(i >= a, (()=>`startFraction must be no more than endFraction, but got startFraction ${a} and endFraction ${i}`));
        let o = 0;
        return Promise.all(e.map((r=>(r.then((r=>{
            const a = n + ++o / e.length * (s - n);
            return t(a),
            r
        }
        )),
        r))))
    }
    async function Cf(e, t) {
        null == t && (t = {});
        const n = null == t.fetchFunc ? ie().platform.fetch : t.fetchFunc
          , s = e.map((e=>n(e, t.requestInit, {
            isBinary: !0
        })))
          , r = (null == t.onProgress ? await Promise.all(s) : await Tf(s, t.onProgress, 0, .5)).map((e=>e.arrayBuffer()));
        return null == t.onProgress ? await Promise.all(r) : await Tf(r, t.onProgress, .5, 1)
    }
    async function $f(e, t="", n, s) {
        return Ef((e=>Cf(e, {
            requestInit: s
        })))(e, t, n)
    }
    function Ef(e) {
        return async(t,n="",s)=>{
            const r = t.map((()=>!1))
              , a = {}
              , i = null != s ? s.map((()=>!1)) : []
              , o = [];
            if (t.forEach(((e,t)=>{
                let n = 0;
                e.weights.forEach((e=>{
                    const l = "quantization"in e ? e.quantization.dtype : e.dtype
                      , u = Pa[l] * v(e.shape)
                      , c = ()=>{
                        r[t] = !0,
                        null == a[t] && (a[t] = []),
                        a[t].push({
                            manifestEntry: e,
                            groupOffset: n,
                            sizeBytes: u
                        })
                    }
                    ;
                    null != s ? s.forEach(((t,n)=>{
                        t === e.name && (c(),
                        i[n] = !0)
                    }
                    )) : c(),
                    o.push(e.name),
                    n += u
                }
                ))
            }
            )),
            !i.every((e=>e))) {
                const e = s.filter(((e,t)=>!i[t]));
                throw new Error(`Could not find weights in manifest with names: ${e.join(", ")}. \nManifest JSON has weights with names: ${o.join(", ")}.`)
            }
            const l = r.reduce(((e,t,n)=>(t && e.push(n),
            e)), [])
              , u = [];
            l.forEach((e=>{
                t[e].paths.forEach((e=>{
                    const t = n + (n.endsWith("/") ? "" : "/") + e;
                    u.push(t)
                }
                ))
            }
            ));
            const c = await e(u)
              , h = {};
            let p = 0;
            return l.forEach((e=>{
                const n = t[e].paths.length;
                let s = 0;
                for (let e = 0; e < n; e++)
                    s += c[p + e].byteLength;
                const r = new ArrayBuffer(s)
                  , i = new Uint8Array(r);
                let o = 0;
                for (let e = 0; e < n; e++) {
                    const t = new Uint8Array(c[p + e]);
                    i.set(t, o),
                    o += t.byteLength
                }
                a[e].forEach((e=>{
                    const t = Zi(r.slice(e.groupOffset, e.groupOffset + e.sizeBytes), [e.manifestEntry]);
                    for (const e in t)
                        h[e] = t[e]
                }
                )),
                p += n
            }
            )),
            h
        }
    }
    uo.registerSaveRouter((e=>ie().getBool("IS_BROWSER") && !Array.isArray(e) && e.startsWith(If.URL_SCHEME) ? function(e="model") {
        return new If(e)
    }(e.slice(If.URL_SCHEME.length)) : null));
    class Af {
        constructor(e, t) {
            if (this.DEFAULT_METHOD = "POST",
            null == t && (t = {}),
            this.weightPathPrefix = t.weightPathPrefix,
            this.onProgress = t.onProgress,
            this.weightUrlConverter = t.weightUrlConverter,
            null != t.fetchFunc ? (b("function" == typeof t.fetchFunc, (()=>"Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)")),
            this.fetch = t.fetchFunc) : this.fetch = ie().platform.fetch,
            b(null != e && e.length > 0, (()=>"URL path for http must not be null, undefined or empty.")),
            Array.isArray(e) && b(2 === e.length, (()=>`URL paths for http must have a length of 2, (actual length is ${e.length}).`)),
            this.path = e,
            null != t.requestInit && null != t.requestInit.body)
                throw new Error("requestInit is expected to have no pre-existing body, but has one.");
            this.requestInit = t.requestInit || {}
        }
        async save(e) {
            if (e.modelTopology instanceof ArrayBuffer)
                throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");
            const t = Object.assign({
                method: this.DEFAULT_METHOD
            }, this.requestInit);
            t.body = new FormData;
            const n = so(e, [{
                paths: ["./model.weights.bin"],
                weights: e.weightSpecs
            }]);
            t.body.append("model.json", new Blob([JSON.stringify(n)],{
                type: "application/json"
            }), "model.json"),
            null != e.weightData && t.body.append("model.weights.bin", new Blob([e.weightData],{
                type: "application/octet-stream"
            }), "model.weights.bin");
            const s = await this.fetch(this.path, t);
            if (s.ok)
                return {
                    modelArtifactsInfo: io(e),
                    responses: [s]
                };
            throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ${s.status}.`)
        }
        async load() {
            const e = await this.fetch(this.path, this.requestInit);
            if (!e.ok)
                throw new Error(`Request to ${this.path} failed with status code ${e.status}. Please verify this URL points to the model JSON of the model to load.`);
            let t;
            try {
                t = await e.json()
            } catch (e) {
                let t = `Failed to parse model JSON of response from ${this.path}.`;
                throw this.path.endsWith(".pb") ? t += " Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository." : t += " Please make sure the server is serving valid JSON for this request.",
                new Error(t)
            }
            const n = t.modelTopology
              , s = t.weightsManifest;
            if (null == n && null == s)
                throw new Error(`The JSON from HTTP path ${this.path} contains neither model topology or manifest for weights.`);
            return ao(t, (e=>this.loadWeights(e)))
        }
        async loadWeights(e) {
            const t = Array.isArray(this.path) ? this.path[1] : this.path
              , [n,s] = function(e) {
                const t = e.lastIndexOf("/")
                  , n = e.lastIndexOf("?")
                  , s = e.substring(0, t)
                  , r = n > t ? e.substring(n) : "";
                return [s + "/", r]
            }(t)
              , r = this.weightPathPrefix || n
              , a = oo(e)
              , i = []
              , o = [];
            for (const t of e)
                for (const e of t.paths)
                    null != this.weightUrlConverter ? o.push(this.weightUrlConverter(e)) : i.push(r + e + s);
            this.weightUrlConverter && i.push(...await Promise.all(o));
            return [a, to(await Cf(i, {
                requestInit: this.requestInit,
                fetchFunc: this.fetch,
                onProgress: this.onProgress
            }))]
        }
    }
    function Rf(e) {
        return null != e.match(Af.URL_SCHEME_REGEX)
    }
    Af.URL_SCHEME_REGEX = /^https?:\/\//;
    const Ff = (e,t)=>{
        if ("undefined" == typeof fetch && (null == t || null == t.fetchFunc))
            return null;
        {
            let n = !0;
            if (n = Array.isArray(e) ? e.every((e=>Rf(e))) : Rf(e),
            n)
                return Df(e, t)
        }
        return null
    }
    ;
    function Df(e, t) {
        return new Af(e,t)
    }
    function _f(e, t) {
        return Df(e, t)
    }
    /**
 * @license
 * Copyright 2018 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
    uo.registerSaveRouter(Ff),
    uo.registerLoadRouter(Ff);
    class Of {
        constructor(e) {
            this.modelArtifacts = e
        }
        load() {
            return this.modelArtifacts
        }
    }
    class Mf {
        constructor(e) {
            this.saveHandler = e
        }
        save(e) {
            return this.saveHandler(e)
        }
    }
    class Lf {
        constructor(e) {
            e.load && (this.load = ()=>Promise.resolve(e.load())),
            e.save && (this.save = t=>Promise.resolve(e.save(t)))
        }
    }
    function zf(e, t, n, s) {
        const r = arguments;
        return new Lf(Bf(...r))
    }
    function Bf(e, t, n, s) {
        if (1 === arguments.length) {
            return null != e.modelTopology || null != e.weightSpecs ? new Of(e) : (console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."),
            new Of({
                modelTopology: e
            }))
        }
        return console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."),
        new Of({
            modelTopology: e,
            weightSpecs: t,
            weightData: n,
            trainingConfig: s
        })
    }
    function Pf(e) {
        return new Mf(e)
    }
    function Wf(e) {
        return new Mf(e)
    }
    var Uf = {};
    let Vf;
    function Gf(e, t=3) {
        if (t > 4)
            throw new Error("Cannot construct Tensor with more than 4 channels from pixels.");
        if (null == e)
            throw new Error("pixels passed to tf.browser.fromPixels() can not be null");
        let n = !1
          , s = !1
          , r = !1
          , a = !1
          , i = !1
          , o = !1;
        if (e.data instanceof Uint8Array)
            n = !0;
        else if ("undefined" != typeof ImageData && e instanceof ImageData)
            s = !0;
        else if ("undefined" != typeof HTMLVideoElement && e instanceof HTMLVideoElement)
            r = !0;
        else if ("undefined" != typeof HTMLImageElement && e instanceof HTMLImageElement)
            a = !0;
        else if (null != e.getContext)
            i = !0;
        else {
            if (!("undefined" != typeof ImageBitmap && e instanceof ImageBitmap))
                throw new Error(`pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32Array, width: number, height: number}, but was ${e.constructor.name}`);
            o = !0
        }
        if (null != Bs(Es, ka.backendName)) {
            const n = {
                pixels: e
            }
              , s = {
                numChannels: t
            };
            return ka.runKernel(Es, n, s)
        }
        const [l,u] = r ? [e.videoWidth, e.videoHeight] : [e.width, e.height];
        let c, h;
        if (i)
            c = e.getContext("2d").getImageData(0, 0, l, u).data;
        else if (s || n)
            c = e.data;
        else if (a || r || o) {
            if (null == Vf)
                if ("undefined" == typeof document) {
                    if ("undefined" == typeof OffscreenCanvas || "undefined" == typeof OffscreenCanvasRenderingContext2D)
                        throw new Error("Cannot parse input in current context. Reason: OffscreenCanvas Context2D rendering is not supported.");
                    Vf = new OffscreenCanvas(1,1).getContext("2d")
                } else
                    Vf = document.createElement("canvas").getContext("2d", {
                        willReadFrequently: !0
                    });
            Vf.canvas.width = l,
            Vf.canvas.height = u,
            Vf.drawImage(e, 0, 0, l, u),
            c = Vf.getImageData(0, 0, l, u).data
        }
        if (4 === t)
            h = new Int32Array(c);
        else {
            const e = l * u;
            h = new Int32Array(e * t);
            for (let n = 0; n < e; n++)
                for (let e = 0; e < t; ++e)
                    h[n * t + e] = c[4 * n + e]
        }
        return Sd(h, [u, l, t], "int32")
    }
    function Hf(e) {
        return "undefined" != typeof window && "undefined" != typeof ImageBitmap && window.hasOwnProperty("createImageBitmap") && !(e instanceof ImageBitmap) && function(e) {
            return null != e && 0 !== e.width && 0 !== e.height
        }(e) && !function(e) {
            return null != e && e.data instanceof Uint8Array
        }(e)
    }
    async function jf(e, t=3) {
        let n = null;
        if (ie().getBool("WRAP_TO_IMAGEBITMAP") && Hf(e)) {
            let t;
            try {
                t = await createImageBitmap(e, {
                    premultiplyAlpha: "none"
                })
            } catch (e) {
                t = null
            }
            n = null != t && t.width === e.width && t.height === e.height ? t : e
        } else
            n = e;
        return Gf(n, t)
    }
    async function qf(e, t) {
        let n = Da(e, "img", "toPixels");
        if (!(e instanceof Zr)) {
            const e = n;
            n = Ko(e, "int32"),
            e.dispose()
        }
        if (2 !== n.rank && 3 !== n.rank)
            throw new Error(`toPixels only supports rank 2 or 3 tensors, got rank ${n.rank}.`);
        const [s,r] = n.shape.slice(0, 2)
          , a = 2 === n.rank ? 1 : n.shape[2];
        if (a > 4 || 2 === a)
            throw new Error(`toPixels only supports depth of size 1, 3 or 4 but got ${a}`);
        if ("float32" !== n.dtype && "int32" !== n.dtype)
            throw new Error(`Unsupported type for toPixels: ${n.dtype}. Please use float32 or int32 tensors.`);
        const i = await n.data()
          , o = "float32" === n.dtype ? 255 : 1
          , l = new Uint8ClampedArray(r * s * 4);
        for (let e = 0; e < s * r; ++e) {
            const t = [0, 0, 0, 255];
            for (let s = 0; s < a; s++) {
                const r = i[e * a + s];
                if ("float32" === n.dtype) {
                    if (r < 0 || r > 1)
                        throw new Error(`Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ${r}.`)
                } else if ("int32" === n.dtype && (r < 0 || r > 255))
                    throw new Error(`Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ${r}.`);
                1 === a ? (t[0] = r * o,
                t[1] = r * o,
                t[2] = r * o) : t[s] = r * o
            }
            const s = 4 * e;
            l[s + 0] = Math.round(t[0]),
            l[s + 1] = Math.round(t[1]),
            l[s + 2] = Math.round(t[2]),
            l[s + 3] = Math.round(t[3])
        }
        if (null != t) {
            t.width = r,
            t.height = s;
            const e = t.getContext("2d")
              , n = new ImageData(l,r,s);
            e.putImageData(n, 0, 0)
        }
        return n !== e && n.dispose(),
        l
    }
    t(Uf, "fromPixelsAsync", (()=>jf)),
    t(Uf, "toPixels", (()=>qf)),
    t(Uf, "fromPixels", (()=>Kf));
    const Kf = Ma({
        fromPixels_: Gf
    });
    var Xf = {};
    t(Xf, "assertParamsValid", (()=>Yf)),
    t(Xf, "maskToAxes", (()=>Zf)),
    t(Xf, "computeOutShape", (()=>Jf)),
    t(Xf, "stridesWithElidedDims", (()=>Qf)),
    t(Xf, "getNormalizedAxes", (()=>nm)),
    t(Xf, "startIndicesWithElidedDims", (()=>sm)),
    t(Xf, "stopIndicesWithElidedDims", (()=>rm)),
    t(Xf, "startForAxis", (()=>im)),
    t(Xf, "stopForAxis", (()=>om)),
    t(Xf, "stridesForAxis", (()=>am)),
    t(Xf, "isSliceContinous", (()=>lm)),
    t(Xf, "computeFlatOffset", (()=>um)),
    t(Xf, "parseSliceParams", (()=>cm)),
    t(Xf, "sliceInfo", (()=>hm));
    function Yf(e, t, n) {
        const s = e.shape.length;
        b(s === t.length, (()=>`Error in slice${s}D: Length of begin ${t} must match the rank of the array (${s}).`)),
        b(s === n.length, (()=>`Error in slice${s}D: Length of size ${n} must match the rank of the array (${s}).`));
        for (let r = 0; r < s; ++r)
            b(t[r] + n[r] <= e.shape[r], (()=>`Error in slice${s}D: begin[${r}] + size[${r}] (${t[r] + n[r]}) would overflow input.shape[${r}] (${e.shape[r]})`))
    }
    function Zf(e) {
        const t = [];
        let n = 0;
        for (; e > 0; )
            1 & e && t.push(n),
            e /= 2,
            n++;
        return t
    }
    function Jf(e, t, n) {
        const s = [];
        for (let r = 0; r < e.length; r++)
            s[r] = Math.ceil((t[r] - e[r]) / n[r]);
        return s
    }
    function Qf(e, t, n, s) {
        const r = [...e];
        for (let e = r.length; e < s.length; e++)
            r.push(1);
        for (let e = 0; e < n; e++)
            0 === e ? r[t] = 1 : (r.splice(t, 0, 1),
            r.pop());
        return r
    }
    function em(e, t, n) {
        return n <= e ? n : n - (t - 1)
    }
    function tm(e, t) {
        const n = [];
        for (let s = 0; s < e; s++)
            n.push(t + s);
        return n
    }
    function nm(e, t, n, s, r, a, i, o, l) {
        const u = e.length;
        let c = new Array(u)
          , h = new Array(u)
          , p = new Array(u);
        if (t.length && n > 0) {
            const l = t[0]
              , u = n + 1;
            c = sm(i, l, u, s, e),
            h = rm(o, l, u, r, e),
            p = Qf(a, l, u, e)
        } else
            for (let t = 0; t < u; t++)
                c[t] = im(i, s, a, e, t, l),
                h[t] = om(o, r, a, e, t, l),
                p[t] = am(a, t, l);
        return {
            begin: c,
            end: h,
            strides: p
        }
    }
    function sm(e, t, n, s, r) {
        const a = [...r]
          , i = tm(n, t);
        for (let r = 0; r < a.length; r++)
            if (i.indexOf(r) > -1)
                a[r] = 0;
            else {
                const i = em(t, n, r);
                let o = s[i];
                e & 1 << i && (o = 0),
                a[r] = o
            }
        return a
    }
    function rm(e, t, n, s, r) {
        const a = [...r]
          , i = tm(n, t);
        for (let r = 0; r < a.length; r++)
            if (i.indexOf(r) > -1)
                a[r] = Number.MAX_SAFE_INTEGER;
            else {
                const i = em(t, n, r);
                let o = s[i];
                e & 1 << i && (o = Number.MAX_SAFE_INTEGER),
                a[r] = o
            }
        for (let e = 0; e < a.length; e++) {
            const t = r[e];
            a[e] < 0 && (a[e] += t),
            a[e] = p(0, a[e], r[e])
        }
        return a
    }
    function am(e, t, n) {
        let s = e[t];
        return (n & 1 << t || null == s) && (s = 1),
        s
    }
    function im(e, t, n, s, r, a) {
        let i = t[r];
        const o = n[r] || 1;
        (e & 1 << r || a & 1 << r || null == i) && (i = o > 0 ? Number.MIN_SAFE_INTEGER : Number.MAX_SAFE_INTEGER);
        const l = s[r];
        return i < 0 && (i += l),
        i = p(0, i, l - 1),
        i
    }
    function om(e, t, n, s, r, a) {
        let i = t[r];
        const o = n[r] || 1;
        (e & 1 << r || a & 1 << r || null == i) && (i = o > 0 ? Number.MAX_SAFE_INTEGER : Number.MIN_SAFE_INTEGER);
        const l = s[r];
        return i < 0 && (i += l),
        i = o > 0 ? p(0, i, l) : p(-1, i, l - 1),
        i
    }
    function lm(e, t, n) {
        let s = n.length;
        for (let e = 0; e < n.length; e++)
            if (n[e] > 1) {
                s = e;
                break
            }
        for (let r = s + 1; r < n.length; r++)
            if (t[r] > 0 || n[r] !== e[r])
                return !1;
        return !0
    }
    function um(e, t) {
        let n = e.length > 0 ? e[e.length - 1] : 1;
        for (let s = 0; s < e.length - 1; s++)
            n += e[s] * t[s];
        return n
    }
    function cm(e, t, n) {
        let s;
        const r = e.shape.length;
        let a;
        return s = "number" == typeof t ? [t, ...new Array(r - 1).fill(0)] : t.length < r ? t.concat(new Array(r - t.length).fill(0)) : t.slice(),
        s.forEach((e=>{
            b(-1 !== e, (()=>"slice() does not support negative begin indexing."))
        }
        )),
        a = null == n ? new Array(r).fill(-1) : "number" == typeof n ? [n, ...new Array(r - 1).fill(-1)] : n.length < r ? n.concat(new Array(r - n.length).fill(-1)) : n,
        a = a.map(((t,n)=>t >= 0 ? t : (b(-1 === t, (()=>`Negative size values should be exactly -1 but got ${t} for the slice() size at index ${n}.`)),
        e.shape[n] - s[n]))),
        [s, a]
    }
    function hm(e, t, n, s, r, a, i, o, l) {
        let u;
        if (null == s ? (u = new Array(t.length),
        u.fill(1)) : u = s,
        null != i && 0 != (i & i - 1))
            throw new Error("Multiple ellipses in slice is not allowed.");
        let c = !1;
        const h = {
            dims: u.length,
            numAddAxisAfterEllipsis: 0,
            begin: t.slice(),
            end: n.slice(),
            strides: u.slice(),
            beginMask: r,
            endMask: a,
            ellipsisMask: i,
            newAxisMask: o,
            shrinkAxisMask: l
        };
        for (let e = 0; e < h.dims; e++)
            c && 0 != (1 << e & o) && h.numAddAxisAfterEllipsis++,
            1 << e & i && (c = !0);
        c || (h.ellipsisMask |= 1 << h.dims,
        h.dims++);
        const p = {
            dims: e.length,
            beginMask: 0,
            endMask: 0,
            beginValid: !1,
            endValid: !1
        };
        !function(e, t) {
            t.beginMask = 0,
            t.endMask = 0,
            t.shrinkAxisMask = 0;
            let n = 0;
            t.beginValid = null != e.begin,
            t.endValid = null != e.end,
            t.begin = new Array(t.dims),
            t.end = new Array(t.dims),
            t.strides = new Array(t.dims),
            t.finalShapeGatherIndices = [],
            t.finalShapeGatherIndicesSparse = [],
            t.inputShapeGatherIndicesSparse = new Array(t.dims);
            for (let s = 0; s < e.dims; s++)
                if (1 << s & e.ellipsisMask) {
                    const r = Math.min(t.dims - (e.dims - s) + 1 + e.numAddAxisAfterEllipsis, t.dims);
                    for (; n < r; n++)
                        t.begin[n] = 0,
                        t.end[n] = 0,
                        t.strides[n] = 1,
                        t.beginMask |= 1 << n,
                        t.endMask |= 1 << n,
                        t.finalShapeGatherIndices.push(n),
                        t.finalShapeGatherIndicesSparse.push(-1),
                        t.inputShapeGatherIndicesSparse[n] = s
                } else if (1 << s & e.newAxisMask)
                    t.finalShapeGatherIndices.push(-2),
                    t.finalShapeGatherIndicesSparse.push(-1);
                else {
                    if (n === t.begin.length)
                        throw Error(`Index out of range using input dim ${n}; input has only ${t.dims} dims, ${t.begin.length}.`);
                    null != e.begin && (t.begin[n] = e.begin[s]),
                    null != e.end && (t.end[n] = e.end[s]),
                    t.strides[n] = e.strides[s],
                    e.beginMask & 1 << s && (t.beginMask |= 1 << n),
                    e.endMask & 1 << s && (t.endMask |= 1 << n),
                    e.shrinkAxisMask & 1 << s ? (t.finalShapeGatherIndices.push(-1),
                    t.finalShapeGatherIndicesSparse.push(-1),
                    t.shrinkAxisMask |= 1 << n) : (t.finalShapeGatherIndices.push(n),
                    t.finalShapeGatherIndicesSparse.push(s)),
                    t.inputShapeGatherIndicesSparse[n] = s,
                    n++
                }
        }(h, p);
        let d = !0
          , f = !0
          , m = !0;
        const g = []
          , y = [];
        for (let t = 0; t < e.length; ++t) {
            if (0 === p.strides[t])
                throw Error(`strides[${t}] must be non-zero`);
            const n = !!(p.shrinkAxisMask & 1 << t)
              , s = e[t];
            if (-1 === s) {
                g.push(n ? 1 : -1);
                continue
            }
            const r = [p.beginMask & 1 << t, p.endMask & 1 << t]
              , a = [p.strides[t] > 0 ? 0 : -1, p.strides[t] > 0 ? s : s - 1];
            if (n && p.strides[t] <= 0)
                throw Error("only stride 1 allowed on non-range indexing.");
            m = m && 1 === p.strides[t];
            const i = !!(p.beginMask & 1 << t && p.endMask & 1 << t);
            if (p.beginValid && p.endValid) {
                if (n) {
                    const e = p.begin[t] < 0 ? s + p.begin[t] : p.begin[t];
                    if (p.begin[t] = e,
                    p.end[t] = p.begin[t] + 1,
                    e < 0 || e >= s)
                        throw Error(`slice index ${p.begin[t]} of dimension ${t} out of bounds.`)
                } else
                    p.begin[t] = pm(p.begin[t], 0, p.strides[t], s, r, a),
                    p.end[t] = pm(p.end[t], 1, p.strides[t], s, r, a);
                const e = 1 === p.strides[t] && 0 === p.begin[t] && p.end[t] === s;
                d = d && e,
                f = f && (0 === t && 1 === p.strides[t] || e)
            } else
                d = d && 1 === p.strides[t] && i,
                f = f && (0 === t && 1 === p.strides[t] || i);
            let o, l = !1;
            if (p.beginValid && p.endValid ? (o = p.end[t] - p.begin[t],
            l = !0) : n ? (o = 1,
            l = !0) : i && s >= 0 && (o = p.strides[t] < 0 ? -s : s,
            l = !0),
            l) {
                let e;
                e = 0 === o || o < 0 != p.strides[t] < 0 ? 0 : Math.trunc(o / p.strides[t]) + (o % p.strides[t] != 0 ? 1 : 0),
                g.push(e)
            } else
                g.push(-1)
        }
        for (let e = 0; e < p.finalShapeGatherIndices.length; ++e) {
            const t = p.finalShapeGatherIndices[e];
            t >= 0 ? y.push(g[t]) : -2 === t && y.push(1)
        }
        return {
            finalShapeSparse: y.filter(((e,t)=>-2 !== p.finalShapeGatherIndices[t])),
            finalShape: y,
            isIdentity: d,
            sliceDim0: f,
            isSimpleSlice: m,
            begin: p.begin,
            end: p.end,
            strides: p.strides
        }
    }
    function pm(e, t, n, s, r, a) {
        if (r[t])
            return n > 0 ? a[t] : a[t + 1 & 1];
        {
            const t = e < 0 ? s + e : e;
            return t < a[0] ? a[0] : t > a[1] ? a[1] : t
        }
    }
    /** @license See the LICENSE file. */
    var dm = {};
    t(dm, "fromUint8ToStringArray", (()=>Rg)),
    t(dm, "fromStringArrayToUint8", (()=>Fg)),
    t(dm, "slice_util", (()=>Xf)),
    t(dm, "upcastType", (()=>ha)),
    t(dm, "segment_util", (()=>fm));
    var fm = {};
    t(fm, "segOpComputeOptimalWindowSize", (()=>bm)),
    t(fm, "computeOutShape", (()=>xm)),
    t(fm, "collectGatherOpShapeInfo", (()=>wm));
    var mm = {};
    t(mm, "PARALLELIZE_THRESHOLD", (()=>gm)),
    t(mm, "computeOptimalWindowSize", (()=>ym));
    const gm = 30;
    function ym(e) {
        return e <= gm ? e : H(e, Math.floor(Math.sqrt(e)))
    }
    function bm(e, t) {
        let n, s = !1;
        for (e <= gm ? (n = e,
        s = !0) : n = H(e, Math.floor(Math.sqrt(e))); !s; )
            n > t || n === e ? s = !0 : n = H(e, n + 1);
        return n
    }
    function xm(e, t, n) {
        const s = []
          , r = e.length;
        for (let a = 0; a < r; a++)
            a !== t ? s.push(e[a]) : s.push(n);
        return s
    }
    function wm(e, t, n, s) {
        const r = t.shape.length
          , a = e.shape.length;
        if (0 !== s && (s < -r || s > r))
            throw new Error(`Expect batchDims in the range of [-${r}, ${r}], but got ${s}`);
        if (s < 0 && (s += r),
        s > a)
            throw new Error(`batchDims (${s}) must be less than rank(x) (\n    ${a}).`);
        if (n < s)
            throw new Error(`batchDims (${s}) must be less than or equal to axis (${n}).`);
        for (let n = 0; n < s; ++n)
            if (e.shape[n] !== t.shape[n])
                throw new Error(`x.shape[${n}]: ${e.shape[n]} should be equal to indices.shape[${n}]: ${t.shape[n]}.`);
        const i = e.shape[n]
          , o = [];
        let l = 1
          , u = 1
          , c = 1;
        for (let t = 0; t < s; ++t)
            o.push(e.shape[t]),
            l *= e.shape[t];
        for (let t = s; t < n; t++)
            o.push(e.shape[t]),
            u *= e.shape[t];
        for (let e = s; e < r; e++)
            o.push(t.shape[e]);
        for (let t = n + 1; t < a; t++)
            o.push(e.shape[t]),
            c *= e.shape[t];
        return {
            batchSize: l,
            sliceSize: c,
            outerSize: u,
            dimSize: i,
            outputShape: o
        }
    }
    var vm = {};
    function km(e, t) {
        const n = e[0].length;
        e.forEach(((e,t)=>{
            b(e.length === n, (()=>`Error in concat${n}D: rank of tensors[${t}] must be the same as the rank of the rest (${n})`))
        }
        )),
        b(t >= 0 && t < n, (()=>`Error in concat${n}D: axis must be between 0 and ${n - 1}.`));
        const s = e[0];
        e.forEach(((e,r)=>{
            for (let a = 0; a < n; a++)
                b(a === t || e[a] === s[a], (()=>`Error in concat${n}D: Shape of tensors[${r}] (${e}) does not match the shape of the rest (${s}) along the non-concatenated axis ${r}.`))
        }
        ))
    }
    function Im(e, t) {
        const n = e[0].slice();
        for (let s = 1; s < e.length; s++)
            n[t] += e[s][t];
        return n
    }
    t(vm, "assertParamsConsistent", (()=>km)),
    t(vm, "computeOutShape", (()=>Im));
    var Sm, Nm = {};
    function Tm(e, t, n) {
        let s = new Array;
        if (null == n && null == t)
            return s;
        if (null == t)
            for (; s.length < e + n.length; )
                s.push(-1);
        else
            s = t.slice();
        if (null == n)
            return s;
        if (e + n.length !== s.length)
            throw new Error(`rt input.shape and shape=${t} are incompatible: rt input.rank = ${e + n.length}, but shape.rank = ${s.length}`);
        for (let r = 1; r < n.length; ++r) {
            const a = n[r]
              , i = s[s.length - n.length + r]
              , o = s[i];
            if (a >= 0)
                if (o >= 0) {
                    if (o !== a)
                        throw new Error(`rt input.shape and shape=${t} are incompatible: rt input.shape[${r + e}] = ${a} but shape[${r + e}] = ${o}`)
                } else
                    s[i] = a
        }
        return s
    }
    function Cm(e) {
        const t = {
            FIRST_DIM_SIZE: Sm.FIRST_DIM_SIZE,
            VALUE_ROWIDS: Sm.VALUE_ROWIDS,
            ROW_LENGTHS: Sm.ROW_LENGTHS,
            ROW_SPLITS: Sm.ROW_SPLITS,
            ROW_LIMITS: Sm.ROW_LIMITS,
            ROW_STARTS: Sm.ROW_STARTS
        }
          , n = [];
        for (const s of e) {
            if (!(s in t))
                break;
            n.push(t[s])
        }
        return n
    }
    function $m(e) {
        return 0 === e.length ? 0 : e[0] === Sm.FIRST_DIM_SIZE ? e.length - 1 : e.length
    }
    function Em(e, t) {
        if (null == e || null == t)
            return;
        const n = e.length
          , s = t.length;
        if (n >= s)
            throw new Error(`defaultValue.shape=${e} and ragged tensor flatValues.shape=${t}, are incompatible: defaultValue.rank = ${n} must be less than ragged tensor input flatValues.rank = ${s})`);
        for (let r = 0; r < Math.min(n, s - 1); ++r) {
            const n = e[r]
              , s = t[r + 1];
            if (n >= 0 && s >= 0 && 1 !== n && n !== s)
                throw new Error(`defaultValue.shape=${e}, and ragged tensor input flatValues.shape=${t} are incompatible: defaultValue.shape[${r - e.length}] = ${n} but ragged tensor input.flatValues.shape[${r - e.length}] = ${s}`)
        }
    }
    t(Nm, "RowPartitionType", (()=>Sm)),
    t(Nm, "combineRaggedTensorToTensorShapes", (()=>Tm)),
    t(Nm, "getRowPartitionTypesHelper", (()=>Cm)),
    t(Nm, "getRaggedRank", (()=>$m)),
    t(Nm, "validateDefaultValueShape", (()=>Em)),
    function(e) {
        e[e.FIRST_DIM_SIZE = 0] = "FIRST_DIM_SIZE",
        e[e.VALUE_ROWIDS = 1] = "VALUE_ROWIDS",
        e[e.ROW_LENGTHS = 2] = "ROW_LENGTHS",
        e[e.ROW_SPLITS = 3] = "ROW_SPLITS",
        e[e.ROW_LIMITS = 4] = "ROW_LIMITS",
        e[e.ROW_STARTS = 5] = "ROW_STARTS"
    }(Sm || (Sm = {}));
    var Am = {};
    function Rm(e, t, n) {
        return [n * ("number" == typeof e ? e : e[0]), t * ("number" == typeof e ? e : e[1])]
    }
    t(Am, "getImageCenter", (()=>Rm));
    var Fm = {};
    function Dm(e, t, n, s=!0) {
        let r = [];
        if (s)
            r = r.concat(t.slice(0)),
            r.push(e[0] / n),
            r = r.concat(e.slice(1));
        else {
            r = r.concat(e[0]);
            const n = t.length;
            for (let s = 0; s < n; ++s)
                r = r.concat([e[s + 1] / t[s], t[s]]);
            r = r.concat(e.slice(n + 1))
        }
        return r
    }
    function _m(e, t, n=!0) {
        const s = [];
        if (n) {
            s.push(t);
            for (let n = t + 1; n < e; ++n)
                n <= 2 * t ? (s.push(n),
                s.push(n - (t + 1))) : s.push(n)
        } else {
            const n = []
              , r = [];
            for (let s = 1; s < e; ++s)
                s >= 2 * t + 1 || s % 2 == 1 ? r.push(s) : n.push(s);
            s.push(...n),
            s.push(0),
            s.push(...r)
        }
        return s
    }
    function Om(e, t, n, s=!0) {
        const r = [];
        s ? r.push(e[0] / n) : r.push(e[0] * n);
        for (let n = 1; n < e.length; ++n)
            n <= t.length ? s ? r.push(t[n - 1] * e[n]) : r.push(e[n] / t[n - 1]) : r.push(e[n]);
        return r
    }
    function Mm(e, t) {
        const n = [0];
        for (let s = 0; s < t; ++s)
            n.push(e[s][0]);
        return n
    }
    function Lm(e, t, n) {
        const s = e.slice(0, 1);
        for (let r = 0; r < n; ++r)
            s.push(e[r + 1] - t[r][0] - t[r][1]);
        return s
    }
    t(Fm, "getReshaped", (()=>Dm)),
    t(Fm, "getPermuted", (()=>_m)),
    t(Fm, "getReshapedPermuted", (()=>Om)),
    t(Fm, "getSliceBeginCoords", (()=>Mm)),
    t(Fm, "getSliceSize", (()=>Lm));
    var zm = {};
    function Bm(e, t) {
        const n = e.shape.length
          , s = t.shape.length;
        if (n < 1)
            throw new Error(`tf.gatherND() expects the input to be rank 1 or higher, but the rank was ${n}.`);
        if (s < 1)
            throw new Error(`tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ${s}.`);
        if ("int32" !== t.dtype)
            throw new Error(`tf.gatherND() expects the indices to be int32 type, but the dtype was ${t.dtype}.`);
        if (t.shape[s - 1] > n)
            throw new Error(`index innermost dimension length must be <= tensor rank; saw: ${t.shape[s - 1]} vs. ${n}`);
        if (0 === v(e.shape))
            throw new Error(`Requested more than 0 entries, but input is empty. Input shape: ${e.shape}.`);
        const r = t.shape
          , a = r[r.length - 1];
        let i = 1;
        for (let e = 0; e < r.length - 1; ++e)
            i *= r[e];
        const o = e.shape
          , l = r.slice();
        l.pop();
        let u = 1;
        for (let e = a; e < n; ++e)
            u *= o[e],
            l.push(o[e]);
        const c = [...j(e.shape).map((e=>e / u)), 1].slice(0, a);
        return [l, i, u, c]
    }
    t(zm, "prepareAndValidate", (()=>Bm));
    var Pm = {};
    t(Pm, "SELU_SCALEALPHA", (()=>Wm)),
    t(Pm, "SELU_SCALE", (()=>Um));
    const Wm = 1.7580993408473768
      , Um = 1.0507009873554805;
    var Vm = {};
    t(Vm, "ERF_P", (()=>Gm)),
    t(Vm, "ERF_A1", (()=>Hm)),
    t(Vm, "ERF_A2", (()=>jm)),
    t(Vm, "ERF_A3", (()=>qm)),
    t(Vm, "ERF_A4", (()=>Km)),
    t(Vm, "ERF_A5", (()=>Xm));
    const Gm = .3275911
      , Hm = .254829592
      , jm = -.284496736
      , qm = 1.421413741
      , Km = -1.453152027
      , Xm = 1.061405429;
    var Ym = {};
    function Zm(e, t) {
        if (e.length !== t.length)
            throw new Error(`Cannot merge real and imag arrays of different lengths. real:${e.length}, imag: ${t.length}.`);
        const n = new Float32Array(2 * e.length);
        for (let s = 0; s < n.length; s += 2)
            n[s] = e[s / 2],
            n[s + 1] = t[s / 2];
        return n
    }
    function Jm(e) {
        const t = new Float32Array(e.length / 2)
          , n = new Float32Array(e.length / 2);
        for (let s = 0; s < e.length; s += 2)
            t[s / 2] = e[s],
            n[s / 2] = e[s + 1];
        return {
            real: t,
            imag: n
        }
    }
    function Qm(e) {
        const t = Math.ceil(e.length / 4)
          , n = new Float32Array(t)
          , s = new Float32Array(t);
        for (let t = 0; t < e.length; t += 4)
            n[Math.floor(t / 4)] = e[t],
            s[Math.floor(t / 4)] = e[t + 1];
        return {
            real: n,
            imag: s
        }
    }
    function eg(e) {
        const t = Math.floor(e.length / 4)
          , n = new Float32Array(t)
          , s = new Float32Array(t);
        for (let t = 2; t < e.length; t += 4)
            n[Math.floor(t / 4)] = e[t],
            s[Math.floor(t / 4)] = e[t + 1];
        return {
            real: n,
            imag: s
        }
    }
    function tg(e, t) {
        return {
            real: e[2 * t],
            imag: e[2 * t + 1]
        }
    }
    function ng(e, t, n, s) {
        e[2 * s] = t,
        e[2 * s + 1] = n
    }
    function sg(e, t) {
        const n = new Float32Array(e / 2)
          , s = new Float32Array(e / 2);
        for (let r = 0; r < Math.ceil(e / 2); r++) {
            const a = (t ? 2 : -2) * Math.PI * (r / e);
            n[r] = Math.cos(a),
            s[r] = Math.sin(a)
        }
        return {
            real: n,
            imag: s
        }
    }
    function rg(e, t, n) {
        const s = (n ? 2 : -2) * Math.PI * (e / t);
        return {
            real: Math.cos(s),
            imag: Math.sin(s)
        }
    }
    t(Ym, "mergeRealAndImagArrays", (()=>Zm)),
    t(Ym, "splitRealAndImagArrays", (()=>Jm)),
    t(Ym, "complexWithEvenIndex", (()=>Qm)),
    t(Ym, "complexWithOddIndex", (()=>eg)),
    t(Ym, "getComplexWithIndex", (()=>tg)),
    t(Ym, "assignToTypedArray", (()=>ng)),
    t(Ym, "exponents", (()=>sg)),
    t(Ym, "exponent", (()=>rg));
    var ag = {};
    t(ag, "decodeEinsumEquation", (()=>lg)),
    t(ag, "getEinsumPermutation", (()=>ug)),
    t(ag, "checkEinsumDimSizes", (()=>cg)),
    t(ag, "getEinsumComputePath", (()=>hg)),
    t(ag, "isIdentityPermutation", (()=>pg));
    const ig = "->"
      , og = /->/g;
    function lg(e, t) {
        const n = ((e = e.replace(/\s/g, "")).length - e.replace(og, "").length) / ig.length;
        if (n < 1)
            throw new Error("Equations without an arrow are not supported.");
        if (n > 1)
            throw new Error('Equation must contain exactly one arrow ("->").');
        const [s,r] = e.split(ig);
        b(-1 === s.indexOf("..."), (()=>'The ellipsis notation ("...") is not supported yet.'));
        const a = s.split(",")
          , i = a.length;
        if (t !== i)
            throw new Error(`Expected ${i} input tensors, received ${t}`);
        if (i > 2)
            throw new Error("Support for more than 2 input tensors is not implemented yet.");
        const o = [];
        for (let e = 0; e < r.length; ++e) {
            const t = r[e];
            if (!a.some((e=>-1 !== e.indexOf(t))))
                throw new Error(`Output subscripts contain the label ${t} not present in the input subscripts.`);
            -1 === o.indexOf(t) && o.push(t)
        }
        for (let e = 0; e < s.length; ++e) {
            const t = s[e];
            -1 === o.indexOf(t) && "," !== t && o.push(t)
        }
        const l = new Array(a.length);
        for (let e = 0; e < i; ++e) {
            if (new Set(a[e].split("")).size !== a[e].length)
                throw new Error(`Found duplicate axes in input component ${a[e]}. Support for duplicate axes in input is not implemented yet.`);
            l[e] = [];
            for (let t = 0; t < a[e].length; ++t)
                l[e].push(o.indexOf(a[e][t]))
        }
        const u = o.length
          , c = [];
        for (let e = r.length; e < u; ++e)
            c.push(e);
        return {
            allDims: o,
            summedDims: c,
            idDims: l
        }
    }
    function ug(e, t) {
        let n = new Array(e);
        n.fill(-1);
        for (let e = 0; e < t.length; ++e)
            n[t[e]] = e;
        const s = [];
        for (let t = 0; t < e; ++t)
            -1 === n[t] && s.push(t);
        return n = n.filter((e=>-1 !== e)),
        {
            permutationIndices: n,
            expandDims: s
        }
    }
    function cg(e, t, n) {
        const s = new Array(e);
        for (let e = 0; e < n.length; ++e) {
            const r = n[e].shape;
            for (let n = 0; n < t[e].length; ++n)
                void 0 === s[t[e][n]] ? s[t[e][n]] = r[n] : b(s[t[e][n]] === r[n], (()=>`Expected dimension ${s[t[e][n]]} at axis ${n} of input shaped ${JSON.stringify(r)}, but got dimension ${r[n]}`))
        }
    }
    function hg(e, t) {
        const n = e
          , s = [];
        let r = 0;
        0 === e.length && n.push(-1),
        r = e.length + 1;
        for (let e = 0; e < r; ++e)
            s.push([]);
        const a = [];
        for (let e = 0; e < n.length; ++e) {
            const r = dg(t, n[e]);
            for (const t of r)
                -1 === a.indexOf(t) && (s[e].push(t),
                a.push(t))
        }
        return {
            path: n,
            steps: s
        }
    }
    function pg(e) {
        return e.every(((e,t)=>e === t))
    }
    function dg(e, t) {
        const n = [];
        for (let s = 0; s < e.length; ++s)
            0 !== e[s].length && -1 === e[s].indexOf(t) && -1 !== t || n.push(s);
        return n
    }
    var fg = {};
    function mg(e, t, n=0) {
        let s = [];
        if ("number" == typeof t)
            b(e.shape[n] % t == 0, (()=>"Number of splits must evenly divide the axis.")),
            s = new Array(t).fill(e.shape[n] / t);
        else {
            b(t.reduce(((e,t)=>(-1 === t && (e += 1),
            e)), 0) <= 1, (()=>"There should be only one negative value in split array."));
            const r = t.indexOf(-1);
            if (-1 !== r) {
                const s = t.reduce(((e,t)=>t > 0 ? e + t : e));
                t[r] = e.shape[n] - s
            }
            b(e.shape[n] === t.reduce(((e,t)=>e + t)), (()=>"The sum of sizes must match the size of the axis dimension.")),
            s = t
        }
        return s
    }
    t(fg, "prepareSplitSize", (()=>mg));
    var gg = {};
    function yg(e) {
        return `Received SparseTensor with denseShape[0] = 0 but\n  indices.shape[0] = ${e}`
    }
    function bg(e, t) {
        return `indices(${e}, 0) is invalid: ${t} < 0`
    }
    function xg(e, t, n) {
        return `indices(${e}, 0) is invalid: ${t} >= ${n}`
    }
    t(gg, "getSparseFillEmptyRowsIndicesDenseShapeMismatch", (()=>yg)),
    t(gg, "getSparseFillEmptyRowsNegativeIndexErrorMessage", (()=>bg)),
    t(gg, "getSparseFillEmptyRowsOutOfRangeIndexErrorMessage", (()=>xg));
    var wg = {};
    function vg(e, t) {
        return `only one output dimension may be -1, not both ${e} and ${t}`
    }
    function kg(e, t) {
        return `size ${e} must be non-negative, not ${t}`
    }
    function Ig() {
        return "reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero"
    }
    function Sg(e, t) {
        return `Input to reshape is a SparseTensor with ${v(e)}\n  dense values, but the requested shape requires a multiple of ${v(t)}. inputShape=${e} outputShape= ${t}`
    }
    function Ng(e, t) {
        return `Input to reshape is a tensor with ${v(e)} dense values, but the requested shape has ${v(t)}. inputShape=${e} outputShape=${t}`
    }
    t(wg, "getSparseReshapeMultipleNegativeOneOutputDimErrorMessage", (()=>vg)),
    t(wg, "getSparseReshapeNegativeOutputDimErrorMessage", (()=>kg)),
    t(wg, "getSparseReshapeEmptyTensorZeroOutputDimErrorMessage", (()=>Ig)),
    t(wg, "getSparseReshapeInputOutputMultipleErrorMessage", (()=>Sg)),
    t(wg, "getSparseReshapeInputOutputMismatchErrorMessage", (()=>Ng));
    var Tg = {};
    function Cg() {
        return "segment ids must be >= 0"
    }
    function $g() {
        return "segment ids are not increasing"
    }
    function Eg(e, t) {
        return `Segment id ${e} out of range [0, ${t}), possibly because segmentIds input is not sorted.`
    }
    function Ag(e, t, n) {
        return `Bad: indices[${e}] == ${t} out of range [0, ${n})`
    }
    function Rg(e) {
        try {
            return e.map((e=>Mr(e)))
        } catch (e) {
            throw new Error(`Failed to decode encoded string bytes into utf-8, error: ${e}`)
        }
    }
    function Fg(e) {
        return e.map((e=>Or(e)))
    }
    t(Tg, "getSparseSegmentReductionNegativeSegmentIdsErrorMessage", (()=>Cg)),
    t(Tg, "getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage", (()=>$g)),
    t(Tg, "getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage", (()=>Eg)),
    t(Tg, "getSparseSegmentReductionIndicesOutOfRangeErrorMessage", (()=>Ag)),
    n(dm, cc),
    n(dm, Nl),
    n(dm, vm),
    n(dm, El),
    n(dm, Kl),
    n(dm, mm),
    n(dm, Am),
    n(dm, Fm),
    n(dm, zm),
    n(dm, Wd),
    n(dm, Pm),
    n(dm, Vm),
    n(dm, _s),
    n(dm, Ym),
    n(dm, ag),
    n(dm, fg),
    n(dm, gg),
    n(dm, wg),
    n(dm, Tg),
    n(dm, {}),
    n(dm, Nm);
    var Dg = {};
    t(Dg, "nonMaxSuppressionV3Impl", (()=>Du)),
    t(Dg, "nonMaxSuppressionV4Impl", (()=>_u)),
    t(Dg, "nonMaxSuppressionV5Impl", (()=>Ou)),
    t(Dg, "whereImpl", (()=>_d));
    const _g = class {
        static sgd(e) {
            return new yf(e)
        }
        static momentum(e, t, n=!1) {
            return new bf(e,t,n)
        }
        static rmsprop(e, t=.9, n=0, s=null, r=!1) {
            return new xf(e,t,n,s,r)
        }
        static adam(e=.001, t=.9, n=.999, s=null) {
            return new mf(e,t,n,s)
        }
        static adadelta(e=.001, t=.95, n=null) {
            return new df(e,t,n)
        }
        static adamax(e=.002, t=.9, n=.999, s=null, r=0) {
            return new gf(e,t,n,s,r)
        }
        static adagrad(e, t=.1) {
            return new ff(e,t)
        }
    }
      , Og = "undefined" != typeof requestAnimationFrame ? requestAnimationFrame : "undefined" != typeof setImmediate ? setImmediate : e=>e();
    /**
 * @license
 * Copyright 2017 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
    function Mg() {
        return new Promise((e=>Og((()=>e()))))
    }
    !function() {
        for (const e of wf)
            hf(e)
    }();
    const Lg = {
        kernelName: Te,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>il(e, tu(Ko(n, "float32"), -1))
            }
        }
    }
      , zg = {
        kernelName: Ce,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>{
                    const t = Ic(Ko(n, "float32"))
                      , s = kc(Yu(wl(1), t));
                    return Ac(al(e, s))
                }
            }
        }
    }
      , Bg = {
        kernelName: $e,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>{
                    const t = kc(Yu(Ic(Ko(n, "float32")), 1));
                    return al(e, t)
                }
            }
        }
    }
      , Pg = {
        kernelName: Ee,
        inputsToSave: ["a", "b"],
        gradFunc: (e,t)=>{
            const [n,s] = t
              , r = $l(n.shape, s.shape);
            return {
                a: ()=>{
                    let t = e;
                    const s = Cl(n.shape, r);
                    return s.length > 0 && (t = nu(t, s)),
                    hl(t, n.shape)
                }
                ,
                b: ()=>{
                    let t = e;
                    const n = Cl(s.shape, r);
                    return n.length > 0 && (t = nu(t, n)),
                    hl(t, s.shape)
                }
            }
        }
    }
      , Wg = {
        kernelName: Ae,
        saveAllInputs: !0,
        gradFunc: (e,t)=>{
            const n = {};
            return t.forEach(((t,s)=>{
                n[s] = ()=>e.clone()
            }
            )),
            n
        }
    }
      , Ug = {
        kernelName: De,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>ml(n)
            }
        }
    }
      , Vg = {
        kernelName: _e,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>ml(n)
            }
        }
    }
      , Gg = {
        kernelName: Oe,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>al(e, kc(Yu(wl(1), Ic(Ko(n, "float32")))))
            }
        }
    }
      , Hg = {
        kernelName: Me,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>{
                    const t = kc(sl(wl(1), Ic(Ko(n, "float32"))));
                    return al(e, t)
                }
            }
        }
    }
      , jg = {
        kernelName: Be,
        inputsToSave: ["a", "b"],
        gradFunc: (e,t)=>{
            const [n,s] = t
              , r = $l(n.shape, s.shape);
            return {
                a: ()=>{
                    const t = sl(Ic(n), Ic(s));
                    let a = il(e, al(s, t));
                    const i = Cl(n.shape, r);
                    return i.length > 0 && (a = nu(a, i)),
                    hl(a, n.shape)
                }
                ,
                b: ()=>{
                    const t = sl(Ic(n), Ic(s));
                    let a = Ac(il(e, al(n, t)));
                    const i = Cl(s.shape, r);
                    return i.length > 0 && (a = nu(a, i)),
                    hl(a, s.shape)
                }
            }
        }
    }
      , qg = {
        kernelName: Le,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>al(e, sl(Ic(Ko(n, "float32")), 1))
            }
        }
    }
      , Kg = {
        kernelName: ze,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>al(e, Yu(wl(1), Ic(Ko(n, "float32"))))
            }
        }
    };
    const Xg = Ma({
        avgPool3dGrad_: function(e, t, n, s, r, a) {
            const i = Da(e, "dy", "avgPool3dGrad")
              , o = Da(t, "input", "avgPool3dGrad");
            let l = i
              , u = o
              , c = !1;
            4 === o.rank && (c = !0,
            l = hl(i, [1, i.shape[0], i.shape[1], i.shape[2], i.shape[3]]),
            u = hl(o, [1, o.shape[0], o.shape[1], o.shape[2], o.shape[3]])),
            b(5 === l.rank, (()=>`Error in avgPool3dGrad: dy must be rank 5 but got rank ${l.rank}.`)),
            b(5 === u.rank, (()=>`Error in avgPool3dGrad: input must be rank 5 but got rank ${u.rank}.`)),
            Gl("avgPool3dGrad", r, a);
            const h = {
                dy: l,
                input: u
            }
              , p = {
                filterSize: n,
                strides: s,
                pad: r,
                dimRoundingMode: a
            }
              , d = ka.runKernel(Ve, h, p);
            return c ? hl(d, [d.shape[1], d.shape[2], d.shape[3], d.shape[4]]) : d
        }
    })
      , Yg = {
        kernelName: Ue,
        inputsToSave: ["x"],
        gradFunc: (e,t,n)=>{
            const [s] = t
              , {filterSize: r, strides: a, pad: i, dimRoundingMode: o} = n;
            return {
                x: ()=>Xg(e, s, r, a, i, o)
            }
        }
    };
    const Zg = Ma({
        avgPoolGrad_: function(e, t, n, s, r) {
            const a = Da(e, "dy", "avgPoolGrad")
              , i = Da(t, "input", "avgPoolGrad");
            b(i.rank === a.rank, (()=>`Rank of input (${i.rank}) does not match rank of dy (${a.rank})`));
            let o = i
              , l = a
              , u = !1;
            3 === i.rank && (u = !0,
            o = hl(i, [1, i.shape[0], i.shape[1], i.shape[2]]),
            l = hl(a, [1, a.shape[0], a.shape[1], a.shape[2]])),
            b(4 === l.rank, (()=>`Error in avgPoolGrad: dy must be rank 4 but got rank ${l.rank}.`)),
            b(4 === o.rank, (()=>`Error in avgPoolGrad: input must be rank 4 but got rank ${o.rank}.`));
            const c = {
                dy: l,
                input: o
            }
              , h = {
                filterSize: n,
                strides: s,
                pad: r
            }
              , p = ka.runKernel(We, c, h);
            return u ? hl(p, [p.shape[1], p.shape[2], p.shape[3]]) : p
        }
    })
      , Jg = {
        kernelName: Pe,
        inputsToSave: ["x"],
        gradFunc: (e,t,n)=>{
            const [s] = t
              , {filterSize: r, strides: a, pad: i} = n;
            return {
                x: ()=>Zg(e, s, r, a, i)
            }
        }
    }
      , Qg = {
        kernelName: Ge,
        inputsToSave: ["a", "b"],
        gradFunc: (e,t,n)=>{
            const [s,r] = t
              , {transposeA: a, transposeB: i} = n;
            return a || i ? !a && i ? {
                a: ()=>pu(e, r, !1, !1),
                b: ()=>pu(e, s, !0, !1)
            } : a && !i ? {
                a: ()=>pu(r, e, !1, !0),
                b: ()=>pu(s, e, !1, !1)
            } : {
                a: ()=>pu(r, e, !0, !0),
                b: ()=>pu(e, s, !0, !0)
            } : {
                a: ()=>pu(e, r, !1, !0),
                b: ()=>pu(s, e, !0, !1)
            }
        }
    }
      , ey = {
        kernelName: He,
        gradFunc: (e,t,n)=>{
            const {blockShape: s, crops: r} = n;
            return {
                x: ()=>Lp(e, s, r)
            }
        }
    }
      , ty = {
        kernelName: "BroadcastTo",
        gradFunc: (e,t,n)=>{
            const s = n
              , r = s.inputShape
              , a = s.shape
              , i = Array.from(a);
            for (let e = r.length - 1; e >= 0; e--)
                if (r[e] === a[e])
                    i[e] = 1;
                else if (1 !== r[e])
                    throw new Error(`broadcastTo(): [${r}] cannot be broadcast to [${a}].`);
            const o = [];
            for (let e = 0; e < i.length; e++)
                i[e] > 1 && o.push(e);
            return {
                x: ()=>nu(e, o, !0)
            }
        }
    }
      , ny = {
        kernelName: Ke,
        gradFunc: e=>({
            x: ()=>e.clone()
        })
    }
      , sy = {
        kernelName: Xe,
        gradFunc: e=>({
            x: ()=>ml(e)
        })
    }
      , ry = {
        kernelName: Ye,
        inputsToSave: ["x"],
        gradFunc: (e,t,n)=>{
            const [s] = t
              , {clipValueMin: r, clipValueMax: a} = n;
            return {
                x: ()=>Qu(rc(sc(s, r), Ku(s, a)), e, ml(e))
            }
        }
    }
      , ay = {
        kernelName: Je,
        inputsToSave: ["x"],
        gradFunc: Lg.gradFunc
    }
      , iy = {
        kernelName: Qe,
        saveAllInputs: !0,
        gradFunc: (e,t,n)=>{
            const s = t.map((e=>e.shape))
              , {axis: r} = n
              , a = R(r, t[0].shape)[0]
              , i = s.map((e=>e[a]));
            return dl(e, i, a).map((e=>()=>e))
        }
    }
      , oy = {
        kernelName: et,
        inputsToSave: ["x", "filter"],
        gradFunc: (e,t,n)=>{
            const [s,r] = t
              , {dilations: a, strides: i, pad: o, dataFormat: l} = n;
            return b(Pl(a), (()=>`Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${a}'`)),
            {
                x: ()=>ql(s.shape, e, r, i, o, l),
                filter: ()=>jl(s, e, r.shape, i, o, l)
            }
        }
    }
      , ly = {
        kernelName: nt,
        inputsToSave: ["dy", "filter"],
        gradFunc: (e,t,n)=>{
            const [s,r] = t
              , {strides: a, pad: i, dataFormat: o, dimRoundingMode: l} = n;
            return {
                dy: ()=>Hl(e, r, a, i, o, 1, l),
                filter: ()=>jl(e, s, r.shape, a, i, o, l)
            }
        }
    };
    const uy = Ma({
        conv3DBackpropFilter_: function(e, t, n, s, r) {
            let a = e;
            4 === e.rank && (a = hl(e, [1, e.shape[0], e.shape[1], e.shape[2], e.shape[3]]));
            let i = t;
            4 === i.rank && (i = hl(t, [1, t.shape[0], t.shape[1], t.shape[2], t.shape[3]])),
            b(5 === a.rank, (()=>`Error in conv3dDerFilter: input must be rank 5, but got shape ${a.shape}.`)),
            b(5 === i.rank, (()=>`Error in conv3dDerFilter: dy must be rank 5, but got shape ${i.shape}.`)),
            b(5 === n.length, (()=>`Error in conv3dDerFilter: filterShape must be length 5, but got ${n}.`)),
            b(a.shape[4] === n[3], (()=>`Error in conv3dDerFilter: depth of input ${a.shape[4]}) must match input depth in filter (${n[3]}.`)),
            b(i.shape[4] === n[4], (()=>`Error in conv3dDerFilter: depth of dy (${i.shape[4]}) must match output depth for filter (${n[4]}).`));
            const o = {
                x: a,
                dy: i
            }
              , l = {
                strides: s,
                pad: r,
                filterShape: n
            };
            return ka.runKernel(rt, o, l)
        }
    })
      , cy = {
        kernelName: st,
        inputsToSave: ["x", "filter"],
        gradFunc: (e,t,n)=>{
            const {dilations: s, strides: r, pad: a} = n;
            b(Pl(s), (()=>`Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${s}'`));
            const [i,o] = t;
            return {
                x: ()=>zh(i.shape, e, o, r, a),
                filter: ()=>uy(i, e, o.shape, r, a)
            }
        }
    }
      , hy = {
        kernelName: it,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>il(Ac(md(Ko(n, "float32"))), e)
            }
        }
    }
      , py = {
        kernelName: ot,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>il(gd(Ko(n, "float32")), e)
            }
        }
    }
      , dy = {
        kernelName: ut,
        inputsToSave: ["x"],
        gradFunc: (e,t,n)=>{
            const [s] = t
              , {axis: r, exclusive: a, reverse: i} = n;
            return {
                x: ()=>{
                    const t = gc([r], s.rank);
                    let n = Vh(e, r, a, !i);
                    return null != t && (n = Fc(n, t)),
                    n
                }
            }
        }
    }
      , fy = {
        kernelName: dt,
        inputsToSave: ["x", "filter"],
        gradFunc: (e,t,n)=>{
            const {dilations: s, strides: r, pad: a, dimRoundingMode: i} = n
              , o = null == s ? [1, 1] : s;
            b(Pl(o), (()=>`Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '${o}'`));
            const [l,u] = t;
            return b(4 === l.rank, (()=>`Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank ${l.rank}.`)),
            b(4 === u.rank, (()=>`Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank ${u.rank}.`)),
            b(l.shape[3] === u.shape[2], (()=>`Error in gradient of depthwiseConv2d: number of input channels (${l.shape[3]}) must match the inChannels dimension in filter ${u.shape[2]}.`)),
            b(Wl(r, o), (()=>`Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides ${r} and dilations '${o}'.`)),
            Gl("depthwiseConv2d", a, i),
            {
                x: ()=>cu(l.shape, e, u, r, a, o, i),
                filter: ()=>uu(l, e, u.shape, r, a, o, i)
            }
        }
    }
      , my = {
        kernelName: yt,
        inputsToSave: ["x", "filter"],
        gradFunc: (e,t,n)=>{
            const [s,r] = t
              , a = {
                x: s,
                filter: r,
                dy: e
            }
              , i = {
                x: s,
                filter: r,
                dy: e
            };
            return {
                x: ()=>ka.runKernel(bt, a, n),
                filter: ()=>ka.runKernel(xt, i, n)
            }
        }
    }
      , gy = {
        kernelName: kt,
        outputsToSave: [!0],
        gradFunc: (e,t)=>{
            const [n] = t
              , s = {
                dy: e,
                y: n
            };
            return {
                x: ()=>ka.runKernel(It, s)
            }
        }
    }
      , yy = {
        kernelName: St,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t
              , s = il(Xc(Ac(Ic(n))), 2 / Math.sqrt(Math.PI));
            return {
                x: ()=>il(e, s)
            }
        }
    }
      , by = {
        kernelName: Tt,
        outputsToSave: [!0],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>il(e, n)
            }
        }
    }
      , xy = {
        kernelName: Ct,
        inputsToSave: ["input"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                input: ()=>hl(e, n.shape)
            }
        }
    }
      , wy = {
        kernelName: $t,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>il(e, Xc(n))
            }
        }
    }
      , vy = {
        kernelName: Ft,
        gradFunc: e=>({
            x: ()=>ml(e)
        })
    }
      , ky = {
        kernelName: Dt,
        inputsToSave: ["a", "b"],
        gradFunc: (e,t)=>{
            const [n,s] = t
              , r = $l(n.shape, s.shape);
            return {
                a: ()=>{
                    const t = al(e, Ko(s, "float32"))
                      , a = Cl(n.shape, r);
                    return a.length > 0 ? hl(nu(t, a), n.shape) : t
                }
                ,
                b: ()=>{
                    let t = il(e, Ko(n, "float32"));
                    const a = Cl(s.shape, r);
                    a.length > 0 && (t = hl(nu(t, a), s.shape));
                    const i = Ic(s);
                    return Ac(al(t, Ko(i, "float32")))
                }
            }
        }
    }
      , Iy = {
        kernelName: _t,
        inputsToSave: ["x", "mean", "variance", "scale"],
        gradFunc: (e,t,n)=>{
            const {varianceEpsilon: s} = n
              , [r,a,i,o] = t
              , l = null == o ? wl(1) : o
              , u = Cl(a.shape, r.shape)
              , c = [];
            if (1 === a.rank) {
                for (let e = 0; e < r.shape.length - 1; ++e)
                    c.push(r.shape[e]);
                c.push(1)
            }
            const h = Yu(r, a)
              , p = il(e, l)
              , d = cd(sl(i, wl(s)))
              , f = il(il(il(d, d), d), wl(-.5));
            return {
                x: ()=>1 === a.rank ? hl(il(il(e, Tu(hl(d, [1, 1, 1, a.shape[0]]), c)), l), r.shape) : hl(il(il(e, d), l), r.shape),
                mean: ()=>{
                    let e = il(il(d, wl(-1)), p);
                    return 1 === a.rank && (e = nu(e, u)),
                    hl(e, a.shape)
                }
                ,
                variance: ()=>{
                    let e = il(il(f, h), p);
                    return 1 === a.rank && (e = nu(e, u)),
                    hl(e, a.shape)
                }
                ,
                scale: ()=>{
                    const t = il(h, d);
                    let n = il(e, t);
                    return 1 === a.rank && (n = nu(n, u)),
                    hl(n, a.shape)
                }
                ,
                offset: ()=>{
                    let t = e;
                    return 1 === a.rank && (t = nu(t, u)),
                    hl(t, a.shape)
                }
            }
        }
    }
      , Sy = {
        kernelName: Ot,
        inputsToSave: ["x", "indices"],
        gradFunc: (e,t,n)=>{
            const [s,r] = t
              , {axis: a} = n
              , i = R(a, s.shape)[0];
            return {
                x: ()=>{
                    const t = s.shape
                      , n = r.size
                      , o = t.slice(0, i)
                      , l = o.length
                      , u = t.slice(a, t.length).slice(1)
                      , c = u.length
                      , h = Ny(0, l)
                      , p = Ny(l + 1, l + 1 + c)
                      , d = Ty([o, [n], u])
                      , f = hl(e, d)
                      , m = hl(r, [n])
                      , g = Ty([[l], h, p])
                      , y = Fc(f, g);
                    let b = Rd(y, m, s.shape[i]);
                    const x = yc(g);
                    return b = Fc(b, x),
                    b
                }
                ,
                indices: ()=>r
            }
        }
    };
    function Ny(e, t) {
        const n = [];
        for (let s = e; s < t; ++s)
            n.push(s);
        return n
    }
    function Ty(e) {
        const t = [];
        for (let n = 0; n < e.length; ++n)
            for (let s = 0; s < e[n].length; ++s)
                t.push(e[n][s]);
        return t
    }
    const Cy = {
        kernelName: zt,
        inputsToSave: ["a", "b"],
        gradFunc: (e,t)=>{
            const [n,s] = t;
            return {
                a: ()=>ml(n),
                b: ()=>ml(s)
            }
        }
    }
      , $y = {
        kernelName: Bt,
        gradFunc: e=>({
            x: ()=>Ko(e, "float32")
        })
    }
      , Ey = {
        kernelName: Ut,
        gradFunc: e=>({
            x: ()=>ml(e)
        })
    }
      , Ay = {
        kernelName: Vt,
        gradFunc: e=>({
            x: ()=>ml(e)
        })
    }
      , Ry = {
        kernelName: Gt,
        gradFunc: e=>({
            x: ()=>ml(e)
        })
    }
      , Fy = {
        kernelName: Ht,
        inputsToSave: ["x"],
        gradFunc: (e,t,n)=>{
            const [s] = t
              , {alpha: r} = n
              , a = Xu(s, 0);
            return {
                x: ()=>Qu(a, e, il(e, r))
            }
        }
    }
      , Dy = {
        kernelName: Yt,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>al(e, sl(n, 1))
            }
        }
    }
      , _y = {
        kernelName: Xt,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>al(e, Ko(n, "float32"))
            }
        }
    }
      , Oy = {
        kernelName: "LogSoftmax",
        inputsToSave: [],
        outputsToSave: [!0],
        gradFunc: (e,t,n)=>{
            const [s] = t
              , {axis: r} = n;
            return {
                logits: ()=>{
                    const t = Xc(s);
                    return Yu(e, il(nu(e, r, !0), t))
                }
            }
        }
    };
    const My = Ma({
        localResponseNormalizationBackprop_: function(e, t, n, s=5, r=1, a=1, i=.5) {
            const o = {
                x: e,
                y: t,
                dy: n
            }
              , l = {
                depthRadius: s,
                bias: r,
                alpha: a,
                beta: i
            };
            return ka.runKernel(tn, o, l)
        }
    })
      , Ly = {
        kernelName: en,
        inputsToSave: ["x"],
        outputsToSave: [!0],
        gradFunc: (e,t,n)=>{
            const [s,r] = t
              , {depthRadius: a, bias: i, alpha: o, beta: l} = n;
            return {
                x: ()=>My(s, r, e, a, i, o, l)
            }
        }
    };
    function zy(e, t, n, s) {
        return t.rank < n.rank && (t = hl(t, fc(t.shape, s))),
        e.rank < n.rank && (e = hl(e, fc(e.shape, s))),
        {
            x: ()=>il(e, Ko(Kh(n, t), e.dtype))
        }
    }
    const By = {
        kernelName: nn,
        inputsToSave: ["x"],
        outputsToSave: [!0],
        gradFunc: (e,t,n)=>{
            const s = n
              , {reductionIndices: r} = s
              , a = t[0]
              , i = zy(e, t[1], a, R(r, a.shape));
            return {
                x: ()=>i.x()
            }
        }
    }
      , Py = {
        kernelName: sn,
        inputsToSave: ["a", "b"],
        gradFunc: (e,t)=>{
            const [n,s] = t;
            return {
                a: ()=>il(e, Ko(sc(n, s), "float32")),
                b: ()=>il(e, Ko(ip(n, s), "float32"))
            }
        }
    };
    const Wy = Ma({
        maxPool3dGrad_: function(e, t, n, s, r, a, i) {
            const o = Da(e, "dy", "maxPool3dGrad")
              , l = Da(t, "input", "maxPool3dGrad")
              , u = Da(n, "output", "maxPool3dGrad");
            let c = o
              , h = l
              , p = u
              , d = !1;
            4 === l.rank && (d = !0,
            c = hl(o, [1, o.shape[0], o.shape[1], o.shape[2], o.shape[3]]),
            h = hl(l, [1, l.shape[0], l.shape[1], l.shape[2], l.shape[3]]),
            p = hl(u, [1, u.shape[0], u.shape[1], u.shape[2], u.shape[3]])),
            b(5 === c.rank, (()=>`Error in maxPool3dGrad: dy must be rank 5 but got rank ${c.rank}.`)),
            b(5 === h.rank, (()=>`Error in maxPool3dGrad: input must be rank 5 but got rank ${h.rank}.`)),
            b(5 === p.rank, (()=>`Error in maxPool3dGrad: output must be rank 5 but got rank ${p.rank}.`)),
            Gl("maxPool3dGrad", a, i);
            const f = {
                dy: c,
                input: h,
                output: p
            }
              , m = {
                filterSize: s,
                strides: r,
                pad: a,
                dimRoundingMode: i
            }
              , g = ka.runKernel(ln, f, m);
            return d ? hl(g, [g.shape[1], g.shape[2], g.shape[3], g.shape[4]]) : g
        }
    })
      , Uy = {
        kernelName: on,
        inputsToSave: ["x"],
        outputsToSave: [!0],
        gradFunc: (e,t,n)=>{
            const [s,r] = t
              , {filterSize: a, strides: i, pad: o, dimRoundingMode: l} = n;
            return {
                x: ()=>Wy(e, s, r, a, i, o, l)
            }
        }
    };
    const Vy = Ma({
        maxPoolGrad_: function(e, t, n, s, r, a, i) {
            const o = Da(e, "dy", "maxPoolGrad")
              , l = Da(t, "input", "maxPoolGrad")
              , u = Da(n, "output", "maxPoolGrad");
            b(l.rank === o.rank, (()=>`Rank of input (${l.rank}) does not match rank of dy (${o.rank})`)),
            b(4 === o.rank, (()=>`Error in maxPoolGrad: dy must be rank 4 but got rank ${o.rank}.`)),
            b(4 === l.rank, (()=>`Error in maxPoolGrad: input must be rank 4 but got rank ${l.rank}.`)),
            Gl("maxPoolGrad", a, i);
            const c = {
                dy: o,
                input: l,
                output: u
            }
              , h = {
                filterSize: s,
                strides: r,
                pad: a,
                dimRoundingMode: i
            };
            return ka.runKernel(an, c, h)
        }
    })
      , Gy = {
        kernelName: Nn,
        inputsToSave: ["x"],
        gradFunc: (e,t,n)=>{
            const s = t[0]
              , {paddings: r} = n
              , a = r.map((e=>e[0]));
            return {
                x: ()=>pl(e, a, s.shape)
            }
        }
    };
    function Hy(e, t, n) {
        const s = e.shape.length
          , r = s - n.length
          , a = dm.getAxesPermutation(n, s);
        let i = e;
        null != a && (i = Fc(e, a));
        const o = i.shape.slice()
          , l = o.splice(s - n.length, n.length).reduce(((e,t)=>e * t), 1);
        o.push(l);
        let u = function(e, t, n) {
            const s = e.shape.slice();
            s[n] = 1;
            const r = hl(t, s)
              , a = Uh(e, n, !0, !1)
              , i = Uh(e, n, !0, !0)
              , o = il(a, i);
            return il(r, o)
        }(i.reshape(o), t, r);
        if (u = u.reshape(i.shape),
        null != a) {
            const e = dm.getUndoAxesPermutation(a);
            u = Fc(u, e)
        }
        return u
    }
    const jy = {
        kernelName: ss,
        gradFunc: (e,t,n)=>{
            const {blockShape: s, paddings: r} = n;
            return {
                x: ()=>Ih(e, s, r)
            }
        }
    }
      , qy = {
        kernelName: rs,
        gradFunc: (e,t,n)=>{
            const {axis: s} = n;
            return {
                x: ()=>ll(e, s)
            }
        }
    };
    const Ky = [Lg, zg, Bg, Pg, Wg, Ug, Vg, Gg, Hg, jg, qg, Kg, Yg, Jg, Qg, ey, ty, ny, sy, ry, ay, iy, ly, oy, cy, hy, py, dy, fy, my, {
        kernelName: wt,
        inputsToSave: ["a", "b"],
        gradFunc: (e,t)=>{
            const [n,s] = t
              , r = $l(n.shape, s.shape);
            return {
                a: ()=>{
                    const t = al(e, Ko(s, "float32"))
                      , a = Cl(n.shape, r);
                    return a.length > 0 ? hl(nu(t, a), n.shape) : t
                }
                ,
                b: ()=>{
                    let t = il(e, Ko(n, "float32"));
                    const a = Cl(s.shape, r);
                    a.length > 0 && (t = hl(nu(t, a), s.shape));
                    const i = Ic(s);
                    return Ac(al(t, Ko(i, "float32")))
                }
            }
        }
    }, gy, yy, by, xy, wy, ky, vy, Iy, Sy, Cy, $y, Ey, Ay, Ry, Fy, Dy, _y, Oy, Ly, By, By, Py, Uy, {
        kernelName: rn,
        inputsToSave: ["x"],
        outputsToSave: [!0],
        gradFunc: (e,t,n)=>{
            const [s,r] = t
              , {filterSize: a, strides: i, pad: o} = n;
            return {
                x: ()=>Vy(e, s, r, a, i, o)
            }
        }
    }, {
        kernelName: cn,
        inputsToSave: ["x"],
        gradFunc: (e,t,n)=>{
            const [s] = t
              , {axis: r} = n
              , a = R(r, s.shape)
              , i = v(dc(s.shape, a)[1]);
            return {
                x: ()=>{
                    const t = s.shape.slice();
                    a.forEach((e=>{
                        t[e] = 1
                    }
                    ));
                    const n = hl(e, t);
                    return al(il(n, zc(s.shape, "float32")), i)
                }
            }
        }
    }, {
        kernelName: hn,
        inputsToSave: ["x"],
        outputsToSave: [!0],
        gradFunc: (e,t,n)=>{
            const s = n
              , {axis: r} = s
              , [a,i] = t
              , o = zy(e, i, a, R(r, a.shape));
            return {
                x: ()=>o.x()
            }
        }
    }, {
        kernelName: pn,
        inputsToSave: ["a", "b"],
        gradFunc: (e,t)=>{
            const [n,s] = t;
            return {
                a: ()=>il(e, Ko(Ku(n, s), "float32")),
                b: ()=>il(e, Ko(Xu(n, s), "float32"))
            }
        }
    }, {
        kernelName: dn,
        inputsToSave: ["x"],
        gradFunc: (e,t,n)=>{
            const s = t[0]
              , {paddings: r} = n
              , a = r.map((e=>e[0]));
            return {
                x: ()=>pl(e, a, s.shape)
            }
        }
    }, {
        kernelName: fn,
        inputsToSave: ["a", "b"],
        gradFunc: (e,t)=>{
            const [n,s] = t
              , r = $l(n.shape, s.shape);
            return {
                a: ()=>{
                    const t = Cl(n.shape, r);
                    return t.length > 0 ? hl(nu(e, t), n.shape) : e
                }
                ,
                b: ()=>{
                    const t = il(e, Ac(tp(al(n, s))))
                      , a = Cl(s.shape, r);
                    return a.length > 0 ? hl(nu(t, a), s.shape) : t
                }
            }
        }
    }, {
        kernelName: gn,
        inputsToSave: ["a", "b"],
        gradFunc: (e,t)=>{
            const [n,s] = t
              , r = $l(n.shape, s.shape);
            return {
                a: ()=>{
                    const t = il(e, Ko(s, "float32"))
                      , a = Cl(n.shape, r);
                    return a.length > 0 ? hl(nu(t, a), n.shape) : t
                }
                ,
                b: ()=>{
                    const t = il(e, Ko(n, "float32"))
                      , a = Cl(s.shape, r);
                    return a.length > 0 ? hl(nu(t, a), s.shape) : t
                }
            }
        }
    }, {
        kernelName: yn,
        gradFunc: e=>({
            x: ()=>Ac(e)
        })
    }, {
        kernelName: In,
        inputsToSave: ["indices"],
        gradFunc: (e,t)=>{
            const n = t[0];
            return {
                indices: ()=>fl(n.shape, "float32")
            }
        }
    }, {
        kernelName: kn,
        gradFunc: e=>({
            x: ()=>ml(e)
        })
    }, {
        kernelName: Sn,
        saveAllInputs: !0,
        gradFunc: (e,t,n)=>{
            const {axis: s} = n;
            return ic(e, s).map((e=>()=>e))
        }
    }, Gy, Gy, {
        kernelName: Tn,
        inputsToSave: ["a", "b"],
        outputsToSave: [!0],
        gradFunc: (e,t)=>{
            const [n,s,r] = t
              , a = n
              , i = s
              , o = $l(a.shape, i.shape);
            return {
                a: ()=>{
                    const t = Ko(i, "float32");
                    let n = il(e, il(t, vc(a, Yu(t, wl(1)))));
                    const s = Cl(a.shape, o);
                    return s.length > 0 && (n = nu(n, s)),
                    hl(n, a.shape)
                }
                ,
                b: ()=>{
                    const t = Xu(a, 0)
                      , n = Qu(t, Hc(a), ml(a));
                    let s = il(e, il(r, n));
                    const l = Cl(i.shape, o);
                    return l.length > 0 && (s = nu(s, l)),
                    hl(s, i.shape)
                }
            }
        }
    }, {
        kernelName: Cn,
        inputsToSave: ["x", "alpha"],
        gradFunc: (e,t)=>{
            const [n,s] = t
              , r = Xu(n, 0);
            return {
                x: ()=>Qu(r, e, il(e, s)),
                alpha: ()=>{
                    let t = Qu(r, ml(e), il(e, n));
                    const a = Cl(s.shape, e.shape);
                    return a.length > 0 && (t = nu(t, a)),
                    hl(t, s.shape)
                }
            }
        }
    }, {
        kernelName: $n,
        inputsToSave: ["x"],
        gradFunc: (e,t,n)=>{
            const [s] = t
              , {axis: r} = n;
            let a = [];
            return a = null == r ? s.shape.map(((e,t)=>t)) : "number" == typeof r ? [r] : r,
            {
                x: ()=>Hy(s, e, a)
            }
        }
    }, {
        kernelName: _n,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>al(e, Ac(Ic(n)))
            }
        }
    }, {
        kernelName: Wn,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t
              , s = il(Ku(n, 6), tu(n));
            return {
                x: ()=>il(e, Ko(s, "float32"))
            }
        }
    }, {
        kernelName: On,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>il(e, Ko(tu(n), "float32"))
            }
        }
    }, {
        kernelName: Mn,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>hl(e, n.shape)
            }
        }
    }, {
        kernelName: Bn,
        inputsToSave: ["images"],
        gradFunc: (e,t,n)=>{
            const [s] = t
              , r = {
                dy: e,
                images: s
            };
            return {
                images: ()=>ka.runKernel(Pn, r, n)
            }
        }
    }, {
        kernelName: Ln,
        inputsToSave: ["images"],
        gradFunc: (e,t,n)=>{
            const [s] = t
              , r = {
                dy: e,
                images: s
            };
            return {
                images: ()=>ka.runKernel(zn, r, n)
            }
        }
    }, {
        kernelName: Un,
        gradFunc: (e,t,n)=>{
            const {dims: s} = n
              , r = R(s, e.shape);
            return {
                x: ()=>xl(e, r)
            }
        }
    }, {
        kernelName: Vn,
        gradFunc: e=>({
            x: ()=>ml(e)
        })
    }, {
        kernelName: Gn,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>Ac(al(e, il(vc(n, 1.5), 2)))
            }
        }
    }, {
        kernelName: qn,
        inputsToSave: ["condition"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                condition: ()=>Ko(ml(n), "float32"),
                t: ()=>il(e, Ko(n, e.dtype)),
                e: ()=>il(e, Ko(pp(n), e.dtype))
            }
        }
    }, {
        kernelName: Kn,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>{
                    const t = Xu(n, wl(0))
                      , s = wl(Wm)
                      , r = wl(Um)
                      , a = il(e, r)
                      , i = il(il(e, s), Xc(Ko(n, "float32")));
                    return Qu(t, a, i)
                }
            }
        }
    }, {
        kernelName: Qn,
        outputsToSave: [!0],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>il(e, il(n, Yu(wl(1), n)))
            }
        }
    }, {
        kernelName: Jn,
        gradFunc: e=>({
            x: ()=>ml(e)
        })
    }, {
        kernelName: Yn,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>il(Ph(Ko(n, "float32")), e)
            }
        }
    }, {
        kernelName: Zn,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>il(Wh(Ko(n, "float32")), e)
            }
        }
    }, {
        kernelName: Xn,
        inputsToSave: ["x"],
        gradFunc: (e,t,n)=>{
            const [s] = t
              , {begin: r, size: a} = n
              , i = s.shape
              , [o,l] = cm(s, r, a)
              , u = [];
            for (let t = 0; t < e.rank; t++)
                u.push([o[t], i[t] - o[t] - l[t]]);
            return {
                x: ()=>Fp(e, u)
            }
        }
    }, {
        kernelName: as,
        outputsToSave: [!0],
        gradFunc: (e,t,n)=>{
            const [s] = t
              , {dim: r} = n
              , a = il(e, s);
            return {
                logits: ()=>Yu(a, il(nu(a, [r], true), s))
            }
        }
    }, {
        kernelName: es,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>il(e, eu(n))
            }
        }
    }, jy, jy, qy, qy, {
        kernelName: ts,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>al(e, il(kc(Ko(n, "float32")), 2))
            }
        }
    }, {
        kernelName: hs,
        inputsToSave: ["a", "b"],
        gradFunc: (e,t)=>{
            const [n,s] = t
              , r = wl(2);
            return {
                a: ()=>il(e, il(r, Yu(n, s))),
                b: ()=>il(e, il(r, Yu(s, n)))
            }
        }
    }, {
        kernelName: ps,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>il(e, il(Ko(n, "float32"), 2))
            }
        }
    }, {
        kernelName: $s,
        gradFunc: e=>({
            x: ()=>ml(e)
        })
    }, {
        kernelName: ys,
        inputsToSave: ["a", "b"],
        gradFunc: (e,t)=>{
            const [n,s] = t
              , r = $l(n.shape, s.shape);
            return {
                a: ()=>{
                    let t = e;
                    const s = Cl(n.shape, r);
                    return s.length > 0 && (t = nu(t, s)),
                    hl(t, n.shape)
                }
                ,
                b: ()=>{
                    let t = e;
                    const n = Cl(s.shape, r);
                    return n.length > 0 && (t = nu(t, n)),
                    hl(Ac(t), s.shape)
                }
            }
        }
    }, {
        kernelName: ns,
        inputsToSave: ["x"],
        gradFunc: (e,t,n)=>{
            const [s] = t
              , r = s.shape.slice()
              , {axis: a} = n;
            R(a, s.shape).forEach((e=>{
                r[e] = 1
            }
            ));
            const i = hl(e, r)
              , o = il(i, zc(s.shape, "float32"));
            return {
                x: ()=>o
            }
        }
    }, {
        kernelName: bs,
        inputsToSave: ["x"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>al(e, Ic(Ph(n)))
            }
        }
    }, {
        kernelName: xs,
        outputsToSave: [!0],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>il(Yu(wl(1), Ic(n)), e)
            }
        }
    }, {
        kernelName: ws,
        inputsToSave: ["x"],
        gradFunc: (e,t,n)=>{
            const [s] = t
              , {reps: r} = n;
            return {
                x: ()=>{
                    let t = ml(s);
                    if (1 === s.rank)
                        for (let n = 0; n < r[0]; ++n)
                            t = sl(t, pl(e, [n * s.shape[0]], [s.shape[0]]));
                    else if (2 === s.rank)
                        for (let n = 0; n < r[0]; ++n)
                            for (let a = 0; a < r[1]; ++a)
                                t = sl(t, pl(e, [n * s.shape[0], a * s.shape[1]], [s.shape[0], s.shape[1]]));
                    else if (3 === s.rank)
                        for (let n = 0; n < r[0]; ++n)
                            for (let a = 0; a < r[1]; ++a)
                                for (let i = 0; i < r[2]; ++i)
                                    t = sl(t, pl(e, [n * s.shape[0], a * s.shape[1], i * s.shape[2]], [s.shape[0], s.shape[1], s.shape[2]]));
                    else {
                        if (4 !== s.rank)
                            throw new Error(`Gradient for tile operation is not implemented for rank-${s.rank} tensors yet.`);
                        for (let n = 0; n < r[0]; ++n)
                            for (let a = 0; a < r[1]; ++a)
                                for (let i = 0; i < r[2]; ++i)
                                    for (let o = 0; o < r[3]; ++o)
                                        t = sl(t, pl(e, [n * s.shape[0], a * s.shape[1], i * s.shape[2], o * s.shape[3]], [s.shape[0], s.shape[1], s.shape[2], s.shape[3]]))
                    }
                    return t
                }
            }
        }
    }, {
        kernelName: Is,
        gradFunc: (e,t,n)=>{
            const s = n
              , {perm: r} = s
              , a = yc(r);
            return {
                x: ()=>Fc(e, a)
            }
        }
    }, {
        kernelName: Ns,
        gradFunc: (e,t,n)=>{
            const s = n
              , {axis: r} = s;
            return {
                value: ()=>ac(e, r)
            }
        }
    }, {
        kernelName: Ts,
        inputsToSave: ["segmentIds"],
        gradFunc: (e,t)=>{
            const [n] = t;
            return {
                x: ()=>function(e, t) {
                    const n = kp(t, ml(t))
                      , s = np(e, n);
                    let r = sc(t, wl(0, "int32"));
                    const a = s.rank - r.rank;
                    for (let e = 0; e < a; ++e)
                        r = $c(r, e + 1);
                    r = rc(r, zc(s.shape, "bool"));
                    const i = ml(s);
                    return Qu(r, s, i)
                }(e, n)
            }
        }
    }, {
        kernelName: Cs,
        gradFunc: e=>({
            x: ()=>ml(e)
        })
    }];
    for (const e of Ky)
        Vs(e);
    function Xy(e, t, n=new Map, s=new Set) {
        if (null == e)
            return null;
        if ("function" == typeof Blob && e instanceof Blob)
            return e.slice();
        if (s.has(e))
            throw new Error("Circular references are not supported.");
        if (n.has(e))
            return n.get(e);
        const r = t(e);
        if (r.recurse && null !== r.value)
            throw new Error("A deep map function may not return both a value and recurse=true.");
        if (r.recurse) {
            if (Qy(e)) {
                const r = Array.isArray(e) ? [] : {};
                s.add(e);
                for (const a in e) {
                    const i = Xy(e[a], t, n, s);
                    r[a] = i
                }
                return s.delete(e),
                e.__proto__ && (r.__proto__ = e.__proto__),
                r
            }
            throw new Error(`Can't recurse into non-iterable type: ${e}`)
        }
        return n.set(e, r.value),
        r.value
    }
    function Yy(e, t=Jy) {
        return Zy(e, t)
    }
    function Zy(e, t, n=new Set) {
        const s = e[0];
        if (n.has(s))
            throw new Error("Circular references are not supported.");
        const r = t(e);
        if (r.recurse && null !== r.value)
            throw new Error("A deep zip function may not return both a value and recurse=true.");
        if (r.recurse) {
            if (Qy(s)) {
                const r = Array.isArray(s) ? [] : {};
                n.add(s);
                for (const a in s) {
                    const s = Zy(e.map((e=>e[a])), t, n);
                    r[a] = s
                }
                return n.delete(s),
                r
            }
            throw new Error(`Can't recurse into non-iterable type: ${s}`)
        }
        return r.value
    }
    function Jy(e) {
        return null === e ? null : Qy(e[0]) ? {
            value: null,
            recurse: !0
        } : {
            value: e,
            recurse: !1
        }
    }
    function Qy(e) {
        let t = !1;
        if (ie().get("IS_BROWSER"))
            t = e instanceof TextDecoder;
        else {
            const {StringDecoder: n} = a("foUwZ");
            t = e instanceof n
        }
        return null != e && !ArrayBuffer.isView(e) && (Array.isArray(e) || "object" == typeof e && !(e instanceof Zr) && !(e instanceof Promise) && !t)
    }
    function eb(e) {
        return Xy(e, tb)
    }
    function tb(e) {
        return e instanceof Zr ? {
            value: e.clone(),
            recurse: !1
        } : Qy(e) ? {
            value: null,
            recurse: !0
        } : {
            value: e,
            recurse: !1
        }
    }
    Jr().prototype.abs = function() {
        return this.throwIfDisposed(),
        uc(this)
    }
    ,
    Jr().prototype.acos = function() {
        return this.throwIfDisposed(),
        oh(this)
    }
    ,
    Jr().prototype.acosh = function() {
        return this.throwIfDisposed(),
        lh(this)
    }
    ,
    Jr().prototype.add = function(e) {
        return this.throwIfDisposed(),
        sl(this, e)
    }
    ,
    Jr().prototype.all = function(e, t) {
        return this.throwIfDisposed(),
        ch(this, e, t)
    }
    ,
    Jr().prototype.any = function(e, t) {
        return this.throwIfDisposed(),
        hh(this, e, t)
    }
    ,
    Jr().prototype.argMax = function(e) {
        return this.throwIfDisposed(),
        ph(this, e)
    }
    ,
    Jr().prototype.argMin = function(e) {
        return this.throwIfDisposed(),
        dh(this, e)
    }
    ,
    Jr().prototype.asScalar = function() {
        return this.throwIfDisposed(),
        b(1 === this.size, (()=>"The array must have only 1 element.")),
        hl(this, [])
    }
    ,
    Jr().prototype.asType = function(e) {
        return this.throwIfDisposed(),
        Ko(this, e)
    }
    ,
    Jr().prototype.as1D = function() {
        return this.throwIfDisposed(),
        hl(this, [this.size])
    }
    ,
    Jr().prototype.as2D = function(e, t) {
        return this.throwIfDisposed(),
        hl(this, [e, t])
    }
    ,
    Jr().prototype.as3D = function(e, t, n) {
        return this.throwIfDisposed(),
        hl(this, [e, t, n])
    }
    ,
    Jr().prototype.as4D = function(e, t, n, s) {
        return this.throwIfDisposed(),
        hl(this, [e, t, n, s])
    }
    ,
    Jr().prototype.as5D = function(e, t, n, s, r) {
        return this.throwIfDisposed(),
        hl(this, [e, t, n, s, r])
    }
    ,
    Jr().prototype.asin = function() {
        return this.throwIfDisposed(),
        fh(this)
    }
    ,
    Jr().prototype.asinh = function() {
        return this.throwIfDisposed(),
        mh(this)
    }
    ,
    Jr().prototype.atan = function() {
        return this.throwIfDisposed(),
        gh(this)
    }
    ,
    Jr().prototype.atan2 = function(e) {
        return this.throwIfDisposed(),
        yh(this, e)
    }
    ,
    Jr().prototype.atanh = function() {
        return this.throwIfDisposed(),
        bh(this)
    }
    ,
    Jr().prototype.avgPool = function(e, t, n, s) {
        return this.throwIfDisposed(),
        xh(this, e, t, n, s)
    }
    ,
    Jr().prototype.batchToSpaceND = function(e, t) {
        return this.throwIfDisposed(),
        Ih(this, e, t)
    }
    ,
    Jr().prototype.batchNorm = function(e, t, n, s, r) {
        return this.throwIfDisposed(),
        Sh(this, e, t, n, s, r)
    }
    ,
    Jr().prototype.broadcastTo = function(e) {
        return this.throwIfDisposed(),
        Ju(this, e)
    }
    ,
    Jr().prototype.cast = function(e) {
        return this.throwIfDisposed(),
        Ko(this, e)
    }
    ,
    Jr().prototype.ceil = function() {
        return this.throwIfDisposed(),
        Eh(this)
    }
    ,
    Jr().prototype.clipByValue = function(e, t) {
        return this.throwIfDisposed(),
        Ah(this, e, t)
    }
    ,
    Jr().prototype.concat = function(e, t) {
        return this.throwIfDisposed(),
        e instanceof Zr && (e = [e]),
        ll([this, ...e], t)
    }
    ,
    Jr().prototype.conv1d = function(e, t, n, s, r, a) {
        return this.throwIfDisposed(),
        Oh(this, e, t, n, s, r, a)
    }
    ,
    Jr().prototype.conv2dTranspose = function(e, t, n, s, r) {
        return this.throwIfDisposed(),
        Mh(this, e, t, n, s, r)
    }
    ,
    Jr().prototype.conv2d = function(e, t, n, s, r, a) {
        return this.throwIfDisposed(),
        Hl(this, e, t, n, s, r, a)
    }
    ,
    Jr().prototype.cos = function() {
        return this.throwIfDisposed(),
        Ph(this)
    }
    ,
    Jr().prototype.cosh = function() {
        return this.throwIfDisposed(),
        Wh(this)
    }
    ,
    Jr().prototype.cumprod = function(e, t, n) {
        return this.throwIfDisposed(),
        Uh(this, e, t, n)
    }
    ,
    Jr().prototype.cumsum = function(e, t, n) {
        return this.throwIfDisposed(),
        Vh(this, e, t, n)
    }
    ,
    Jr().prototype.depthToSpace = function(e, t) {
        return this.throwIfDisposed(),
        Hh(this, e, t)
    }
    ,
    Jr().prototype.depthwiseConv2d = function(e, t, n, s, r, a) {
        return this.throwIfDisposed(),
        lu(this, e, t, n, s, r, a)
    }
    ,
    Jr().prototype.dilation2d = function(e, t, n, s, r) {
        return this.throwIfDisposed(),
        qh(this, e, t, n, s, r)
    }
    ,
    Jr().prototype.divNoNan = function(e) {
        return this.throwIfDisposed(),
        Xh(this, e)
    }
    ,
    Jr().prototype.div = function(e) {
        return this.throwIfDisposed(),
        al(this, e)
    }
    ,
    Jr().prototype.dot = function(e) {
        return this.throwIfDisposed(),
        Yh(this, e)
    }
    ,
    Jr().prototype.elu = function() {
        return this.throwIfDisposed(),
        Xl(this)
    }
    ,
    Jr().prototype.equal = function(e) {
        return this.throwIfDisposed(),
        Kh(this, e)
    }
    ,
    Jr().prototype.erf = function() {
        return this.throwIfDisposed(),
        Jh(this)
    }
    ,
    Jr().prototype.euclideanNorm = function(e, t) {
        return this.throwIfDisposed(),
        Qh(this, e, t)
    }
    ,
    Jr().prototype.exp = function() {
        return this.throwIfDisposed(),
        Xc(this)
    }
    ,
    Jr().prototype.expandDims = function(e) {
        return this.throwIfDisposed(),
        $c(this, e)
    }
    ,
    Jr().prototype.expm1 = function() {
        return this.throwIfDisposed(),
        ep(this)
    }
    ,
    Jr().prototype.fft = function() {
        return this.throwIfDisposed(),
        gl(this)
    }
    ,
    Jr().prototype.flatten = function() {
        return this.throwIfDisposed(),
        hl(this, [this.size])
    }
    ,
    Jr().prototype.floor = function() {
        return this.throwIfDisposed(),
        tp(this)
    }
    ,
    Jr().prototype.floorDiv = function(e) {
        return this.throwIfDisposed(),
        rl(this, e)
    }
    ,
    Jr().prototype.gather = function(e, t) {
        return this.throwIfDisposed(),
        np(this, e, t)
    }
    ,
    Jr().prototype.greaterEqual = function(e) {
        return this.throwIfDisposed(),
        sc(this, e)
    }
    ,
    Jr().prototype.greater = function(e) {
        return this.throwIfDisposed(),
        Xu(this, e)
    }
    ,
    Jr().prototype.ifft = function() {
        return this.throwIfDisposed(),
        bl(this)
    }
    ,
    Jr().prototype.irfft = function() {
        return this.throwIfDisposed(),
        vl(this)
    }
    ,
    Jr().prototype.isFinite = function() {
        return this.throwIfDisposed(),
        sp(this)
    }
    ,
    Jr().prototype.isInf = function() {
        return this.throwIfDisposed(),
        rp(this)
    }
    ,
    Jr().prototype.isNaN = function() {
        return this.throwIfDisposed(),
        ap(this)
    }
    ,
    Jr().prototype.leakyRelu = function(e) {
        return this.throwIfDisposed(),
        Yl(this, e)
    }
    ,
    Jr().prototype.lessEqual = function(e) {
        return this.throwIfDisposed(),
        Ku(this, e)
    }
    ,
    Jr().prototype.less = function(e) {
        return this.throwIfDisposed(),
        ip(this, e)
    }
    ,
    Jr().prototype.localResponseNormalization = function(e, t, n, s) {
        return this.throwIfDisposed(),
        lp(this, e, t, n, s)
    }
    ,
    Jr().prototype.logSigmoid = function() {
        return this.throwIfDisposed(),
        cp(this)
    }
    ,
    Jr().prototype.logSoftmax = function(e) {
        return this.throwIfDisposed(),
        hp(this, e)
    }
    ,
    Jr().prototype.logSumExp = function(e, t) {
        return this.throwIfDisposed(),
        Jc(this, e, t)
    }
    ,
    Jr().prototype.log = function() {
        return this.throwIfDisposed(),
        Hc(this)
    }
    ,
    Jr().prototype.log1p = function() {
        return this.throwIfDisposed(),
        Yc(this)
    }
    ,
    Jr().prototype.logicalAnd = function(e) {
        return this.throwIfDisposed(),
        rc(this, e)
    }
    ,
    Jr().prototype.logicalNot = function() {
        return this.throwIfDisposed(),
        pp(this)
    }
    ,
    Jr().prototype.logicalOr = function(e) {
        return this.throwIfDisposed(),
        dp(this, e)
    }
    ,
    Jr().prototype.logicalXor = function(e) {
        return this.throwIfDisposed(),
        fp(this, e)
    }
    ,
    Jr().prototype.matMul = function(e, t, n) {
        return this.throwIfDisposed(),
        pu(this, e, t, n)
    }
    ,
    Jr().prototype.maxPool = function(e, t, n, s) {
        return this.throwIfDisposed(),
        xp(this, e, t, n, s)
    }
    ,
    Jr().prototype.max = function(e, t) {
        return this.throwIfDisposed(),
        xc(this, e, t)
    }
    ,
    Jr().prototype.maximum = function(e) {
        return this.throwIfDisposed(),
        kp(this, e)
    }
    ,
    Jr().prototype.mean = function(e, t) {
        return this.throwIfDisposed(),
        Mc(this, e, t)
    }
    ,
    Jr().prototype.min = function(e, t) {
        return this.throwIfDisposed(),
        wc(this, e, t)
    }
    ,
    Jr().prototype.minimum = function(e) {
        return this.throwIfDisposed(),
        Vc(this, e)
    }
    ,
    Jr().prototype.mirrorPad = function(e, t) {
        return this.throwIfDisposed(),
        Sp(this, e, t)
    }
    ,
    Jr().prototype.mod = function(e) {
        return this.throwIfDisposed(),
        Np(this, e)
    }
    ,
    Jr().prototype.mul = function(e) {
        return this.throwIfDisposed(),
        il(this, e)
    }
    ,
    Jr().prototype.neg = function() {
        return this.throwIfDisposed(),
        Ac(this)
    }
    ,
    Jr().prototype.norm = function(e, t, n) {
        return this.throwIfDisposed(),
        Nc(this, e, t, n)
    }
    ,
    Jr().prototype.notEqual = function(e) {
        return this.throwIfDisposed(),
        Lc(this, e)
    }
    ,
    Jr().prototype.oneHot = function(e, t=1, n=0) {
        return this.throwIfDisposed(),
        Ep(this, e, t, n)
    }
    ,
    Jr().prototype.onesLike = function() {
        return this.throwIfDisposed(),
        Ap(this)
    }
    ,
    Jr().prototype.pad = function(e, t) {
        return this.throwIfDisposed(),
        Fp(this, e, t)
    }
    ,
    Jr().prototype.pool = function(e, t, n, s, r, a) {
        return this.throwIfDisposed(),
        zp(this, e, t, n, s, r, a)
    }
    ,
    Jr().prototype.pow = function(e) {
        return this.throwIfDisposed(),
        vc(this, e)
    }
    ,
    Jr().prototype.prelu = function(e) {
        return this.throwIfDisposed(),
        Zl(this, e)
    }
    ,
    Jr().prototype.prod = function(e, t) {
        return this.throwIfDisposed(),
        Bp(this, e, t)
    }
    ,
    Jr().prototype.reciprocal = function() {
        return this.throwIfDisposed(),
        ad(this)
    }
    ,
    Jr().prototype.relu = function() {
        return this.throwIfDisposed(),
        Jl(this)
    }
    ,
    Jr().prototype.relu6 = function() {
        return this.throwIfDisposed(),
        Ql(this)
    }
    ,
    Jr().prototype.reshapeAs = function(e) {
        return this.throwIfDisposed(),
        hl(this, e.shape)
    }
    ,
    Jr().prototype.reshape = function(e) {
        return this.throwIfDisposed(),
        hl(this, e)
    }
    ,
    Jr().prototype.resizeBilinear = function(e, t, n) {
        return this.throwIfDisposed(),
        Hu(this, e, t, n)
    }
    ,
    Jr().prototype.resizeNearestNeighbor = function(e, t, n) {
        return this.throwIfDisposed(),
        ju(this, e, t, n)
    }
    ,
    Jr().prototype.reverse = function(e) {
        return this.throwIfDisposed(),
        xl(this, e)
    }
    ,
    Jr().prototype.rfft = function() {
        return this.throwIfDisposed(),
        yl(this)
    }
    ,
    Jr().prototype.round = function() {
        return this.throwIfDisposed(),
        Zu(this)
    }
    ,
    Jr().prototype.rsqrt = function() {
        return this.throwIfDisposed(),
        cd(this)
    }
    ,
    Jr().prototype.selu = function() {
        return this.throwIfDisposed(),
        hd(this)
    }
    ,
    Jr().prototype.separableConv2d = function(e, t, n, s, r, a) {
        return this.throwIfDisposed(),
        pd(this, e, t, n, s, r, a)
    }
    ,
    Jr().prototype.sigmoid = function() {
        return this.throwIfDisposed(),
        eu(this)
    }
    ,
    Jr().prototype.sign = function() {
        return this.throwIfDisposed(),
        fd(this)
    }
    ,
    Jr().prototype.sin = function() {
        return this.throwIfDisposed(),
        md(this)
    }
    ,
    Jr().prototype.sinh = function() {
        return this.throwIfDisposed(),
        gd(this)
    }
    ,
    Jr().prototype.slice = function(e, t) {
        return this.throwIfDisposed(),
        pl(this, e, t)
    }
    ,
    Jr().prototype.softmax = function(e) {
        return this.throwIfDisposed(),
        vd(this, e)
    }
    ,
    Jr().prototype.softplus = function() {
        return this.throwIfDisposed(),
        up(this)
    }
    ,
    Jr().prototype.spaceToBatchND = function(e, t) {
        return this.throwIfDisposed(),
        Lp(this, e, t)
    }
    ,
    Jr().prototype.split = function(e, t) {
        return this.throwIfDisposed(),
        dl(this, e, t)
    }
    ,
    Jr().prototype.sqrt = function() {
        return this.throwIfDisposed(),
        kc(this)
    }
    ,
    Jr().prototype.square = function() {
        return this.throwIfDisposed(),
        Ic(this)
    }
    ,
    Jr().prototype.squaredDifference = function(e) {
        return this.throwIfDisposed(),
        qc(this, e)
    }
    ,
    Jr().prototype.squeeze = function(e) {
        return this.throwIfDisposed(),
        Tc(this, e)
    }
    ,
    Jr().prototype.stack = function(e, t) {
        this.throwIfDisposed();
        const n = e instanceof Zr ? [this, e] : [this, ...e];
        return ac(n, t)
    }
    ,
    Jr().prototype.step = function(e) {
        return this.throwIfDisposed(),
        tu(this, e)
    }
    ,
    Jr().prototype.stridedSlice = function(e, t, n, s, r, a, i, o) {
        return this.throwIfDisposed(),
        kd(this, e, t, n, s, r, a, i, o)
    }
    ,
    Jr().prototype.sub = function(e) {
        return this.throwIfDisposed(),
        Yu(this, e)
    }
    ,
    Jr().prototype.sum = function(e, t) {
        return this.throwIfDisposed(),
        nu(this, e, t)
    }
    ,
    Jr().prototype.tan = function() {
        return this.throwIfDisposed(),
        Id(this)
    }
    ,
    Jr().prototype.tanh = function() {
        return this.throwIfDisposed(),
        vh(this)
    }
    ,
    Jr().prototype.tile = function(e) {
        return this.throwIfDisposed(),
        Tu(this, e)
    }
    ,
    Jr().prototype.toBool = function() {
        return this.throwIfDisposed(),
        Ko(this, "bool")
    }
    ,
    Jr().prototype.toFloat = function() {
        return this.throwIfDisposed(),
        Ko(this, "float32")
    }
    ,
    Jr().prototype.toInt = function() {
        return this.throwIfDisposed(),
        Ko(this, "int32")
    }
    ,
    Jr().prototype.topk = function(e, t) {
        return this.throwIfDisposed(),
        $d(this, e, t)
    }
    ,
    Jr().prototype.transpose = function(e) {
        return this.throwIfDisposed(),
        Fc(this, e)
    }
    ,
    Jr().prototype.unique = function(e) {
        return this.throwIfDisposed(),
        Ad(this, e)
    }
    ,
    Jr().prototype.unsortedSegmentSum = function(e, t) {
        return this.throwIfDisposed(),
        Rd(this, e, t)
    }
    ,
    Jr().prototype.unstack = function(e) {
        return this.throwIfDisposed(),
        ic(this, e)
    }
    ,
    Jr().prototype.where = function(e, t) {
        return this.throwIfDisposed(),
        Qu(e, this, t)
    }
    ,
    Jr().prototype.zerosLike = function() {
        return this.throwIfDisposed(),
        ml(this)
    }
    ;
    class nb {
        constructor(e) {
            if (this.capacity = e,
            this.begin = 0,
            this.end = 0,
            null == e)
                throw new RangeError("Can't create a ring buffer of unknown capacity.");
            if (e < 1)
                throw new RangeError("Can't create ring buffer of capacity < 1.");
            this.data = new Array(e),
            this.doubledCapacity = 2 * e
        }
        wrap(e) {
            for (; e < 0; )
                e += this.doubledCapacity;
            return e % this.doubledCapacity
        }
        get(e) {
            if (e < 0)
                throw new RangeError("Can't get item at a negative index.");
            return this.data[e % this.capacity]
        }
        set(e, t) {
            if (e < 0)
                throw new RangeError("Can't set item at a negative index.");
            this.data[e % this.capacity] = t
        }
        length() {
            let e = this.end - this.begin;
            return e < 0 && (e = this.doubledCapacity + e),
            e
        }
        isFull() {
            return this.length() === this.capacity
        }
        isEmpty() {
            return 0 === this.length()
        }
        push(e) {
            if (this.isFull())
                throw new RangeError("Ring buffer is full.");
            this.set(this.end, e),
            this.end = this.wrap(this.end + 1)
        }
        pushAll(e) {
            for (const t of e)
                this.push(t)
        }
        pop() {
            if (this.isEmpty())
                throw new RangeError("Ring buffer is empty.");
            this.end = this.wrap(this.end - 1);
            const e = this.get(this.end);
            return this.set(this.end, void 0),
            e
        }
        unshift(e) {
            if (this.isFull())
                throw new RangeError("Ring buffer is full.");
            this.begin = this.wrap(this.begin - 1),
            this.set(this.begin, e)
        }
        shift() {
            if (this.isEmpty())
                throw new RangeError("Ring buffer is empty.");
            const e = this.get(this.begin);
            return this.set(this.begin, void 0),
            this.begin = this.wrap(this.begin + 1),
            e
        }
        shuffleExcise(e) {
            if (this.isEmpty())
                throw new RangeError("Ring buffer is empty.");
            const t = this.wrap(this.begin + e)
              , n = this.get(t);
            return this.set(t, this.pop()),
            n
        }
    }
    class sb extends nb {
        constructor() {
            super(sb.INITIAL_CAPACITY)
        }
        isFull() {
            return !1
        }
        push(e) {
            super.isFull() && this.expand(),
            super.push(e)
        }
        unshift(e) {
            super.isFull() && this.expand(),
            super.unshift(e)
        }
        expand() {
            const e = 2 * this.capacity
              , t = new Array(e)
              , n = this.length();
            for (let e = 0; e < n; e++)
                t[e] = this.get(this.wrap(this.begin + e));
            this.data = t,
            this.capacity = e,
            this.doubledCapacity = 2 * this.capacity,
            this.begin = 0,
            this.end = n
        }
    }
    function rb(e) {
        return new lb(e)
    }
    function ab(e) {
        return new ub(e)
    }
    function ib(e, t) {
        return new wb(e,t)
    }
    sb.INITIAL_CAPACITY = 32;
    class ob {
        async toArray() {
            const e = [];
            let t = await this.next();
            for (; !t.done; )
                e.push(t.value),
                t = await this.next();
            return e
        }
        async toArrayForTest() {
            const e = this.prefetch(100)
              , t = [];
            let n = await e.next();
            for (; !n.done; )
                t.push(n.value),
                n = await e.next();
            return t
        }
        async resolveFully() {
            let e = await this.next();
            for (; !e.done; )
                e = await this.next()
        }
        async resolveWhile(e) {
            let t = await this.next()
              , n = e(t.value);
            for (; !t.done && n; )
                t = await this.next(),
                n = e(t.value)
        }
        handleErrors(e) {
            return new gb(this,e)
        }
        filter(e) {
            return new fb(this,e)
        }
        map(e) {
            return new mb(this,e)
        }
        mapAsync(e) {
            return new yb(this,e)
        }
        serialMapAsync(e) {
            return new yb(this,e).serial()
        }
        flatmap(e) {
            return new xb(this,e)
        }
        async forEachAsync(e) {
            return this.map(e).resolveFully()
        }
        async serialForEach(e) {
            return this.serialMapAsync(e).resolveWhile((e=>!0 === e))
        }
        rowMajorBatch(e, t=!0) {
            return new db(this,e,t)
        }
        columnMajorBatch(e, t=!0, n=Jy) {
            return this.rowMajorBatch(e, t).map((e=>Yy(e, n)))
        }
        concatenate(e, t) {
            return new wb(rb([this, e]),t)
        }
        take(e) {
            return e < 0 || null == e ? this : new pb(this,e)
        }
        skip(e) {
            return e < 0 || null == e ? this : new hb(this,e)
        }
        prefetch(e) {
            return new kb(this,e)
        }
        shuffle(e, t) {
            return new Ib(this,e,t)
        }
        serial() {
            return new cb(this)
        }
    }
    class lb extends ob {
        constructor(e) {
            super(),
            this.items = e,
            this.trav = 0
        }
        summary() {
            return `Array of ${this.items.length} items`
        }
        async next() {
            if (this.trav >= this.items.length)
                return {
                    value: null,
                    done: !0
                };
            const e = this.items[this.trav];
            return this.trav++,
            {
                value: eb(e),
                done: !1
            }
        }
    }
    class ub extends ob {
        constructor(e) {
            super(),
            this.nextFn = e
        }
        summary() {
            return "Function call"
        }
        async next() {
            try {
                return this.nextFn()
            } catch (e) {
                throw e.message = `Error thrown while iterating through a dataset: ${e.message}`,
                e
            }
        }
    }
    class cb extends ob {
        constructor(e) {
            super(),
            this.upstream = e,
            this.lastRead = Promise.resolve({
                value: null,
                done: !1
            })
        }
        summary() {
            return `${this.upstream.summary()} -> Serial`
        }
        async next() {
            return this.lastRead = this.lastRead.then((()=>this.serialNext())),
            this.lastRead
        }
        async serialNext() {
            return this.upstream.next()
        }
    }
    class hb extends ob {
        constructor(e, t) {
            super(),
            this.upstream = e,
            this.maxCount = t,
            this.count = 0,
            this.lastRead = Promise.resolve({
                value: null,
                done: !1
            })
        }
        summary() {
            return `${this.upstream.summary()} -> Skip`
        }
        async next() {
            return this.lastRead = this.lastRead.then((()=>this.serialNext())),
            this.lastRead
        }
        async serialNext() {
            for (; this.count++ < this.maxCount; ) {
                const e = await this.upstream.next();
                if (e.done)
                    return e;
                el(e.value)
            }
            return this.upstream.next()
        }
    }
    class pb extends ob {
        constructor(e, t) {
            super(),
            this.upstream = e,
            this.maxCount = t,
            this.count = 0
        }
        summary() {
            return `${this.upstream.summary()} -> Take`
        }
        async next() {
            return this.count++ >= this.maxCount ? {
                value: null,
                done: !0
            } : this.upstream.next()
        }
    }
    class db extends ob {
        constructor(e, t, n=!0) {
            super(),
            this.upstream = e,
            this.batchSize = t,
            this.enableSmallLastBatch = n,
            this.lastRead = Promise.resolve({
                value: null,
                done: !1
            })
        }
        summary() {
            return `${this.upstream.summary()} -> RowMajorBatch`
        }
        async next() {
            return this.lastRead = this.lastRead.then((()=>this.serialNext())),
            this.lastRead
        }
        async serialNext() {
            const e = [];
            for (; e.length < this.batchSize; ) {
                const t = await this.upstream.next();
                if (t.done)
                    return this.enableSmallLastBatch && e.length > 0 ? {
                        value: e,
                        done: !1
                    } : {
                        value: null,
                        done: !0
                    };
                e.push(t.value)
            }
            return {
                value: e,
                done: !1
            }
        }
    }
    class fb extends ob {
        constructor(e, t) {
            super(),
            this.upstream = e,
            this.predicate = t,
            this.lastRead = Promise.resolve({
                value: null,
                done: !1
            })
        }
        summary() {
            return `${this.upstream.summary()} -> Filter`
        }
        async next() {
            return this.lastRead = this.lastRead.then((()=>this.serialNext())),
            this.lastRead
        }
        async serialNext() {
            for (; ; ) {
                const e = await this.upstream.next();
                if (e.done || this.predicate(e.value))
                    return e;
                el(e.value)
            }
        }
    }
    class mb extends ob {
        constructor(e, t) {
            super(),
            this.upstream = e,
            this.transform = t
        }
        summary() {
            return `${this.upstream.summary()} -> Map`
        }
        async next() {
            const e = await this.upstream.next();
            if (e.done)
                return {
                    value: null,
                    done: !0
                };
            const t = ua.getTensorsInContainer(e.value)
              , n = this.transform(e.value)
              , s = ua.getTensorsInContainer(n);
            for (const e of t)
                ua.isTensorInList(e, s) || e.dispose();
            return {
                value: n,
                done: !1
            }
        }
    }
    class gb extends ob {
        constructor(e, t) {
            super(),
            this.upstream = e,
            this.handler = t,
            this.count = 0,
            this.lastRead = Promise.resolve({
                value: null,
                done: !1
            })
        }
        summary() {
            return `${this.upstream.summary()} -> handleErrors`
        }
        async next() {
            return this.lastRead = this.lastRead.then((()=>this.serialNext())),
            this.lastRead
        }
        async serialNext() {
            for (; ; )
                try {
                    return await this.upstream.next()
                } catch (e) {
                    if (!this.handler(e))
                        return {
                            value: null,
                            done: !0
                        }
                }
        }
    }
    class yb extends ob {
        constructor(e, t) {
            super(),
            this.upstream = e,
            this.transform = t
        }
        summary() {
            return `${this.upstream.summary()} -> AsyncMap`
        }
        async next() {
            const e = await this.upstream.next();
            if (e.done)
                return {
                    value: null,
                    done: !0
                };
            const t = ua.getTensorsInContainer(e.value)
              , n = await this.transform(e.value)
              , s = ua.getTensorsInContainer(n);
            for (const e of t)
                ua.isTensorInList(e, s) || e.dispose();
            return {
                value: n,
                done: !1
            }
        }
    }
    class bb extends ob {
        constructor() {
            super(),
            this.outputQueue = new sb,
            this.lastRead = Promise.resolve({
                value: null,
                done: !1
            })
        }
        async next() {
            return this.lastRead = this.lastRead.then((()=>this.serialNext())),
            this.lastRead
        }
        async serialNext() {
            for (; 0 === this.outputQueue.length(); )
                if (!await this.pump())
                    return {
                        value: null,
                        done: !0
                    };
            return {
                value: this.outputQueue.shift(),
                done: !1
            }
        }
    }
    class xb extends bb {
        constructor(e, t) {
            super(),
            this.upstream = e,
            this.transform = t
        }
        summary() {
            return `${this.upstream.summary()} -> Flatmap`
        }
        async pump() {
            const e = await this.upstream.next();
            if (e.done)
                return !1;
            const t = ua.getTensorsInContainer(e.value)
              , n = this.transform(e.value)
              , s = ua.getTensorsInContainer(n);
            this.outputQueue.pushAll(n);
            for (const e of t)
                ua.isTensorInList(e, s) || e.dispose();
            return !0
        }
    }
    class wb extends ob {
        constructor(e, t) {
            super(),
            this.baseErrorHandler = t,
            this.lastRead = null,
            this.iterator = null,
            this.moreIterators = e
        }
        summary() {
            return "TODO: fill in upstream of chained summaries -> Chained"
        }
        async next() {
            return this.lastRead = this.readFromChain(this.lastRead),
            this.lastRead
        }
        async readFromChain(e) {
            if (await e,
            null == this.iterator) {
                const e = await this.moreIterators.next();
                if (e.done)
                    return {
                        value: null,
                        done: !0
                    };
                this.iterator = e.value,
                null != this.baseErrorHandler && (this.iterator = this.iterator.handleErrors(this.baseErrorHandler))
            }
            const t = await this.iterator.next();
            return t.done ? (this.iterator = null,
            this.readFromChain(e)) : t
        }
    }
    var vb;
    !function(e) {
        e[e.FAIL = 0] = "FAIL",
        e[e.SHORTEST = 1] = "SHORTEST",
        e[e.LONGEST = 2] = "LONGEST"
    }(vb || (vb = {}));
    class kb extends ob {
        constructor(e, t) {
            super(),
            this.upstream = e,
            this.bufferSize = t,
            this.buffer = new nb(t)
        }
        summary() {
            return `${this.upstream.summary()} -> Prefetch`
        }
        refill() {
            for (; !this.buffer.isFull(); ) {
                const e = this.upstream.next();
                this.buffer.push(e)
            }
        }
        next() {
            return this.refill(),
            this.buffer.shift()
        }
    }
    class Ib extends kb {
        constructor(e, t, n) {
            super(e, t),
            this.upstream = e,
            this.windowSize = t,
            this.upstreamExhausted = !1,
            this.random = Gp.alea(n || Hs.now().toString()),
            this.lastRead = Promise.resolve({
                value: null,
                done: !1
            })
        }
        async next() {
            return this.lastRead = this.lastRead.then((()=>this.serialNext())),
            this.lastRead
        }
        randomInt(e) {
            return Math.floor(this.random() * e)
        }
        chooseIndex() {
            return this.randomInt(this.buffer.length())
        }
        async serialNext() {
            for (this.upstreamExhausted || this.refill(); !this.buffer.isEmpty(); ) {
                const e = this.chooseIndex()
                  , t = await this.buffer.shuffleExcise(e);
                if (!t.done)
                    return this.refill(),
                    t;
                this.upstreamExhausted = !0
            }
            return {
                value: null,
                done: !0
            }
        }
    }
    class Sb {
        constructor() {
            this.size = null
        }
        batch(e, t=!0) {
            const n = this;
            let s;
            return Hs.assert(e > 0, (()=>`batchSize needs to be positive, but it is\n      ${e}`)),
            s = this.size === 1 / 0 || null == this.size ? this.size : t ? Math.ceil(this.size / e) : Math.floor(this.size / e),
            Nb((async()=>(await n.iterator()).columnMajorBatch(e, t, Tb)), s)
        }
        concatenate(e) {
            const t = this;
            let n;
            return n = this.size === 1 / 0 || e.size === 1 / 0 ? 1 / 0 : null != this.size && null != e.size ? this.size + e.size : null,
            Nb((async()=>(await t.iterator()).concatenate(await e.iterator())), n)
        }
        filter(e) {
            const t = this;
            let n;
            return n = this.size === 1 / 0 ? 1 / 0 : null,
            Nb((async()=>(await t.iterator()).filter((t=>Qo((()=>e(t)))))), n)
        }
        async forEachAsync(e) {
            return (await this.iterator()).forEachAsync(e)
        }
        map(e) {
            const t = this;
            return Nb((async()=>(await t.iterator()).map((t=>Qo((()=>e(t)))))), this.size)
        }
        mapAsync(e) {
            const t = this;
            return Nb((async()=>(await t.iterator()).mapAsync(e)), this.size)
        }
        prefetch(e) {
            if (null == e)
                throw new RangeError("`Dataset.prefetch()` requires bufferSize to be specified.");
            const t = this;
            return Nb((async()=>(await t.iterator()).prefetch(e)), this.size)
        }
        repeat(e) {
            const t = this;
            let n;
            return n = null != this.size && e > 0 ? this.size * e : 0 === e ? 0 : null != this.size && (void 0 === e || e < 0) ? 1 / 0 : null,
            Nb((async()=>ib(ab((async()=>({
                value: await t.iterator(),
                done: !1
            }))).take(e))), n)
        }
        skip(e) {
            const t = this;
            let n;
            return n = null != this.size && e >= 0 && this.size >= e ? this.size - e : null != this.size && (this.size < e || void 0 === e || e < 0) ? 0 : null,
            Nb((async()=>(await t.iterator()).skip(e)), n)
        }
        shuffle(e, t, n=!0) {
            if (null == e || e < 0)
                throw null == this.size ? new RangeError("`Dataset.shuffle()` requires bufferSize to be specified.") : new RangeError(`\`Dataset.shuffle()\` requires bufferSize to be specified.  If your data fits in main memory (for regular JS objects), and/or GPU memory (for \`tf.Tensor\`s), consider setting bufferSize to the dataset size (${this.size} elements)`);
            const s = this
              , r = Gp.alea(t || Hs.now().toString());
            return Nb((async()=>{
                let t = r.int32();
                return n && (t += r.int32()),
                (await s.iterator()).shuffle(e, t.toString())
            }
            ), this.size)
        }
        take(e) {
            const t = this;
            let n;
            return n = null != this.size && this.size > e ? e : null != this.size && this.size <= e ? this.size : null,
            Nb((async()=>(await t.iterator()).take(e)), n)
        }
        async toArray() {
            if (this.size === 1 / 0)
                throw new Error("Can not convert infinite data stream to array.");
            return (await this.iterator()).toArray()
        }
        async toArrayForTest() {
            if (this.size === 1 / 0)
                throw new Error("Can not convert infinite data stream to array.");
            return (await this.iterator()).toArrayForTest()
        }
    }
    function Nb(e, t=null) {
        return new class extends Sb {
            constructor() {
                super(...arguments),
                this.size = t
            }
            async iterator() {
                return e()
            }
        }
    }
    function Tb(e) {
        if (null === e)
            return null;
        const t = e[0];
        if (null == (n = t) || null === (s = n) || "object" != typeof s && "function" != typeof s || Array.isArray(n) || "object" == typeof n && n instanceof Zr || Hs.isTypedArray(n)) {
            return {
                value: function(e) {
                    if (0 === e.length)
                        throw new Error("Can't make a batch of zero elements.");
                    return e[0]instanceof Zr ? ac(e) : Ba(e)
                }(e),
                recurse: !1
            }
        }
        var n, s;
        return {
            value: null,
            recurse: !0
        }
    }
    Sb.MAX_BUFFER_SIZE = 1e4;
    Symbol("out"),
    Symbol("field"),
    Symbol("quote"),
    Symbol("quoteafterquote"),
    Symbol("quoteinquote");
    function Cb(e, t) {
        Array.isArray(e) || (e = [e]),
        e.forEach((e=>{
            null != e && Hs.assert("complex64" !== e.dtype, (()=>`${t} does not support complex64 tensors in the CPU backend.`))
        }
        ))
    }
    function $b(e, t, n) {
        return ({inputs: s, attrs: r, backend: a})=>{
            const {x: i} = s;
            if (Cb(i, e),
            "string" === i.dtype || "string" === n)
                throw new Error("unaryKernelFunc does not support string input/output");
            const o = a
              , l = o.data.get(i.dataId).values
              , u = Hs.sizeFromShape(i.shape)
              , c = n || i.dtype
              , h = Hs.getArrayFromDType(c, u);
            for (let e = 0; e < u; ++e)
                h[e] = t(l[e], r);
            return o.makeTensorInfo(i.shape, c, h)
        }
    }
    function Eb(e, t, n) {
        return ({inputs: s, attrs: r, backend: a})=>{
            const {x: i} = s;
            if (Cb(i, e),
            "string" === i.dtype || "string" === n)
                throw new Error("unaryKernelFunc does not support string input/output");
            const o = a
              , l = o.data.get(i.dataId).values
              , u = n || i.dtype
              , c = t(l, u, r);
            return o.makeTensorInfo(i.shape, u, c)
        }
    }
    const Ab = $b(kt, (e=>e >= 0 ? e : Math.exp(e) - 1))
      , Rb = {
        kernelName: kt,
        backendName: "cpu",
        kernelFunc: Ab
    };
    function Fb(e) {
        const {inputs: t, backend: n} = e
          , {x: s} = t;
        return n.incRef(s.dataId),
        {
            dataId: s.dataId,
            shape: s.shape,
            dtype: s.dtype
        }
    }
    const Db = {
        kernelName: Bt,
        backendName: "cpu",
        kernelFunc: Fb
    };
    function _b(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {x: r} = t
          , {alpha: a} = s;
        Cb([r], "leakyRelu");
        const i = Hs.sizeFromShape(r.shape)
          , o = n.data.get(r.dataId).values
          , l = Hs.getTypedArrayFromDType("float32", i);
        for (let e = 0; e < o.length; e++)
            l[e] = o[e] < 0 ? a * o[e] : o[e];
        return n.makeTensorInfo(r.shape, "float32", l)
    }
    const Ob = {
        kernelName: Ht,
        backendName: "cpu",
        kernelFunc: _b
    };
    function Mb(e) {
        return (t,n,s,r,a)=>{
            const i = dm.assertAndGetBroadcastShape(t, n)
              , o = i.length
              , l = Hs.computeStrides(i)
              , u = Hs.sizeFromShape(i)
              , c = Hs.getTypedArrayFromDType(a, u)
              , h = t.length
              , p = n.length
              , d = Hs.computeStrides(t)
              , f = Hs.computeStrides(n)
              , m = dm.getBroadcastDims(t, i)
              , g = dm.getBroadcastDims(n, i);
            if (m.length + g.length === 0)
                for (let t = 0; t < c.length; ++t)
                    c[t] = e(s[t % s.length], r[t % r.length]);
            else
                for (let t = 0; t < c.length; ++t) {
                    const n = Hs.indexToLoc(t, o, l)
                      , a = n.slice(-h);
                    m.forEach((e=>a[e] = 0));
                    const i = Hs.locToIndex(a, h, d)
                      , u = n.slice(-p);
                    g.forEach((e=>u[e] = 0));
                    const y = Hs.locToIndex(u, p, f);
                    c[t] = e(s[i], r[y])
                }
            return [c, i]
        }
    }
    const Lb = Mb(((e,t)=>e < 0 ? t * e : e));
    function zb(e) {
        const {inputs: t, backend: n} = e
          , {x: s, alpha: r} = t;
        Cb([s, r], "prelu");
        const a = n.data.get(s.dataId).values
          , i = n.data.get(r.dataId).values
          , [o,l] = Lb(s.shape, r.shape, a, i, "float32");
        return n.makeTensorInfo(l, "float32", o)
    }
    const Bb = {
        kernelName: Cn,
        backendName: "cpu",
        kernelFunc: zb
    }
      , Pb = $b(On, (e=>Math.max(0, e)))
      , Wb = {
        kernelName: On,
        backendName: "cpu",
        kernelFunc: Pb
    }
      , Ub = $b(Wn, (e=>Math.min(Math.max(0, e), 6)))
      , Vb = {
        kernelName: Wn,
        backendName: "cpu",
        kernelFunc: Ub
    };
    function Gb(e) {
        return (t,n,s)=>{
            const r = Hs.getTypedArrayFromDType(n, t.length);
            for (let n = 0; n < t.length; ++n)
                r[n] = e(t[n], s);
            return r
        }
    }
    const Hb = Gb((e=>1 / (1 + Math.exp(-e))))
      , jb = $b(Qn, (e=>1 / (1 + Math.exp(-e))))
      , qb = {
        kernelName: Qn,
        backendName: "cpu",
        kernelFunc: jb
    };
    function Kb(e, t, n, s, r) {
        if ("linear" === n)
            return Fb({
                inputs: {
                    x: t
                },
                backend: e
            });
        if ("relu" === n)
            return Pb({
                inputs: {
                    x: t
                },
                backend: e
            });
        if ("elu" === n)
            return Ab({
                inputs: {
                    x: t
                },
                backend: e
            });
        if ("relu6" === n)
            return Ub({
                inputs: {
                    x: t
                },
                backend: e
            });
        if ("prelu" === n)
            return zb({
                inputs: {
                    x: t,
                    alpha: s
                },
                backend: e
            });
        if ("leakyrelu" === n)
            return _b({
                inputs: {
                    x: t
                },
                backend: e,
                attrs: {
                    alpha: r
                }
            });
        if ("sigmoid" === n)
            return jb({
                inputs: {
                    x: t
                },
                backend: e
            });
        throw new Error(`Activation ${n} has not been implemented for the CPU backend.`)
    }
    function Xb(e) {
        const {inputs: t, backend: n} = e
          , {real: s, imag: r} = t
          , a = n.data.get(s.dataId).values
          , i = n.data.get(r.dataId).values
          , o = n.makeTensorInfo(s.shape, "complex64");
        return n.data.get(o.dataId).complexTensorInfos = {
            real: n.makeTensorInfo(s.shape, "float32", a),
            imag: n.makeTensorInfo(r.shape, "float32", i)
        },
        o
    }
    const Yb = {
        kernelName: Ze,
        backendName: "cpu",
        kernelFunc: Xb
    };
    function Zb(e, t, n="float32") {
        if ("complex64" === n) {
            return Xb({
                inputs: {
                    real: Zb(e, t, "float32"),
                    imag: Zb(e, t, "float32")
                },
                backend: e
            })
        }
        const s = Hs.makeZerosTypedArray(Hs.sizeFromShape(t), n);
        return e.makeTensorInfo(t, n, s)
    }
    function Jb(e) {
        const {inputs: t, backend: n} = e
          , {input: s} = t
          , r = n.data.get(s.dataId).complexTensorInfos.real
          , a = n.data.get(r.dataId).values;
        return n.makeTensorInfo(r.shape, r.dtype, a)
    }
    const Qb = {
        kernelName: Dn,
        backendName: "cpu",
        kernelFunc: Jb
    };
    function ex(e, t, n, s) {
        if ("int32" === s) {
            return [t, "int32", Int32Array.from(e)]
        }
        if ("bool" === s) {
            const s = Hs.toTypedArray([0], n)
              , [r,a] = Mb(((e,t)=>e !== t ? 1 : 0))(t, [], e, s, "bool");
            return [a, "bool", r]
        }
        throw new Error(`Error in Cast: failed to cast ${n} to ${s}`)
    }
    function tx(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {x: r} = t
          , {dtype: a} = s;
        if ("complex64" === a) {
            if ("complex64" === r.dtype)
                return Fb({
                    inputs: {
                        x: r
                    },
                    backend: n
                });
            const e = Zb(n, r.shape, r.dtype)
              , t = tx({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    dtype: "float32"
                }
            })
              , s = Xb({
                inputs: {
                    real: t,
                    imag: e
                },
                backend: n
            });
            return n.disposeIntermediateTensorInfo(e),
            n.disposeIntermediateTensorInfo(t),
            s
        }
        if ("complex64" === r.dtype) {
            const e = Jb({
                inputs: {
                    input: r
                },
                backend: n
            })
              , t = tx({
                inputs: {
                    x: e
                },
                backend: n,
                attrs: {
                    dtype: a
                }
            });
            return n.disposeIntermediateTensorInfo(e),
            t
        }
        if (!Hs.hasEncodingLoss(r.dtype, a)) {
            const e = Fb({
                inputs: {
                    x: r
                },
                backend: n
            });
            return {
                dataId: e.dataId,
                shape: e.shape,
                dtype: a
            }
        }
        const i = n.data.get(r.dataId).values
          , [o,l,u] = ex(i, r.shape, r.dtype, a);
        return n.makeTensorInfo(o, l, u)
    }
    const nx = {
        kernelName: Ke,
        backendName: "cpu",
        kernelFunc: tx
    };
    function sx(e, t, n, s) {
        return null == n ? ({inputs: n, backend: r})=>{
            const {a: a, b: i} = n
              , o = r;
            Cb([a, i], e);
            const l = o.data.get(a.dataId).values
              , u = o.data.get(i.dataId).values
              , c = "string" === a.dtype ? dm.fromUint8ToStringArray(l) : l
              , h = "string" === a.dtype ? dm.fromUint8ToStringArray(u) : u
              , p = s || a.dtype
              , [d,f] = t(a.shape, i.shape, c, h, p);
            return o.makeTensorInfo(f, p, d)
        }
        : ({inputs: e, backend: r})=>{
            const {a: a, b: i} = e
              , o = r;
            if ("complex64" === a.dtype || "complex64" === i.dtype) {
                const e = tx({
                    inputs: {
                        x: a
                    },
                    backend: o,
                    attrs: {
                        dtype: "complex64"
                    }
                })
                  , t = o.data.get(e.dataId)
                  , s = t.complexTensorInfos.real
                  , r = t.complexTensorInfos.imag
                  , l = o.data.get(s.dataId).values
                  , u = o.data.get(r.dataId).values
                  , c = tx({
                    inputs: {
                        x: i
                    },
                    backend: o,
                    attrs: {
                        dtype: "complex64"
                    }
                })
                  , h = o.data.get(c.dataId)
                  , p = h.complexTensorInfos.real
                  , d = h.complexTensorInfos.imag
                  , f = o.data.get(p.dataId).values
                  , m = o.data.get(d.dataId).values
                  , [g,y,b] = n(a.shape, i.shape, l, u, f, m)
                  , x = o.makeTensorInfo(b, "float32", g)
                  , w = o.makeTensorInfo(b, "float32", y)
                  , v = Xb({
                    inputs: {
                        real: x,
                        imag: w
                    },
                    backend: o
                });
                return o.disposeIntermediateTensorInfo(e),
                o.disposeIntermediateTensorInfo(c),
                o.disposeIntermediateTensorInfo(x),
                o.disposeIntermediateTensorInfo(w),
                v
            }
            {
                const e = o.data.get(a.dataId).values
                  , n = o.data.get(i.dataId).values
                  , r = s || a.dtype
                  , [l,u] = t(a.shape, i.shape, e, n, r);
                return o.makeTensorInfo(u, r, l)
            }
        }
    }
    function rx(e) {
        return (t,n,s,r,a,i)=>{
            const o = dm.assertAndGetBroadcastShape(t, n)
              , l = Hs.sizeFromShape(o)
              , u = o.length
              , c = Hs.computeStrides(o)
              , h = Hs.getTypedArrayFromDType("float32", l)
              , p = Hs.getTypedArrayFromDType("float32", l)
              , d = dm.getBroadcastDims(t, o)
              , f = dm.getBroadcastDims(n, o)
              , m = dm.mergeRealAndImagArrays(s, r)
              , g = dm.mergeRealAndImagArrays(a, i)
              , y = t.length
              , b = Hs.computeStrides(t)
              , x = n.length
              , w = Hs.computeStrides(n);
            if (d.length + f.length === 0)
                for (let t = 0; t < h.length; t++) {
                    const n = t % m.length
                      , s = t % g.length
                      , r = e(m[2 * n], m[2 * n + 1], g[2 * s], g[2 * s + 1]);
                    h[t] = r.real,
                    p[t] = r.imag
                }
            else
                for (let t = 0; t < h.length; t++) {
                    const n = Hs.indexToLoc(t, u, c)
                      , s = n.slice(-y);
                    d.forEach((e=>s[e] = 0));
                    const r = Hs.locToIndex(s, y, b)
                      , a = n.slice(-x);
                    f.forEach((e=>a[e] = 0));
                    const i = Hs.locToIndex(a, x, w)
                      , o = e(m[2 * r], m[2 * r + 1], g[2 * i], g[2 * i + 1]);
                    h[t] = o.real,
                    p[t] = o.imag
                }
            return [h, p, o]
        }
    }
    const ax = Mb(((e,t)=>e + t))
      , ix = rx(((e,t,n,s)=>({
        real: e + n,
        imag: t + s
    })))
      , ox = sx(Ee, ax, ix)
      , lx = {
        kernelName: Ee,
        backendName: "cpu",
        kernelFunc: ox
    };
    function ux(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {x: r} = t
          , {shape: a} = s
          , i = Hs.sizeFromShape(r.shape)
          , o = Hs.inferFromImplicitShape(a, i)
          , l = Hs.sizeFromShape(o);
        Hs.assert(i === l, (()=>`The new shape (${o}) has ${l} elements and the old shape (${r.shape}) has ${i} elements. The new shape and old shape must have the same number of elements.`)),
        n.incRef(r.dataId);
        const u = n.data.get(r.dataId);
        if (null != u.complexTensorInfos) {
            const e = u.complexTensorInfos.real
              , t = u.complexTensorInfos.imag;
            e.shape = o,
            t.shape = o
        }
        return {
            dataId: r.dataId,
            shape: o,
            dtype: r.dtype
        }
    }
    const cx = {
        kernelName: Mn,
        backendName: "cpu",
        kernelFunc: ux
    };
    function hx(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {a: r, b: a} = t
          , {transposeA: i, transposeB: o} = s;
        Cb([r, a], "matMul");
        const l = r.shape.length
          , u = a.shape.length
          , c = i ? r.shape[l - 2] : r.shape[l - 1]
          , h = o ? a.shape[u - 1] : a.shape[u - 2]
          , p = i ? r.shape[l - 1] : r.shape[l - 2]
          , d = o ? a.shape[u - 2] : a.shape[u - 1]
          , f = r.shape.slice(0, -2)
          , m = a.shape.slice(0, -2)
          , g = Hs.sizeFromShape(f)
          , y = Hs.sizeFromShape(m)
          , b = Nl.assertAndGetBroadcastShape(r.shape.slice(0, -2), a.shape.slice(0, -2)).concat([p, d]);
        Hs.assert(c === h, (()=>`Error in matMul: inner shapes (${c}) and (${h}) of Tensors with shapes ${r.shape} and ${a.shape} and transposeA=${i} and transposeB=${o} must match.`));
        const x = o ? [y, d, h] : [y, h, d]
          , w = ux({
            inputs: {
                x: r
            },
            backend: n,
            attrs: {
                shape: i ? [g, c, p] : [g, p, c]
            }
        })
          , v = ux({
            inputs: {
                x: a
            },
            backend: n,
            attrs: {
                shape: x
            }
        })
          , k = i ? w.shape[1] : w.shape[2]
          , I = i ? w.shape[2] : w.shape[1]
          , S = o ? v.shape[1] : v.shape[2]
          , N = Math.max(g, y)
          , T = n.data.get(w.dataId).values
          , C = n.data.get(v.dataId).values
          , $ = Hs.computeStrides(w.shape)
          , E = Hs.computeStrides(v.shape)
          , [A,R,F] = i ? [$[0], 1, $[1]] : [$[0], $[1], 1]
          , [D,_,O] = o ? [1, E[1], E[0]] : [E[1], 1, E[0]]
          , M = I * S
          , L = qo([N, I, S], w.dtype)
          , z = L.values
          , B = n.blockSize;
        for (let e = 0; e < N; e++) {
            const t = e % g
              , n = e % y;
            for (let s = 0; s < I; s += B) {
                const r = Math.min(s + B, I);
                for (let a = 0; a < S; a += B) {
                    const i = Math.min(a + B, S);
                    for (let o = 0; o < k; o += B) {
                        const l = Math.min(o + B, k);
                        for (let u = s; u < r; u++)
                            for (let s = a; s < i; s++) {
                                let r = 0;
                                for (let e = o; e < l; e++) {
                                    r += T[t * A + u * R + e * F] * C[e * D + s * _ + n * O]
                                }
                                z[e * M + (u * S + s)] += r
                            }
                    }
                }
            }
        }
        return n.disposeIntermediateTensorInfo(w),
        n.disposeIntermediateTensorInfo(v),
        n.makeTensorInfo(b, L.dtype, L.values)
    }
    const px = {
        kernelName: Ge,
        backendName: "cpu",
        kernelFunc: hx
    };
    const dx = {
        kernelName: Rs,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {a: r, b: a, bias: i, preluActivationWeights: o} = t
              , {transposeA: l, transposeB: u, activation: c, leakyreluAlpha: h} = s;
            let p, d, f;
            const m = [];
            p = hx({
                inputs: {
                    a: r,
                    b: a
                },
                attrs: {
                    transposeA: l,
                    transposeB: u
                },
                backend: n
            }),
            i && (d = ox({
                inputs: {
                    a: p,
                    b: i
                },
                backend: n
            }),
            m.push(p),
            p = d),
            c && (f = Kb(n, p, c, o, h),
            m.push(p),
            p = f);
            for (const e of m)
                n.disposeIntermediateTensorInfo(e);
            return p
        }
    };
    function fx(e) {
        const t = new Float32Array(e.length);
        for (let n = 0; n < e.length; ++n)
            t[n] = Math.abs(e[n]);
        return t
    }
    const mx = {
        kernelName: Te,
        backendName: "cpu",
        kernelFunc: e=>{
            const {x: t} = e.inputs
              , n = e.backend;
            Cb(t, "abs");
            let s = new Float32Array(Hs.sizeFromShape(t.shape));
            return s = fx(n.data.get(t.dataId).values),
            n.makeOutput(s, t.shape, t.dtype)
        }
    }
      , gx = $b(Ce, (e=>Math.acos(e)))
      , yx = {
        kernelName: Ce,
        backendName: "cpu",
        kernelFunc: gx
    }
      , bx = $b($e, (e=>Math.acosh(e)))
      , xx = {
        kernelName: $e,
        backendName: "cpu",
        kernelFunc: bx
    };
    const wx = {
        kernelName: Ae,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , s = t;
            Cb(t, "addN");
            const r = s.map((e=>n.data.get(e.dataId).values))
              , a = qo(s[0].shape, s[0].dtype)
              , i = a.values;
            for (let e = 0; e < s.length; e++) {
                const t = r[e];
                for (let e = 0; e < i.length; e++)
                    i[e] += t[e]
            }
            return n.makeTensorInfo(a.shape, a.dtype, a.values)
        }
    };
    function vx(e, t, n, s, r) {
        const a = t.length
          , i = Hs.sizeFromShape(t)
          , o = Hs.computeStrides(t)
          , l = Hs.computeStrides(r)
          , u = Hs.getTypedArrayFromDType(n, Hs.sizeFromShape(r));
        for (let t = 0; t < i; ++t) {
            const n = Hs.indexToLoc(t, a, o)
              , r = new Array(n.length);
            for (let e = 0; e < r.length; e++)
                r[e] = n[s[e]];
            u[Hs.locToIndex(r, a, l)] = e[t]
        }
        return u
    }
    function kx(e) {
        const {inputs: t, attrs: n, backend: s} = e
          , {x: r} = t
          , {perm: a} = n;
        Cb(r, "transpose");
        const i = r.shape.length
          , o = new Array(i);
        for (let e = 0; e < o.length; e++)
            o[e] = r.shape[a[e]];
        const l = vx(s.data.get(r.dataId).values, r.shape, r.dtype, a, o);
        return {
            dataId: s.write(l, o, r.dtype),
            shape: o,
            dtype: r.dtype
        }
    }
    const Ix = {
        kernelName: Is,
        backendName: "cpu",
        kernelFunc: kx
    };
    const Sx = {
        kernelName: Re,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {axis: a, keepDims: i} = s;
            Cb(r, "all");
            const o = Hs.parseAxisParam(a, r.shape);
            let l = o;
            const u = dm.getAxesPermutation(l, r.shape.length);
            let c = r;
            null != u && (c = kx({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    perm: u
                }
            }),
            l = dm.getInnerMostAxes(l.length, r.shape.length)),
            dm.assertAxesAreInnerMostDims("all", l, c.shape.length);
            const [h,p] = dm.computeOutAndReduceShapes(c.shape, l)
              , d = Hs.sizeFromShape(p)
              , f = Hs.makeZerosTypedArray(Hs.sizeFromShape(h), c.dtype)
              , m = n.data.get(c.dataId).values;
            for (let e = 0; e < f.length; ++e) {
                const t = e * d;
                let n = m[t];
                for (let e = 0; e < d; ++e) {
                    const s = m[t + e];
                    n = n && s
                }
                f[e] = n
            }
            null != u && n.disposeIntermediateTensorInfo(c);
            const g = n.makeTensorInfo(h, c.dtype, f);
            if (i) {
                const e = ux({
                    inputs: {
                        x: g
                    },
                    backend: n,
                    attrs: {
                        shape: dm.expandShapeToKeepDim(h, o)
                    }
                });
                return n.disposeIntermediateTensorInfo(g),
                e
            }
            return g
        }
    };
    const Nx = {
        kernelName: Fe,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {axis: a, keepDims: i} = s;
            Cb(r, "any");
            const o = Hs.parseAxisParam(a, r.shape);
            let l = o;
            const u = dm.getAxesPermutation(l, r.shape.length);
            let c = r;
            null != u && (c = kx({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    perm: u
                }
            }),
            l = dm.getInnerMostAxes(l.length, r.shape.length)),
            dm.assertAxesAreInnerMostDims("any", l, c.shape.length);
            const [h,p] = dm.computeOutAndReduceShapes(c.shape, l)
              , d = Hs.sizeFromShape(p)
              , f = Hs.makeZerosTypedArray(Hs.sizeFromShape(h), c.dtype)
              , m = n.data.get(c.dataId).values;
            for (let e = 0; e < f.length; ++e) {
                const t = e * d;
                let n = m[t];
                for (let e = 0; e < d; ++e) {
                    const s = m[t + e];
                    n = n || s
                }
                f[e] = n
            }
            null != u && n.disposeIntermediateTensorInfo(c);
            const g = n.makeTensorInfo(h, c.dtype, f);
            if (i) {
                const e = ux({
                    inputs: {
                        x: g
                    },
                    backend: n,
                    attrs: {
                        shape: dm.expandShapeToKeepDim(h, o)
                    }
                });
                return n.disposeIntermediateTensorInfo(g),
                e
            }
            return g
        }
    };
    const Tx = {
        kernelName: De,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {axis: a} = s;
            Cb(r, "argMax");
            let i = Hs.parseAxisParam(a, r.shape);
            const o = dm.getAxesPermutation(i, r.shape.length);
            let l = r;
            const u = [];
            null != o && (l = kx({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    perm: o
                }
            }),
            u.push(l),
            i = dm.getInnerMostAxes(i.length, l.shape.length)),
            i = [i[0]],
            dm.assertAxesAreInnerMostDims("argMax", i, l.shape.length);
            const [c,h] = dm.computeOutAndReduceShapes(l.shape, i)
              , p = Hs.sizeFromShape(c)
              , d = Hs.makeZerosTypedArray(p, "int32")
              , f = Hs.sizeFromShape(h)
              , m = n.data.get(l.dataId).values;
            for (let e = 0; e < d.length; ++e) {
                const t = e * f;
                let n = m[t]
                  , s = 0;
                for (let e = 0; e < f; ++e) {
                    const r = m[t + e];
                    r > n && (n = r,
                    s = e)
                }
                d[e] = s
            }
            return u.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            n.makeTensorInfo(c, "int32", d)
        }
    };
    const Cx = {
        kernelName: _e,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {axis: a} = s;
            Cb(r, "argMin");
            let i = Hs.parseAxisParam(a, r.shape);
            const o = dm.getAxesPermutation(i, r.shape.length);
            let l = r;
            const u = [];
            null != o && (l = kx({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    perm: o
                }
            }),
            u.push(l),
            i = dm.getInnerMostAxes(i.length, l.shape.length)),
            i = [i[0]],
            dm.assertAxesAreInnerMostDims("argMin", i, l.shape.length);
            const [c,h] = dm.computeOutAndReduceShapes(l.shape, i)
              , p = Hs.sizeFromShape(c)
              , d = Hs.makeZerosTypedArray(p, "int32")
              , f = Hs.sizeFromShape(h)
              , m = n.data.get(l.dataId).values;
            for (let e = 0; e < d.length; ++e) {
                const t = e * f;
                let n = m[t]
                  , s = 0;
                for (let e = 0; e < f; ++e) {
                    const r = m[t + e];
                    r < n && (n = r,
                    s = e)
                }
                d[e] = s
            }
            return u.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            n.makeTensorInfo(c, "int32", d)
        }
    }
      , $x = $b(Oe, (e=>Math.asin(e)))
      , Ex = {
        kernelName: Oe,
        backendName: "cpu",
        kernelFunc: $x
    }
      , Ax = $b(Me, (e=>Math.asinh(e)))
      , Rx = {
        kernelName: Me,
        backendName: "cpu",
        kernelFunc: Ax
    }
      , Fx = $b(Le, (e=>Math.atan(e)))
      , Dx = {
        kernelName: Le,
        backendName: "cpu",
        kernelFunc: Fx
    }
      , _x = Mb(((e,t)=>Math.atan2(e, t)))
      , Ox = sx(Be, _x)
      , Mx = {
        kernelName: Be,
        backendName: "cpu",
        kernelFunc: Ox
    }
      , Lx = $b(ze, (e=>Math.atanh(e)))
      , zx = {
        kernelName: ze,
        backendName: "cpu",
        kernelFunc: Lx
    };
    function Bx(e, t, n, s, r, a) {
        const i = r.strideHeight
          , o = r.strideWidth
          , l = r.dilationHeight
          , u = r.dilationWidth
          , c = r.effectiveFilterHeight
          , h = r.effectiveFilterWidth
          , p = r.padInfo.top
          , d = r.padInfo.left
          , f = "max" === a ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY
          , m = qo(r.outShape, n)
          , g = m.values
          , y = r.outShape[1] * r.outShape[2] * r.outShape[3]
          , b = r.outShape[2] * r.outShape[3]
          , x = r.outShape[3];
        for (let t = 0; t < r.batchSize; ++t) {
            const n = t * y
              , m = t * s[0];
            for (let t = 0; t < r.inChannels; ++t)
                for (let y = 0; y < r.outHeight; ++y) {
                    const w = y * i - p
                      , v = Math.max(0, w)
                      , k = Math.min(r.inHeight, c + w)
                      , I = n + y * b;
                    for (let n = 0; n < r.outWidth; ++n) {
                        const i = n * o - d
                          , c = Math.max(0, i)
                          , p = Math.min(r.inWidth, h + i);
                        let y = f
                          , b = 0
                          , w = 0;
                        for (let n = v; n < k; n += l) {
                            const r = m + n * s[1];
                            for (let n = c; n < p; n += u) {
                                const i = e[r + n * s[2] + t];
                                "max" === a && i > y ? y = i : "avg" === a && (b += i,
                                w++)
                            }
                            if (isNaN(y))
                                break
                        }
                        g[I + n * x + t] = "avg" === a ? b / w : y
                    }
                }
        }
        return m
    }
    function Px(e, t, n, s, r=!1, a=!1) {
        const i = qo(s.outShape, "int32")
          , o = s.strideHeight
          , l = s.strideWidth
          , u = s.dilationHeight
          , c = s.dilationWidth
          , h = s.effectiveFilterHeight
          , p = s.effectiveFilterWidth
          , d = s.padInfo.top
          , f = s.padInfo.left
          , m = qo(t, n, e);
        for (let e = 0; e < s.batchSize; ++e)
            for (let t = 0; t < s.inChannels; ++t)
                for (let n = 0; n < s.outHeight; ++n) {
                    const g = n * o - d;
                    let y = g;
                    for (; y < 0; )
                        y += u;
                    const b = Math.min(s.inHeight, h + g);
                    for (let o = 0; o < s.outWidth; ++o) {
                        const h = o * l - f;
                        let d = h;
                        for (; d < 0; )
                            d += c;
                        const x = Math.min(s.inWidth, p + h);
                        let w = Number.NEGATIVE_INFINITY
                          , v = -1;
                        for (let n = y; n < b; n += u) {
                            const i = n - g;
                            for (let o = d; o < x; o += c) {
                                const l = o - h
                                  , u = m.get(e, n, o, t);
                                u > w && (w = u,
                                v = r ? a ? ((e * s.inHeight + n) * s.inWidth + o) * s.inChannels + t : (n * s.inWidth + o) * s.inChannels + t : i * p + l)
                            }
                        }
                        i.set(v, e, n, o, t)
                    }
                }
        return i
    }
    function Wx(e, t, n, s, r, a) {
        const i = r.strideDepth
          , o = r.strideHeight
          , l = r.strideWidth
          , u = r.dilationDepth
          , c = r.dilationHeight
          , h = r.dilationWidth
          , p = r.effectiveFilterDepth
          , d = r.effectiveFilterHeight
          , f = r.effectiveFilterWidth
          , m = r.padInfo.front
          , g = r.padInfo.top
          , y = r.padInfo.left
          , b = "max" === a ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY
          , x = qo(r.outShape, n)
          , w = x.values
          , v = r.outShape[1] * r.outShape[2] * r.outShape[3] * r.outShape[4]
          , k = r.outShape[2] * r.outShape[3] * r.outShape[4]
          , I = r.outShape[3] * r.outShape[4]
          , S = r.outShape[4];
        for (let t = 0; t < r.batchSize; ++t) {
            const n = t * v
              , x = t * s[0];
            for (let t = 0; t < r.inChannels; ++t)
                for (let v = 0; v < r.outDepth; ++v) {
                    const N = v * i - m;
                    let T = N;
                    for (; T < 0; )
                        T += u;
                    const C = Math.min(r.inDepth, p + N)
                      , $ = n + v * k;
                    for (let n = 0; n < r.outHeight; ++n) {
                        const i = n * o - g;
                        let p = i;
                        for (; p < 0; )
                            p += c;
                        const m = Math.min(r.inHeight, d + i)
                          , v = $ + n * I;
                        for (let n = 0; n < r.outWidth; ++n) {
                            const i = n * l - y;
                            let o = i;
                            for (; o < 0; )
                                o += h;
                            const d = Math.min(r.inWidth, f + i)
                              , g = v + n * S;
                            let k = b
                              , I = 0
                              , N = 0;
                            for (let n = T; n < C; n += u) {
                                const r = x + n * s[1];
                                for (let n = p; n < m; n += c) {
                                    const i = r + n * s[2];
                                    for (let n = o; n < d; n += h) {
                                        const r = e[i + n * s[3] + t];
                                        if ("max" === a && r > k ? k = r : "avg" === a && (I += r,
                                        N++),
                                        isNaN(k))
                                            break
                                    }
                                    if (isNaN(k))
                                        break
                                }
                                if (isNaN(k))
                                    break
                            }
                            w[g + t] = "avg" === a ? I / Math.max(N, 1) : k
                        }
                    }
                }
        }
        return x
    }
    const Ux = {
        kernelName: Pe,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t;
            Cb(r, "avgPool");
            const {filterSize: a, strides: i, pad: o, dimRoundingMode: l} = s;
            Hs.assert(dm.eitherStridesOrDilationsAreOne(i, 1), (()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${i} and dilations '1'`));
            const u = dm.computePool2DInfo(r.shape, a, i, 1, o, l);
            let c;
            if (1 === u.filterWidth && 1 === u.filterHeight && Hs.arraysEqual(u.inShape, u.outShape))
                c = Fb({
                    inputs: {
                        x: r
                    },
                    backend: n
                });
            else {
                const e = n.data.get(r.dataId).values
                  , t = Hs.computeStrides(r.shape)
                  , s = Bx(e, r.shape, r.dtype, t, u, "avg");
                c = n.makeTensorInfo(u.outShape, r.dtype, s.values)
            }
            return c
        }
    };
    const Vx = {
        kernelName: Ue,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {filterSize: a, strides: i, pad: o, dimRoundingMode: l, dataFormat: u} = s;
            Cb(r, "avgPool3d");
            const c = dm.computePool3DInfo(r.shape, a, i, 1, o, l, u)
              , h = Wx(n.data.get(r.dataId).values, r.shape, r.dtype, Hs.computeStrides(r.shape), c, "avg");
            return n.makeTensorInfo(h.shape, "float32", h.values)
        }
    };
    const Gx = {
        kernelName: Ve,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {dy: r, input: a} = t
              , {filterSize: i, strides: o, pad: l, dimRoundingMode: u} = s;
            Cb([r, a], "avgPool3DGrad");
            const c = dm.computePool3DInfo(a.shape, i, o, 1, l, u)
              , h = c.strideDepth
              , p = c.strideHeight
              , d = c.strideWidth
              , f = c.filterDepth
              , m = c.filterHeight
              , g = c.filterWidth
              , y = c.dilationDepth
              , b = c.dilationHeight
              , x = c.dilationWidth
              , w = c.effectiveFilterDepth
              , v = c.effectiveFilterHeight
              , k = c.effectiveFilterWidth
              , I = w - 1 - c.padInfo.front
              , S = k - 1 - c.padInfo.left
              , N = v - 1 - c.padInfo.top
              , T = qo(a.shape, "float32")
              , C = 1 / (f * m * g)
              , $ = n.bufferSync(r);
            for (let e = 0; e < c.batchSize; ++e)
                for (let t = 0; t < c.inChannels; ++t)
                    for (let n = 0; n < c.inDepth; ++n)
                        for (let s = 0; s < c.inHeight; ++s)
                            for (let r = 0; r < c.inWidth; ++r) {
                                const a = n - I
                                  , i = s - N
                                  , o = r - S;
                                let l = 0;
                                for (let n = 0; n < w; n += y) {
                                    const s = (a + n) / h;
                                    if (!(s < 0 || s >= c.outDepth || Math.floor(s) !== s))
                                        for (let n = 0; n < v; n += b) {
                                            const r = (i + n) / p;
                                            if (!(r < 0 || r >= c.outHeight || Math.floor(r) !== r))
                                                for (let n = 0; n < k; n += x) {
                                                    const a = (o + n) / d;
                                                    if (a < 0 || a >= c.outWidth || Math.floor(a) !== a)
                                                        continue;
                                                    l += $.get(e, s, r, a, t)
                                                }
                                        }
                                }
                                T.set(l * C, e, n, s, r, t)
                            }
            return n.makeTensorInfo(T.shape, T.dtype, T.values)
        }
    };
    const Hx = {
        kernelName: We,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {dy: r, input: a} = t
              , i = a;
            Cb([r, a], "avgPoolGrad");
            const {filterSize: o, strides: l, pad: u} = s
              , c = dm.computePool2DInfo(i.shape, o, l, 1, u)
              , h = c.strideHeight
              , p = c.strideWidth
              , d = c.filterHeight
              , f = c.filterWidth
              , m = c.dilationHeight
              , g = c.dilationWidth
              , y = c.effectiveFilterHeight
              , b = c.effectiveFilterWidth
              , x = b - 1 - c.padInfo.left
              , w = y - 1 - c.padInfo.top
              , v = qo(i.shape, "float32")
              , k = 1 / (d * f)
              , I = n.data.get(r.dataId).values
              , S = qo(r.shape, "float32", I);
            for (let e = 0; e < c.batchSize; ++e)
                for (let t = 0; t < c.inChannels; ++t)
                    for (let n = 0; n < c.inHeight; ++n)
                        for (let s = 0; s < c.inWidth; ++s) {
                            const r = n - w
                              , a = s - x;
                            let i = 0;
                            for (let n = 0; n < y; n += m) {
                                const s = (r + n) / h;
                                if (!(s < 0 || s >= c.outHeight || Math.floor(s) !== s))
                                    for (let n = 0; n < b; n += g) {
                                        const r = (a + n) / p;
                                        if (r < 0 || r >= c.outWidth || Math.floor(r) !== r)
                                            continue;
                                        i += S.get(e, s, r, t)
                                    }
                            }
                            v.set(i * k, e, n, s, t)
                        }
            return n.makeTensorInfo(v.shape, v.dtype, v.values)
        }
    };
    const jx = {
        kernelName: _t,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, scale: a, offset: i, mean: o, variance: l} = t;
            Hs.assert(o.shape.length === l.shape.length, (()=>"Batch normalization gradient requires mean and variance to have equal ranks.")),
            Hs.assert(null == i || o.shape.length === i.shape.length, (()=>"Batch normalization gradient requires mean and offset to have equal ranks.")),
            Hs.assert(null == a || o.shape.length === a.shape.length, (()=>"Batch normalization gradient requires mean and scale to have equal ranks.")),
            Cb([r, o, l, a, i], "batchNorm");
            let {varianceEpsilon: u} = s;
            null == u && (u = .001);
            const c = n.data.get(r.dataId).values
              , h = n.data.get(o.dataId).values
              , p = n.data.get(l.dataId).values
              , d = a ? n.data.get(a.dataId).values : new Float32Array([1])
              , f = i ? n.data.get(i.dataId).values : new Float32Array([0])
              , m = new Float32Array(c.length)
              , g = f.length
              , y = d.length
              , b = p.length
              , x = h.length;
            let w = 0
              , v = 0
              , k = 0
              , I = 0;
            for (let e = 0; e < c.length; ++e)
                m[e] = f[w++] + (c[e] - h[v++]) * d[k++] / Math.sqrt(p[I++] + u),
                w >= g && (w = 0),
                v >= x && (v = 0),
                k >= y && (k = 0),
                I >= b && (I = 0);
            return n.makeTensorInfo(r.shape, r.dtype, m)
        }
    };
    function qx(e, t, n, s, r) {
        const a = Xf.isSliceContinous(s, t, n)
          , i = Hs.sizeFromShape(n)
          , o = Hs.computeStrides(s);
        if (a) {
            const n = Xf.computeFlatOffset(t, o);
            return "string" === r ? e.slice(n, n + i) : e.subarray(n, n + i)
        }
        const l = qo(s, r, "string" === r ? dm.fromUint8ToStringArray(e) : e)
          , u = qo(n, r);
        for (let e = 0; e < u.size; ++e) {
            const n = u.indexToLoc(e)
              , s = n.map(((e,n)=>e + t[n]));
            u.set(l.get(...s), ...n)
        }
        return "string" === r ? dm.fromStringArrayToUint8(u.values) : u.values
    }
    function Kx(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {x: r} = t
          , {begin: a, size: i} = s;
        Cb(r, "slice");
        const [o,l] = Xf.parseSliceParams(r, a, i);
        Xf.assertParamsValid(r, o, l);
        const u = qx(n.data.get(r.dataId).values, o, l, r.shape, r.dtype);
        return n.makeTensorInfo(l, r.dtype, u)
    }
    const Xx = {
        kernelName: Xn,
        backendName: "cpu",
        kernelFunc: Kx
    };
    const Yx = {
        kernelName: He,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {blockShape: a, crops: i} = s;
            Cb([r], "batchToSpaceND");
            const o = a.reduce(((e,t)=>e * t))
              , l = dm.getReshaped(r.shape, a, o)
              , u = dm.getPermuted(l.length, a.length)
              , c = dm.getReshapedPermuted(r.shape, a, o)
              , h = dm.getSliceBeginCoords(i, a.length)
              , p = dm.getSliceSize(c, i, a.length)
              , d = ux({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    shape: l
                }
            })
              , f = kx({
                inputs: {
                    x: d
                },
                backend: n,
                attrs: {
                    perm: u
                }
            })
              , m = ux({
                inputs: {
                    x: f
                },
                backend: n,
                attrs: {
                    shape: c
                }
            })
              , g = Kx({
                inputs: {
                    x: m
                },
                backend: n,
                attrs: {
                    begin: h,
                    size: p
                }
            });
            return n.disposeIntermediateTensorInfo(d),
            n.disposeIntermediateTensorInfo(f),
            n.disposeIntermediateTensorInfo(m),
            g
        }
    };
    function Zx(e, t, n, s, r) {
        const a = Hs.sizeFromShape(s)
          , i = Hs.makeZerosTypedArray(r, n);
        for (let n = 0; n < e.length; n++) {
            const s = e[n];
            if (s < 0)
                throw new Error("Input x must be non-negative!");
            s >= r || (i[s] += a > 0 ? t[n] : 1)
        }
        return i
    }
    function Jx(e, t, n, s=!1) {
        const r = e.shape[0]
          , a = e.shape[1]
          , i = qo([r, n], t.dtype);
        for (let o = 0; o < r; o++)
            for (let r = 0; r < a; r++) {
                const a = e.get(o, r);
                if (a < 0)
                    throw new Error("Input x must be non-negative!");
                a >= n || (s ? i.set(1, o, a) : t.size > 0 ? i.set(i.get(o, a) + t.get(o, r), o, a) : i.set(i.get(o, a) + 1, o, a))
            }
        return i
    }
    const Qx = {
        kernelName: je,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, weights: a} = t
              , {size: i} = s
              , o = Zx(n.data.get(r.dataId).values, n.data.get(a.dataId).values, a.dtype, a.shape, i);
            return n.makeTensorInfo([i], a.dtype, o)
        }
    };
    const ew = {
        kernelName: qe,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {s0: s, s1: r} = t
              , a = n.data.get(s.dataId).values
              , i = n.data.get(r.dataId).values
              , o = dm.assertAndGetBroadcastShape(Array.from(a), Array.from(i));
            return n.makeTensorInfo([o.length], "int32", Int32Array.from(o))
        }
    }
      , tw = Gb((e=>Math.ceil(e)))
      , nw = Eb(Xe, tw)
      , sw = {
        kernelName: Xe,
        backendName: "cpu",
        kernelFunc: nw
    }
      , rw = $b(Ye, ((e,t)=>{
        const n = t;
        return e > n.clipValueMax ? n.clipValueMax : e < n.clipValueMin ? n.clipValueMin : e
    }
    ))
      , aw = {
        kernelName: Ye,
        backendName: "cpu",
        kernelFunc: rw
    }
      , iw = {
        kernelName: Je,
        backendName: "cpu",
        kernelFunc: e=>{
            const {x: t} = e.inputs
              , n = e.backend
              , s = new Float32Array(Hs.sizeFromShape(t.shape))
              , r = n.data.get(t.dataId)
              , a = r.complexTensorInfos.real
              , i = r.complexTensorInfos.imag
              , o = n.data.get(a.dataId).values
              , l = n.data.get(i.dataId).values;
            for (let e = 0; e < o.length; e++) {
                const t = o[e]
                  , n = l[e];
                s[e] = Math.hypot(t, n)
            }
            return n.makeOutput(s, t.shape, "float32")
        }
    };
    function ow(e, t, n, s) {
        const r = Hs.getArrayFromDType(n, Hs.sizeFromShape(t));
        if (s && "string" !== n) {
            let t = 0;
            e.forEach((e=>{
                const n = Hs.sizeFromShape(e.shape);
                r.set(e.vals, t),
                t += n
            }
            ))
        } else {
            let s = 0;
            e.forEach((e=>{
                const a = "string" === n ? dm.fromUint8ToStringArray(e.vals) : e.vals;
                let i = 0;
                for (let n = 0; n < e.shape[0]; ++n) {
                    const o = n * t[1] + s;
                    for (let t = 0; t < e.shape[1]; ++t)
                        r[o + t] = a[i++]
                }
                s += e.shape[1]
            }
            ))
        }
        return r
    }
    function lw(e) {
        const {inputs: t, backend: n} = e
          , {input: s} = t
          , r = n.data.get(s.dataId).complexTensorInfos.imag
          , a = n.data.get(r.dataId).values;
        return n.makeTensorInfo(r.shape, r.dtype, a)
    }
    const uw = {
        kernelName: Wt,
        backendName: "cpu",
        kernelFunc: lw
    };
    function cw(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {axis: r} = s
          , a = Hs.parseAxisParam(r, t[0].shape)[0]
          , i = t.map((e=>e.shape));
        dm.assertParamsConsistent(i, a);
        let o = dm.computeOutShape(t.map((e=>e.shape)), a);
        if (0 === Hs.sizeFromShape(o))
            return n.makeTensorInfo(o, t[0].dtype, []);
        const l = t.filter((e=>Hs.sizeFromShape(e.shape) > 0));
        if (1 === l.length)
            return Fb({
                inputs: {
                    x: l[0]
                },
                backend: n
            });
        if ("complex64" === l[0].dtype) {
            const e = l.map((e=>Jb({
                inputs: {
                    input: e
                },
                backend: n
            })))
              , t = l.map((e=>lw({
                inputs: {
                    input: e
                },
                backend: n
            })))
              , s = cw({
                inputs: e,
                backend: n,
                attrs: {
                    axis: a
                }
            })
              , r = cw({
                inputs: t,
                backend: n,
                attrs: {
                    axis: a
                }
            })
              , i = Xb({
                inputs: {
                    real: s,
                    imag: r
                },
                backend: n
            });
            return e.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            t.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            n.disposeIntermediateTensorInfo(s),
            n.disposeIntermediateTensorInfo(r),
            i
        }
        const u = l.map((e=>{
            const t = Hs.sizeFromShape(e.shape.slice(a));
            return ux({
                inputs: {
                    x: e
                },
                backend: n,
                attrs: {
                    shape: [-1, t]
                }
            })
        }
        ))
          , c = u.map((e=>({
            vals: n.data.get(e.dataId).values,
            shape: e.shape
        })));
        o = dm.computeOutShape(u.map((e=>e.shape)), 1);
        const h = 1 === u[0].shape[0]
          , p = ow(c, o, t[0].dtype, h)
          , d = dm.computeOutShape(l.map((e=>e.shape)), a)
          , f = n.makeTensorInfo(d, t[0].dtype, p);
        return u.forEach((e=>n.disposeIntermediateTensorInfo(e))),
        f
    }
    const hw = {
        kernelName: Qe,
        backendName: "cpu",
        kernelFunc: cw
    };
    function pw(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {x: r, filter: a} = t
          , {strides: i, pad: o, dataFormat: l, dilations: u, dimRoundingMode: c} = s;
        Cb([r, a], "conv2d");
        const h = dm.convertConv2DDataFormat(l)
          , p = dm.computeConv2DInfo(r.shape, a.shape, i, u, o, c, !1, h)
          , d = p.filterHeight
          , f = p.filterWidth
          , m = p.dilationHeight
          , g = p.dilationWidth
          , y = p.padInfo.left
          , b = p.padInfo.top
          , x = "channelsLast" === p.dataFormat
          , w = new qr(p.outShape,r.dtype)
          , v = Hs.computeStrides(r.shape)
          , k = Hs.computeStrides(a.shape)
          , I = v[0]
          , S = x ? v[1] : v[2]
          , N = x ? v[2] : 1
          , T = x ? 1 : v[1]
          , C = w.strides[0]
          , $ = x ? w.strides[1] : w.strides[2]
          , E = x ? w.strides[2] : 1
          , A = x ? 1 : w.strides[1]
          , R = n.data.get(r.dataId).values
          , F = n.data.get(a.dataId).values
          , D = w.values;
        for (let e = 0; e < p.batchSize; ++e) {
            const t = e * I
              , n = e * C;
            for (let e = 0; e < p.outHeight; ++e) {
                const s = n + e * $
                  , r = e * p.strideHeight - b;
                for (let e = 0; e < d; ++e) {
                    const n = r + e * m;
                    if (n < 0 || n >= p.inHeight)
                        continue;
                    const a = e * k[0]
                      , i = t + n * S;
                    for (let e = 0; e < p.outWidth; ++e) {
                        const t = s + e * E
                          , n = e * p.strideWidth - y;
                        for (let e = 0; e < f; ++e) {
                            const s = n + e * g;
                            if (s < 0 || s >= p.inWidth)
                                continue;
                            const r = i + s * N;
                            let o = a + e * k[1];
                            for (let e = 0; e < p.inChannels; ++e) {
                                const n = R[r + e * T];
                                for (let e = 0; e < p.outChannels; ++e)
                                    D[t + e * A] += n * F[o + e];
                                o += p.outChannels
                            }
                        }
                    }
                }
            }
        }
        return n.makeTensorInfo(w.shape, w.dtype, D)
    }
    const dw = {
        kernelName: et,
        backendName: "cpu",
        kernelFunc: pw
    };
    const fw = {
        kernelName: tt,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, dy: a} = t
              , {strides: i, pad: o, dataFormat: l, dimRoundingMode: u, filterShape: c} = s;
            Cb([r, a], "conv2dBackpropFilter");
            const h = dm.convertConv2DDataFormat(l)
              , p = dm.computeConv2DInfo(r.shape, c, i, 1, o, u, !1, h)
              , {strideHeight: d, strideWidth: f, filterHeight: m, filterWidth: g} = p
              , y = "channelsLast" === p.dataFormat
              , b = new qr(p.filterShape,"float32")
              , x = p.padInfo.left
              , w = p.padInfo.top
              , v = n.data.get(r.dataId).values
              , k = n.data.get(a.dataId).values
              , I = new qr(r.shape,r.dtype,v)
              , S = new qr(a.shape,a.dtype,k);
            for (let e = 0; e < m; ++e) {
                const t = Math.max(0, Math.ceil((w - e) / d))
                  , n = Math.min(p.outHeight, (p.inHeight + w - e) / d);
                for (let s = 0; s < g; ++s) {
                    const r = Math.max(0, Math.ceil((x - s) / f))
                      , a = Math.min(p.outWidth, (p.inWidth + x - s) / f);
                    for (let i = 0; i < p.inChannels; ++i)
                        for (let o = 0; o < p.outChannels; ++o) {
                            let l = 0;
                            for (let u = 0; u < p.batchSize; ++u)
                                for (let c = t; c < n; ++c) {
                                    const t = e + c * d - w;
                                    for (let e = r; e < a; ++e) {
                                        const n = s + e * f - x;
                                        l += y ? I.get(u, t, n, i) * S.get(u, c, e, o) : I.get(u, i, t, n) * S.get(u, o, c, e)
                                    }
                                }
                            b.set(l, e, s, i, o)
                        }
                }
            }
            return n.makeTensorInfo(b.shape, b.dtype, b.values)
        }
    };
    const mw = {
        kernelName: nt,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {dy: r, filter: a} = t
              , {inputShape: i, strides: o, pad: l, dataFormat: u, dimRoundingMode: c} = s;
            Cb([r, a], "conv2dBackpropInput");
            const h = Hs.computeStrides(a.shape)
              , p = Hs.computeStrides(r.shape);
            let d = dm.convertConv2DDataFormat(u);
            const f = dm.computeConv2DInfo(i, a.shape, o, 1, l, c, !1, d)
              , m = new qr(f.inShape,"float32")
              , g = m.values
              , y = n.data.get(r.dataId).values
              , b = n.data.get(a.dataId).values
              , [x,w,v] = h
              , {batchSize: k, filterHeight: I, filterWidth: S, inChannels: N, inHeight: T, inWidth: C, outChannels: $, outHeight: E, outWidth: A, strideHeight: R, strideWidth: F} = f;
            d = f.dataFormat;
            const D = I - 1 - f.padInfo.top
              , _ = S - 1 - f.padInfo.left
              , O = "channelsLast" === d
              , M = m.strides[0]
              , L = O ? m.strides[1] : m.strides[2]
              , z = O ? m.strides[2] : 1
              , B = O ? 1 : m.strides[1]
              , P = p[0]
              , W = O ? p[1] : p[2]
              , U = O ? p[2] : 1
              , V = O ? 1 : p[1];
            for (let e = 0; e < k; ++e)
                for (let t = 0; t < N; ++t)
                    for (let n = 0; n < T; ++n) {
                        const s = n - D
                          , r = Math.max(0, Math.ceil(s / R))
                          , a = Math.min(E, (I + s) / R);
                        for (let i = 0; i < C; ++i) {
                            const o = i - _
                              , l = Math.max(0, Math.ceil(o / F))
                              , u = Math.min(A, (S + o) / F);
                            let c = 0;
                            for (let n = r; n < a; ++n) {
                                const r = n * R - s;
                                for (let s = l; s < u; ++s) {
                                    const a = P * e + W * n + U * s
                                      , i = x * (I - 1 - r) + w * (S - 1 - (s * F - o)) + v * t;
                                    for (let e = 0; e < $; ++e) {
                                        c += y[a + V * e] * b[i + e]
                                    }
                                }
                            }
                            g[M * e + L * n + z * i + B * t] = c
                        }
                    }
            return n.makeTensorInfo(m.shape, m.dtype, m.values)
        }
    };
    const gw = {
        kernelName: st,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, filter: a} = t
              , {strides: i, pad: o, dilations: l} = s;
            Cb([r, a], "conv3d");
            const u = dm.computeConv3DInfo(r.shape, a.shape, i, l, o)
              , {filterDepth: c, filterHeight: h, filterWidth: p, dilationDepth: d, dilationHeight: f, dilationWidth: m, padInfo: g} = u
              , y = g.front
              , b = g.left
              , x = g.top
              , w = new qr(u.outShape,r.dtype)
              , v = n.data.get(r.dataId).values
              , k = n.data.get(a.dataId).values
              , I = w.values
              , S = Hs.computeStrides(r.shape)
              , N = Hs.computeStrides(a.shape);
            for (let e = 0; e < u.batchSize; ++e) {
                const t = e * S[0]
                  , n = e * w.strides[0];
                for (let e = 0; e < u.outDepth; ++e) {
                    const s = n + e * w.strides[1]
                      , r = e * u.strideDepth - y;
                    for (let e = 0; e < c; ++e) {
                        const n = r + e * d;
                        if (n < 0 || n >= u.inDepth)
                            continue;
                        const a = e * N[0]
                          , i = t + n * S[1];
                        for (let e = 0; e < u.outHeight; ++e) {
                            const t = s + e * w.strides[2]
                              , n = e * u.strideHeight - x;
                            for (let e = 0; e < h; ++e) {
                                const s = n + e * f;
                                if (s < 0 || s >= u.inHeight)
                                    continue;
                                const r = a + e * N[1]
                                  , o = i + s * S[2];
                                for (let e = 0; e < u.outWidth; ++e) {
                                    const n = t + e * u.outChannels
                                      , s = e * u.strideWidth - b;
                                    for (let e = 0; e < p; ++e) {
                                        const t = s + e * m;
                                        if (t < 0 || t >= u.inWidth)
                                            continue;
                                        const a = r + e * N[2]
                                          , i = o + t * u.inChannels;
                                        let l = a;
                                        for (let e = 0; e < u.inChannels; ++e) {
                                            const t = v[i + e];
                                            for (let e = 0; e < u.outChannels; ++e)
                                                I[n + e] += t * k[l + e];
                                            l += u.outChannels
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }
            return n.makeTensorInfo(w.shape, w.dtype, w.values)
        }
    };
    const yw = {
        kernelName: rt,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, dy: a} = t
              , {strides: i, pad: o, filterShape: l} = s;
            Cb([r, a], "conv3dBackpropFilterV2");
            const u = Hs.computeStrides(r.shape)
              , c = Hs.computeStrides(a.shape)
              , h = dm.computeConv3DInfo(r.shape, l, i, 1, o)
              , p = h.strideDepth
              , d = h.strideHeight
              , f = h.strideWidth
              , m = h.filterDepth
              , g = h.filterHeight
              , y = h.filterWidth
              , b = new qr(h.filterShape,"float32")
              , x = b.values
              , [w,v,k,I] = b.strides
              , S = n.data.get(a.dataId).values
              , [N,T,C,$] = c
              , E = n.data.get(r.dataId).values
              , [A,R,F,D] = u
              , _ = h.padInfo.front
              , O = h.padInfo.left
              , M = h.padInfo.top;
            for (let e = 0; e < m; ++e) {
                const t = Math.max(0, Math.ceil((_ - e) / p))
                  , n = Math.min(h.outDepth, (h.inDepth + _ - e) / p)
                  , s = e * w;
                for (let r = 0; r < g; ++r) {
                    const a = Math.max(0, Math.ceil((M - r) / d))
                      , i = Math.min(h.outHeight, (h.inHeight + M - r) / d)
                      , o = r * v + s;
                    for (let s = 0; s < y; ++s) {
                        const l = Math.max(0, Math.ceil((O - s) / f))
                          , u = Math.min(h.outWidth, (h.inWidth + O - s) / f)
                          , c = s * k + o;
                        for (let o = 0; o < h.inChannels; ++o) {
                            const m = o * I + c;
                            for (let c = 0; c < h.outChannels; ++c) {
                                let g = 0;
                                for (let m = 0; m < h.batchSize; ++m) {
                                    const h = m * A
                                      , y = m * N;
                                    for (let m = t; m < n; ++m) {
                                        const t = (e + m * p - _) * R + h
                                          , n = m * T + y;
                                        for (let e = a; e < i; ++e) {
                                            const a = (r + e * d - M) * F + t
                                              , i = e * C + n;
                                            for (let e = l; e < u; ++e) {
                                                const t = e * $ + i;
                                                g += E[(s + e * f - O) * D + a + o] * S[t + c]
                                            }
                                        }
                                    }
                                }
                                x[m + c] = g
                            }
                        }
                    }
                }
            }
            return n.makeTensorInfo(b.shape, b.dtype, b.values)
        }
    };
    const bw = {
        kernelName: at,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {dy: r, filter: a} = t
              , {pad: i, strides: o, inputShape: l} = s;
            Cb([r], "conv3dBackpropInputV2");
            const u = Hs.computeStrides(r.shape)
              , c = Hs.computeStrides(a.shape)
              , h = dm.computeConv3DInfo(l, a.shape, o, 1, i)
              , p = new qr(h.inShape,"float32")
              , d = p.values
              , [f,m,g,y] = p.strides
              , b = n.data.get(r.dataId).values
              , [x,w,v,k] = u
              , I = n.data.get(a.dataId).values
              , [S,N,T,C] = c
              , {batchSize: $, filterDepth: E, filterHeight: A, filterWidth: R, inChannels: F, inDepth: D, inHeight: _, inWidth: O, outChannels: M, outDepth: L, outHeight: z, outWidth: B, strideDepth: P, strideHeight: W, strideWidth: U} = h
              , V = E - 1 - h.padInfo.front
              , G = A - 1 - h.padInfo.top
              , H = R - 1 - h.padInfo.left;
            for (let e = 0; e < $; ++e)
                for (let t = 0; t < F; ++t)
                    for (let n = 0; n < D; ++n) {
                        const s = n - V
                          , r = Math.max(0, Math.ceil(s / P))
                          , a = Math.min(L, (E + s) / P);
                        for (let i = 0; i < _; ++i) {
                            const o = i - G
                              , l = Math.max(0, Math.ceil(o / W))
                              , u = Math.min(z, (A + o) / W);
                            for (let c = 0; c < O; ++c) {
                                const h = c - H
                                  , p = Math.max(0, Math.ceil(h / U))
                                  , $ = Math.min(B, (R + h) / U);
                                let F = 0;
                                for (let n = r; n < a; ++n) {
                                    const r = n * P - s;
                                    for (let s = l; s < u; ++s) {
                                        const a = s * W - o;
                                        for (let i = p; i < $; ++i) {
                                            const o = x * e + w * n + v * s + k * i
                                              , l = S * (E - 1 - r) + N * (A - 1 - a) + T * (R - 1 - (i * U - h)) + C * t;
                                            for (let e = 0; e < M; ++e) {
                                                F += b[o + e] * I[l + e]
                                            }
                                        }
                                    }
                                }
                                d[f * e + m * n + g * i + y * c + t] = F
                            }
                        }
                    }
            return n.makeTensorInfo(p.shape, p.dtype, p.values)
        }
    }
      , xw = $b(it, (e=>Math.cos(e)))
      , ww = {
        kernelName: it,
        backendName: "cpu",
        kernelFunc: xw
    }
      , vw = $b(ot, (e=>Math.cosh(e)))
      , kw = {
        kernelName: ot,
        backendName: "cpu",
        kernelFunc: vw
    };
    const Iw = {
        kernelName: ct,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {image: r, boxes: a, boxInd: i} = t
              , {cropSize: o, method: l, extrapolationValue: u} = s
              , [c,h,p,d] = r.shape
              , f = a.shape[0]
              , [m,g] = o
              , y = qo([f, m, g, d], "float32")
              , b = n.data.get(a.dataId).values
              , x = n.data.get(i.dataId).values
              , w = n.data.get(r.dataId).values
              , v = Hs.computeStrides(r.shape)
              , k = Hs.computeStrides(y.shape);
            for (let e = 0; e < f; e++) {
                const t = 4 * e
                  , n = b[t]
                  , s = b[t + 1]
                  , r = b[t + 2]
                  , a = b[t + 3]
                  , i = x[e];
                if (i >= c)
                    continue;
                const o = m > 1 ? (r - n) * (h - 1) / (m - 1) : 0
                  , f = g > 1 ? (a - s) * (p - 1) / (g - 1) : 0;
                for (let t = 0; t < m; t++) {
                    const c = m > 1 ? n * (h - 1) + t * o : .5 * (n + r) * (h - 1);
                    if (c < 0 || c > h - 1)
                        for (let n = 0; n < g; n++)
                            for (let s = 0; s < d; s++) {
                                const r = s + n * k[2] + t * k[1] + e * k[0];
                                y.values[r] = u
                            }
                    else if ("bilinear" === l) {
                        const n = Math.floor(c)
                          , r = Math.ceil(c)
                          , o = c - n;
                        for (let l = 0; l < g; l++) {
                            const c = g > 1 ? s * (p - 1) + l * f : .5 * (s + a) * (p - 1);
                            if (c < 0 || c > p - 1) {
                                for (let n = 0; n < d; n++) {
                                    const s = n + l * k[2] + t * k[1] + e * k[0];
                                    y.values[s] = u
                                }
                                continue
                            }
                            const h = Math.floor(c)
                              , m = Math.ceil(c)
                              , b = c - h;
                            for (let s = 0; s < d; s++) {
                                let a = s + h * v[2] + n * v[1] + i * v[0];
                                const u = w[a];
                                a = s + m * v[2] + n * v[1] + i * v[0];
                                const c = w[a];
                                a = s + h * v[2] + r * v[1] + i * v[0];
                                const p = w[a];
                                a = s + m * v[2] + r * v[1] + i * v[0];
                                const d = u + (c - u) * b
                                  , f = p + (w[a] - p) * b;
                                a = s + l * k[2] + t * k[1] + e * k[0],
                                y.values[a] = d + (f - d) * o
                            }
                        }
                    } else
                        for (let n = 0; n < g; ++n) {
                            const r = g > 1 ? s * (p - 1) + n * f : .5 * (s + a) * (p - 1);
                            if (r < 0 || r > p - 1) {
                                for (let s = 0; s < d; s++) {
                                    const r = s + n * k[2] + t * k[1] + e * k[0];
                                    y.values[r] = u
                                }
                                continue
                            }
                            const o = Math.round(r)
                              , l = Math.round(c);
                            for (let s = 0; s < d; s++) {
                                const r = s + o * v[2] + l * v[1] + i * v[0]
                                  , a = s + n * k[2] + t * k[1] + e * k[0];
                                y.values[a] = w[r]
                            }
                        }
                }
            }
            return n.makeTensorInfo(y.shape, y.dtype, y.values)
        }
    };
    const Sw = {
        kernelName: lt,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {axis: a, exclusive: i, reverse: o} = s;
            Cb(r, "cumprod");
            const l = dm.getAxesPermutation([a], r.shape.length);
            let u = r;
            null != l && (u = kx({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    perm: l
                }
            }));
            const c = dm.getInnerMostAxes(1, r.shape.length)[0];
            if (c !== u.shape.length - 1)
                throw new Error(`backend.cumprod in CPU expects an inner-most axis=${u.shape.length - 1} but got axis=${c}`);
            const h = ha(u.dtype, "int32")
              , p = Hs.makeOnesTypedArray(Hs.sizeFromShape(u.shape), h)
              , d = n.data.get(u.dataId).values
              , f = u.shape[u.shape.length - 1]
              , m = o ? (e,t)=>e + f - t - 1 : (e,t)=>e + t;
            for (let e = 0; e < d.length; e += f)
                for (let t = 0; t < f; t++) {
                    const n = m(e, t);
                    if (0 === t)
                        p[n] = i ? 1 : d[n];
                    else {
                        const s = m(e, t - 1);
                        p[n] = i ? d[s] * p[s] : d[n] * p[s]
                    }
                }
            const g = n.makeTensorInfo(u.shape, h, p);
            if (null != l) {
                const e = kx({
                    inputs: {
                        x: g
                    },
                    backend: n,
                    attrs: {
                        perm: dm.getUndoAxesPermutation(l)
                    }
                });
                return n.disposeIntermediateTensorInfo(g),
                n.disposeIntermediateTensorInfo(u),
                e
            }
            return g
        }
    };
    const Nw = {
        kernelName: ut,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {axis: a, exclusive: i, reverse: o} = s;
            Cb(r, "cumsum");
            const l = dm.getAxesPermutation([a], r.shape.length);
            let u = r;
            null != l && (u = kx({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    perm: l
                }
            }));
            const c = dm.getInnerMostAxes(1, r.shape.length)[0];
            if (c !== u.shape.length - 1)
                throw new Error(`backend.cumsum in CPU expects an inner-most axis=${u.shape.length - 1} but got axis=${c}`);
            const h = ha(u.dtype, "int32")
              , p = Hs.makeZerosTypedArray(Hs.sizeFromShape(u.shape), h)
              , d = n.data.get(u.dataId).values
              , f = u.shape[u.shape.length - 1]
              , m = o ? (e,t)=>e + f - t - 1 : (e,t)=>e + t;
            for (let e = 0; e < d.length; e += f)
                for (let t = 0; t < f; t++) {
                    const n = m(e, t);
                    if (0 === t)
                        p[n] = i ? 0 : d[n];
                    else {
                        const s = m(e, t - 1);
                        p[n] = i ? d[s] + p[s] : d[n] + p[s]
                    }
                }
            const g = n.makeTensorInfo(u.shape, h, p);
            if (null != l) {
                const e = kx({
                    inputs: {
                        x: g
                    },
                    backend: n,
                    attrs: {
                        perm: dm.getUndoAxesPermutation(l)
                    }
                });
                return n.disposeIntermediateTensorInfo(g),
                n.disposeIntermediateTensorInfo(u),
                e
            }
            return g
        }
    };
    const Tw = {
        kernelName: ht,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, weights: a} = t
              , {size: i, binaryOutput: o} = s;
            if (1 === r.shape.length) {
                const e = Zx(n.data.get(r.dataId).values, n.data.get(a.dataId).values, a.dtype, a.shape, i);
                return n.makeTensorInfo([i], a.dtype, e)
            }
            if (2 === r.shape.length) {
                const e = Jx(n.bufferSync(r), n.bufferSync(a), i, o);
                return n.makeTensorInfo(e.shape, a.dtype, e.values)
            }
            throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${r.shape.length}.`)
        }
    };
    const Cw = {
        kernelName: pt,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {blockSize: a, dataFormat: i} = s;
            Hs.assert("NHWC" === i, (()=>`Only NHWC dataFormat supported on CPU for depthToSpace. Got ${i}`));
            const o = r.shape[0]
              , l = r.shape[1]
              , u = r.shape[2]
              , c = r.shape[3]
              , h = l * a
              , p = u * a
              , d = c / (a * a)
              , f = n.data.get(r.dataId).values
              , m = new Float32Array(o * h * p * d);
            let g = 0;
            for (let e = 0; e < o; ++e)
                for (let t = 0; t < h; ++t) {
                    const n = Math.floor(t / a)
                      , s = t % a;
                    for (let t = 0; t < p; ++t) {
                        const r = Math.floor(t / a)
                          , i = (s * a + t % a) * d;
                        for (let t = 0; t < d; ++t) {
                            const s = t + i + c * (r + u * (n + l * e));
                            m[g++] = f[s]
                        }
                    }
                }
            return n.makeTensorInfo([o, h, p, d], r.dtype, m)
        }
    };
    function $w(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {x: r, filter: a} = t
          , {strides: i, pad: o, dilations: l, dimRoundingMode: u} = s;
        Cb([r, a], "depthwiseConv2DNative");
        const c = Hs.computeStrides(r.shape)
          , h = Hs.computeStrides(a.shape);
        let p = l;
        null == p && (p = [1, 1]),
        Hs.assert(dm.eitherStridesOrDilationsAreOne(i, p), (()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${i} and dilations '${p}'`));
        const d = dm.computeConv2DInfo(r.shape, a.shape, i, p, o, u, !0)
          , {filterHeight: f, filterWidth: m, dilationHeight: g, dilationWidth: y, padInfo: b} = d
          , x = b.left
          , w = b.top
          , v = d.outChannels / d.inChannels
          , k = new qr(d.outShape,r.dtype)
          , I = n.data.get(r.dataId).values
          , S = n.data.get(a.dataId).values
          , N = k.values;
        for (let e = 0; e < d.batchSize; ++e) {
            const t = e * c[0]
              , n = e * k.strides[0];
            for (let e = 0; e < d.outHeight; ++e) {
                const s = n + e * k.strides[1]
                  , r = e * d.strideHeight - w;
                for (let e = 0; e < f; ++e) {
                    const n = r + e * g;
                    if (n < 0 || n >= d.inHeight)
                        continue;
                    const a = e * h[0]
                      , i = t + n * c[1];
                    for (let e = 0; e < d.outWidth; ++e) {
                        const t = s + e * k.strides[2]
                          , n = e * d.strideWidth - x;
                        for (let e = 0; e < m; ++e) {
                            const s = n + e * y;
                            if (s < 0 || s >= d.inWidth)
                                continue;
                            const r = a + e * h[1]
                              , o = i + s * d.inChannels;
                            let l = t
                              , u = r;
                            for (let e = 0; e < d.inChannels; ++e) {
                                const t = I[o + e];
                                for (let e = 0; e < v; ++e)
                                    N[l + e] += t * S[u + e];
                                l += v,
                                u += v
                            }
                        }
                    }
                }
            }
        }
        return n.makeTensorInfo(k.shape, k.dtype, k.values)
    }
    const Ew = {
        kernelName: dt,
        backendName: "cpu",
        kernelFunc: $w
    };
    const Aw = {
        kernelName: ft,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, dy: a} = t
              , {strides: i, dilations: o, pad: l, dimRoundingMode: u, filterShape: c} = s;
            Cb([r, a], "depthwiseConv2dNativeBackpropFilter");
            const h = dm.computeConv2DInfo(r.shape, c, i, o, l, u, !0)
              , {strideHeight: p, strideWidth: d, filterHeight: f, filterWidth: m} = h
              , g = new qr(h.filterShape,"float32")
              , y = h.padInfo.left
              , b = h.padInfo.top
              , x = h.outChannels / h.inChannels
              , w = n.data.get(r.dataId).values
              , v = new qr(r.shape,r.dtype,w)
              , k = n.data.get(a.dataId).values
              , I = new qr(a.shape,a.dtype,k);
            for (let e = 0; e < f; ++e) {
                const t = Math.max(0, Math.ceil((b - e) / p))
                  , n = Math.min(h.outHeight, (h.inHeight + b - e) / p);
                for (let s = 0; s < m; ++s) {
                    const r = Math.max(0, Math.ceil((y - s) / d))
                      , a = Math.min(h.outWidth, (h.inWidth + y - s) / d);
                    for (let i = 0; i < h.outChannels; ++i) {
                        const o = Math.trunc(i / x)
                          , l = i % x;
                        let u = 0;
                        for (let l = 0; l < h.batchSize; ++l)
                            for (let c = t; c < n; ++c) {
                                const t = e + c * p - b;
                                for (let e = r; e < a; ++e) {
                                    const n = s + e * d - y;
                                    u += v.get(l, t, n, o) * I.get(l, c, e, i)
                                }
                            }
                        g.set(u, e, s, o, l)
                    }
                }
            }
            return n.makeTensorInfo(g.shape, g.dtype, g.values)
        }
    };
    const Rw = {
        kernelName: mt,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {dy: r, filter: a} = t
              , {strides: i, dilations: o, pad: l, dimRoundingMode: u, inputShape: c} = s;
            Cb([r, a], "depthwiseConv2DNativeBackpropInput");
            const h = Hs.computeStrides(r.shape)
              , p = Hs.computeStrides(a.shape)
              , d = dm.computeConv2DInfo(c, a.shape, i, o, l, u, !0)
              , f = new qr(d.inShape,"float32")
              , m = f.values
              , [g,y,b] = f.strides
              , x = n.data.get(r.dataId).values
              , [w,v,k] = h
              , I = n.data.get(a.dataId).values
              , [S,N,T] = p
              , {batchSize: C, filterHeight: $, filterWidth: E, inChannels: A, inHeight: R, inWidth: F, outChannels: D, outHeight: _, outWidth: O, strideHeight: M, strideWidth: L} = d
              , z = $ - 1 - d.padInfo.top
              , B = E - 1 - d.padInfo.left
              , P = D / A;
            for (let e = 0; e < C; ++e)
                for (let t = 0; t < A; ++t)
                    for (let n = 0; n < R; ++n) {
                        const s = n - z
                          , r = Math.max(0, Math.ceil(s / M))
                          , a = Math.min(_, ($ + s) / M);
                        for (let i = 0; i < F; ++i) {
                            const o = i - B
                              , l = Math.max(0, Math.ceil(o / L))
                              , u = Math.min(O, (E + o) / L);
                            let c = 0;
                            for (let n = r; n < a; ++n) {
                                const r = n * M - s;
                                for (let s = l; s < u; ++s) {
                                    const a = w * e + v * n + k * s
                                      , i = S * ($ - 1 - r) + N * (E - 1 - (s * L - o)) + T * t;
                                    for (let e = 0; e < P; ++e) {
                                        c += x[a + (t * P + e)] * I[i + e]
                                    }
                                }
                            }
                            m[g * e + y * n + b * i + t] = c
                        }
                    }
            return n.makeTensorInfo(f.shape, f.dtype, f.values)
        }
    };
    const Fw = {
        kernelName: gt,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {x: s} = t
              , r = Hs.sizeFromShape(s.shape)
              , a = n.data.get(s.dataId).values
              , i = qo([r, r], s.dtype)
              , o = i.values;
            for (let e = 0; e < a.length; e++)
                o[e * r + e] = a[e];
            const l = [...s.shape, ...s.shape];
            return n.makeTensorInfo(l, i.dtype, i.values)
        }
    }
      , Dw = {
        kernelName: yt,
        backendName: "cpu",
        kernelFunc: ({inputs: e, backend: t, attrs: n})=>{
            const {x: s, filter: r} = e
              , {strides: a, pad: i, dilations: o} = n
              , l = t
              , u = l.data.get(s.dataId).values
              , c = s.shape.length
              , h = l.data.get(r.dataId).values
              , p = r.shape.length
              , {batchSize: d, inHeight: f, inWidth: m, inChannels: g, outHeight: y, outWidth: b, padInfo: x, strideHeight: w, strideWidth: v, filterHeight: k, filterWidth: I, dilationHeight: S, dilationWidth: N, outShape: T} = dm.computeDilation2DInfo(s.shape, r.shape, a, i, "NHWC", o)
              , C = Hs.sizeFromShape(T)
              , $ = T.length
              , E = Hs.getArrayFromDType(s.dtype, C);
            for (let e = 0; e < d; ++e)
                for (let t = 0; t < y; ++t) {
                    const n = t * w - x.top;
                    for (let a = 0; a < b; ++a) {
                        const i = a * v - x.left;
                        for (let o = 0; o < g; ++o) {
                            let l = Number.MIN_SAFE_INTEGER;
                            for (let t = 0; t < k; ++t) {
                                const a = n + t * S;
                                if (a >= 0 && a < f)
                                    for (let n = 0; n < I; ++n) {
                                        const d = i + n * N;
                                        if (d >= 0 && d < m) {
                                            const i = Hs.locToIndex([e, a, d, o], c, Hs.computeStrides(s.shape))
                                              , f = Hs.locToIndex([t, n, o], p, Hs.computeStrides(r.shape))
                                              , m = u[i] + h[f];
                                            m > l && (l = m)
                                        }
                                    }
                            }
                            E[Hs.locToIndex([e, t, a, o], $, Hs.computeStrides(T))] = l
                        }
                    }
                }
            return {
                dataId: l.write(Hs.toTypedArray(E, s.dtype), T, s.dtype),
                shape: T,
                dtype: s.dtype
            }
        }
    }
      , _w = {
        kernelName: xt,
        backendName: "cpu",
        kernelFunc: ({inputs: e, backend: t, attrs: n})=>{
            const {x: s, filter: r, dy: a} = e
              , {strides: i, pad: o, dilations: l} = n
              , u = t
              , c = Hs.toNestedArray(s.shape, u.data.get(s.dataId).values)
              , h = Hs.toNestedArray(r.shape, u.data.get(r.dataId).values)
              , {batchSize: p, inHeight: d, inWidth: f, inChannels: m, outHeight: g, outWidth: y, padInfo: b, strideHeight: x, strideWidth: w, filterHeight: v, filterWidth: k, dilationHeight: I, dilationWidth: S, outShape: N} = dm.computeDilation2DInfo(s.shape, r.shape, i, o, "NHWC", l);
            Hs.assert(a.rank === N.length, (()=>`Error in Dilation2DBackpropFilter, dy must have the same rank as output ${N.length}, but got ${a.rank}`));
            const T = Hs.toNestedArray(N, u.data.get(a.dataId).values)
              , C = Hs.makeZerosNestedTypedArray(r.shape, r.dtype);
            for (let e = 0; e < p; ++e)
                for (let t = 0; t < g; ++t) {
                    const n = t * x - b.top;
                    for (let s = 0; s < y; ++s) {
                        const r = s * w - b.left;
                        for (let a = 0; a < m; ++a) {
                            let i = Number.MIN_SAFE_INTEGER
                              , o = 0
                              , l = 0;
                            for (let t = 0; t < v; ++t) {
                                const s = n + t * I;
                                if (s >= 0 && s < d)
                                    for (let n = 0; n < k; ++n) {
                                        const u = r + n * S;
                                        if (u >= 0 && u < f) {
                                            const r = c[e][s][u][a] + h[t][n][a];
                                            r > i && (i = r,
                                            o = t,
                                            l = n)
                                        }
                                    }
                            }
                            C[o][l][a] += T[e][t][s][a]
                        }
                    }
                }
            return {
                dataId: u.write(Hs.toTypedArray(C, s.dtype), r.shape, r.dtype),
                shape: r.shape,
                dtype: r.dtype
            }
        }
    }
      , Ow = {
        kernelName: bt,
        backendName: "cpu",
        kernelFunc: ({inputs: e, backend: t, attrs: n})=>{
            const {x: s, filter: r, dy: a} = e
              , {strides: i, pad: o, dilations: l} = n
              , u = t
              , c = Hs.toNestedArray(s.shape, u.data.get(s.dataId).values)
              , h = Hs.toNestedArray(r.shape, u.data.get(r.dataId).values)
              , {batchSize: p, inHeight: d, inWidth: f, inChannels: m, outHeight: g, outWidth: y, padInfo: b, strideHeight: x, strideWidth: w, filterHeight: v, filterWidth: k, dilationHeight: I, dilationWidth: S, outShape: N} = dm.computeDilation2DInfo(s.shape, r.shape, i, o, "NHWC", l);
            Hs.assert(a.rank === N.length, (()=>`Error in Dilation2DBackpropInput, dy must have the same rank as output ${N.length}, but got ${a.rank}`));
            const T = Hs.toNestedArray(N, u.data.get(a.dataId).values)
              , C = Hs.makeZerosNestedTypedArray(s.shape, s.dtype);
            for (let e = 0; e < p; ++e)
                for (let t = 0; t < g; ++t) {
                    const n = t * x - b.top;
                    for (let s = 0; s < y; ++s) {
                        const r = s * w - b.left;
                        for (let a = 0; a < m; ++a) {
                            let i = Number.MIN_SAFE_INTEGER
                              , o = n < 0 ? 0 : n
                              , l = r < 0 ? 0 : r;
                            for (let t = 0; t < v; ++t) {
                                const s = n + t * I;
                                if (s >= 0 && s < d)
                                    for (let n = 0; n < k; ++n) {
                                        const u = r + n * S;
                                        if (u >= 0 && u < f) {
                                            const r = c[e][s][u][a] + h[t][n][a];
                                            r > i && (i = r,
                                            o = s,
                                            l = u)
                                        }
                                    }
                            }
                            C[e][o][l][a] += T[e][t][s][a]
                        }
                    }
                }
            return {
                dataId: u.write(Hs.toTypedArray(C, s.dtype), s.shape, s.dtype),
                shape: s.shape,
                dtype: s.dtype
            }
        }
    }
      , Mw = Mb(((e,t)=>e * t))
      , Lw = rx(((e,t,n,s)=>({
        real: e * n - t * s,
        imag: e * s + t * n
    })))
      , zw = sx(gn, Mw, Lw)
      , Bw = {
        kernelName: gn,
        backendName: "cpu",
        kernelFunc: zw
    };
    function Pw(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {x: r} = t
          , {axis: a, keepDims: i} = s;
        let o;
        Cb(r, "sum"),
        o = "bool" === r.dtype ? tx({
            inputs: {
                x: r
            },
            backend: n,
            attrs: {
                dtype: "int32"
            }
        }) : Fb({
            inputs: {
                x: r
            },
            backend: n
        });
        const l = o.shape.length
          , u = Hs.parseAxisParam(a, o.shape)
          , c = dm.getAxesPermutation(u, l);
        let h = u
          , p = o;
        null != c && (p = kx({
            inputs: {
                x: o
            },
            backend: n,
            attrs: {
                perm: c
            }
        }),
        h = dm.getInnerMostAxes(h.length, l)),
        dm.assertAxesAreInnerMostDims("sum", h, p.shape.length);
        const [d,f] = dm.computeOutAndReduceShapes(p.shape, h);
        let m = Zb(n, d, dm.upcastType(p.dtype, "int32"));
        const g = Hs.sizeFromShape(f)
          , y = n.data.get(m.dataId).values
          , b = n.data.get(p.dataId).values;
        for (let e = 0; e < y.length; ++e) {
            const t = e * g;
            let n = 0;
            for (let e = 0; e < g; ++e)
                n += b[t + e];
            y[e] = n
        }
        if (i) {
            const e = m;
            m = ux({
                inputs: {
                    x: m
                },
                backend: n,
                attrs: {
                    shape: dm.expandShapeToKeepDim(m.shape, u)
                }
            }),
            n.disposeIntermediateTensorInfo(e)
        }
        return n.disposeIntermediateTensorInfo(o),
        null != c && n.disposeIntermediateTensorInfo(p),
        m
    }
    const Ww = {
        kernelName: ns,
        backendName: "cpu",
        kernelFunc: Pw
    };
    const Uw = {
        kernelName: vt,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {equation: r} = s
              , a = t
              , {allDims: i, summedDims: o, idDims: l} = dm.decodeEinsumEquation(r, a.length);
            dm.checkEinsumDimSizes(i.length, l, a);
            const {path: u, steps: c} = dm.getEinsumComputePath(o, l)
              , h = c.length;
            let p = null
              , d = i.length;
            const f = [];
            for (let e = 0; e < h; ++e) {
                for (const t of c[e]) {
                    const {permutationIndices: e, expandDims: s} = dm.getEinsumPermutation(d, l[t]);
                    let r;
                    dm.isIdentityPermutation(e) ? r = a[t] : (r = kx({
                        inputs: {
                            x: a[t]
                        },
                        backend: n,
                        attrs: {
                            perm: e
                        }
                    }),
                    f.push(r));
                    const i = r.shape.slice();
                    for (let e = 0; e < s.length; ++e)
                        i.splice(s[e], 0, 1);
                    Hs.arraysEqual(r.shape, i) || (r = ux({
                        inputs: {
                            x: r
                        },
                        backend: n,
                        attrs: {
                            shape: i
                        }
                    }),
                    f.push(r)),
                    null === p ? p = r : (p = zw({
                        inputs: {
                            a: r,
                            b: p
                        },
                        backend: n
                    }),
                    f.push(p))
                }
                e < h - 1 && (u[e] >= 0 && (p = Pw({
                    inputs: {
                        x: p
                    },
                    backend: n,
                    attrs: {
                        axis: u[e] - (i.length - d),
                        keepDims: !1
                    }
                }),
                f.push(p)),
                d--)
            }
            for (const e of f)
                e !== p && n.disposeIntermediateTensorInfo(e);
            return p
        }
    };
    const Vw = {
        kernelName: It,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {dy: s, y: r} = t;
            Cb([s, r], "eluGrad");
            const a = new Float32Array(Hs.sizeFromShape(r.shape))
              , i = n.data.get(r.dataId).values
              , o = n.data.get(s.dataId).values;
            for (let e = 0; e < i.length; ++e) {
                const t = i[e];
                a[e] = t >= 1 ? o[e] : o[e] * (t + 1)
            }
            return n.makeTensorInfo(r.shape, "float32", a)
        }
    }
      , Gw = Mb(((e,t)=>e === t ? 1 : 0))
      , Hw = sx(Nt, Gw, null, "bool")
      , jw = {
        kernelName: Nt,
        backendName: "cpu",
        kernelFunc: Hw
    }
      , qw = dm.ERF_P
      , Kw = dm.ERF_A1
      , Xw = dm.ERF_A2
      , Yw = dm.ERF_A3
      , Zw = dm.ERF_A4
      , Jw = dm.ERF_A5
      , Qw = $b(St, (e=>{
        const t = Math.sign(e)
          , n = Math.abs(e)
          , s = 1 / (1 + qw * n);
        return t * (1 - ((((Jw * s + Zw) * s + Yw) * s + Xw) * s + Kw) * s * Math.exp(-n * n))
    }
    ))
      , ev = {
        kernelName: St,
        backendName: "cpu",
        kernelFunc: Qw
    }
      , tv = Gb((e=>Math.exp(e)))
      , nv = Eb(Tt, tv, "float32")
      , sv = {
        kernelName: Tt,
        backendName: "cpu",
        kernelFunc: nv
    };
    function rv(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {input: r} = t
          , {dim: a} = s
          , i = r.shape.length
          , o = r.shape.slice();
        let l = a;
        return a < 0 && (Hs.assert(-(i + 1) <= a, (()=>`Axis must be in the interval [${-(i + 1)}, ${i}]`)),
        l = i + a + 1),
        o.splice(l, 0, 1),
        ux({
            inputs: {
                x: r
            },
            backend: n,
            attrs: {
                shape: o
            }
        })
    }
    const av = {
        kernelName: Ct,
        backendName: "cpu",
        kernelFunc: rv
    }
      , iv = Gb((e=>Math.expm1(e)))
      , ov = Eb($t, iv)
      , lv = {
        kernelName: $t,
        backendName: "cpu",
        kernelFunc: ov
    }
      , uv = Mb(((e,t)=>e / t))
      , cv = sx(wt, uv)
      , hv = {
        kernelName: wt,
        backendName: "cpu",
        kernelFunc: cv
    }
      , pv = Mb(((e,t)=>e - t))
      , dv = rx(((e,t,n,s)=>({
        real: e - n,
        imag: t - s
    })))
      , fv = sx(ys, pv, dv)
      , mv = {
        kernelName: ys,
        backendName: "cpu",
        kernelFunc: fv
    };
    function gv(e, t, n) {
        const s = e.shape
          , r = s[0]
          , a = s[1]
          , i = n.data.get(e.dataId)
          , o = i.complexTensorInfos.real
          , l = i.complexTensorInfos.imag
          , u = [r, a]
          , c = Hs.sizeFromShape(u)
          , h = Hs.getTypedArrayFromDType("float32", c)
          , p = Hs.getTypedArrayFromDType("float32", c);
        for (let e = 0; e < r; e++) {
            const s = Kx({
                inputs: {
                    x: o
                },
                backend: n,
                attrs: {
                    begin: [e, 0],
                    size: [1, a]
                }
            })
              , r = Kx({
                inputs: {
                    x: l
                },
                backend: n,
                attrs: {
                    begin: [e, 0],
                    size: [1, a]
                }
            })
              , i = Xb({
                inputs: {
                    real: s,
                    imag: r
                },
                backend: n
            })
              , {real: u, imag: c} = yv(i, t, n)
              , d = dm.mergeRealAndImagArrays(u, c);
            for (let t = 0; t < a; t++) {
                const n = dm.getComplexWithIndex(d, t);
                h[e * a + t] = n.real,
                p[e * a + t] = n.imag
            }
            n.disposeIntermediateTensorInfo(s),
            n.disposeIntermediateTensorInfo(r),
            n.disposeIntermediateTensorInfo(i)
        }
        const d = n.makeTensorInfo(u, "float32", h)
          , f = n.makeTensorInfo(u, "float32", p)
          , m = Xb({
            inputs: {
                real: d,
                imag: f
            },
            backend: n
        });
        return n.disposeIntermediateTensorInfo(d),
        n.disposeIntermediateTensorInfo(f),
        m
    }
    function yv(e, t, n) {
        const s = Hs.sizeFromShape(e.shape)
          , r = n.data.get(e.dataId)
          , a = n.data.get(r.complexTensorInfos.real.dataId).values
          , i = n.data.get(r.complexTensorInfos.imag.dataId).values;
        if (0 == ((o = s) & o - 1)) {
            const r = bv(a, i, s, t, n)
              , o = [e.shape[0], e.shape[1]];
            if (t) {
                const e = n.makeTensorInfo(o, "float32", r.real)
                  , t = n.makeTensorInfo(o, "float32", r.imag)
                  , a = n.makeTensorInfo([], "float32", Hs.createScalarValue(s, "float32"))
                  , i = Fb({
                    inputs: {
                        x: a
                    },
                    backend: n
                })
                  , l = hv.kernelFunc({
                    inputs: {
                        a: e,
                        b: a
                    },
                    backend: n
                })
                  , u = hv.kernelFunc({
                    inputs: {
                        a: t,
                        b: i
                    },
                    backend: n
                })
                  , c = n.data.get(l.dataId).values
                  , h = n.data.get(u.dataId).values;
                return n.disposeIntermediateTensorInfo(e),
                n.disposeIntermediateTensorInfo(t),
                n.disposeIntermediateTensorInfo(a),
                n.disposeIntermediateTensorInfo(i),
                n.disposeIntermediateTensorInfo(l),
                n.disposeIntermediateTensorInfo(u),
                {
                    real: c,
                    imag: h
                }
            }
            return r
        }
        {
            const e = function(e, t, n) {
                const s = new Float32Array(2 * t);
                for (let r = 0; r < t; r++) {
                    let a = 0
                      , i = 0;
                    for (let s = 0; s < t; s++) {
                        const o = dm.exponent(r * s, t, n)
                          , l = dm.getComplexWithIndex(e, s);
                        a += l.real * o.real - l.imag * o.imag,
                        i += l.real * o.imag + l.imag * o.real
                    }
                    n && (a /= t,
                    i /= t),
                    dm.assignToTypedArray(s, a, i, r)
                }
                return s
            }(dm.mergeRealAndImagArrays(a, i), s, t);
            return dm.splitRealAndImagArrays(e)
        }
        var o
    }
    function bv(e, t, n, s, r) {
        if (1 === n)
            return {
                real: e,
                imag: t
            };
        const a = dm.mergeRealAndImagArrays(e, t)
          , i = n / 2
          , o = dm.complexWithEvenIndex(a)
          , l = o.real
          , u = o.imag
          , c = [l.length]
          , h = r.makeTensorInfo(c, "float32", l)
          , p = r.makeTensorInfo(c, "float32", u)
          , d = Xb({
            inputs: {
                real: h,
                imag: p
            },
            backend: r
        })
          , f = dm.complexWithOddIndex(a)
          , m = f.real
          , g = f.imag
          , y = [m.length]
          , b = r.makeTensorInfo(y, "float32", m)
          , x = r.makeTensorInfo(y, "float32", g)
          , w = Xb({
            inputs: {
                real: b,
                imag: x
            },
            backend: r
        })
          , v = bv(l, u, i, s, r)
          , k = v.real
          , I = v.imag
          , S = [k.length]
          , N = r.makeTensorInfo(S, "float32", k)
          , T = r.makeTensorInfo(S, "float32", I)
          , C = Xb({
            inputs: {
                real: N,
                imag: T
            },
            backend: r
        })
          , $ = bv(m, g, i, s, r)
          , E = $.real
          , A = $.imag
          , R = [E.length]
          , F = r.makeTensorInfo(R, "float32", E)
          , D = r.makeTensorInfo(R, "float32", A)
          , _ = Xb({
            inputs: {
                real: F,
                imag: D
            },
            backend: r
        })
          , O = dm.exponents(n, s)
          , M = [O.real.length]
          , L = r.makeTensorInfo(M, "float32", O.real)
          , z = r.makeTensorInfo(M, "float32", O.imag)
          , B = Xb({
            inputs: {
                real: L,
                imag: z
            },
            backend: r
        })
          , P = zw({
            inputs: {
                a: B,
                b: _
            },
            backend: r
        })
          , W = ox({
            inputs: {
                a: C,
                b: P
            },
            backend: r
        })
          , U = fv({
            inputs: {
                a: C,
                b: P
            },
            backend: r
        })
          , V = Jb({
            inputs: {
                input: W
            },
            backend: r
        })
          , G = Jb({
            inputs: {
                input: U
            },
            backend: r
        })
          , H = lw({
            inputs: {
                input: W
            },
            backend: r
        })
          , j = lw({
            inputs: {
                input: U
            },
            backend: r
        })
          , q = cw({
            inputs: [V, G],
            backend: r,
            attrs: {
                axis: 0
            }
        })
          , K = cw({
            inputs: [H, j],
            backend: r,
            attrs: {
                axis: 0
            }
        })
          , X = r.data.get(q.dataId).values
          , Y = r.data.get(K.dataId).values;
        return r.disposeIntermediateTensorInfo(h),
        r.disposeIntermediateTensorInfo(p),
        r.disposeIntermediateTensorInfo(d),
        r.disposeIntermediateTensorInfo(b),
        r.disposeIntermediateTensorInfo(x),
        r.disposeIntermediateTensorInfo(w),
        r.disposeIntermediateTensorInfo(N),
        r.disposeIntermediateTensorInfo(T),
        r.disposeIntermediateTensorInfo(C),
        r.disposeIntermediateTensorInfo(F),
        r.disposeIntermediateTensorInfo(D),
        r.disposeIntermediateTensorInfo(_),
        r.disposeIntermediateTensorInfo(L),
        r.disposeIntermediateTensorInfo(z),
        r.disposeIntermediateTensorInfo(B),
        r.disposeIntermediateTensorInfo(P),
        r.disposeIntermediateTensorInfo(W),
        r.disposeIntermediateTensorInfo(U),
        r.disposeIntermediateTensorInfo(V),
        r.disposeIntermediateTensorInfo(H),
        r.disposeIntermediateTensorInfo(G),
        r.disposeIntermediateTensorInfo(j),
        r.disposeIntermediateTensorInfo(q),
        r.disposeIntermediateTensorInfo(K),
        {
            real: X,
            imag: Y
        }
    }
    const xv = {
        kernelName: Et,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {input: s} = t
              , r = Hs.sizeFromShape(s.shape)
              , a = s.shape[s.shape.length - 1]
              , i = ux({
                inputs: {
                    x: s
                },
                backend: n,
                attrs: {
                    shape: [r / a, a]
                }
            })
              , o = gv(i, !1, n)
              , l = ux({
                inputs: {
                    x: o
                },
                backend: n,
                attrs: {
                    shape: s.shape
                }
            });
            return n.disposeIntermediateTensorInfo(i),
            n.disposeIntermediateTensorInfo(o),
            l
        }
    };
    function wv(e) {
        const {backend: t, attrs: n} = e
          , {shape: s, value: r, dtype: a} = n
          , i = a || Hs.inferDtype(r)
          , o = Hs.getArrayFromDType(i, Hs.sizeFromShape(s));
        return function(e, t, n) {
            e.fill(t)
        }(o, r),
        t.makeTensorInfo(s, i, o)
    }
    const vv = {
        kernelName: At,
        backendName: "cpu",
        kernelFunc: wv
    };
    const kv = {
        kernelName: Rt,
        backendName: "cpu",
        kernelFunc: ({inputs: e, attrs: t, backend: n})=>{
            const {image: s} = e
              , r = n
              , a = Hs.getTypedArrayFromDType(s.dtype, Hs.sizeFromShape(s.shape))
              , [i,o,l,u] = s.shape
              , c = r.data.get(s.dataId).values;
            for (let e = 0; e < i; e++) {
                const t = e * l * o * u;
                for (let e = 0; e < o; e++) {
                    const n = e * (l * u);
                    for (let e = 0; e < l; e++) {
                        const s = e * u;
                        for (let r = 0; r < u; r++) {
                            const i = Math.round(l - e - 1)
                              , o = t + n + s + r;
                            let h = c[o];
                            if (i >= 0 && i < l) {
                                h = c[t + n + i * u + r]
                            }
                            a[o] = h
                        }
                    }
                }
            }
            return {
                dataId: r.write(a, s.shape, s.dtype),
                shape: s.shape,
                dtype: s.dtype
            }
        }
    }
      , Iv = Gb((e=>Math.floor(e)))
      , Sv = Eb(Ft, Iv)
      , Nv = {
        kernelName: Ft,
        backendName: "cpu",
        kernelFunc: Sv
    }
      , Tv = Mb(((e,t)=>Math.floor(e / t)))
      , Cv = sx(Dt, Tv, null, "int32")
      , $v = {
        kernelName: Dt,
        backendName: "cpu",
        kernelFunc: Cv
    };
    const Ev = {
        kernelName: Fs,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, filter: a, bias: i, preluActivationWeights: o} = t
              , {strides: l, pad: u, dataFormat: c, dilations: h, dimRoundingMode: p, activation: d, leakyreluAlpha: f} = s;
            let m = pw({
                inputs: {
                    x: r,
                    filter: a
                },
                backend: n,
                attrs: {
                    strides: l,
                    pad: u,
                    dataFormat: c,
                    dilations: h,
                    dimRoundingMode: p
                }
            });
            if (i) {
                const e = m;
                if ("NCHW" === c && 1 === i.shape.length && 1 !== i.shape[0]) {
                    const e = ux({
                        inputs: {
                            x: i
                        },
                        backend: n,
                        attrs: {
                            shape: [i.shape[0], 1, 1]
                        }
                    });
                    m = ox({
                        inputs: {
                            a: m,
                            b: e
                        },
                        backend: n
                    }),
                    n.disposeIntermediateTensorInfo(e)
                } else
                    m = ox({
                        inputs: {
                            a: m,
                            b: i
                        },
                        backend: n
                    });
                n.disposeIntermediateTensorInfo(e)
            }
            if (d) {
                const e = m;
                if ("NCHW" === c && "prelu" === d && 1 === o.shape.length && 1 !== o.shape[0]) {
                    const e = ux({
                        inputs: {
                            x: o
                        },
                        backend: n,
                        attrs: {
                            shape: [o.shape[0], 1, 1]
                        }
                    });
                    m = Kb(n, m, d, e, f),
                    n.disposeIntermediateTensorInfo(e)
                } else
                    m = Kb(n, m, d, o, f);
                n.disposeIntermediateTensorInfo(e)
            }
            return m
        }
    };
    const Av = {
        kernelName: Ds,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, filter: a, bias: i, preluActivationWeights: o} = t
              , {strides: l, pad: u, dataFormat: c, dilations: h, dimRoundingMode: p, activation: d, leakyreluAlpha: f} = s;
            let m = $w({
                inputs: {
                    x: r,
                    filter: a
                },
                backend: n,
                attrs: {
                    strides: l,
                    pad: u,
                    dataFormat: c,
                    dilations: h,
                    dimRoundingMode: p
                }
            });
            if (i) {
                const e = m;
                m = ox({
                    inputs: {
                        a: m,
                        b: i
                    },
                    backend: n
                }),
                n.disposeIntermediateTensorInfo(e)
            }
            if (d) {
                const e = m;
                m = Kb(n, m, d, o, f),
                n.disposeIntermediateTensorInfo(e)
            }
            return m
        }
    };
    function Rv(e, t, n, s, r, a, i, o, l) {
        const u = qo([s, a], n);
        for (let n = 0; n < s; n++) {
            const s = [];
            let c = 0;
            for (let t = 0; t < r; t++) {
                const a = e[n * r + t];
                c += a * i[t],
                s.push(a)
            }
            if (c < 0 || c >= l / a)
                throw new Error(`Invalid indices: ${s} does not index into ${o}`);
            for (let e = 0; e < a; e++)
                u.values[n * a + e] = t.get(...t.indexToLoc(c * a + e))
        }
        return u
    }
    const Fv = {
        kernelName: Mt,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {params: s, indices: r} = t
              , a = Hs.sizeFromShape(s.shape)
              , i = r.shape
              , o = i[i.length - 1]
              , [l,u,c,h] = dm.prepareAndValidate(s, r);
            if (0 === u)
                return n.makeTensorInfo(l, s.dtype, []);
            const p = Rv(n.data.get(r.dataId).values, n.bufferSync(s), s.dtype, u, o, c, h, s.shape, a);
            return n.makeTensorInfo(l, s.dtype, p.values)
        }
    };
    function Dv(e, t, n) {
        const s = qo(n, e.dtype);
        for (let n = 0; n < s.size; ++n) {
            const r = s.indexToLoc(n).slice()
              , a = r[0]
              , i = r[2]
              , o = t.locToIndex([a, i]);
            r[2] = t.values[o];
            const l = e.locToIndex(r);
            0 <= l && l < e.values.length && (s.values[n] = e.values[l])
        }
        return s
    }
    const _v = {
        kernelName: Ot,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, indices: a} = t
              , {axis: i, batchDims: o} = s;
            Cb([r, a], "gatherV2");
            const l = Hs.parseAxisParam(i, r.shape)[0]
              , u = n.data.get(a.dataId).values
              , c = r.shape[l];
            for (let e = 0; e < u.length; ++e) {
                const t = u[e];
                Hs.assert(t <= c - 1 && t >= 0, (()=>`GatherV2: the index value ${t} is not in [0, ${c - 1}]`))
            }
            let h = o;
            null == o && (h = 0);
            const p = Hs.sizeFromShape(a.shape)
              , d = dm.segment_util.collectGatherOpShapeInfo(r, a, l, h)
              , f = ux({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    shape: [d.batchSize, d.outerSize, d.dimSize, d.sliceSize]
                }
            })
              , m = ux({
                inputs: {
                    x: a
                },
                backend: n,
                attrs: {
                    shape: [d.batchSize, p / d.batchSize]
                }
            })
              , g = [d.batchSize, d.outerSize, p / d.batchSize, d.sliceSize]
              , y = n.bufferSync(m)
              , b = Dv(n.bufferSync(f), y, g);
            return n.disposeIntermediateTensorInfo(f),
            n.disposeIntermediateTensorInfo(m),
            n.makeTensorInfo(d.outputShape, b.dtype, b.values)
        }
    }
      , Ov = Mb(((e,t)=>e > t ? 1 : 0))
      , Mv = sx(Lt, Ov, null, "bool")
      , Lv = {
        kernelName: Lt,
        backendName: "cpu",
        kernelFunc: Mv
    }
      , zv = Mb(((e,t)=>e >= t ? 1 : 0))
      , Bv = sx(zt, zv, null, "bool")
      , Pv = {
        kernelName: zt,
        backendName: "cpu",
        kernelFunc: Bv
    };
    const Wv = {
        kernelName: Pt,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {input: s} = t
              , r = Hs.sizeFromShape(s.shape)
              , a = s.shape[s.shape.length - 1]
              , i = ux({
                inputs: {
                    x: s
                },
                backend: n,
                attrs: {
                    shape: [r / a, a]
                }
            })
              , o = gv(i, !0, n)
              , l = ux({
                inputs: {
                    x: o
                },
                backend: n,
                attrs: {
                    shape: s.shape
                }
            });
            return n.disposeIntermediateTensorInfo(i),
            n.disposeIntermediateTensorInfo(o),
            l
        }
    }
      , Uv = $b(Ut, (e=>Number.isFinite(e) ? 1 : 0), "bool")
      , Vv = {
        kernelName: Ut,
        backendName: "cpu",
        kernelFunc: Uv
    }
      , Gv = $b(Vt, (e=>Math.abs(e) === 1 / 0 ? 1 : 0), "bool")
      , Hv = {
        kernelName: Vt,
        backendName: "cpu",
        kernelFunc: Gv
    }
      , jv = $b(Gt, (e=>Number.isNaN(e) ? 1 : 0), "bool")
      , qv = {
        kernelName: Gt,
        backendName: "cpu",
        kernelFunc: jv
    }
      , Kv = Mb(((e,t)=>e < t ? 1 : 0))
      , Xv = sx(jt, Kv, null, "bool")
      , Yv = {
        kernelName: jt,
        backendName: "cpu",
        kernelFunc: Xv
    }
      , Zv = Mb(((e,t)=>e <= t ? 1 : 0))
      , Jv = sx(qt, Zv, null, "bool")
      , Qv = {
        kernelName: qt,
        backendName: "cpu",
        kernelFunc: Jv
    };
    function ek(e, t, n) {
        const s = (t - e) / (n - 1)
          , r = Hs.makeZerosTypedArray(n, "float32");
        r[0] = e;
        for (let e = 1; e < r.length; e++)
            r[e] = r[e - 1] + s;
        return r
    }
    const tk = {
        kernelName: Kt,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {backend: t, attrs: n} = e
              , {start: s, stop: r, num: a} = n
              , i = ek(s, r, a);
            return t.makeTensorInfo([i.length], "float32", i)
        }
    }
      , nk = Gb((e=>Math.log(e)))
      , sk = Eb(Xt, nk)
      , rk = {
        kernelName: Xt,
        backendName: "cpu",
        kernelFunc: sk
    }
      , ak = $b(Yt, (e=>Math.log1p(e)))
      , ik = {
        kernelName: Yt,
        backendName: "cpu",
        kernelFunc: ak
    }
      , ok = Mb(((e,t)=>e && t))
      , lk = sx(Zt, ok, null, "bool")
      , uk = {
        kernelName: Zt,
        backendName: "cpu",
        kernelFunc: lk
    }
      , ck = $b(Jt, (e=>e ? 0 : 1), "bool")
      , hk = {
        kernelName: Jt,
        backendName: "cpu",
        kernelFunc: ck
    }
      , pk = Mb(((e,t)=>e || t))
      , dk = sx(Qt, pk, null, "bool")
      , fk = {
        kernelName: Qt,
        backendName: "cpu",
        kernelFunc: dk
    };
    const mk = {
        kernelName: en,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {depthRadius: a, bias: i, alpha: o, beta: l} = s;
            Cb(r, "LRN");
            const u = r.shape[3]
              , c = u - 1
              , h = n.data.get(r.dataId).values
              , p = Hs.sizeFromShape(r.shape)
              , d = new Float32Array(p);
            function f(e) {
                const t = e % u;
                let n = e - t + Math.max(0, t - a);
                const s = e - t + Math.min(t + a, c);
                let r = 0;
                for (; n <= s; n++) {
                    const e = h[n];
                    r += e * e
                }
                return r
            }
            for (let e = 0; e < p; e++) {
                const t = f(e)
                  , n = h[e] * Math.pow(i + o * t, -l);
                d[e] = n
            }
            return n.makeTensorInfo(r.shape, r.dtype, d)
        }
    };
    const gk = {
        kernelName: tn,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, y: a, dy: i} = t
              , {depthRadius: o, bias: l, alpha: u, beta: c} = s;
            Cb(i, "LRNGrad");
            const h = Hs.sizeFromShape(i.shape)
              , p = i.shape[3]
              , d = n.data.get(i.dataId).values
              , f = n.data.get(r.dataId).values
              , m = n.data.get(a.dataId).values
              , g = new Float32Array(h)
              , y = h;
            for (let e = 0; e < y; e++) {
                const t = e % p
                  , n = e - t + Math.max(0, t - o)
                  , s = e - t + Math.min(p, t + o + 1);
                let r = 0;
                for (let e = n; e < s; e++)
                    r += Math.pow(f[e], 2);
                r = u * r + l;
                for (let t = n; t < s; t++) {
                    let n = -2 * u * c * f[t] * m[e] / r;
                    e === t && (n += Math.pow(r, -c)),
                    n *= d[e],
                    g[t] += n
                }
            }
            return n.makeTensorInfo(i.shape, r.dtype, g)
        }
    };
    function yk(e, t, n, s) {
        const r = Hs.getTypedArrayFromDType(s, Hs.sizeFromShape(n));
        for (let n = 0; n < r.length; ++n) {
            const s = n * t;
            let a = e[s];
            for (let n = 0; n < t; ++n) {
                const t = e[s + n];
                (Number.isNaN(t) || t > a) && (a = t)
            }
            r[n] = a
        }
        return r
    }
    function bk(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {x: r} = t
          , {reductionIndices: a, keepDims: i} = s
          , o = n;
        let l = r.shape;
        const u = l.length
          , c = Hs.parseAxisParam(a, l);
        let h = c;
        const p = dm.getAxesPermutation(h, u);
        let d = o.data.get(r.dataId).values;
        if (null != p) {
            const e = new Array(u);
            for (let t = 0; t < e.length; t++)
                e[t] = l[p[t]];
            d = vx(d, l, r.dtype, p, e),
            h = dm.getInnerMostAxes(h.length, u),
            l = e
        }
        Cb(r, "max"),
        dm.assertAxesAreInnerMostDims("max", h, u);
        const [f,m] = dm.computeOutAndReduceShapes(l, h)
          , g = yk(d, Hs.sizeFromShape(m), f, r.dtype)
          , y = o.write(g, f, r.dtype);
        let b = f;
        if (i) {
            b = dm.expandShapeToKeepDim(f, c)
        }
        return {
            dataId: y,
            shape: b,
            dtype: r.dtype
        }
    }
    const xk = {
        kernelName: nn,
        backendName: "cpu",
        kernelFunc: bk
    }
      , wk = Mb(((e,t)=>Math.max(e, t)))
      , vk = sx(sn, wk)
      , kk = {
        kernelName: sn,
        backendName: "cpu",
        kernelFunc: vk
    };
    const Ik = {
        kernelName: rn,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t;
            Cb(r, "maxPool");
            const {filterSize: a, strides: i, pad: o, dimRoundingMode: l} = s;
            Hs.assert(dm.eitherStridesOrDilationsAreOne(i, 1), (()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${i} and dilations '1'`));
            const u = dm.computePool2DInfo(r.shape, a, i, 1, o, l);
            let c;
            if (1 === u.filterWidth && 1 === u.filterHeight && Hs.arraysEqual(u.inShape, u.outShape))
                c = Fb({
                    inputs: {
                        x: r
                    },
                    backend: n
                });
            else {
                const e = n.data.get(r.dataId).values
                  , t = Hs.computeStrides(r.shape)
                  , s = Bx(e, r.shape, r.dtype, t, u, "max");
                c = n.makeTensorInfo(u.outShape, r.dtype, s.values)
            }
            return c
        }
    };
    const Sk = {
        kernelName: on,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {filterSize: a, strides: i, pad: o, dimRoundingMode: l, dataFormat: u} = s;
            Cb(r, "maxPool3d");
            const c = dm.computePool3DInfo(r.shape, a, i, 1, o, l, u)
              , h = Wx(n.data.get(r.dataId).values, r.shape, r.dtype, Hs.computeStrides(r.shape), c, "max");
            return n.makeTensorInfo(h.shape, "float32", h.values)
        }
    };
    const Nk = {
        kernelName: ln,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {dy: r, input: a} = t
              , {filterSize: i, strides: o, pad: l, dimRoundingMode: u} = s;
            Cb([r, a], "maxPool3DGrad");
            const c = dm.computePool3DInfo(a.shape, i, o, 1, l, u)
              , h = function(e, t) {
                const n = qo(t.outShape, "int32")
                  , s = t.strideDepth
                  , r = t.strideHeight
                  , a = t.strideWidth
                  , i = t.dilationDepth
                  , o = t.dilationHeight
                  , l = t.dilationWidth
                  , u = t.effectiveFilterDepth
                  , c = t.effectiveFilterHeight
                  , h = t.effectiveFilterWidth
                  , p = t.padInfo.front
                  , d = t.padInfo.top
                  , f = t.padInfo.left;
                for (let m = 0; m < t.batchSize; ++m)
                    for (let g = 0; g < t.inChannels; ++g)
                        for (let y = 0; y < t.outDepth; ++y) {
                            const b = y * s - p;
                            let x = b;
                            for (; x < 0; )
                                x += i;
                            const w = Math.min(t.inDepth, u + b);
                            for (let s = 0; s < t.outHeight; ++s) {
                                const u = s * r - d;
                                let p = u;
                                for (; p < 0; )
                                    p += o;
                                const v = Math.min(t.inHeight, c + u);
                                for (let r = 0; r < t.outWidth; ++r) {
                                    const d = r * a - f;
                                    let k = d;
                                    for (; k < 0; )
                                        k += l;
                                    const I = Math.min(t.inWidth, h + d);
                                    let S = Number.NEGATIVE_INFINITY
                                      , N = -1;
                                    for (let t = x; t < w; t += i) {
                                        const n = t - b;
                                        for (let s = p; s < v; s += o) {
                                            const r = s - u;
                                            for (let a = k; a < I; a += l) {
                                                const i = a - d
                                                  , o = e.get(m, t, s, a, g);
                                                o >= S && (S = o,
                                                N = n * c * h + r * c + i)
                                            }
                                        }
                                    }
                                    n.set(N, m, y, s, r, g)
                                }
                            }
                        }
                return n
            }(n.bufferSync(a), c)
              , p = c.strideDepth
              , d = c.strideHeight
              , f = c.strideWidth
              , m = c.dilationDepth
              , g = c.dilationHeight
              , y = c.dilationWidth
              , b = c.effectiveFilterDepth
              , x = c.effectiveFilterHeight
              , w = c.effectiveFilterWidth
              , v = b - 1 - c.padInfo.front
              , k = w - 1 - c.padInfo.left
              , I = x - 1 - c.padInfo.top
              , S = qo(a.shape, "float32")
              , N = n.bufferSync(r);
            for (let e = 0; e < c.batchSize; ++e)
                for (let t = 0; t < c.inChannels; ++t)
                    for (let n = 0; n < c.inDepth; ++n)
                        for (let s = 0; s < c.inHeight; ++s)
                            for (let r = 0; r < c.inWidth; ++r) {
                                const a = n - v
                                  , i = s - I
                                  , o = r - k;
                                let l = 0;
                                for (let n = 0; n < b; n += m) {
                                    const s = (a + n) / p;
                                    if (!(s < 0 || s >= c.outDepth || Math.floor(s) !== s))
                                        for (let r = 0; r < x; r += g) {
                                            const a = (i + r) / d;
                                            if (!(a < 0 || a >= c.outHeight || Math.floor(a) !== a))
                                                for (let i = 0; i < w; i += y) {
                                                    const u = (o + i) / f;
                                                    if (u < 0 || u >= c.outWidth || Math.floor(u) !== u)
                                                        continue;
                                                    const p = b * x * w - 1 - h.get(e, s, a, u, t) === n * x * w + r * w + i ? 1 : 0;
                                                    if (0 === p)
                                                        continue;
                                                    l += N.get(e, s, a, u, t) * p
                                                }
                                        }
                                }
                                S.set(l, e, n, s, r, t)
                            }
            return n.makeTensorInfo(S.shape, S.dtype, S.values)
        }
    };
    const Tk = {
        kernelName: an,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {dy: r, input: a, output: i} = t
              , o = a;
            Cb([a, i], "maxPoolGrad");
            const {filterSize: l, strides: u, pad: c, dimRoundingMode: h} = s
              , p = dm.computePool2DInfo(o.shape, l, u, 1, c, h)
              , d = n.data.get(o.dataId).values
              , f = qo(p.outShape, o.dtype, Px(d, o.shape, o.dtype, p).values)
              , m = p.strideHeight
              , g = p.strideWidth
              , y = p.dilationHeight
              , b = p.dilationWidth
              , x = p.effectiveFilterHeight
              , w = p.effectiveFilterWidth
              , v = w - 1 - p.padInfo.left
              , k = x - 1 - p.padInfo.top
              , I = qo(o.shape, "float32")
              , S = n.data.get(r.dataId).values
              , N = qo(r.shape, "float32", S);
            for (let e = 0; e < p.batchSize; ++e)
                for (let t = 0; t < p.inChannels; ++t)
                    for (let n = 0; n < p.inHeight; ++n)
                        for (let s = 0; s < p.inWidth; ++s) {
                            const r = n - k
                              , a = s - v;
                            let i = 0;
                            for (let n = 0; n < x; n += y) {
                                const s = (r + n) / m;
                                if (!(s < 0 || s >= p.outHeight || Math.floor(s) !== s))
                                    for (let r = 0; r < w; r += b) {
                                        const o = (a + r) / g;
                                        if (o < 0 || o >= p.outWidth || Math.floor(o) !== o)
                                            continue;
                                        const l = x * w - 1 - f.get(e, s, o, t) === n * w + r ? 1 : 0;
                                        if (0 === l)
                                            continue;
                                        i += N.get(e, s, o, t) * l
                                    }
                            }
                            I.set(i, e, n, s, t)
                        }
            return n.makeTensorInfo(I.shape, I.dtype, I.values)
        }
    };
    const Ck = {
        kernelName: un,
        backendName: "cpu",
        kernelFunc: ({inputs: e, attrs: t, backend: n})=>{
            const {x: s} = e
              , {filterSize: r, strides: a, pad: i, includeBatchInIndex: o} = t
              , l = n;
            Cb(s, "MaxPoolWithArgmax");
            const u = l.data.get(s.dataId).values
              , c = dm.computePool2DInfo(s.shape, r, a, [1, 1], i)
              , [h,p] = function(e, t, n, s, r) {
                const a = Bx(e, 0, n, Hs.computeStrides(t), r, "max")
                  , i = Px(e, t, n, r, !0, s);
                return [a.values, i.values]
            }(u, s.shape, s.dtype, o, c)
              , d = l.write(h, c.outShape, s.dtype)
              , f = l.write(p, c.outShape, s.dtype);
            return [{
                dataId: d,
                shape: c.outShape,
                dtype: s.dtype
            }, {
                dataId: f,
                shape: c.outShape,
                dtype: "int32"
            }]
        }
    };
    const $k = {
        kernelName: cn,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {axis: a, keepDims: i} = s
              , o = Hs.parseAxisParam(a, r.shape)
              , l = dm.computeOutAndReduceShapes(r.shape, o)[1]
              , u = Hs.sizeFromShape(l)
              , c = []
              , h = n.makeTensorInfo([], "float32", new Float32Array([u]));
            c.push(h);
            const p = tx({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    dtype: "float32"
                }
            });
            c.push(p);
            const d = cv({
                inputs: {
                    a: p,
                    b: h
                },
                backend: n
            });
            c.push(d);
            const f = Pw({
                inputs: {
                    x: d
                },
                backend: n,
                attrs: {
                    axis: a,
                    keepDims: i
                }
            });
            return c.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            f
        }
    };
    const Ek = {
        kernelName: hn,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {axis: a, keepDims: i} = s;
            Cb(r, "min");
            const o = Hs.parseAxisParam(a, r.shape);
            let l = o;
            const u = dm.getAxesPermutation(l, r.shape.length);
            let c = r;
            null != u && (c = kx({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    perm: u
                }
            }),
            l = dm.getInnerMostAxes(l.length, r.shape.length)),
            dm.assertAxesAreInnerMostDims("min", l, c.shape.length);
            const [h,p] = dm.computeOutAndReduceShapes(c.shape, l)
              , d = Hs.sizeFromShape(p)
              , f = Hs.makeZerosTypedArray(Hs.sizeFromShape(h), c.dtype)
              , m = n.data.get(c.dataId).values;
            for (let e = 0; e < f.length; ++e) {
                const t = e * d;
                let n = m[t];
                for (let e = 0; e < d; ++e) {
                    const s = m[t + e];
                    (Number.isNaN(s) || s < n) && (n = s)
                }
                f[e] = n
            }
            null != u && n.disposeIntermediateTensorInfo(c);
            const g = n.makeTensorInfo(h, c.dtype, f);
            if (i) {
                const e = ux({
                    inputs: {
                        x: g
                    },
                    backend: n,
                    attrs: {
                        shape: dm.expandShapeToKeepDim(h, o)
                    }
                });
                return n.disposeIntermediateTensorInfo(g),
                e
            }
            return g
        }
    }
      , Ak = Mb(((e,t)=>Math.min(e, t)))
      , Rk = sx(pn, Ak)
      , Fk = {
        kernelName: pn,
        backendName: "cpu",
        kernelFunc: Rk
    };
    const Dk = {
        kernelName: dn,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {paddings: a, mode: i} = s;
            Cb(r, "mirrorPad");
            const o = a.map(((e,t)=>e[0] + r.shape[t] + e[1]))
              , l = a.map((e=>e[0]))
              , u = a.map(((e,t)=>e[0] + r.shape[t]))
              , c = "reflect" === i ? 0 : 1
              , h = n.data.get(r.dataId).values
              , p = r.shape.length
              , d = Hs.computeStrides(r.shape)
              , f = Hs.sizeFromShape(o)
              , m = o.length
              , g = Hs.computeStrides(o)
              , y = Hs.getTypedArrayFromDType(r.dtype, f);
            for (let e = 0; e < f; e++) {
                let t = Hs.indexToLoc(e, m, g);
                for (let e = 0; e < m; e++)
                    t[e] < l[e] ? t[e] = 2 * l[e] - t[e] - c : t[e] >= u[e] && (t[e] = 2 * (u[e] - 1) - t[e] + c);
                t = t.map(((e,t)=>e - l[t]));
                const n = Hs.locToIndex(t, p, d);
                y[e] = h[n]
            }
            return {
                dataId: n.write(y, o, r.dtype),
                shape: o,
                dtype: r.dtype
            }
        }
    }
      , _k = Mb(((e,t)=>{
        const n = e % t;
        return e < 0 && t < 0 || e >= 0 && t >= 0 ? n : (n + t) % t
    }
    ))
      , Ok = sx(fn, _k)
      , Mk = {
        kernelName: fn,
        backendName: "cpu",
        kernelFunc: Ok
    };
    function Lk(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {logits: r} = t
          , {dim: a} = s
          , i = r.shape.length;
        let o = a;
        if (-1 === o && (o = i - 1),
        o !== i - 1)
            throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${i} and dim was ${o}`);
        const l = Hs.parseAxisParam([o], r.shape)
          , u = bk({
            inputs: {
                x: r
            },
            backend: n,
            attrs: {
                reductionIndices: l,
                keepDims: !1
            }
        })
          , c = dm.expandShapeToKeepDim(u.shape, l)
          , h = ux({
            inputs: {
                x: u
            },
            backend: n,
            attrs: {
                shape: c
            }
        })
          , p = fv({
            inputs: {
                a: r,
                b: h
            },
            backend: n
        })
          , d = nv({
            inputs: {
                x: p
            },
            backend: n
        })
          , f = Pw({
            inputs: {
                x: d
            },
            backend: n,
            attrs: {
                axis: l,
                keepDims: !1
            }
        })
          , m = ux({
            inputs: {
                x: f
            },
            backend: n,
            attrs: {
                shape: c
            }
        })
          , g = cv({
            inputs: {
                a: d,
                b: m
            },
            backend: n
        });
        return n.disposeIntermediateTensorInfo(u),
        n.disposeIntermediateTensorInfo(h),
        n.disposeIntermediateTensorInfo(p),
        n.disposeIntermediateTensorInfo(d),
        n.disposeIntermediateTensorInfo(f),
        n.disposeIntermediateTensorInfo(m),
        g
    }
    const zk = {
        kernelName: as,
        backendName: "cpu",
        kernelFunc: Lk
    };
    const Bk = {
        kernelName: mn,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {logits: r} = t
              , {numSamples: a, seed: i, normalized: o} = s;
            Cb(r, "multinomial");
            const l = o ? r : Lk({
                inputs: {
                    logits: r
                },
                backend: n,
                attrs: {
                    dim: -1
                }
            })
              , u = l.shape[0]
              , c = l.shape[1]
              , h = n.data.get(l.dataId).values
              , p = [u, a]
              , d = Hs.makeZerosTypedArray(Hs.sizeFromShape(p), "int32");
            for (let e = 0; e < u; ++e) {
                const t = e * c
                  , n = new Float32Array(c - 1);
                n[0] = h[t];
                for (let e = 1; e < n.length; ++e)
                    n[e] = n[e - 1] + h[t + e];
                const s = Gp.alea(i.toString())
                  , r = e * a;
                for (let e = 0; e < a; ++e) {
                    const t = s();
                    d[r + e] = n.length;
                    for (let s = 0; s < n.length; s++)
                        if (t < n[s]) {
                            d[r + e] = s;
                            break
                        }
                }
            }
            return o || n.disposeIntermediateTensorInfo(l),
            n.makeTensorInfo(p, "int32", d)
        }
    };
    function Pk(e, t, n) {
        const s = Hs.createScalarValue(-1, n);
        return Mw([], t, s, e, n)
    }
    const Wk = {
        kernelName: yn,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {x: s} = t;
            Cb(s, "neg");
            const r = n.data.get(s.dataId).values
              , [a,i] = Pk(r, s.shape, s.dtype);
            return n.makeTensorInfo(i, s.dtype, a)
        }
    }
      , Uk = Dg.nonMaxSuppressionV3Impl;
    const Vk = {
        kernelName: xn,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {boxes: r, scores: a} = t
              , {maxOutputSize: i, iouThreshold: o, scoreThreshold: l} = s;
            Cb(r, "NonMaxSuppression");
            const u = n.data.get(r.dataId).values
              , c = n.data.get(a.dataId).values
              , {selectedIndices: h} = Uk(u, c, i, o, l);
            return n.makeTensorInfo([h.length], "int32", new Int32Array(h))
        }
    }
      , Gk = Dg.nonMaxSuppressionV4Impl;
    const Hk = {
        kernelName: wn,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {boxes: r, scores: a} = t
              , {maxOutputSize: i, iouThreshold: o, scoreThreshold: l, padToMaxOutputSize: u} = s;
            Cb(r, "NonMaxSuppressionPadded");
            const c = n.data.get(r.dataId).values
              , h = n.data.get(a.dataId).values
              , {selectedIndices: p, validOutputs: d} = Gk(c, h, i, o, l, u);
            return [n.makeTensorInfo([p.length], "int32", new Int32Array(p)), n.makeTensorInfo([], "int32", new Int32Array([d]))]
        }
    }
      , jk = Dg.nonMaxSuppressionV5Impl;
    const qk = {
        kernelName: vn,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {boxes: r, scores: a} = t
              , {maxOutputSize: i, iouThreshold: o, scoreThreshold: l, softNmsSigma: u} = s;
            Cb(r, "NonMaxSuppressionWithScore");
            const c = n.data.get(r.dataId).values
              , h = n.data.get(a.dataId).values
              , p = i
              , d = o
              , f = l
              , m = u
              , {selectedIndices: g, selectedScores: y} = jk(c, h, p, d, f, m);
            return [n.makeTensorInfo([g.length], "int32", new Int32Array(g)), n.makeTensorInfo([y.length], "float32", new Float32Array(y))]
        }
    }
      , Kk = Mb(((e,t)=>e !== t ? 1 : 0))
      , Xk = sx(bn, Kk, null, "bool")
      , Yk = {
        kernelName: bn,
        backendName: "cpu",
        kernelFunc: Xk
    };
    const Zk = {
        kernelName: In,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {indices: r} = t
              , {dtype: a, depth: i, onValue: o, offValue: l} = s;
            Cb(r, "oneHot");
            const u = Hs.sizeFromShape(r.shape)
              , c = new Float32Array(u * i);
            c.fill(l);
            const h = n.data.get(r.dataId).values;
            for (let e = 0; e < u; ++e)
                h[e] >= 0 && h[e] < i && (c[e * i + h[e]] = o);
            return n.makeTensorInfo([...r.shape, i], a, c)
        }
    };
    function Jk(e) {
        const {inputs: t, backend: n} = e
          , {x: s} = t;
        if ("string" === s.dtype)
            throw new Error("zerosLike is not supported for string tensors");
        if ("complex64" === s.dtype) {
            const e = Jb({
                inputs: {
                    input: s
                },
                backend: n
            })
              , t = Jk({
                inputs: {
                    x: e
                },
                backend: n
            })
              , r = lw({
                inputs: {
                    input: s
                },
                backend: n
            })
              , a = Jk({
                inputs: {
                    x: r
                },
                backend: n
            })
              , i = Xb({
                inputs: {
                    real: t,
                    imag: a
                },
                backend: n
            });
            return n.disposeIntermediateTensorInfo(e),
            n.disposeIntermediateTensorInfo(t),
            n.disposeIntermediateTensorInfo(r),
            n.disposeIntermediateTensorInfo(a),
            i
        }
        return wv({
            backend: n,
            attrs: {
                shape: s.shape,
                value: 0,
                dtype: s.dtype
            }
        })
    }
    const Qk = {
        kernelName: Cs,
        backendName: "cpu",
        kernelFunc: Jk
    };
    const eI = {
        kernelName: kn,
        backendName: "cpu",
        kernelFunc: function e(t) {
            const {inputs: n, backend: s} = t
              , {x: r} = n;
            if ("string" === r.dtype)
                throw new Error("onesLike is not supported for string tensors");
            if ("complex64" === r.dtype) {
                const t = Jb({
                    inputs: {
                        input: r
                    },
                    backend: s
                })
                  , n = e({
                    inputs: {
                        x: t
                    },
                    backend: s
                })
                  , a = lw({
                    inputs: {
                        input: r
                    },
                    backend: s
                })
                  , i = Jk({
                    inputs: {
                        x: a
                    },
                    backend: s
                })
                  , o = Xb({
                    inputs: {
                        real: n,
                        imag: i
                    },
                    backend: s
                });
                return s.disposeIntermediateTensorInfo(t),
                s.disposeIntermediateTensorInfo(n),
                s.disposeIntermediateTensorInfo(a),
                s.disposeIntermediateTensorInfo(i),
                o
            }
            return wv({
                backend: s,
                attrs: {
                    shape: r.shape,
                    value: 1,
                    dtype: r.dtype
                }
            })
        }
    };
    function tI(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {axis: r} = s;
        if (1 === t.length)
            return rv({
                inputs: {
                    input: t[0]
                },
                backend: n,
                attrs: {
                    dim: r
                }
            });
        const a = t[0].shape
          , i = t[0].dtype;
        t.forEach((e=>{
            Hs.assertShapesMatch(a, e.shape, "All tensors passed to stack must have matching shapes"),
            Hs.assert(i === e.dtype, (()=>"All tensors passed to stack must have matching dtypes"))
        }
        ));
        const o = []
          , l = cw({
            inputs: t.map((e=>{
                const t = rv({
                    inputs: {
                        input: e
                    },
                    backend: n,
                    attrs: {
                        dim: r
                    }
                });
                return o.push(t),
                t
            }
            )),
            backend: n,
            attrs: {
                axis: r
            }
        });
        return o.forEach((e=>n.disposeIntermediateTensorInfo(e))),
        l
    }
    const nI = {
        kernelName: Sn,
        backendName: "cpu",
        kernelFunc: tI
    };
    const sI = {
        kernelName: Nn,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {paddings: a, constantValue: i} = s;
            Cb(r, "pad");
            const o = a.map(((e,t)=>e[0] + r.shape[t] + e[1]))
              , l = a.map((e=>e[0]))
              , u = n.data.get(r.dataId).values
              , c = Hs.sizeFromShape(r.shape)
              , h = r.shape.length
              , p = Hs.computeStrides(r.shape)
              , d = Hs.sizeFromShape(o)
              , f = o.length
              , m = Hs.computeStrides(o)
              , g = Hs.getTypedArrayFromDType(r.dtype, d);
            0 !== i && g.fill(i);
            for (let e = 0; e < c; e++) {
                const t = Hs.indexToLoc(e, h, p).map(((e,t)=>e + l[t]));
                g[Hs.locToIndex(t, f, m)] = u[e]
            }
            return {
                dataId: n.write(g, o, r.dtype),
                shape: o,
                dtype: r.dtype
            }
        }
    }
      , rI = Mb(((e,t)=>Math.pow(e, t)))
      , aI = sx(Tn, rI)
      , iI = {
        kernelName: Tn,
        backendName: "cpu",
        kernelFunc: aI
    };
    function oI(e, t, n, s) {
        const [r,a] = dm.computeOutAndReduceShapes(e, s)
          , i = ha(t, "int32")
          , o = Hs.makeZerosTypedArray(Hs.sizeFromShape(r), i)
          , l = Hs.sizeFromShape(a);
        for (let e = 0; e < o.length; ++e) {
            const t = e * l;
            let s = 1;
            for (let e = 0; e < l; ++e)
                s *= n[t + e];
            o[e] = s
        }
        return {
            outVals: o,
            outShape: r,
            outDtype: i
        }
    }
    const lI = {
        kernelName: $n,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {axis: a, keepDims: i} = s;
            Cb(r, "prod");
            const o = r.shape.length
              , l = Hs.parseAxisParam(a, r.shape)
              , u = dm.getAxesPermutation(l, o);
            let c = l
              , h = r;
            const p = [];
            null != u && (h = kx({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    perm: u
                }
            }),
            p.push(h),
            c = dm.getInnerMostAxes(c.length, o));
            const d = n.data.get(h.dataId).values
              , {outVals: f, outShape: m, outDtype: g} = oI(h.shape, h.dtype, d, c);
            let y = m;
            return i && (y = dm.expandShapeToKeepDim(m, l)),
            p.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            n.makeTensorInfo(y, g, f)
        }
    };
    function uI(e, t, n, s) {
        const r = [];
        let a = 0;
        const i = t.length - 1 + n.length
          , o = new Array(i).fill(null).map((()=>[0]));
        !function(e, t) {
            for (let n = 0; n < e.length; ++n) {
                const s = e[n]
                  , r = n === e.length - 1 ? t : e[n + 1].length;
                if (0 === s.length)
                    throw new Error("Ragged splits may not be empty");
                if (s[0] < 0)
                    throw new Error("Ragged splits must be non-negative");
                if (s[s.length - 1] > r)
                    throw new Error("Ragged splits must not point past values");
                for (let e = 1; e < s.length; ++e)
                    if (s[e - 1] > s[e])
                        throw new Error("Ragged splits must be sorted in ascending order")
            }
        }(n, s);
        let l = 1;
        for (let e = 0; e < t.length - 1; ++e) {
            l *= t[e];
            const n = t[e + 1];
            for (let t = 1; t < l + 1; ++t)
                o[e].push(t * n)
        }
        for (let s = 0; s < e.length; ++s) {
            let i = e[s]
              , l = e[s] + 1;
            for (let e = 0; e < n.length; ++e) {
                const s = n[e]
                  , r = e + t.length - 1;
                if (r >= 0) {
                    const e = o[r]
                      , t = e[e.length - 1] - s[i];
                    for (let e = i; e < l; ++e)
                        o[r].push(s[e + 1] + t)
                }
                i = s[i],
                l = s[l]
            }
            l !== i && (r.push([i, l]),
            a += l - i)
        }
        return {
            outSplits: o,
            valueSlices: r,
            numValues: a
        }
    }
    function cI(e, t) {
        const n = e.slice(0, t);
        for (; n.length < t; )
            n.push(1);
        for (let s = t; s < e.length; s++)
            n[t - 1] *= e[s];
        return n
    }
    function hI(e, t, n, s, r) {
        const a = t.slice();
        a[0] = r;
        const i = Hs.getArrayFromDType(n, Hs.sizeFromShape(a))
          , o = e.length;
        return function(e, t, n, s, r, a) {
            const i = cI(t, 2)[1]
              , o = cI(a, 2)[1];
            let l = 0;
            for (const t of n)
                for (let n = t[0]; n < t[1]; ++n) {
                    for (let t = 0; t < s; ++t)
                        r[l * o + t] = e[n * i + t];
                    ++l
                }
        }(e, t, s, 0 === o ? 0 : o / t[0], i, a),
        [i, a]
    }
    function pI(e, t, n, s, r, a, i, o) {
        if (0 === e.length)
            throw new Error("paramsNestedSplits must be non empty");
        if (0 === t[0].length)
            throw new Error("Split tensors must not be scalars");
        if (function(e, t, n) {
            e.forEach(((e,s)=>{
                if (e < 0 || e >= n) {
                    const r = Hs.indexToLoc(s, t.length, Hs.computeStrides(t)).join(",");
                    throw new Error(`indices[${r}] = ${e} is not in [0, ${n})`)
                }
            }
            ))
        }(a, i, t[0][0] - 1),
        0 === s.length)
            throw new Error("params.rank must be nonzero");
        const l = s[0]
          , {outSplits: u, valueSlices: c, numValues: h} = uI(a, i, e, l)
          , p = function(e) {
            const t = [];
            for (let n = 0; n < e.length; ++n) {
                const s = e[n].length
                  , r = Hs.getArrayFromDType("int32", s);
                t.push(r),
                e[n].forEach(((e,t)=>r[t] = e))
            }
            return t
        }(u)
          , d = hI(n, s, r, c, h);
        return [p, d[0], d[1]]
    }
    const dI = {
        kernelName: En,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {paramsNestedSplits: r, paramsDenseValues: a, indices: i} = t
              , {outputRaggedRank: o} = s
              , l = r.map((e=>n.data.get(e.dataId).values))
              , u = r.map((e=>e.shape))
              , c = n.data.get(a.dataId).values
              , h = n.data.get(i.dataId).values
              , [p,d,f] = pI(l, u, c, a.shape, a.dtype, h, i.shape)
              , m = p.map((e=>n.makeTensorInfo([e.length], "int32", e)))
              , g = n.makeTensorInfo(f, a.dtype, d);
            return m.concat([g])
        }
    }
      , fI = 2147483647;
    function mI(e, t, n, s, r, a, i) {
        if (t.length > 1)
            throw new Error("starts must be a scalar or vector");
        if (r.length > 1)
            throw new Error("limits must be a scalar or vector");
        if (i.length > 1)
            throw new Error("deltas must be a scalar or vector");
        const o = 0 === t.length
          , l = 0 === r.length
          , u = 0 === i.length
          , c = [];
        o || c.push(t[0]),
        l || c.push(r[0]),
        u || c.push(i[0]);
        for (let e = 1; e < c.length; ++e)
            if (c[e] !== c[e - 1])
                throw new Error("starts, limits, and deltas must have the same shape");
        const h = 0 === c.length ? 1 : c[0]
          , p = Hs.getArrayFromDType("int32", h + 1);
        p[0] = 0;
        for (let t = 0; t < h; ++t) {
            const n = o ? e[0] : e[t]
              , r = l ? s[0] : s[t]
              , i = u ? a[0] : a[t];
            if (0 === i)
                throw new Error("Requires delta != 0");
            let c;
            if (i > 0 && r < n || i < 0 && r > n)
                c = 0;
            else if (c = Math.ceil(Math.abs((r - n) / i)),
            c > fI)
                throw new Error("Requires ((limit - start) / delta) <= 2147483647");
            p[t + 1] = p[t] + c
        }
        const d = p[h]
          , f = Hs.getArrayFromDType(n, d);
        let m = 0;
        for (let t = 0; t < h; ++t) {
            const n = p[t + 1] - p[t];
            let s = o ? e[0] : e[t];
            const r = u ? a[0] : a[t];
            for (let e = 0; e < n; ++e)
                f[m++] = s,
                s += r
        }
        return [p, f]
    }
    const gI = {
        kernelName: An,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {starts: s, limits: r, deltas: a} = t
              , i = n.data.get(s.dataId).values
              , o = n.data.get(r.dataId).values
              , l = n.data.get(a.dataId).values
              , [u,c] = mI(i, s.shape, s.dtype, o, r.shape, l, a.shape);
            return [n.makeTensorInfo([u.length], "int32", u), n.makeTensorInfo([c.length], s.dtype, c)]
        }
    };
    var yI = dm.RowPartitionType;
    class bI {
        constructor(e, t, n, s, r, a, i, o, l, u) {
            this.shape = e,
            this.shapeShape = t,
            this.values = n,
            this.valuesShape = s,
            this.valuesDType = r,
            this.defaultValue = a,
            this.defaultValueShape = i,
            this.rowPartitionValues = o,
            this.rowPartitionValuesShapes = l,
            this.rowPartitionTypes = dm.getRowPartitionTypesHelper(u),
            this.raggedRank = dm.getRaggedRank(this.rowPartitionTypes)
        }
        getRowPartitionTypeByDimension(e) {
            return this.rowPartitionTypes[0] === yI.FIRST_DIM_SIZE ? this.rowPartitionTypes[e + 1] : this.rowPartitionTypes[e]
        }
        getRowPartitionTensor(e) {
            return this.rowPartitionTypes[0] === yI.FIRST_DIM_SIZE ? this.rowPartitionValues[e + 1] : this.rowPartitionValues[e]
        }
        getMaxWidth(e) {
            const t = this.getRowPartitionTensor(e - 1);
            switch (this.getRowPartitionTypeByDimension(e - 1)) {
            case yI.VALUE_ROWIDS:
                return bI.getMaxWidthValueRowID(t);
            case yI.ROW_SPLITS:
                return bI.getMaxWidthRowSplit(t);
            default:
                throw new Error(`Cannot handle partition type ${yI[this.getRowPartitionTypeByDimension(e - 1)]}`)
            }
        }
        static getMaxWidthRowSplit(e) {
            const t = e.length;
            if (0 === t || 1 === t)
                return 0;
            let n = 0;
            for (let s = 0; s < t - 1; ++s) {
                const t = e[s + 1] - e[s];
                t > n && (n = t)
            }
            return n
        }
        static getMaxWidthValueRowID(e) {
            const t = e.length;
            if (0 === t)
                return 0;
            let n = 0
              , s = e[0]
              , r = 0;
            for (let a = 1; a < t; ++a) {
                const t = e[a];
                t !== s && (s = t,
                r = Math.max(a - n, r),
                n = a)
            }
            return Math.max(t - n, r)
        }
        tensorShapeFromTensor(e, t, n=!0) {
            if (0 === t.length) {
                if (-1 === e[0])
                    return [];
                throw new Error("The only valid scalar shape tensor is the fully unknown shape specified as -1.")
            }
            return wI(e, n)
        }
        calculateOutputSize(e) {
            const t = this.valuesShape
              , n = this.defaultValueShape;
            dm.validateDefaultValueShape(n, t);
            const s = this.tensorShapeFromTensor(this.shape, this.shapeShape)
              , r = dm.combineRaggedTensorToTensorShapes(this.raggedRank, s, t);
            r[0] < 0 && (r[0] = e);
            for (let e = 1; e <= this.raggedRank; ++e)
                r[e] < 0 && (r[e] = this.getMaxWidth(e));
            return r
        }
        calculateFirstParentOutputIndex(e, t, n) {
            const s = Math.min(e, n)
              , r = [];
            let a = 0;
            for (let e = 0; e < s; ++e,
            a += t)
                r.push(a);
            for (let t = s; t < e; ++t)
                r.push(-1);
            return Hs.assert(r.length === e, (()=>"Final length of result must be equal to firstDimension.")),
            r
        }
        calculateOutputIndexRowSplit(e, t, n, s) {
            const r = e.length
              , a = [];
            for (let i = 0; i < r - 1; ++i) {
                const r = e[i + 1] - e[i];
                let o = Math.min(s, r)
                  , l = t[i];
                -1 === l && (o = 0);
                for (let e = 0; e < o; ++e)
                    a.push(l),
                    l += n;
                for (let e = 0; e < r - o; ++e)
                    a.push(-1)
            }
            if (r > 0 && a.length !== e[r - 1])
                throw new Error("Invalid row split size.");
            return a
        }
        calculateOutputIndexValueRowID(e, t, n, s) {
            const r = e.length
              , a = [];
            if (0 === r)
                return [];
            let i = 0
              , o = e[0];
            if (o >= t.length)
                throw new Error(`Got currentValueRowId=${o}, which is not less than ${t.length}`);
            let l = t[o];
            a.push(l);
            for (let u = 1; u < r; ++u) {
                const r = e[u];
                if (r === o)
                    l >= 0 && (++i,
                    i < s ? l += n : l = -1);
                else {
                    if (i = 0,
                    o = r,
                    r >= t.length)
                        throw new Error(`Got nextValueRowId=${r} which is not less than ${t.length}`);
                    l = t[r]
                }
                a.push(l)
            }
            if (a.length !== e.length)
                throw new Error("Invalid row ids.");
            return a
        }
        calculateOutputIndex(e, t, n, s) {
            const r = this.getRowPartitionTensor(e)
              , a = this.getRowPartitionTypeByDimension(e);
            switch (a) {
            case yI.VALUE_ROWIDS:
                return this.calculateOutputIndexValueRowID(r, t, n, s);
            case yI.ROW_SPLITS:
                if (r.length - 1 > t.length)
                    throw new Error(`Row partition size is greater than output size: ${r.length - 1} > ${t.length}`);
                return this.calculateOutputIndexRowSplit(r, t, n, s);
            default:
                throw new Error(`Unsupported partition type: ${yI[a]}`)
            }
        }
        getFirstDimensionSize() {
            const e = this.rowPartitionValues[0];
            if (0 === this.rowPartitionTypes.length)
                throw new Error("No row_partition_types given.");
            const t = this.rowPartitionTypes[0];
            switch (t) {
            case yI.FIRST_DIM_SIZE:
                return e[0];
            case yI.VALUE_ROWIDS:
                throw new Error("Cannot handle VALUE_ROWIDS in first dimension.");
            case yI.ROW_SPLITS:
                return this.rowPartitionValuesShapes[0][0] - 1;
            default:
                throw new Error(`Cannot handle type ${yI[t]}`)
            }
        }
        compute() {
            if (this.rowPartitionValues[0].length <= 0)
                throw new Error("Invalid first partition input. Tensor requires at least one element.");
            const e = this.getFirstDimensionSize()
              , t = this.calculateOutputSize(e)
              , n = new Array(this.raggedRank + 1);
            n[n.length - 1] = 1;
            for (let e = n.length - 2; e >= 0; --e)
                n[e] = n[e + 1] * t[e + 1];
            const s = wI(t, !1)
              , r = Hs.getArrayFromDType(this.valuesDType, Hs.sizeFromShape(s));
            if (n[0] * t[0] > 0) {
                let a = this.calculateFirstParentOutputIndex(e, n[0], t[0]);
                for (let e = 1; e <= this.raggedRank; ++e) {
                    a = this.calculateOutputIndex(e - 1, a, n[e], t[e])
                }
                this.setOutput(this.raggedRank, a, r, s)
            }
            return [s, r]
        }
        setOutput(e, t, n, s) {
            if (0 === n.length)
                return;
            const r = this.values
              , a = n;
            let i = s.slice();
            i = i.slice(e + 1);
            const o = Hs.sizeFromShape(i)
              , l = t.length;
            let u = this.defaultValue;
            if (u.length !== o && 1 !== u.length) {
                const e = this.defaultValueShape;
                Qo((()=>{
                    const t = hl(u, e)
                      , n = Ju(t, i);
                    u = n.dataSync()
                }
                ))
            }
            let c = 0
              , h = 0
              , p = 0;
            for (let e = 0; e <= l; ++e) {
                let s = e < l ? t[e] : -1;
                if (s !== p) {
                    if (h < p) {
                        const e = r.subarray(c * o);
                        xI(a.subarray(h * o), e, (p - h) * o)
                    }
                    if (e >= l) {
                        const e = n.length;
                        s = Math.floor(e / o)
                    }
                    if (s > p)
                        if (1 === this.defaultValue.length)
                            a.subarray(p * o, s * o).fill(this.defaultValue[0]),
                            p = s;
                        else
                            for (; s > p; ) {
                                xI(a.slice(p * o), u, o),
                                ++p
                            }
                    s < 0 ? (c = e + 1,
                    h = p) : (c = e,
                    h = p,
                    p = h + 1)
                } else
                    ++p
            }
        }
    }
    function xI(e, t, n) {
        for (let s = 0; s < n; s++)
            e[s] = t[s]
    }
    function wI(e, t) {
        const n = [];
        for (let s of e) {
            if (s < 0) {
                if (!t)
                    throw new Error(`Dimension ${s} must be >= 0`);
                if (s < -1)
                    throw new Error(`Dimension ${s} must be >= -1`);
                s = -1
            }
            n.push(s)
        }
        return n
    }
    function vI(e, t, n, s, r, a, i, o, l, u) {
        return new bI(e,t,n,s,r,a,i,o,l,u).compute()
    }
    const kI = {
        kernelName: Rn,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {shape: r, values: a, defaultValue: i, rowPartitionTensors: o} = t
              , {rowPartitionTypes: l} = s
              , u = n.data.get(r.dataId).values
              , c = n.data.get(a.dataId).values
              , h = n.data.get(i.dataId).values
              , p = o.map((e=>n.data.get(e.dataId).values))
              , d = o.map((e=>e.shape))
              , [f,m] = vI(u, r.shape, c, a.shape, a.dtype, h, i.shape, p, d, l);
            return n.makeTensorInfo(f, a.dtype, m)
        }
    };
    function II(e, t, n, s) {
        if (e === t || e < t && n < 0 || t < e && n > 1)
            return Hs.makeZerosTypedArray(0, s);
        const r = Math.abs(Math.ceil((t - e) / n))
          , a = Hs.makeZerosTypedArray(r, s);
        t < e && 1 === n && (n = -1),
        a[0] = e;
        for (let e = 1; e < a.length; e++)
            a[e] = a[e - 1] + n;
        return a
    }
    const SI = {
        kernelName: Fn,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {backend: t, attrs: n} = e
              , {start: s, stop: r, dtype: a, step: i} = n
              , o = II(s, r, i, a);
            return t.makeTensorInfo([o.length], a, o)
        }
    }
      , NI = $b(_n, (e=>1 / e))
      , TI = {
        kernelName: _n,
        backendName: "cpu",
        kernelFunc: NI
    };
    const CI = {
        kernelName: Bn,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {images: r} = t
              , {alignCorners: a, halfPixelCenters: i, size: o} = s;
            Cb(r, "resizeBilinear");
            const l = Hs.computeStrides(r.shape)
              , [u,c] = o
              , [h,p,d,f] = r.shape
              , m = n.data.get(r.dataId).values
              , g = new Float32Array(Hs.sizeFromShape([h, u, c, f]))
              , y = [a && u > 1 ? p - 1 : p, a && c > 1 ? d - 1 : d]
              , b = [a && u > 1 ? u - 1 : u, a && c > 1 ? c - 1 : c];
            let x = 0;
            const w = y[0] / b[0]
              , v = y[1] / b[1];
            for (let e = 0; e < h; e++)
                for (let t = 0; t < u; t++) {
                    let n;
                    n = i ? w * (t + .5) - .5 : w * t;
                    const s = Math.max(0, Math.floor(n))
                      , r = n - s
                      , a = Math.min(p - 1, Math.ceil(n))
                      , o = e * l[0] + s * l[1]
                      , u = e * l[0] + a * l[1];
                    for (let e = 0; e < c; e++) {
                        let t;
                        t = i ? v * (e + .5) - .5 : v * e;
                        const n = Math.max(0, Math.floor(t))
                          , s = t - n
                          , a = Math.min(d - 1, Math.ceil(t))
                          , c = o + n * l[2]
                          , h = u + n * l[2]
                          , p = o + a * l[2]
                          , y = u + a * l[2];
                        for (let e = 0; e < f; e++) {
                            const t = m[c + e]
                              , n = m[h + e]
                              , a = t + (m[p + e] - t) * s
                              , i = a + (n + (m[y + e] - n) * s - a) * r;
                            g[x++] = i
                        }
                    }
                }
            return n.makeTensorInfo([h, u, c, f], "float32", g)
        }
    };
    const $I = {
        kernelName: Pn,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {images: r, dy: a} = t
              , {alignCorners: i} = s;
            Cb([a, r], "resizeBilinearGrad");
            const o = Hs.computeStrides(r.shape)
              , [l,u,c,h] = r.shape
              , [,p,d] = a.shape
              , f = new Float32Array(l * u * c * h)
              , m = [i && p > 1 ? u - 1 : u, i && d > 1 ? c - 1 : c]
              , g = [i && p > 1 ? p - 1 : p, i && d > 1 ? d - 1 : d]
              , y = m[0] / g[0]
              , b = m[1] / g[1]
              , x = n.data.get(a.dataId).values;
            let w = 0;
            for (let e = 0; e < l; e++) {
                const t = e * o[0];
                for (let e = 0; e < p; e++) {
                    const n = e * y
                      , s = Math.floor(n)
                      , r = Math.min(Math.ceil(n), u - 1)
                      , a = t + s * o[1]
                      , i = t + r * o[1]
                      , l = n - s
                      , p = 1 - l;
                    for (let e = 0; e < d; e++) {
                        const t = e * b
                          , n = Math.floor(t)
                          , s = Math.min(Math.ceil(t), c - 1)
                          , r = t - n
                          , u = 1 - r
                          , d = a + n * o[2]
                          , m = a + s * o[2]
                          , g = i + n * o[2]
                          , y = i + s * o[2]
                          , v = p * u
                          , k = p * r
                          , I = l * u
                          , S = l * r;
                        for (let e = 0; e < h; e++) {
                            const t = x[w++];
                            f[d + e] += t * v,
                            f[m + e] += t * k,
                            f[g + e] += t * I,
                            f[y + e] += t * S
                        }
                    }
                }
            }
            return n.makeTensorInfo([l, c, u, h], "float32", f)
        }
    };
    const EI = {
        kernelName: Ln,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {images: r} = t
              , {alignCorners: a, halfPixelCenters: i, size: o} = s;
            Cb(r, "resizeNearestNeighbor");
            const l = Hs.computeStrides(r.shape)
              , [u,c] = o
              , [h,p,d,f] = r.shape
              , m = n.data.get(r.dataId).values
              , g = new Float32Array(h * u * c * f)
              , y = [a && u > 1 ? p - 1 : p, a && c > 1 ? d - 1 : d]
              , b = [a && u > 1 ? u - 1 : u, a && c > 1 ? c - 1 : c]
              , x = y[0] / b[0]
              , w = y[1] / b[1];
            let v = 0;
            for (let e = 0; e < h; e++) {
                const t = e * l[0];
                for (let e = 0; e < u; e++) {
                    const n = i ? x * (e + .5) : x * e;
                    let s = Math.min(p - 1, a ? Math.round(n) : Math.floor(n));
                    i && (s = Math.max(0, s));
                    const r = t + s * l[1];
                    for (let e = 0; e < c; e++) {
                        const t = i ? w * (e + .5) : w * e;
                        let n = Math.min(d - 1, a ? Math.round(t) : Math.floor(t));
                        i && (n = Math.max(0, n));
                        const s = r + n * l[2];
                        for (let e = 0; e < f; e++) {
                            const t = m[s + e];
                            g[v++] = t
                        }
                    }
                }
            }
            return n.makeTensorInfo([h, u, c, f], r.dtype, g)
        }
    };
    const AI = {
        kernelName: zn,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {images: r, dy: a} = t
              , {alignCorners: i} = s;
            Cb([a, r], "resizeNearestNeighborGrad");
            const o = Hs.computeStrides(r.shape)
              , l = Hs.computeStrides(a.shape)
              , [u,c,h,p] = r.shape
              , [,d,f] = a.shape
              , m = new Float32Array(u * c * h * p)
              , g = n.data.get(a.dataId).values
              , y = [i && d > 1 ? c - 1 : c, i && f > 1 ? h - 1 : h]
              , b = [i && d > 1 ? d - 1 : d, i && f > 1 ? f - 1 : f]
              , x = y[0] / b[0]
              , w = y[1] / b[1]
              , v = 1 / x
              , k = 1 / w
              , I = 2 * Math.ceil(v) + 2
              , S = 2 * Math.ceil(k) + 2;
            for (let e = 0; e < u; e++) {
                const t = e * o[0];
                for (let e = 0; e < c; e++) {
                    const n = t + e * o[1]
                      , s = Math.floor(e * v)
                      , r = Math.floor(s - I / 2);
                    for (let s = 0; s < h; s++) {
                        const a = n + s * o[2]
                          , u = Math.floor(s * k)
                          , y = Math.floor(u - S / 2);
                        for (let n = 0; n < p; n++) {
                            let o = 0;
                            for (let a = 0; a < I; a++) {
                                const u = a + r;
                                if (u < 0 || u >= d)
                                    continue;
                                const p = t + u * l[1]
                                  , m = u * x;
                                if (e === Math.min(c - 1, i ? Math.round(m) : Math.floor(m)))
                                    for (let e = 0; e < S; e++) {
                                        const t = e + y;
                                        if (t < 0 || t >= f)
                                            continue;
                                        const r = p + t * l[2]
                                          , a = t * w;
                                        s === Math.min(h - 1, i ? Math.round(a) : Math.floor(a)) && (o += g[r + n])
                                    }
                            }
                            m[a + n] = o
                        }
                    }
                }
            }
            return n.makeTensorInfo(r.shape, r.dtype, m)
        }
    };
    const RI = {
        kernelName: Un,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {dims: a} = s;
            Cb(r, "reverse");
            const i = r.shape.length
              , o = Hs.parseAxisParam(a, r.shape);
            if (0 === i)
                return Fb({
                    inputs: {
                        x: r
                    },
                    backend: n
                });
            const l = new qr(r.shape,r.dtype)
              , u = n.bufferSync(r);
            for (let e = 0; e < l.size; e++) {
                const t = l.indexToLoc(e)
                  , n = t.slice();
                o.forEach((e=>n[e] = r.shape[e] - 1 - n[e])),
                l.set(u.get(...n), ...t)
            }
            return n.makeTensorInfo(l.shape, l.dtype, l.values)
        }
    }
      , FI = {
        kernelName: As,
        backendName: "cpu",
        kernelFunc: ({inputs: e, attrs: t, backend: n})=>{
            const {image: s} = e
              , {radians: r, fillValue: a, center: i} = t
              , o = n
              , l = Hs.getTypedArrayFromDType(s.dtype, Hs.sizeFromShape(s.shape))
              , [u,c,h,p] = s.shape
              , [d,f] = dm.getImageCenter(i, c, h)
              , m = Math.sin(r)
              , g = Math.cos(r)
              , y = o.data.get(s.dataId).values;
            for (let e = 0; e < u; e++) {
                const t = e * h * c * p;
                for (let e = 0; e < c; e++) {
                    const n = e * (h * p);
                    for (let s = 0; s < h; s++) {
                        const r = s * p;
                        for (let i = 0; i < p; i++) {
                            const o = [u, e, s, i]
                              , b = o[2]
                              , x = o[1];
                            let w = (b - d) * g - (x - f) * m
                              , v = (b - d) * m + (x - f) * g;
                            w = Math.round(w + d),
                            v = Math.round(v + f);
                            let k = a;
                            if ("number" != typeof a && (k = 3 === i ? 255 : a[i]),
                            w >= 0 && w < h && v >= 0 && v < c) {
                                k = y[t + v * (h * p) + w * p + i]
                            }
                            l[t + n + r + i] = k
                        }
                    }
                }
            }
            return {
                dataId: o.write(l, s.shape, s.dtype),
                shape: s.shape,
                dtype: s.dtype
            }
        }
    }
      , DI = $b(Vn, (e=>{
        const t = Math.floor(e);
        return e - t < .5 ? Math.floor(e) : e - t > .5 ? Math.ceil(e) : t % 2 == 0 ? t : t + 1
    }
    ))
      , _I = {
        kernelName: Vn,
        backendName: "cpu",
        kernelFunc: DI
    }
      , OI = Gb((e=>1 / Math.sqrt(e)))
      , MI = Eb(Gn, OI)
      , LI = {
        kernelName: Gn,
        backendName: "cpu",
        kernelFunc: MI
    };
    function zI(e, t, n, s, r, a, i, o, l, u) {
        const c = [s / r, r]
          , h = e.values
          , p = t.values;
        if (0 === s)
            return qo(n, t.dtype);
        const d = qo(c, t.dtype);
        "string" == typeof l || "number" == typeof l ? d.values.fill(l) : "boolean" == typeof l && d.values.fill(+l);
        for (let e = 0; e < a; e++) {
            const a = [];
            let l = 0;
            for (let t = 0; t < i; t++) {
                const n = h[e * i + t];
                a.push(n),
                l += n * o[t]
            }
            if (l < 0 || l >= s / r)
                throw new Error(`Invalid indices: ${a} does not index into ${n}`);
            for (let n = 0; n < r; n++)
                u ? d.values[l * r + n] += p[e * r + n] : d.values[l * r + n] = 0 === t.rank ? p[0] : p[e * r + n]
        }
        return d
    }
    const BI = {
        kernelName: Hn,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {indices: r, updates: a} = t
              , {shape: i} = s
              , {sliceRank: o, numUpdates: l, sliceSize: u, strides: c, outputSize: h} = dm.calculateShapes(a, r, i)
              , p = zI(n.bufferSync(r), n.bufferSync(a), i, h, u, l, o, c, 0, !0);
            return n.makeTensorInfo(i, p.dtype, p.values)
        }
    };
    function PI(e, t) {
        let n = 0
          , s = e.length
          , r = 0;
        for (; n < s; )
            r = Math.floor((n + s) / 2),
            e[r] < t ? n = r + 1 : s = r;
        return s
    }
    function WI(e, t) {
        let n = 0
          , s = e.length
          , r = 0;
        for (; n < s; )
            r = Math.floor((n + s) / 2),
            e[r] <= t ? n = r + 1 : s = r;
        return s
    }
    const UI = {
        kernelName: jn,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {sortedSequence: r, values: a} = t
              , {side: i} = s
              , o = function(e, t, n, s, r, a) {
                const i = Hs.getArrayFromDType("int32", n * r);
                for (let o = 0; o < n; ++o) {
                    const n = e.slice(o * s, (o + 1) * s)
                      , l = o * r;
                    for (let e = 0; e < r; ++e)
                        i[l + e] = "left" === a ? PI(n, t[e + l]) : WI(n, t[e + l])
                }
                return i
            }(n.data.get(r.dataId).values, n.data.get(a.dataId).values, r.shape[0], r.shape[1], a.shape[1], i);
            return n.makeTensorInfo(a.shape, "int32", o)
        }
    };
    const VI = {
        kernelName: qn,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {condition: s, t: r, e: a} = t;
            Cb([s, r, a], "select");
            const i = s.shape.length
              , o = n.data.get(s.dataId).values
              , l = n.data.get(r.dataId).values
              , u = n.data.get(a.dataId).values
              , c = ha(r.dtype, a.dtype)
              , h = Hs.makeZerosTypedArray(Hs.sizeFromShape(r.shape), c);
            let p = 0;
            const d = 0 === i || i > 1 || 1 === r.shape.length ? 1 : Hs.sizeFromShape(r.shape.slice(1));
            for (let e = 0; e < o.length; e++)
                for (let t = 0; t < d; t++)
                    1 === o[e] ? h[p++] = l[e] : h[p++] = u[e];
            return n.makeTensorInfo(r.shape, c, h)
        }
    }
      , GI = dm.SELU_SCALEALPHA
      , HI = dm.SELU_SCALE
      , jI = $b(Kn, (e=>e >= 0 ? HI * e : GI * (Math.exp(e) - 1)))
      , qI = {
        kernelName: Kn,
        backendName: "cpu",
        kernelFunc: jI
    }
      , KI = $b(Jn, (e=>e < 0 ? -1 : e > 0 ? 1 : 0))
      , XI = {
        kernelName: Jn,
        backendName: "cpu",
        kernelFunc: KI
    }
      , YI = $b(Yn, (e=>Math.sin(e)))
      , ZI = {
        kernelName: Yn,
        backendName: "cpu",
        kernelFunc: YI
    }
      , JI = $b(Zn, (e=>Math.sinh(e)))
      , QI = {
        kernelName: Zn,
        backendName: "cpu",
        kernelFunc: JI
    }
      , eS = Math.log(1.1920928955078125e-7) + 2
      , tS = $b(es, (e=>{
        const t = e > -eS
          , n = e < eS
          , s = Math.exp(e);
        let r;
        return r = n ? s : t ? e : Math.log(1 + s),
        r
    }
    ))
      , nS = {
        kernelName: es,
        backendName: "cpu",
        kernelFunc: tS
    };
    const sS = {
        kernelName: ss,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {blockShape: a, paddings: i} = s;
            Cb([r], "spaceToBatchND");
            const o = Hs.sizeFromShape(a)
              , l = [[0, 0]];
            l.push(...i);
            for (let e = 1 + a.length; e < r.shape.length; ++e)
                l.push([0, 0]);
            const u = sI.kernelFunc({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    paddings: l,
                    constantValue: 0
                }
            })
              , c = dm.getReshaped(u.shape, a, o, !1)
              , h = dm.getPermuted(c.length, a.length, !1)
              , p = dm.getReshapedPermuted(u.shape, a, o, !1)
              , d = ux({
                inputs: {
                    x: u
                },
                backend: n,
                attrs: {
                    shape: c
                }
            })
              , f = kx({
                inputs: {
                    x: d
                },
                backend: n,
                attrs: {
                    perm: h
                }
            })
              , m = ux({
                inputs: {
                    x: f
                },
                backend: n,
                attrs: {
                    shape: p
                }
            });
            return n.disposeIntermediateTensorInfo(u),
            n.disposeIntermediateTensorInfo(d),
            n.disposeIntermediateTensorInfo(f),
            m
        }
    };
    function rS(e, t, n, s, r, a, i) {
        const o = t[0]
          , l = a[0]
          , u = new Array(l)
          , c = new Array(o)
          , h = t[1];
        if (0 === l) {
            if (0 !== o)
                throw new Error(dm.getSparseFillEmptyRowsIndicesDenseShapeMismatch(o));
            return [Hs.getArrayFromDType(n, 0), [0, h], Hs.getArrayFromDType(r, 0), u, c]
        }
        let p = !0
          , d = 0;
        const f = new Array(l).fill(0);
        for (let t = 0; t < o; ++t) {
            const n = e[t * h];
            if (n < 0)
                throw new Error(dm.getSparseFillEmptyRowsNegativeIndexErrorMessage(t, n));
            if (n >= l)
                throw new Error(dm.getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(t, n, l));
            ++f[n],
            p = p && n >= d,
            d = n
        }
        let m = !0;
        for (let e = 0; e < l; ++e) {
            const t = 0 === f[e];
            u[e] = t,
            m = m && !t,
            f[e] = Math.max(f[e], 1),
            e > 0 && (f[e] += f[e - 1])
        }
        if (m && p) {
            const t = e
              , n = s;
            for (let e = 0; e < o; ++e)
                c[e] = e;
            return [t, [o, h], n, u, c]
        }
        {
            const t = f[l - 1]
              , a = Hs.getArrayFromDType(n, t * h)
              , p = Hs.getArrayFromDType(r, t)
              , d = new Array(l).fill(0);
            for (let t = 0; t < o; ++t) {
                const n = e[t * h]
                  , r = d[n]
                  , i = (0 === n ? 0 : f[n - 1]) + r;
                d[n]++;
                for (let n = 0; n < h; ++n)
                    a[i * h + n] = e[t * h + n];
                p[i] = s[t],
                c[t] = i
            }
            for (let e = 0; e < l; ++e) {
                if (0 === d[e]) {
                    const t = 0 === e ? 0 : f[e - 1];
                    a[t * h + 0] = e;
                    for (let e = 1; e < h; ++e)
                        a[t * h + e] = 0;
                    p[t] = i
                }
            }
            return [a, [t, h], p, u, c]
        }
    }
    const aS = {
        kernelName: is,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {indices: s, values: r, denseShape: a, defaultValue: i} = t;
            if (1 !== a.shape.length)
                throw new Error(`Dense shape must be a vector, saw:\n        ${a.shape}`);
            if (2 !== s.shape.length)
                throw new Error(`Indices must be a matrix, saw:\n        ${s.shape}`);
            if (1 !== r.shape.length)
                throw new Error(`Values must be a vector, saw:\n        ${r.shape}`);
            if (0 !== i.shape.length)
                throw new Error(`Default value must be a scalar, saw:\n        ${i.shape}`);
            const o = n.data.get(s.dataId).values
              , l = n.data.get(r.dataId).values
              , u = n.data.get(a.dataId).values
              , c = n.data.get(i.dataId).values[0]
              , [h,p,d,f,m] = rS(o, s.shape, s.dtype, l, r.dtype, u, c);
            return [n.makeTensorInfo(p, s.dtype, h), n.makeTensorInfo([p[0]], r.dtype, d), n.makeTensorInfo([f.length], "bool", new Uint8Array(f.map((e=>Number(e))))), n.makeTensorInfo([m.length], s.dtype, new Int32Array(m))]
        }
    };
    function iS(e, t, n, s, r) {
        const a = Hs.sizeFromShape(s)
          , i = t[0]
          , o = r.length
          , l = [];
        let u = 1
          , c = -1;
        for (let e = 0; e < o; ++e) {
            const t = r[e];
            if (-1 === t) {
                if (-1 !== c)
                    throw new Error(dm.getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(c, e));
                c = e,
                l.push(1)
            } else {
                if (t < 0)
                    throw new Error(dm.getSparseReshapeNegativeOutputDimErrorMessage(e, t));
                u *= t,
                l.push(t)
            }
        }
        if (-1 !== c) {
            if (u <= 0)
                throw new Error(dm.getSparseReshapeEmptyTensorZeroOutputDimErrorMessage());
            const e = Math.trunc(a / u);
            if (u * e !== a)
                throw new Error(dm.getSparseReshapeInputOutputMultipleErrorMessage(s, l));
            l[c] = e
        }
        if (Hs.sizeFromShape(l) !== a)
            throw new Error(dm.getSparseReshapeInputOutputMismatchErrorMessage(s, l));
        const h = s.length
          , p = [];
        if (h > 0) {
            p[h - 1] = 1;
            for (let e = h - 2; e >= 0; --e)
                p[e] = p[e + 1] * s[e + 1]
        }
        const d = [];
        if (o > 0) {
            d[o - 1] = 1;
            for (let e = o - 2; e >= 0; --e)
                d[e] = d[e + 1] * l[e + 1]
        }
        const f = Hs.getArrayFromDType(n, i * o);
        for (let t = 0; t < i; ++t) {
            let n = 0;
            for (let s = 0; s < h; ++s)
                n += e[t * h + s] * p[s];
            for (let e = 0; e < o; ++e)
                f[t * o + e] = Math.trunc(n / d[e]),
                n %= d[e]
        }
        return [f, [i, o], l]
    }
    const oS = {
        kernelName: os,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {inputIndices: s, inputShape: r, newShape: a} = t;
            if (2 !== s.shape.length)
                throw new Error(`Input indices should be a matrix but received shape\n        ${s.shape}`);
            if (1 !== r.shape.length)
                throw new Error(`Input shape should be a vector but received shape\n        ${r.shape}`);
            if (1 !== a.shape.length)
                throw new Error(`Target shape should be a vector but received shape ${a.shape}`);
            const i = Array.from(n.data.get(r.dataId).values)
              , o = n.data.get(s.dataId).values
              , l = Array.from(n.data.get(a.dataId).values)
              , [u,c,h] = iS(o, s.shape, s.dtype, i, l);
            return [n.makeTensorInfo(c, s.dtype, u), n.makeTensorInfo([h.length], a.dtype, new Int32Array(h))]
        }
    };
    function lS(e, t, n, s, r, a=!1, i=0) {
        const o = s.length
          , l = [t[0], e.length / t[0]]
          , u = l[1]
          , c = o > 0 ? r[o - 1] + 1 : 0;
        if (c < 0)
            throw new Error(dm.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());
        const h = t.slice();
        h[0] = c;
        const p = h.reduce(((e,t)=>e * t), 1)
          , d = Hs.getArrayFromDType(n, p);
        if (0 === o)
            return c > 0 && d.fill(i),
            [d, h];
        if (c <= 0)
            throw new Error(dm.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());
        let f = 0
          , m = 1
          , g = 0
          , y = r[f];
        for (; ; ) {
            let t = 0;
            if (m < o) {
                if (t = r[m],
                y === t) {
                    ++m;
                    continue
                }
                if (y >= t)
                    throw new Error(dm.getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage())
            }
            if (y < 0 || y >= c)
                throw new Error(dm.getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(y, c));
            y > g && d.fill(i, g * u, y * u);
            for (let t = f; t < m; ++t) {
                const n = s[t];
                if (n < 0 || n >= l[0])
                    throw new Error(dm.getSparseSegmentReductionIndicesOutOfRangeErrorMessage(t, s[t], l[0]));
                for (let t = 0; t < u; t++)
                    d[y * u + t] += e[n * u + t]
            }
            if (a)
                for (let e = 0; e < u; e++)
                    d[y * u + e] /= m - f;
            if (f = m,
            ++m,
            g = y + 1,
            y = t,
            m > o)
                break
        }
        return g < c && d.fill(i, g * u, c * u),
        [d, h]
    }
    const uS = {
        kernelName: ls,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {data: s, indices: r, segmentIds: a} = t;
            if (s.shape.length < 1)
                throw new Error("Data should be at least 1 dimensional but received scalar");
            if (1 !== r.shape.length)
                throw new Error(`Indices should be a vector but received shape\n          ${r.shape}`);
            if (1 !== a.shape.length)
                throw new Error(`Segment ids should be a vector but received shape\n          ${a.shape}`);
            if (r.shape[0] !== a.shape[0])
                throw new Error("segmentIds and indices should have same size.");
            const i = n.data.get(s.dataId).values
              , o = n.data.get(r.dataId).values
              , l = n.data.get(a.dataId).values
              , [u,c] = lS(i, s.shape, s.dtype, o, l, !0);
            return n.makeTensorInfo(c, s.dtype, u)
        }
    };
    const cS = {
        kernelName: us,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {data: s, indices: r, segmentIds: a} = t;
            if (s.shape.length < 1)
                throw new Error("Data should be at least 1 dimensional but received scalar");
            if (1 !== r.shape.length)
                throw new Error(`Indices should be a vector but received shape\n         ${r.shape}`);
            if (1 !== a.shape.length)
                throw new Error(`Segment ids should be a vector but received shape\n         ${a.shape}`);
            if (r.shape[0] !== a.shape[0])
                throw new Error("segmentIds and indices should have same size.");
            const i = n.data.get(s.dataId).values
              , o = n.data.get(r.dataId).values
              , l = n.data.get(a.dataId).values
              , [u,c] = lS(i, s.shape, s.dtype, o, l);
            return n.makeTensorInfo(c, s.dtype, u)
        }
    };
    const hS = {
        kernelName: cs,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {sparseIndices: r, sparseValues: a, defaultValue: i} = t
              , {outputShape: o} = s
              , {sliceRank: l, numUpdates: u, sliceSize: c, strides: h, outputSize: p} = dm.calculateShapes(a, r, o)
              , d = !1
              , f = n.bufferSync(r);
            let m;
            switch (a.dtype) {
            case "bool":
                m = zI(f, n.bufferSync(a), o, p, c, u, l, h, Boolean(n.data.get(i.dataId).values[0]), d);
                break;
            case "float32":
                m = zI(f, n.bufferSync(a), o, p, c, u, l, h, n.data.get(i.dataId).values[0], d);
                break;
            case "int32":
                m = zI(f, n.bufferSync(a), o, p, c, u, l, h, n.data.get(i.dataId).values[0], d);
                break;
            case "string":
                m = zI(f, n.bufferSync(a), o, p, c, u, l, h, Hs.decodeString(n.data.get(i.dataId).values[0]), d);
                break;
            default:
                throw new Error(`Unsupported type ${a.dtype}`)
            }
            return n.makeTensorInfo(o, m.dtype, m.values)
        }
    };
    const pS = {
        kernelName: rs,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {numOrSizeSplits: a, axis: i} = s
              , o = Hs.parseAxisParam(i, r.shape)[0]
              , l = dm.prepareSplitSize(r, a, o)
              , u = new Array(r.shape.length).fill(0)
              , c = r.shape.slice();
            return l.map((e=>{
                const t = [...c];
                t[o] = e;
                const s = Kx({
                    inputs: {
                        x: r
                    },
                    backend: n,
                    attrs: {
                        begin: u,
                        size: t
                    }
                });
                return u[o] += e,
                s
            }
            ))
        }
    }
      , dS = Gb((e=>Math.sqrt(e)))
      , fS = $b(ts, (e=>Math.sqrt(e)))
      , mS = {
        kernelName: ts,
        backendName: "cpu",
        kernelFunc: fS
    }
      , gS = {
        kernelName: ps,
        backendName: "cpu",
        kernelFunc: ({inputs: e, backend: t})=>{
            const {x: n} = e
              , s = t;
            Cb(n, "square");
            const r = s.data.get(n.dataId).values
              , a = new Float32Array(r.length);
            for (let e = 0; e < r.length; ++e) {
                const t = r[e];
                a[e] = t * t
            }
            return {
                dataId: s.write(a, n.shape, n.dtype),
                shape: n.shape,
                dtype: n.dtype
            }
        }
    }
      , yS = Mb(((e,t)=>{
        const n = e - t;
        return n * n
    }
    ))
      , bS = sx(hs, yS)
      , xS = {
        kernelName: hs,
        backendName: "cpu",
        kernelFunc: bS
    }
      , wS = $b($s, ((e,t)=>{
        const n = t;
        return isNaN(e) ? NaN : e > 0 ? 1 : n.alpha
    }
    ))
      , vS = {
        kernelName: $s,
        backendName: "cpu",
        kernelFunc: wS
    };
    function kS(e, t, n, s) {
        const r = qo(e, t.dtype);
        for (let e = 0; e < r.size; e++) {
            const a = r.indexToLoc(e)
              , i = new Array(a.length);
            for (let e = 0; e < i.length; e++)
                i[e] = a[e] * n[e] + s[e];
            r.set(t.get(...i), ...a)
        }
        return r
    }
    const IS = {
        kernelName: ds,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {begin: a, end: i, strides: o, beginMask: l, endMask: u, ellipsisMask: c, newAxisMask: h, shrinkAxisMask: p} = s;
            Cb(r, "stridedSlice");
            const {finalShapeSparse: d, finalShape: f, isIdentity: m, sliceDim0: g, isSimpleSlice: y, begin: b, end: x, strides: w} = Xf.sliceInfo(r.shape, a, i, o, l, u, c, h, p);
            let v;
            if (m)
                v = ux({
                    inputs: {
                        x: r
                    },
                    backend: n,
                    attrs: {
                        shape: f
                    }
                });
            else if (g || y) {
                Hs.assert(r.shape.length >= 1, (()=>`Input must have rank at least 1, got: ${r.shape.length}`));
                const e = Xf.computeOutShape(b, x, w)
                  , t = Kx({
                    inputs: {
                        x: r
                    },
                    backend: n,
                    attrs: {
                        begin: b,
                        size: e
                    }
                });
                v = ux({
                    inputs: {
                        x: t
                    },
                    backend: n,
                    attrs: {
                        shape: f
                    }
                }),
                n.disposeIntermediateTensorInfo(t)
            } else {
                const e = kS(d, n.bufferSync(r), w, b);
                v = n.makeTensorInfo(f, e.dtype, e.values)
            }
            return v
        }
    };
    class SS {
        constructor(e, t, n, s, r, a) {
            this.separator = Hs.encodeString(e),
            this.nGramWidths = t,
            this.leftPad = Hs.encodeString(n),
            this.rightPad = Hs.encodeString(s),
            this.padWidth = r,
            this.preserveShort = a
        }
        getPadWidth(e) {
            return Math.min(this.padWidth < 0 ? e - 1 : this.padWidth, e - 1)
        }
        getNumNGrams(e, t) {
            const n = this.getPadWidth(t);
            return Math.max(0, e + 2 * n - t + 1)
        }
        createNGrams(e, t, n, s, r, a) {
            for (let i = 0; i < r; ++i) {
                const o = this.getPadWidth(a)
                  , l = Math.max(0, o - i)
                  , u = Math.max(0, o - (r - (i + 1)))
                  , c = a - (l + u)
                  , h = t + (l > 0 ? 0 : i - o);
                let p = 0;
                p += l * this.leftPad.length;
                for (let t = 0; t < c; ++t)
                    p += e[h + t].length;
                p += u * this.rightPad.length;
                p += (l + u + c - 1) * this.separator.length,
                n[s + i] = new Uint8Array(p);
                const d = n[s + i];
                let f = 0;
                const m = e=>e.forEach((e=>d[f++] = e));
                for (let e = 0; e < l; ++e)
                    m(this.leftPad),
                    m(this.separator);
                for (let t = 0; t < c - 1; ++t)
                    m(e[h + t]),
                    m(this.separator);
                if (c > 0) {
                    m(e[h + c - 1]);
                    for (let e = 0; e < u; ++e)
                        m(this.separator),
                        m(this.rightPad)
                } else {
                    for (let e = 0; e < u - 1; ++e)
                        m(this.rightPad),
                        m(this.separator);
                    m(this.rightPad)
                }
            }
        }
        compute(e, t) {
            const n = e.length
              , s = t.length;
            if (s > 0) {
                let e = t[0];
                if (0 !== e)
                    throw new Error(`First split value must be 0, got ${e}`);
                for (let r = 1; r < s; ++r) {
                    let s = t[r] >= e;
                    if (s = s && t[r] <= n,
                    !s)
                        throw new Error(`Invalid split value ${t[r]}, must be in [${e}, ${n}]`);
                    e = t[r]
                }
                if (e !== n)
                    throw new Error(`Last split value must be data size. Expected ${n}, got ${e}`)
            }
            const r = s - 1
              , a = Hs.getArrayFromDType("int32", s);
            if (0 === n || 0 === s) {
                const e = new Array(n);
                for (let e = 0; e <= r; ++e)
                    a[e] = 0;
                return [e, a]
            }
            a[0] = 0;
            for (let e = 1; e <= r; ++e) {
                const n = t[e] - t[e - 1];
                let s = 0;
                this.nGramWidths.forEach((e=>{
                    s += this.getNumNGrams(n, e)
                }
                )),
                this.preserveShort && n > 0 && 0 === s && (s = 1),
                a[e] = a[e - 1] + s
            }
            const i = new Array(a[r]);
            for (let n = 0; n < r; ++n) {
                const s = t[n];
                let r = a[n];
                if (this.nGramWidths.forEach((a=>{
                    const o = t[n + 1] - t[n]
                      , l = this.getNumNGrams(o, a);
                    this.createNGrams(e, s, i, r, l, a),
                    r += l
                }
                )),
                this.preserveShort && r === a[n]) {
                    const a = t[n + 1] - t[n];
                    if (0 === a)
                        continue;
                    const o = a + 2 * this.padWidth
                      , l = 1;
                    this.createNGrams(e, s, i, r, l, o)
                }
            }
            return [i, a]
        }
    }
    function NS(e, t, n, s, r, a, i, o) {
        return new SS(n,s,r,a,i,o).compute(e, t)
    }
    const TS = {
        kernelName: fs,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {separator: r, nGramWidths: a, leftPad: i, rightPad: o, padWidth: l, preserveShortSequences: u} = s
              , {data: c, dataSplits: h} = t
              , p = n.data.get(c.dataId).values
              , d = n.data.get(h.dataId).values
              , [f,m] = NS(p, d, r, a, i, o, l, u);
            return [n.makeTensorInfo([f.length], "string", f), n.makeTensorInfo(h.shape, "int32", m)]
        }
    };
    function CS(e, t, n, s) {
        if (!e.length)
            return;
        if (0 === t.length) {
            for (let t = 0; t < e.length; ++t)
                s.push(e.subarray(t, t + 1));
            return
        }
        if (1 === t.length) {
            const r = t[0];
            let a = e.indexOf(r);
            for (; -1 !== a; ) {
                const t = e.subarray(0, a);
                n && 0 === t.length || s.push(t),
                a = (e = e.subarray(a + 1)).indexOf(r)
            }
            return void (n && 0 === e.length || s.push(e))
        }
        let r = 0;
        for (let a = 0; a < e.length + 1; a++)
            if (a === e.length || -1 !== t.indexOf(e[a])) {
                const t = e.subarray(r, a);
                n && 0 === t.length || s.push(t),
                r = a + 1
            }
    }
    function $S(e, t, n) {
        const s = e.length
          , r = [];
        let a = 0
          , i = 0;
        const o = new Array(s);
        for (let l = 0; l < s; ++l) {
            const s = r.length;
            CS(e[l], t, n, r);
            const u = r.length - s;
            o[l] = u,
            a += u,
            i = Math.max(i, u)
        }
        const l = Hs.getArrayFromDType("int32", 2 * a)
          , u = new Array(a)
          , c = [s, i];
        let h = 0;
        for (let e = 0; e < s; ++e)
            for (let t = 0; t < o[e]; ++t)
                l[2 * h] = e,
                l[2 * h + 1] = t,
                u[h] = r[h],
                ++h;
        return [l, u, c]
    }
    const ES = {
        kernelName: ms,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {skipEmpty: r} = s
              , {input: a, delimiter: i} = t;
            if ("string" !== a.dtype)
                throw new Error("Input must be of datatype string");
            if (1 !== a.shape.length)
                throw new Error(`Input must be a vector, got shape: ${a.shape}`);
            if (0 !== i.shape.length)
                throw new Error(`Delimiter must be a scalar, got shape: ${i.shape}`);
            const o = n.data.get(a.dataId).values
              , l = n.data.get(i.dataId).values[0]
              , [u,c,h] = $S(o, l, r)
              , p = c.length;
            return [n.makeTensorInfo([p, 2], "int32", u), n.makeTensorInfo([p], "string", c), n.makeTensorInfo([2], "int32", new Int32Array(h))]
        }
    };
    function AS(e, t) {
        const n = Hs.getArrayFromDType("int32", e.length);
        for (let s = 0; s < e.length; ++s)
            n[s] = Hs.fingerPrint64(e[s]).modulo(t).getLowBitsUnsigned();
        return n
    }
    const RS = {
        kernelName: gs,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {numBuckets: r} = s
              , {input: a} = t;
            if ("string" !== a.dtype)
                throw new Error("Input must be of datatype string");
            if (r <= 0)
                throw new Error("Number of buckets must be at least 1");
            const i = AS(n.data.get(a.dataId).values, r);
            return n.makeTensorInfo(a.shape, "int32", i)
        }
    }
      , FS = $b(bs, (e=>Math.tan(e)))
      , DS = {
        kernelName: bs,
        backendName: "cpu",
        kernelFunc: FS
    }
      , _S = $b(xs, (e=>Math.tanh(e)));
    function OS(e, t) {
        const n = new Array(e.rank);
        for (let s = 0; s < n.length; s++)
            n[s] = e.shape[s] * t[s];
        const s = qo(n, e.dtype);
        for (let t = 0; t < s.values.length; ++t) {
            const n = s.indexToLoc(t)
              , r = new Array(e.rank);
            for (let t = 0; t < r.length; t++)
                r[t] = n[t] % e.shape[t];
            const a = e.locToIndex(r);
            s.values[t] = e.values[a]
        }
        return s
    }
    const MS = (e,t)=>{
        const n = t.value - e.value;
        return 0 === n ? e.index - t.index : n
    }
    ;
    function LS(e, t, n=0, s=e.length - 1) {
        for (; s > n; ) {
            if (s - n > 600) {
                const r = s - n + 1
                  , a = t - n + 1
                  , i = Math.log(r)
                  , o = .5 * Math.exp(2 * i / 3)
                  , l = .5 * Math.sqrt(i * o * (r - o) / r) * Math.sign(a - r / 2);
                LS(e, t, Math.max(n, Math.floor(t - a * o / r + l)), Math.min(s, Math.floor(t + (r - a) * o / r + l)))
            }
            const r = e[t];
            let a = n
              , i = s;
            for (Hs.swap(e, n, t),
            MS(e[s], r) > 0 && Hs.swap(e, n, s); a < i; ) {
                for (Hs.swap(e, a, i),
                a++,
                i--; MS(e[a], r) < 0; )
                    a += 1;
                for (; MS(e[i], r) > 0; )
                    i -= 1
            }
            0 === MS(e[n], r) ? Hs.swap(e, n, i) : (i += 1,
            Hs.swap(e, i, s)),
            i <= t && (n = i + 1),
            t <= i && (s = i - 1)
        }
    }
    function zS(e, t, n, s, r) {
        const a = t[t.length - 1]
          , [i,o] = [e.length / a, a]
          , l = Hs.getTypedArrayFromDType(n, i * s)
          , u = Hs.getTypedArrayFromDType("int32", i * s);
        for (let t = 0; t < i; t++) {
            const n = t * o
              , a = e.subarray(n, n + o);
            let i = new Array(a.length);
            a.forEach(((e,t)=>i[t] = {
                value: e,
                index: t
            })),
            s < i.length && (LS(i, s),
            i = i.slice(0, s)),
            r && i.sort(MS);
            const c = t * s
              , h = l.subarray(c, c + s)
              , p = u.subarray(c, c + s);
            for (let e = 0; e < s; e++)
                h[e] = i[e].value,
                p[e] = i[e].index
        }
        const c = t.slice();
        return c[c.length - 1] = s,
        [qo(c, n, l), qo(c, "int32", u)]
    }
    const BS = {
        kernelName: ks,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, attrs: n, backend: s} = e
              , {image: r, transforms: a} = t
              , {interpolation: i, fillMode: o, fillValue: l, outputShape: u} = n
              , [c,h,p,d] = r.shape
              , [f,m] = null != u ? u : [h, p]
              , g = [c, f, m, d]
              , y = Hs.computeStrides(r.shape)
              , b = y[0]
              , x = y[1]
              , w = y[2]
              , v = Hs.computeStrides(g)
              , k = v[0]
              , I = v[1]
              , S = v[2]
              , N = Hs.getTypedArrayFromDType(r.dtype, Hs.sizeFromShape(g));
            N.fill(l);
            const T = s.data.get(r.dataId).values
              , C = s.data.get(a.dataId).values;
            for (let e = 0; e < c; ++e) {
                const t = 1 === a.shape[0] ? C : C.subarray(8 * e, 8 * e + 8);
                for (let n = 0; n < f; ++n)
                    for (let s = 0; s < m; ++s)
                        for (let r = 0; r < d; ++r) {
                            let a;
                            const u = t[6] * s + t[7] * n + 1;
                            if (0 === u)
                                continue;
                            const c = (t[0] * s + t[1] * n + t[2]) / u
                              , d = (t[3] * s + t[4] * n + t[5]) / u
                              , f = PS(c, p, o)
                              , m = PS(d, h, o);
                            switch (i) {
                            case "nearest":
                                a = US(T, h, p, b, x, w, e, m, f, r, l);
                                break;
                            case "bilinear":
                                a = VS(T, h, p, b, x, w, e, m, f, r, l);
                                break;
                            default:
                                throw new Error(`Error in Transform: Expect 'nearest' or 'bilinear', but got ${i}`)
                            }
                            N[e * k + n * I + s * S + r] = a
                        }
                return s.makeTensorInfo(g, r.dtype, N)
            }
            return {
                dataId: s.write(N, g, r.dtype),
                shape: r.shape,
                dtype: r.dtype
            }
        }
    };
    function PS(e, t, n) {
        switch (n) {
        case "reflect":
            return function(e, t) {
                let n = e;
                if (n < 0)
                    if (t <= 1)
                        n = 0;
                    else {
                        const e = 2 * t;
                        n < e && (n = e * Math.trunc(-n / e) + n),
                        n = n < -t ? n + e : -n - 1
                    }
                else if (n > t - 1)
                    if (t <= 1)
                        n = 0;
                    else {
                        const e = 2 * t;
                        n -= e * Math.trunc(n / e),
                        n >= t && (n = e - n - 1)
                    }
                return Hs.clamp(0, n, t - 1)
            }(e, t);
        case "wrap":
            return function(e, t) {
                let n = e;
                if (n < 0)
                    if (t <= 1)
                        n = 0;
                    else {
                        const e = t - 1;
                        n += t * (Math.trunc(-n / e) + 1)
                    }
                else if (n > t - 1)
                    if (t <= 1)
                        n = 0;
                    else {
                        const e = t - 1;
                        n -= t * Math.trunc(n / e)
                    }
                return Hs.clamp(0, n, t - 1)
            }(e, t);
        case "nearest":
            return function(e, t) {
                return Hs.clamp(0, e, t - 1)
            }(e, t);
        default:
            return function(e, t) {
                return e
            }(e)
        }
    }
    function WS(e, t, n, s, r, a, i, o, l, u, c) {
        return 0 <= o && o < t && 0 <= l && l < n ? e[i * s + o * r + l * a + u] : c
    }
    function US(e, t, n, s, r, a, i, o, l, u, c) {
        return WS(e, t, n, s, r, a, i, Math.round(o), Math.round(l), u, c)
    }
    function VS(e, t, n, s, r, a, i, o, l, u, c) {
        const h = Math.floor(o)
          , p = Math.floor(l)
          , d = h + 1
          , f = p + 1;
        return (d - o) * ((f - l) * WS(e, t, n, s, r, a, i, h, p, u, c) + (l - p) * WS(e, t, n, s, r, a, i, h, f, u, c)) + (o - h) * ((f - l) * WS(e, t, n, s, r, a, i, d, p, u, c) + (l - p) * WS(e, t, n, s, r, a, i, d, f, u, c))
    }
    function GS(e, t, n, s) {
        const r = Hs.parseAxisParam(t, n)[0]
          , a = [1, n[0], 1];
        for (let e = 0; e < r; e++)
            a[0] *= n[e];
        a[1] = n[r];
        for (let e = r + 1; e < n.length; e++)
            a[2] *= n[e];
        const i = {}
          , o = new Int32Array(n[r])
          , l = new qr(a,s,e)
          , u = []
          , c = 1 === a[0] && 1 === a[2];
        for (let t = 0; t < n[r]; t++) {
            let n;
            if (c)
                n = e[t].toString();
            else {
                const e = [];
                for (let n = 0; n < a[0]; n++)
                    for (let s = 0; s < a[2]; s++)
                        e.push(l.get(n, t, s));
                n = e.join(",")
            }
            if (void 0 !== i[n])
                o[t] = i[n];
            else {
                const e = Object.keys(i).length;
                i[n] = e,
                o[t] = e,
                u.push(t)
            }
        }
        const h = a.slice();
        h[1] = Object.keys(i).length;
        const p = new qr(h,s);
        u.forEach(((e,t)=>{
            for (let n = 0; n < a[0]; n++)
                for (let s = 0; s < a[2]; s++)
                    p.set(l.get(n, e, s), n, t, s)
        }
        ));
        const d = n.slice();
        return d[r] = h[1],
        {
            outputValues: p.values,
            outputShape: d,
            indices: o
        }
    }
    const HS = [dx, mx, yx, xx, lx, wx, Sx, Nx, Tx, Cx, Ex, Rx, Dx, Mx, zx, Ux, Vx, Gx, Hx, px, jx, Yx, Qx, ew, nx, sw, aw, Yb, iw, hw, dw, fw, mw, gw, yw, bw, ww, kw, Iw, Sw, Nw, Tw, Cw, Ew, Aw, Rw, Fw, Dw, _w, Ow, Uw, Rb, Vw, jw, ev, sv, av, lv, xv, vv, kv, Nv, $v, Ev, Av, Fv, _v, Lv, Pv, Db, Wv, uw, Vv, Hv, qv, Ob, Yv, Qv, tk, rk, ik, uk, hk, fk, mk, gk, xk, kk, Ik, Sk, Nk, Tk, Ck, $k, Ek, Fk, Dk, Mk, Bk, Bw, Wk, Vk, Hk, qk, Yk, Zk, eI, nI, sI, iI, Bb, lI, dI, gI, kI, SI, Qb, hv, TI, Wb, Vb, cx, CI, $I, EI, AI, RI, FI, _I, LI, BI, UI, VI, qI, qb, XI, ZI, QI, Xx, zk, nS, sS, aS, oS, uS, cS, hS, pS, mS, gS, xS, vS, IS, TS, ES, RS, mv, Ww, DS, {
        kernelName: xs,
        backendName: "cpu",
        kernelFunc: _S
    }, {
        kernelName: ws,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {reps: a} = s;
            Cb(r, "tile");
            const i = OS(n.bufferSync(r), a);
            return n.makeTensorInfo(i.shape, i.dtype, i.values)
        }
    }, {
        kernelName: vs,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {k: a, sorted: i} = s;
            Cb(r, "topk");
            const o = n.data.get(r.dataId).values
              , [l,u] = zS(o, r.shape, r.dtype, a, i);
            return [n.makeTensorInfo(l.shape, l.dtype, l.values), n.makeTensorInfo(u.shape, u.dtype, u.values)]
        }
    }, BS, Ix, {
        kernelName: Ss,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, attrs: n, backend: s} = e
              , {axis: r} = n
              , {x: a} = t;
            Cb(a, "unique");
            const i = s.data.get(a.dataId).values
              , {outputValues: o, outputShape: l, indices: u} = GS(i, r, a.shape, a.dtype);
            return [s.makeTensorInfo(l, a.dtype, o), s.makeTensorInfo([u.length], "int32", u)]
        }
    }, {
        kernelName: Ns,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {value: r} = t;
            let {axis: a} = s;
            a < 0 && (a += r.shape.length);
            const i = r.shape.length
              , o = r.shape[a]
              , l = new Array(i - 1);
            let u = 0;
            for (let e = 0; e < i; e++)
                e !== a && (l[u++] = r.shape[e]);
            const c = new Array(i).fill(0)
              , h = r.shape.slice();
            h[a] = 1;
            const p = new Array(o);
            for (let e = 0; e < p.length; e++) {
                c[a] = e;
                const t = Kx({
                    inputs: {
                        x: r
                    },
                    backend: n,
                    attrs: {
                        begin: c,
                        size: h
                    }
                });
                p[e] = ux({
                    inputs: {
                        x: t
                    },
                    backend: n,
                    attrs: {
                        shape: l
                    }
                }),
                n.disposeIntermediateTensorInfo(t)
            }
            return p
        }
    }, {
        kernelName: Ts,
        backendName: "cpu",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, segmentIds: a} = t
              , {numSegments: i} = s;
            Cb(r, "unsortedSegmentSum");
            const o = []
              , l = []
              , u = r.shape.length - a.shape.length;
            let c = a;
            for (let e = 0; e < u; ++e) {
                const t = rv({
                    inputs: {
                        input: c
                    },
                    backend: n,
                    attrs: {
                        dim: e + 1
                    }
                });
                c = t,
                l.push(t)
            }
            for (let e = 0; e < i; ++e) {
                const t = Hs.createScalarValue(e, "int32")
                  , s = n.makeTensorInfo([], "int32", t)
                  , a = Hw({
                    inputs: {
                        a: s,
                        b: c
                    },
                    backend: n
                })
                  , i = tx({
                    inputs: {
                        x: a
                    },
                    backend: n,
                    attrs: {
                        dtype: "float32"
                    }
                })
                  , u = zw({
                    inputs: {
                        a: i,
                        b: r
                    },
                    backend: n
                })
                  , h = Pw({
                    inputs: {
                        x: u
                    },
                    backend: n,
                    attrs: {
                        axis: 0,
                        keepDims: !1
                    }
                });
                o.push(h),
                l.push(s),
                l.push(a),
                l.push(i),
                l.push(u),
                l.push(h)
            }
            const h = tI({
                inputs: o,
                backend: n,
                attrs: {
                    axis: 0
                }
            });
            return l.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            h
        }
    }, Qk];
    for (const e of HS)
        Us(e);
    const jS = Dg.whereImpl;
    class qS extends o {
        constructor() {
            super(),
            this.blockSize = 48,
            this.firstUse = !0,
            this.data = new i(this,Zo())
        }
        nextDataId() {
            return qS.nextDataId++
        }
        write(e, t, n) {
            this.firstUse && (this.firstUse = !1,
            ie().get("IS_NODE") && dm.warn("\n============================\nHi, looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, visit https://github.com/tensorflow/tfjs-node for more details. \n============================"));
            const s = {
                id: this.nextDataId()
            };
            return this.data.set(s, {
                values: e,
                dtype: n,
                refCount: 1
            }),
            s
        }
        makeTensorInfo(e, t, n) {
            let s;
            if ("string" === t && null != n && n.length > 0 && Hs.isString(n[0])) {
                const r = n.map((e=>Hs.encodeString(e)));
                s = this.write(r, e, t)
            } else
                s = this.write(n, e, t);
            return {
                dataId: s,
                shape: e,
                dtype: t
            }
        }
        refCount(e) {
            if (this.data.has(e)) {
                return this.data.get(e).refCount
            }
            return 0
        }
        incRef(e) {
            this.data.get(e).refCount++
        }
        decRef(e) {
            if (this.data.has(e)) {
                this.data.get(e).refCount--
            }
        }
        move(e, t, n, s, r) {
            this.data.set(e, {
                values: t,
                dtype: s,
                refCount: r
            })
        }
        numDataIds() {
            return this.data.numDataIds()
        }
        async read(e) {
            return this.readSync(e)
        }
        readSync(e) {
            const {dtype: t, complexTensorInfos: n} = this.data.get(e);
            if ("complex64" === t) {
                const e = this.readSync(n.real.dataId)
                  , t = this.readSync(n.imag.dataId);
                return dm.mergeRealAndImagArrays(e, t)
            }
            return Hs.convertBackendValuesAndArrayBuffer(this.data.get(e).values, t)
        }
        bufferSync(e) {
            const t = this.readSync(e.dataId);
            if ("string" === e.dtype)
                try {
                    const n = t.map((e=>Hs.decodeString(e)));
                    return qo(e.shape, e.dtype, n)
                } catch (e) {
                    throw new Error("Failed to decode encoded string bytes into utf-8")
                }
            return qo(e.shape, e.dtype, t)
        }
        makeOutput(e, t, n) {
            return Zo().makeTensorFromTensorInfo(this.makeTensorInfo(t, n, e), this)
        }
        disposeData(e, t=!1) {
            if (this.data.has(e)) {
                if (this.data.get(e).refCount--,
                !t && this.data.get(e).refCount > 0)
                    return !1;
                const {complexTensorInfos: n} = this.data.get(e);
                null != n && (this.disposeData(n.real.dataId, !0),
                this.disposeData(n.imag.dataId, !0)),
                this.data.delete(e)
            }
            return !0
        }
        disposeIntermediateTensorInfo(e) {
            this.disposeData(e.dataId)
        }
        async time(e) {
            const t = Hs.now();
            e();
            return {
                kernelMs: Hs.now() - t
            }
        }
        memory() {
            return {
                unreliable: !0,
                reasons: ["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."]
            }
        }
        where(e) {
            Cb([e], "where");
            const t = this.readSync(e.dataId);
            return jS(e.shape, t)
        }
        dispose() {}
        floatPrecision() {
            return 32
        }
        epsilon() {
            return super.epsilon()
        }
    }
    qS.nextDataId = 0;
    function KS() {
        let e, t, n, s, r, a, i, o, l, u;
        return 2 === ie().getNumber("WEBGL_VERSION") ? (e = "#version 300 es",
        t = "in",
        n = "out",
        s = "in",
        r = "texture",
        a = "outputColor",
        i = "out vec4 outputColor;",
        o = ie().getBool("WEBGL2_ISNAN_CUSTOM") ? "\n      bool isnan_custom(float val) {\n        uint floatToUint = floatBitsToUint(val);\n        return (floatToUint & 0x7fffffffu) > 0x7f800000u;\n      }\n\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan_custom(val.x),\n          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));\n      }\n\n      #define isnan(value) isnan_custom(value)\n    " : "",
        l = "",
        u = "\n      #define round(value) newRound(value)\n      int newRound(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 newRound(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    ") : (e = "",
        t = "attribute",
        n = "varying",
        s = "varying",
        r = "texture2D",
        a = "gl_FragColor",
        i = "",
        o = "\n      #define isnan(value) isnan_custom(value)\n      bool isnan_custom(float val) {\n        return (val > 0. || val < 1. || val == 0.) ? false : true;\n      }\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));\n      }\n    ",
        l = "\n      uniform float INFINITY;\n\n      bool isinf(float val) {\n        return abs(val) == INFINITY;\n      }\n      bvec4 isinf(vec4 val) {\n        return equal(abs(val), vec4(INFINITY));\n      }\n    ",
        u = "\n      int round(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 round(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    "),
        {
            version: e,
            attribute: t,
            varyingVs: n,
            varyingFs: s,
            texture2D: r,
            output: a,
            defineOutput: i,
            defineSpecialNaN: o,
            defineSpecialInf: l,
            defineRound: u
        }
    }
    function XS(e, t, n="index") {
        const s = Hs.computeStrides(t);
        return s.map(((t,r)=>`${`int ${e[r]} = ${n} / ${t}`}; ${r === s.length - 1 ? `int ${e[r + 1]} = ${n} - ${e[r]} * ${t}` : `index -= ${e[r]} * ${t}`};`)).join("")
    }
    function YS(e, t, n="index") {
        const s = Hs.computeStrides(t);
        return s.map(((t,r)=>`${`int ${e[r]} = ${n} / outShapeStrides[${r}]`}; ${r === s.length - 1 ? `int ${e[r + 1]} = ${n} - ${e[r]} * outShapeStrides[${r}]` : `index -= ${e[r]} * outShapeStrides[${r}]`};`)).join("")
    }
    function ZS(e, t, n="index") {
        const s = function(e, t) {
            const n = e.length
              , s = e.map((e=>`${t}[${e}]`))
              , r = new Array(n - 1);
            r[n - 2] = s[n - 1];
            for (let e = n - 3; e >= 0; --e)
                r[e] = `(${r[e + 1]} * ${s[e + 1]})`;
            return r
        }(e.map(((e,t)=>t)), t);
        return s.map(((t,r)=>`${`int ${e[r]} = ${n} / ${s[r]}`}; ${r === s.length - 1 ? `int ${e[r + 1]} = ${n} - ${e[r]} * ${s[r]}` : `index -= ${e[r]} * ${s[r]}`};`)).join("")
    }
    function JS(e) {
        const t = Hs.computeStrides(e).map((e=>e.toString()));
        return `\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * ${t[0]} + coords.y * ${t[1]} + coords.z;\n  }\n`
    }
    nl("cpu", (()=>new qS), 1);
    const QS = "\n  const float FLOAT_MAX = 1.70141184e38;\n  const float FLOAT_MIN = 1.17549435e-38;\n\n  lowp vec4 encode_float(highp float v) {\n    if (isnan(v)) {\n      return vec4(255, 255, 255, 255);\n    }\n\n    highp float av = abs(v);\n\n    if(av < FLOAT_MIN) {\n      return vec4(0.0, 0.0, 0.0, 0.0);\n    } else if(v > FLOAT_MAX) {\n      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;\n    } else if(v < -FLOAT_MAX) {\n      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;\n    }\n\n    highp vec4 c = vec4(0,0,0,0);\n\n    highp float e = floor(log2(av));\n    highp float m = exp2(fract(log2(av))) - 1.0;\n\n    c[2] = floor(128.0 * m);\n    m -= c[2] / 128.0;\n    c[1] = floor(32768.0 * m);\n    m -= c[1] / 32768.0;\n    c[0] = floor(8388608.0 * m);\n\n    highp float ebias = e + 127.0;\n    c[3] = floor(ebias / 2.0);\n    ebias -= c[3] * 2.0;\n    c[2] += floor(ebias) * 128.0;\n\n    c[3] += 128.0 * step(0.0, -v);\n\n    return c / 255.0;\n  }\n"
      , {getBroadcastDims: eN} = dm;
    function tN(e, t, n) {
        const s = [];
        if (e.forEach((e=>{
            const t = Hs.sizeFromShape(e.shapeInfo.logicalShape);
            if (e.shapeInfo.isUniform ? s.push(`uniform float ${e.name}${t > 1 ? `[${t}]` : ""};`) : (s.push(`uniform sampler2D ${e.name};`),
            s.push(`uniform int offset${e.name};`)),
            n.enableShapeUniforms) {
                const {uniformShape: t} = pN(n.packedInputs, e.shapeInfo.logicalShape, e.shapeInfo.texShape);
                switch (t.length) {
                case 1:
                    s.push(`uniform int ${e.name}Shape;`);
                    break;
                case 2:
                    s.push(`uniform ivec2 ${e.name}Shape;`);
                    break;
                case 3:
                    s.push(`uniform ivec3 ${e.name}Shape;`);
                    break;
                case 4:
                    s.push(`uniform ivec4 ${e.name}Shape;`)
                }
                s.push(`uniform ivec2 ${e.name}TexShape;`)
            }
        }
        )),
        n.enableShapeUniforms) {
            switch (t.logicalShape.length) {
            case 1:
                s.push("uniform int outShape;");
                break;
            case 2:
                s.push("uniform ivec2 outShape;"),
                s.push("uniform int outShapeStrides;");
                break;
            case 3:
                s.push("uniform ivec3 outShape;"),
                s.push("uniform ivec2 outShapeStrides;");
                break;
            case 4:
                s.push("uniform ivec4 outShape;"),
                s.push("uniform ivec3 outShapeStrides;")
            }
            s.push("uniform ivec2 outTexShape;")
        }
        n.customUniforms && n.customUniforms.forEach((e=>{
            s.push(`uniform ${e.type} ${e.name}${e.arrayIndex ? `[${e.arrayIndex}]` : ""};`)
        }
        ));
        const r = s.join("\n")
          , a = e.map((e=>function(e, t, n=!1, s) {
            let r = "";
            r += n ? sN(e, s) : nN(e, s);
            const a = e.shapeInfo.logicalShape
              , i = t.logicalShape;
            a.length <= i.length && (r += n ? function(e, t) {
                const n = e.name
                  , s = n.charAt(0).toUpperCase() + n.slice(1)
                  , r = "get" + s + "AtOutCoords"
                  , a = e.shapeInfo.logicalShape.length
                  , i = t.logicalShape.length
                  , o = eN(e.shapeInfo.logicalShape, t.logicalShape)
                  , l = hN(i)
                  , u = i - a;
                let c;
                const h = ["x", "y", "z", "w", "u", "v"];
                c = 0 === a ? "" : i < 2 && o.length >= 1 ? "coords = 0;" : o.map((e=>`coords.${h[e + u]} = 0;`)).join("\n");
                let p = "";
                p = i < 2 && a > 0 ? "coords" : e.shapeInfo.logicalShape.map(((e,t)=>`coords.${h[t + u]}`)).join(", ");
                let d = "return outputValue;";
                const f = 1 === Hs.sizeFromShape(e.shapeInfo.logicalShape)
                  , m = 1 === Hs.sizeFromShape(t.logicalShape);
                if (1 !== a || f || m) {
                    if (f && !m)
                        d = 1 === i ? "\n        return vec4(outputValue.x, outputValue.x, 0., 0.);\n      " : "\n        return vec4(outputValue.x);\n      ";
                    else if (o.length) {
                        const e = a - 2
                          , t = a - 1;
                        o.indexOf(e) > -1 && o.indexOf(t) > -1 ? d = "return vec4(outputValue.x);" : o.indexOf(e) > -1 ? d = "return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);" : o.indexOf(t) > -1 && (d = "return vec4(outputValue.xx, outputValue.zz);")
                    }
                } else
                    d = "\n      return vec4(outputValue.xy, outputValue.xy);\n    ";
                return `\n    vec4 ${r}() {\n      ${l} coords = getOutputCoords();\n      ${c}\n      vec4 outputValue = get${s}(${p});\n      ${d}\n    }\n  `
            }(e, t) : function(e, t) {
                const n = e.name
                  , s = n.charAt(0).toUpperCase() + n.slice(1)
                  , r = "get" + s + "AtOutCoords"
                  , a = t.texShape
                  , i = e.shapeInfo.texShape
                  , o = e.shapeInfo.logicalShape.length
                  , l = t.logicalShape.length;
                if (!e.shapeInfo.isUniform && o === l && null == e.shapeInfo.flatOffset && Hs.arraysEqual(i, a))
                    return `\n      float ${r}() {\n        return sampleTexture(${n}, resultUV);\n      }\n    `;
                const u = hN(l)
                  , c = eN(e.shapeInfo.logicalShape, t.logicalShape)
                  , h = l - o;
                let p;
                const d = ["x", "y", "z", "w", "u", "v"];
                p = 0 === o ? "" : l < 2 && c.length >= 1 ? "coords = 0;" : c.map((e=>`coords.${d[e + h]} = 0;`)).join("\n");
                let f = "";
                f = l < 2 && o > 0 ? "coords" : e.shapeInfo.logicalShape.map(((e,t)=>`coords.${d[t + h]}`)).join(", ");
                return `\n    float ${r}() {\n      ${u} coords = getOutputCoords();\n      ${p}\n      return get${s}(${f});\n    }\n  `
            }(e, t));
            return r
        }(e, t, n.packedInputs, n.enableShapeUniforms))).join("\n")
          , i = t.texShape
          , o = KS()
          , l = function(e) {
            return `\n    float sampleTexture(sampler2D textureSampler, vec2 uv) {\n      return ${e.texture2D}(textureSampler, uv).r;\n    }\n  `
        }(o);
        let u, c, h = function(e) {
            return `${e.version}\n    precision highp float;\n    precision highp int;\n    precision highp sampler2D;\n    ${e.varyingFs} vec2 resultUV;\n    ${e.defineOutput}\n    const vec2 halfCR = vec2(0.5, 0.5);\n\n    struct ivec5\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n    };\n\n    struct ivec6\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n      int v;\n    };\n\n    uniform float NAN;\n    ${e.defineSpecialNaN}\n    ${e.defineSpecialInf}\n    ${e.defineRound}\n\n    int imod(int x, int y) {\n      return x - y * (x / y);\n    }\n\n    int idiv(int a, int b, float sign) {\n      int res = a / b;\n      int mod = imod(a, b);\n      if (sign < 0. && mod != 0) {\n        res -= 1;\n      }\n      return res;\n    }\n\n    //Based on the work of Dave Hoskins\n    //https://www.shadertoy.com/view/4djSRW\n    #define HASHSCALE1 443.8975\n    float random(float seed){\n      vec2 p = resultUV * seed;\n      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);\n      p3 += dot(p3, p3.yzx + 19.19);\n      return fract((p3.x + p3.y) * p3.z);\n    }\n\n    ${rN}\n    ${aN}\n    ${iN}\n  `
        }(o);
        t.isPacked ? (u = function(e, t, n) {
            switch (e.length) {
            case 0:
                return lN();
            case 1:
                return function(e, t, n) {
                    const s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)];
                    if (1 === s[0])
                        return n ? "\n      int getOutputCoords() {\n        return 2 * int(resultUV.x * ceil(float(outTexShape[1]) / 2.0));\n      }\n    " : `\n      int getOutputCoords() {\n        return 2 * int(resultUV.x * ${s[1]}.0);\n      }\n    `;
                    if (1 === s[1])
                        return n ? "\n      int getOutputCoords() {\n        return 2 * int(resultUV.y * ceil(float(outTexShape[0]) / 2.0));\n      }\n    " : `\n      int getOutputCoords() {\n        return 2 * int(resultUV.y * ${s[0]}.0);\n      }\n    `;
                    return n ? "\n    int getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      return 2 * (resTexRC.x * packedTexShape[1] + resTexRC.y);\n    }\n  " : `\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${s[0]}, ${s[1]}));\n      return 2 * (resTexRC.x * ${s[1]} + resTexRC.y);\n    }\n  `
                }(0, t, n);
            case 2:
                return function(e, t, n) {
                    const s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)];
                    if (Hs.arraysEqual(e, t))
                        return n ? "\n      ivec2 getOutputCoords() {\n        ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n        return 2 * ivec2(resultUV.yx * vec2(packedTexShape[0], packedTexShape[1]));\n      }\n    " : `\n      ivec2 getOutputCoords() {\n        return 2 * ivec2(resultUV.yx * vec2(${s[0]}, ${s[1]}));\n      }\n    `;
                    const r = Math.ceil(e[1] / 2);
                    return n ? "\n    ivec2 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      int texelsInLogicalRow = int(ceil(float(outShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec2(r, c);\n    }\n  " : `\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${s[0]}, ${s[1]}));\n\n      int index = resTexRC.x * ${s[1]} + resTexRC.y;\n      int r = 2 * (index / ${r});\n      int c = imod(index, ${r}) * 2;\n\n      return ivec2(r, c);\n    }\n  `
                }(e, t, n);
            case 3:
                return function(e, t, n) {
                    if (n)
                        return "\n    ivec3 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      int texelsInLogicalRow = int(ceil(float(outShape[2]) / 2.0));\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n\n      int b = index / texelsInBatch;\n      index -= b * texelsInBatch;\n\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec3(b, r, c);\n    }\n  ";
                    const s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)]
                      , r = Math.ceil(e[2] / 2)
                      , a = r * Math.ceil(e[1] / 2);
                    return `\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${s[0]}, ${s[1]}));\n      int index = resTexRC.x * ${s[1]} + resTexRC.y;\n\n      int b = index / ${a};\n      index -= b * ${a};\n\n      int r = 2 * (index / ${r});\n      int c = imod(index, ${r}) * 2;\n\n      return ivec3(b, r, c);\n    }\n  `
                }(e, t, n);
            default:
                return function(e, t, n) {
                    if (n)
                        return "\n    ivec4 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n\n      int texelsInLogicalRow = int(ceil(float(outShape[3]) / 2.0));\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[2]) / 2.0));\n      int texelsInBatchN = texelsInBatch * outShape[1];\n\n      int b2 = index / texelsInBatchN;\n      index -= b2 * texelsInBatchN;\n\n      int b = index / texelsInBatch;\n      index -= b * texelsInBatch;\n\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec4(b2, b, r, c);\n    }\n  ";
                    const s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)]
                      , r = Math.ceil(e[e.length - 1] / 2)
                      , a = r * Math.ceil(e[e.length - 2] / 2);
                    let i = a
                      , o = ""
                      , l = "b, r, c";
                    for (let t = 2; t < e.length - 1; t++)
                        i *= e[e.length - t - 1],
                        o = `\n      int b${t} = index / ${i};\n      index -= b${t} * ${i};\n    ` + o,
                        l = `b${t}, ` + l;
                    return `\n    ivec${e.length} getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${s[0]}, ${s[1]}));\n      int index = resTexRC.x * ${s[1]} + resTexRC.y;\n\n      ${o}\n\n      int b = index / ${a};\n      index -= b * ${a};\n\n      int r = 2 * (index / ${r});\n      int c = imod(index, ${r}) * 2;\n\n      return ivec${e.length}(${l});\n    }\n  `
                }(e, t, n)
            }
        }(t.logicalShape, i, n.enableShapeUniforms),
        c = function(e) {
            return `\n    void setOutput(vec4 val) {\n      ${e.output} = val;\n    }\n  `
        }(o)) : (u = function(e, t, n) {
            switch (e.length) {
            case 0:
                return lN();
            case 1:
                return function(e, t, n) {
                    if (1 === t[0])
                        return n ? "\n      int getOutputCoords() {\n        return int(resultUV.x * float(outTexShape[1]));\n      }\n    " : `\n      int getOutputCoords() {\n        return int(resultUV.x * ${t[1]}.0);\n      }\n    `;
                    if (1 === t[1])
                        return n ? "\n      int getOutputCoords() {\n        return int(resultUV.y * float(outTexShape[0]));\n      }\n    " : `\n      int getOutputCoords() {\n        return int(resultUV.y * ${t[0]}.0);\n      }\n    `;
                    return n ? "\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(outTexShape[0], outTexShape[1]));\n      return resTexRC.x * outTexShape[1] + resTexRC.y;\n    }\n  " : `\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${t[0]}, ${t[1]}));\n      return resTexRC.x * ${t[1]} + resTexRC.y;\n    }\n  `
                }(0, t, n);
            case 2:
                return function(e, t, n) {
                    if (Hs.arraysEqual(e, t))
                        return n ? "\n      ivec2 getOutputCoords() {\n        return ivec2(resultUV.yx * vec2(outTexShape[0], outTexShape[1]));\n      }\n    " : `\n      ivec2 getOutputCoords() {\n        return ivec2(resultUV.yx * vec2(${t[0]}, ${t[1]}));\n      }\n    `;
                    if (1 === e[1])
                        return n ? "\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(outTexShape[0], outTexShape[1]));\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n        return ivec2(index, 0);\n      }\n    " : `\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(${t[0]}, ${t[1]}));\n        int index = resTexRC.x * ${t[1]} + resTexRC.y;\n        return ivec2(index, 0);\n      }\n    `;
                    if (1 === e[0])
                        return n ? "\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(outTexShape[0], outTexShape[1]));\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n        return ivec2(0, index);\n      }\n    " : `\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(${t[0]}, ${t[1]}));\n        int index = resTexRC.x * ${t[1]} + resTexRC.y;\n        return ivec2(0, index);\n      }\n    `;
                    return n ? "\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(outTexShape[0], outTexShape[1]));\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n      int r = index / outShape[1];\n      int c = index - r * outShape[1];\n      return ivec2(r, c);\n    }\n  " : `\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${t[0]}, ${t[1]}));\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n      int r = index / ${e[1]};\n      int c = index - r * ${e[1]};\n      return ivec2(r, c);\n    }\n  `
                }(e, t, n);
            case 3:
                return function(e, t, n) {
                    if (n) {
                        return `\n  ivec3 getOutputCoords() {\n    ivec2 resTexRC = ivec2(resultUV.yx *\n                           vec2(outTexShape[0], outTexShape[1]));\n    int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n    ${YS(["r", "c", "d"], e)}\n    return ivec3(r, c, d);\n  }\n`
                    }
                    const s = XS(["r", "c", "d"], e);
                    return `\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${t[0]}, ${t[1]}));\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n      ${s}\n      return ivec3(r, c, d);\n    }\n  `
                }(e, t, n);
            case 4:
                return function(e, t, n) {
                    if (n) {
                        return `\n    ivec4 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(outTexShape[0], outTexShape[1]));\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n      ${YS(["r", "c", "d", "d2"], e)}\n      return ivec4(r, c, d, d2);\n    }\n  `
                    }
                    const s = XS(["r", "c", "d", "d2"], e);
                    return `\n    ivec4 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(${t[0]}, ${t[1]}));\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n      ${s}\n      return ivec4(r, c, d, d2);\n    }\n  `
                }(e, t, n);
            case 5:
                return function(e, t) {
                    const n = XS(["r", "c", "d", "d2", "d3"], e);
                    return `\n    ivec5 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx * vec2(${t[0]},\n                             ${t[1]}));\n\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n\n      ${n}\n\n      ivec5 outShape = ivec5(r, c, d, d2, d3);\n      return outShape;\n    }\n  `
                }(e, t);
            case 6:
                return function(e, t) {
                    const n = XS(["r", "c", "d", "d2", "d3", "d4"], e);
                    return `\n    ivec6 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(${t[0]}, ${t[1]}));\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n\n      ${n}\n\n      ivec6 result = ivec6(r, c, d, d2, d3, d4);\n      return result;\n    }\n  `
                }(e, t);
            default:
                throw new Error(`${e.length}-D output sampling is not yet supported`)
            }
        }(t.logicalShape, i, n.enableShapeUniforms),
        c = function(e) {
            return `\n    void setOutput(float val) {\n      ${e.output} = vec4(val, 0, 0, 0);\n    }\n  `
        }(o)),
        n.packedInputs && (h += oN);
        return [h, l, c, r, u, a, n.userCode].join("\n")
    }
    function nN(e, t=!1) {
        const n = e.shapeInfo.logicalShape;
        switch (n.length) {
        case 0:
            return function(e, t) {
                const n = e.name
                  , s = "get" + n.charAt(0).toUpperCase() + n.slice(1);
                if (e.shapeInfo.isUniform)
                    return `float ${s}() {return ${n};}`;
                const [r,a] = e.shapeInfo.texShape;
                if (1 === r && 1 === a)
                    return `\n      float ${s}() {\n        return sampleTexture(${n}, halfCR);\n      }\n    `;
                const i = uN(n);
                if (t)
                    return `\n    float ${s}() {\n      vec2 uv = uvFromFlat(${n}TexShape[0], ${n}TexShape[1], ${i});\n      return sampleTexture(${n}, uv);\n    }\n  `;
                const [o,l] = e.shapeInfo.texShape;
                return `\n    float ${s}() {\n      vec2 uv = uvFromFlat(${o}, ${l}, ${i});\n      return sampleTexture(${n}, uv);\n    }\n  `
            }(e, t);
        case 1:
            return function(e, t) {
                const n = e.name
                  , s = "get" + n.charAt(0).toUpperCase() + n.slice(1);
                if (e.shapeInfo.isUniform)
                    return `\n      float ${s}(int index) {\n        ${cN(e)}\n      }\n    `;
                const r = e.shapeInfo.texShape
                  , a = r[0]
                  , i = r[1];
                if (1 === i && 1 === a)
                    return `\n      float ${s}(int index) {\n        return sampleTexture(${n}, halfCR);\n      }\n    `;
                const o = uN(n);
                if (1 === i)
                    return t ? `\n      float ${s}(int index) {\n        vec2 uv = vec2(0.5, (float(index + ${o}) + 0.5) / float(${n}TexShape[0]));\n        return sampleTexture(${n}, uv);\n      }\n    ` : `\n      float ${s}(int index) {\n        vec2 uv = vec2(0.5, (float(index + ${o}) + 0.5) / ${a}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;
                if (1 === a)
                    return t ? `\n      float ${s}(int index) {\n        vec2 uv = vec2((float(index + ${o}) + 0.5) / float(${n}TexShape[1]), 0.5);\n        return sampleTexture(${n}, uv);\n      }\n    ` : `\n      float ${s}(int index) {\n        vec2 uv = vec2((float(index + ${o}) + 0.5) / ${i}.0, 0.5);\n        return sampleTexture(${n}, uv);\n      }\n    `;
                return t ? `\n    float ${s}(int index) {\n      vec2 uv = uvFromFlat(${n}TexShape[0], ${n}TexShape[1], index + ${o});\n      return sampleTexture(${n}, uv);\n    }\n  ` : `\n    float ${s}(int index) {\n      vec2 uv = uvFromFlat(${a}, ${i}, index + ${o});\n      return sampleTexture(${n}, uv);\n    }\n  `
            }(e, t);
        case 2:
            return function(e, t) {
                const n = e.shapeInfo.logicalShape
                  , s = e.name
                  , r = "get" + s.charAt(0).toUpperCase() + s.slice(1)
                  , a = e.shapeInfo.texShape;
                if (null != a && Hs.arraysEqual(n, a)) {
                    if (t)
                        return `\n      float ${r}(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(${s}TexShape[1], ${s}TexShape[0]);\n        return sampleTexture(${s}, uv);\n      }\n    `;
                    const e = a[0];
                    return `\n    float ${r}(int row, int col) {\n      vec2 uv = (vec2(col, row) + halfCR) / vec2(${a[1]}.0, ${e}.0);\n      return sampleTexture(${s}, uv);\n    }\n  `
                }
                const {newShape: i, keptDims: o} = Hs.squeezeShape(n)
                  , l = i;
                if (l.length < n.length) {
                    const n = ["row", "col"];
                    return `\n      ${nN(dN(e, l), t)}\n      float ${r}(int row, int col) {\n        return ${r}(${fN(n, o)});\n      }\n    `
                }
                if (e.shapeInfo.isUniform)
                    return `\n      float ${r}(int row, int col) {\n        int index = round(dot(vec2(row, col), vec2(${n[1]}, 1)));\n        ${cN(e)}\n      }\n    `;
                const u = a[0]
                  , c = a[1]
                  , h = uN(s);
                if (1 === c)
                    return t ? `\n      float ${r}(int row, int col) {\n        float index = dot(vec3(row, col, ${h}), vec3(${s}Shape[1], 1, 1));\n        vec2 uv = vec2(0.5, (index + 0.5) / float(${s}TexShape[0]));\n        return sampleTexture(${s}, uv);\n      }\n    ` : `\n    float ${r}(int row, int col) {\n      float index = dot(vec3(row, col, ${h}), vec3(${n[1]}, 1, 1));\n      vec2 uv = vec2(0.5, (index + 0.5) / ${u}.0);\n      return sampleTexture(${s}, uv);\n    }\n  `;
                if (1 === u)
                    return t ? `\n      float ${r}(int row, int col) {\n        float index = dot(vec3(row, col, ${h}), vec3(${s}Shape[1], 1, 1));\n        vec2 uv = vec2((index + 0.5) / float(${s}TexShape[1]), 0.5);\n        return sampleTexture(${s}, uv);\n      }\n    ` : `\n    float ${r}(int row, int col) {\n      float index = dot(vec3(row, col, ${h}), vec3(${n[1]}, 1, 1));\n      vec2 uv = vec2((index + 0.5) / ${c}.0, 0.5);\n      return sampleTexture(${s}, uv);\n    }\n  `;
                return t ? `\n      float ${r}(int row, int col) {\n        // Explicitly use integer operations as dot() only works on floats.\n        int index = row * ${s}Shape[1] + col + ${h};\n        vec2 uv = uvFromFlat(${s}TexShape[0], ${s}TexShape[1], index);\n        return sampleTexture(${s}, uv);\n      }\n    ` : `\n  float ${r}(int row, int col) {\n    // Explicitly use integer operations as dot() only works on floats.\n    int index = row * ${n[1]} + col + ${h};\n    vec2 uv = uvFromFlat(${u}, ${c}, index);\n    return sampleTexture(${s}, uv);\n  }\n`
            }(e, t);
        case 3:
            return function(e, t) {
                const n = e.shapeInfo.logicalShape
                  , s = e.name
                  , r = "get" + s.charAt(0).toUpperCase() + s.slice(1)
                  , a = n[1] * n[2]
                  , i = n[2]
                  , {newShape: o, keptDims: l} = Hs.squeezeShape(n)
                  , u = o;
                if (u.length < n.length) {
                    const n = ["row", "col", "depth"];
                    return `\n        ${nN(dN(e, u), t)}\n        float ${r}(int row, int col, int depth) {\n          return ${r}(${fN(n, l)});\n        }\n      `
                }
                if (e.shapeInfo.isUniform)
                    return `\n      float ${r}(int row, int col, int depth) {\n        int index = round(dot(vec3(row, col, depth),\n                          vec3(${a}, ${i}, 1)));\n        ${cN(e)}\n      }\n    `;
                const c = e.shapeInfo.texShape
                  , h = c[0]
                  , p = c[1]
                  , d = e.shapeInfo.flatOffset;
                if (p === a && null == d)
                    return t ? `\n      float ${r}(int row, int col, int depth) {\n        int stride1 = ${s}Shape[2];\n        float texR = float(row);\n        float texC = dot(vec2(col, depth), vec2(stride1, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${s}TexShape[1], ${s}TexShape[0]);\n        return sampleTexture(${s}, uv);\n      }\n    ` : `\n        float ${r}(int row, int col, int depth) {\n          float texR = float(row);\n          float texC = dot(vec2(col, depth), vec2(${i}, 1));\n          vec2 uv = (vec2(texC, texR) + halfCR) /\n                     vec2(${p}.0, ${h}.0);\n          return sampleTexture(${s}, uv);\n        }\n      `;
                if (p === i && null == d)
                    return t ? `\n      float ${r}(int row, int col, int depth) {\n        float texR = dot(vec2(row, col), vec2(${s}Shape[1], 1));\n        float texC = float(depth);\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${s}TexShape[1], ${s}TexShape[0]);\n        return sampleTexture(${s}, uv);\n      }\n    ` : `\n    float ${r}(int row, int col, int depth) {\n      float texR = dot(vec2(row, col), vec2(${n[1]}, 1));\n      float texC = float(depth);\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${p}.0, ${h}.0);\n      return sampleTexture(${s}, uv);\n    }\n  `;
                const f = uN(s);
                return t ? `\n    float ${r}(int row, int col, int depth) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int stride0 = ${s}Shape[1] * ${s}Shape[2];\n      int stride1 = ${s}Shape[2];\n      int index = row * stride0 + col * stride1 + depth + ${f};\n      vec2 uv = uvFromFlat(${s}TexShape[0], ${s}TexShape[1], index);\n      return sampleTexture(${s}, uv);\n    }\n    ` : `\n      float ${r}(int row, int col, int depth) {\n        // Explicitly use integer operations as dot() only works on floats.\n        int index = row * ${a} + col * ${i} + depth + ${f};\n        vec2 uv = uvFromFlat(${h}, ${p}, index);\n        return sampleTexture(${s}, uv);\n      }\n  `
            }(e, t);
        case 4:
            return function(e, t) {
                const n = e.shapeInfo.logicalShape
                  , s = e.name
                  , r = "get" + s.charAt(0).toUpperCase() + s.slice(1)
                  , a = n[3]
                  , i = n[2] * a
                  , o = n[1] * i
                  , {newShape: l, keptDims: u} = Hs.squeezeShape(n);
                if (l.length < n.length) {
                    const n = ["row", "col", "depth", "depth2"];
                    return `\n      ${nN(dN(e, l), t)}\n      float ${r}(int row, int col, int depth, int depth2) {\n        return ${r}(${fN(n, u)});\n      }\n    `
                }
                if (e.shapeInfo.isUniform)
                    return `\n      float ${r}(int row, int col, int depth, int depth2) {\n        int index = round(dot(vec4(row, col, depth, depth2),\n                          vec4(${o}, ${i}, ${a}, 1)));\n        ${cN(e)}\n      }\n    `;
                const c = e.shapeInfo.flatOffset
                  , h = e.shapeInfo.texShape
                  , p = h[0]
                  , d = h[1]
                  , f = `int stride2 = ${s}Shape[3];`
                  , m = `int stride1 = ${s}Shape[2] * stride2;`
                  , g = `int stride0 = ${s}Shape[1] * stride1;`;
                if (d === o && null == c)
                    return t ? `\n      float ${r}(int row, int col, int depth, int depth2) {\n        ${f}\n        ${m}\n        float texR = float(row);\n        float texC =\n            dot(vec3(col, depth, depth2),\n                vec3(stride1, stride2, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${s}TexShape[1], ${s}TexShape[0]);\n        return sampleTexture(${s}, uv);\n      }\n    ` : `\n      float ${r}(int row, int col, int depth, int depth2) {\n        float texR = float(row);\n        float texC =\n            dot(vec3(col, depth, depth2),\n                vec3(${i}, ${a}, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${d}.0, ${p}.0);\n        return sampleTexture(${s}, uv);\n      }\n    `;
                if (d === a && null == c)
                    return t ? `\n      float ${r}(int row, int col, int depth, int depth2) {\n        float texR = dot(vec3(row, col, depth),\n                         vec3(${s}Shape[1] * ${s}Shape[2], ${s}Shape[2], 1));\n        float texC = float(depth2);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${s}TexShape[1], ${s}TexShape[0]);\n        return sampleTexture(${s}, uv);\n      }\n    ` : `\n      float ${r}(int row, int col, int depth, int depth2) {\n        float texR = dot(vec3(row, col, depth),\n                         vec3(${n[1] * n[2]}, ${n[2]}, 1));\n        float texC = float(depth2);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${d}.0, ${p}.0);\n        return sampleTexture(${s}, uv);\n      }\n    `;
                const y = uN(s);
                return t ? `\n    float ${r}(int row, int col, int depth, int depth2) {\n      // Explicitly use integer operations as dot() only works on floats.\n      ${f}\n      ${m}\n      ${g}\n      int index = row * stride0 + col * stride1 +\n          depth * stride2 + depth2;\n      vec2 uv = uvFromFlat(${s}TexShape[0], ${s}TexShape[1], index + ${y});\n      return sampleTexture(${s}, uv);\n    }\n  ` : `\n    float ${r}(int row, int col, int depth, int depth2) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${o} + col * ${i} +\n          depth * ${a} + depth2;\n      vec2 uv = uvFromFlat(${p}, ${d}, index + ${y});\n      return sampleTexture(${s}, uv);\n    }\n  `
            }(e, t);
        case 5:
            return function(e) {
                const t = e.shapeInfo.logicalShape
                  , n = e.name
                  , s = "get" + n.charAt(0).toUpperCase() + n.slice(1)
                  , r = t[4]
                  , a = t[3] * r
                  , i = t[2] * a
                  , o = t[1] * i
                  , {newShape: l, keptDims: u} = Hs.squeezeShape(t);
                if (l.length < t.length) {
                    const t = ["row", "col", "depth", "depth2", "depth3"];
                    return `\n      ${nN(dN(e, l))}\n      float ${s}(int row, int col, int depth, int depth2, int depth3) {\n        return ${s}(${fN(t, u)});\n      }\n    `
                }
                if (e.shapeInfo.isUniform)
                    return `\n      float ${s}(int row, int col, int depth, int depth2, int depth3) {\n        float index = dot(\n          vec4(row, col, depth, depth2),\n          vec4(${o}, ${i}, ${a}, ${r})) +\n          depth3;\n        ${cN(e)}\n      }\n    `;
                const c = e.shapeInfo.flatOffset
                  , h = e.shapeInfo.texShape
                  , p = h[0]
                  , d = h[1];
                if (d === o && null == c)
                    return `\n      float ${s}(int row, int col, int depth, int depth2, int depth3) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n                         vec4(${i}, ${a}, ${r}, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${d}.0, ${p}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;
                if (d === r && null == c)
                    return `\n      float ${s}(int row, int col, int depth, int depth2, int depth3) {\n        float texR = dot(\n          vec4(row, col, depth, depth2),\n          vec4(${t[1] * t[2] * t[3]},\n               ${t[2] * t[3]}, ${t[3]}, 1));\n        int texC = depth3;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${d}.0, ${p}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;
                const f = uN(n);
                return `\n    float ${s}(int row, int col, int depth, int depth2, int depth3) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${o} + col * ${i} + depth * ${a} +\n          depth2 * ${r} + depth3 + ${f};\n      vec2 uv = uvFromFlat(${p}, ${d}, index);\n      return sampleTexture(${n}, uv);\n    }\n  `
            }(e);
        case 6:
            return function(e) {
                const t = e.shapeInfo.logicalShape
                  , n = e.name
                  , s = "get" + n.charAt(0).toUpperCase() + n.slice(1)
                  , {newShape: r, keptDims: a} = Hs.squeezeShape(t);
                if (r.length < t.length) {
                    const t = ["row", "col", "depth", "depth2", "depth3", "depth4"];
                    return `\n      ${nN(dN(e, r))}\n      float ${s}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        return ${s}(${fN(t, a)});\n      }\n    `
                }
                const i = t[5]
                  , o = t[4] * i
                  , l = t[3] * o
                  , u = t[2] * l
                  , c = t[1] * u;
                if (e.shapeInfo.isUniform)
                    return `\n      float ${s}(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n        int index = round(dot(\n          vec4(row, col, depth, depth2),\n          vec4(${c}, ${u}, ${l}, ${o})) +\n          dot(\n            vec2(depth3, depth4),\n            vec2(${i}, 1)));\n        ${cN(e)}\n      }\n    `;
                const h = e.shapeInfo.flatOffset
                  , p = e.shapeInfo.texShape
                  , d = p[0]
                  , f = p[1];
                if (f === c && null == h)
                    return `\n      float ${s}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n          vec4(${u}, ${l}, ${o}, ${i})) +\n               float(depth4);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${f}.0, ${d}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;
                if (f === i && null == h)
                    return `\n      float ${s}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        float texR = dot(vec4(row, col, depth, depth2),\n          vec4(${t[1] * t[2] * t[3] * t[4]},\n               ${t[2] * t[3] * t[4]},\n               ${t[3] * t[4]},\n               ${t[4]})) + float(depth3);\n        int texC = depth4;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${f}.0, ${d}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;
                const m = uN(n);
                return `\n    float ${s}(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${c} + col * ${u} + depth * ${l} +\n          depth2 * ${o} + depth3 * ${i} + depth4 + ${m};\n      vec2 uv = uvFromFlat(${d}, ${f}, index);\n      return sampleTexture(${n}, uv);\n    }\n  `
            }(e);
        default:
            throw new Error(`${n.length}-D input sampling is not yet supported`)
        }
    }
    function sN(e, t) {
        switch (e.shapeInfo.logicalShape.length) {
        case 0:
            return function(e) {
                const t = e.name
                  , n = "get" + t.charAt(0).toUpperCase() + t.slice(1)
                  , s = KS();
                return `\n    vec4 ${n}() {\n      return ${s.texture2D}(${t}, halfCR);\n    }\n  `
            }(e);
        case 1:
            return function(e, t) {
                const n = e.name
                  , s = "get" + n.charAt(0).toUpperCase() + n.slice(1)
                  , r = e.shapeInfo.texShape
                  , a = KS();
                if (t)
                    return `\n    vec4 ${s}(int index) {\n      ivec2 packedTexShape = ivec2(ceil(float(${n}TexShape[0]) / 2.0), ceil(float(${n}TexShape[1]) / 2.0));\n      vec2 uv = packedUVfrom1D(\n        packedTexShape[0], packedTexShape[1], index);\n      return ${a.texture2D}(${n}, uv);\n    }\n  `;
                const i = [Math.ceil(r[0] / 2), Math.ceil(r[1] / 2)];
                return `\n    vec4 ${s}(int index) {\n      vec2 uv = packedUVfrom1D(\n        ${i[0]}, ${i[1]}, index);\n      return ${a.texture2D}(${n}, uv);\n    }\n  `
            }(e, t);
        case 2:
            return function(e, t) {
                const n = e.shapeInfo.logicalShape
                  , s = e.name
                  , r = "get" + s.charAt(0).toUpperCase() + s.slice(1)
                  , a = e.shapeInfo.texShape
                  , i = a[0]
                  , o = a[1]
                  , l = KS();
                if (null != a && Hs.arraysEqual(n, a))
                    return t ? `\n      vec4 ${r}(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(${s}TexShape[1], ${s}TexShape[0]);\n\n        return ${l.texture2D}(${s}, uv);\n      }\n    ` : `\n      vec4 ${r}(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(${o}.0, ${i}.0);\n\n        return ${l.texture2D}(${s}, uv);\n      }\n    `;
                if (t)
                    return `\n    vec4 ${r}(int row, int col) {\n      ivec2 packedTexShape = ivec2(ceil(float(${s}TexShape[0]) / 2.0), ceil(float(${s}TexShape[1]) / 2.0));\n      int valuesPerRow = int(ceil(float(${s}Shape[1]) / 2.0));\n      vec2 uv = packedUVfrom2D(valuesPerRow, packedTexShape[0], packedTexShape[1], row, col);\n      return ${l.texture2D}(${s}, uv);\n    }\n  `;
                const u = [Math.ceil(a[0] / 2), Math.ceil(a[1] / 2)]
                  , c = Math.ceil(n[1] / 2);
                return `\n    vec4 ${r}(int row, int col) {\n      vec2 uv = packedUVfrom2D(${c}, ${u[0]}, ${u[1]}, row, col);\n      return ${l.texture2D}(${s}, uv);\n    }\n  `
            }(e, t);
        case 3:
            return function(e, t) {
                const n = e.shapeInfo.logicalShape
                  , s = e.name
                  , r = "get" + s.charAt(0).toUpperCase() + s.slice(1)
                  , a = e.shapeInfo.texShape
                  , i = [Math.ceil(a[0] / 2), Math.ceil(a[1] / 2)];
                if (1 === n[0]) {
                    const s = [1, 2]
                      , a = ["b", "row", "col"];
                    return `\n        ${sN(dN(e, n.slice(1)), t)}\n        vec4 ${r}(int b, int row, int col) {\n          return ${r}(${fN(a, s)});\n        }\n      `
                }
                const o = KS();
                if (t)
                    return `\n    vec4 ${r}(int b, int row, int col) {\n      ivec2 packedTexShape = ivec2(ceil(float(${s}TexShape[0]) / 2.0), ceil(float(${s}TexShape[1]) / 2.0));\n      int valuesPerRow = int(ceil(float(${s}Shape[2]) / 2.0));\n      int texelsInBatch = valuesPerRow * int(ceil(float(${s}Shape[1]) / 2.0));\n      vec2 uv = packedUVfrom3D(\n        packedTexShape[0], packedTexShape[1], texelsInBatch, valuesPerRow, b, row, col);\n      return ${o.texture2D}(${s}, uv);\n    }\n  `;
                const l = i[0]
                  , u = i[1]
                  , c = Math.ceil(n[2] / 2)
                  , h = c * Math.ceil(n[1] / 2);
                return `\n    vec4 ${r}(int b, int row, int col) {\n      vec2 uv = packedUVfrom3D(\n        ${l}, ${u}, ${h}, ${c}, b, row, col);\n      return ${o.texture2D}(${s}, uv);\n    }\n  `
            }(e, t);
        default:
            return function(e, t) {
                const n = e.name
                  , s = "get" + n.charAt(0).toUpperCase() + n.slice(1)
                  , r = KS();
                if (t)
                    return `\n    vec4 ${s}(int b2, int b, int row, int col) {\n      int valuesPerRow = int(ceil(float(${n}Shape[3]) / 2.0));\n      int texelsInBatch = valuesPerRow * int(ceil(float(${n}Shape[2]) / 2.0));\n      int index = b * texelsInBatch + (row / 2) * valuesPerRow + (col / 2);\n      texelsInBatch *= ${n}Shape[1];\n      index = b2 * texelsInBatch + index;\n      ivec2 packedTexShape = ivec2(ceil(float(${n}TexShape[0]) / 2.0), ceil(float(${n}TexShape[1]) / 2.0));\n      int texR = index / packedTexShape[1];\n      int texC = index - texR * packedTexShape[1];\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(packedTexShape[1], packedTexShape[0]); return ${r.texture2D}(${n}, uv);\n    }\n  `;
                const a = e.shapeInfo.logicalShape
                  , i = a.length
                  , o = e.shapeInfo.texShape
                  , l = [Math.ceil(o[0] / 2), Math.ceil(o[1] / 2)]
                  , u = l[0]
                  , c = l[1]
                  , h = Math.ceil(a[i - 1] / 2);
                let p = h * Math.ceil(a[i - 2] / 2)
                  , d = "int b, int row, int col"
                  , f = `b * ${p} + (row / 2) * ${h} + (col / 2)`;
                for (let e = 2; e < i - 1; e++)
                    d = `int b${e}, ` + d,
                    p *= a[i - e - 1],
                    f = `b${e} * ${p} + ` + f;
                return `\n    vec4 ${s}(${d}) {\n      int index = ${f};\n      int texR = index / ${c};\n      int texC = index - texR * ${c};\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${c}, ${u});\n      return ${r.texture2D}(${n}, uv);\n    }\n  `
            }(e, t)
        }
    }
    const rN = "\nvec2 uvFromFlat(int texNumR, int texNumC, int index) {\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\nvec2 packedUVfrom1D(int texNumR, int texNumC, int index) {\n  int texelIndex = index / 2;\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n"
      , aN = "\nvec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,\n  int texNumC, int row, int col) {\n  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n"
      , iN = "\nvec2 packedUVfrom3D(int texNumR, int texNumC,\n    int texelsInBatch, int texelsInLogicalRow, int b,\n    int row, int col) {\n  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n"
      , oN = "\n  float getChannel(vec4 frag, vec2 innerDims) {\n    vec2 modCoord = mod(innerDims, 2.);\n    return modCoord.x == 0. ?\n      (modCoord.y == 0. ? frag.r : frag.g) :\n      (modCoord.y == 0. ? frag.b : frag.a);\n  }\n  float getChannel(vec4 frag, int dim) {\n    float modCoord = mod(float(dim), 2.);\n    return modCoord == 0. ? frag.r : frag.g;\n  }\n";
    function lN() {
        return "\n    int getOutputCoords() {\n      return 0;\n    }\n  "
    }
    function uN(e) {
        return `offset${e}`
    }
    function cN(e) {
        const t = e.name
          , n = Hs.sizeFromShape(e.shapeInfo.logicalShape);
        return n < 2 ? `return ${t};` : `\n    for (int i = 0; i < ${n}; i++) {\n      if (i == index) {\n        return ${t}[i];\n      }\n    }\n  `
    }
    function hN(e) {
        if (e <= 1)
            return "int";
        if (2 === e)
            return "ivec2";
        if (3 === e)
            return "ivec3";
        if (4 === e)
            return "ivec4";
        if (5 === e)
            return "ivec5";
        if (6 === e)
            return "ivec6";
        throw Error(`GPU for rank ${e} is not yet supported`)
    }
    function pN(e, t, n) {
        const {newShape: s, keptDims: r} = Hs.squeezeShape(t)
          , a = t.length
          , i = e && 3 === a && 1 === t[0]
          , o = i ? t.slice(1) : s
          , l = !e && a > 1 && !Hs.arraysEqual(t, n) && s.length < a || i;
        return {
            useSqueezeShape: l,
            uniformShape: l ? o : t,
            keptDims: r
        }
    }
    function dN(e, t) {
        const n = JSON.parse(JSON.stringify(e));
        return n.shapeInfo.logicalShape = t,
        n
    }
    function fN(e, t) {
        return t.map((t=>e[t])).join(", ")
    }
    const mN = {}
      , gN = {
        alpha: !1,
        antialias: !1,
        premultipliedAlpha: !1,
        preserveDrawingBuffer: !1,
        depth: !1,
        stencil: !1,
        failIfMajorPerformanceCaveat: !0
    };
    function yN(e, t) {
        if (!(e in mN) || null != t) {
            const n = function(e, t) {
                if (1 !== e && 2 !== e)
                    throw new Error("Cannot get WebGL rendering context, WebGL is disabled.");
                const n = null == t ? function(e) {
                    if ("undefined" != typeof OffscreenCanvas && 2 === e)
                        return new OffscreenCanvas(300,150);
                    if ("undefined" != typeof document)
                        return document.createElement("canvas");
                    throw new Error("Cannot create a canvas in this context")
                }(e) : t;
                n.addEventListener("webglcontextlost", (t=>{
                    t.preventDefault(),
                    delete mN[e]
                }
                ), !1),
                ie().getBool("SOFTWARE_WEBGL_ENABLED") && (gN.failIfMajorPerformanceCaveat = !1);
                return 1 === e ? n.getContext("webgl", gN) || n.getContext("experimental-webgl", gN) : n.getContext("webgl2", gN)
            }(e, t);
            if (null === n)
                return console.log("Could not get context for WebGL version", e),
                null;
            mN[e] = n
        }
        const n = mN[e];
        return null == n || n.isContextLost() ? (delete mN[e],
        yN(e)) : (n.disable(n.DEPTH_TEST),
        n.disable(n.STENCIL_TEST),
        n.disable(n.BLEND),
        n.disable(n.DITHER),
        n.disable(n.POLYGON_OFFSET_FILL),
        n.disable(n.SAMPLE_COVERAGE),
        n.enable(n.SCISSOR_TEST),
        n.enable(n.CULL_FACE),
        n.cullFace(n.BACK),
        mN[e])
    }
    var bN, xN, wN;
    function vN(e, t) {
        return [t, e]
    }
    function kN(e) {
        const t = Hs.sizeFromShape(e)
          , n = Math.ceil(t / 4);
        return Hs.sizeToSquarishShape(n)
    }
    function IN(e, t) {
        return [Math.max(1, Math.ceil(t / 2)), Math.max(1, Math.ceil(e / 2))]
    }
    function SN(e, t) {
        const n = e;
        let s, r, a, i, o, l, u, c, h, p;
        return 2 === ie().getNumber("WEBGL_VERSION") ? (s = n.R32F,
        r = n.R16F,
        a = n.RGBA16F,
        i = n.RGBA32F,
        o = n.RED,
        u = 4,
        c = 1,
        h = n.HALF_FLOAT,
        p = n.FLOAT,
        l = n.RGBA8) : (s = e.RGBA,
        r = e.RGBA,
        a = e.RGBA,
        i = n.RGBA,
        o = e.RGBA,
        u = 4,
        c = 4,
        h = null != t ? t.HALF_FLOAT_OES : null,
        p = e.FLOAT,
        l = e.RGBA),
        {
            internalFormatFloat: s,
            internalFormatHalfFloat: r,
            internalFormatPackedHalfFloat: a,
            internalFormatPackedFloat: i,
            textureFormatFloat: o,
            downloadTextureFormat: l,
            downloadUnpackNumChannels: u,
            defaultNumChannels: c,
            textureTypeHalfFloat: h,
            textureTypeFloat: p
        }
    }
    function NN(e, t) {
        const n = t();
        return ie().getBool("DEBUG") && function(e) {
            const t = e.getError();
            if (t !== e.NO_ERROR)
                throw new Error("WebGL Error: " + function(e, t) {
                    switch (t) {
                    case e.NO_ERROR:
                        return "NO_ERROR";
                    case e.INVALID_ENUM:
                        return "INVALID_ENUM";
                    case e.INVALID_VALUE:
                        return "INVALID_VALUE";
                    case e.INVALID_OPERATION:
                        return "INVALID_OPERATION";
                    case e.INVALID_FRAMEBUFFER_OPERATION:
                        return "INVALID_FRAMEBUFFER_OPERATION";
                    case e.OUT_OF_MEMORY:
                        return "OUT_OF_MEMORY";
                    case e.CONTEXT_LOST_WEBGL:
                        return "CONTEXT_LOST_WEBGL";
                    default:
                        return `Unknown error code ${t}`
                    }
                }(e, t))
        }(e),
        n
    }
    !function(e) {
        e[e.DENSE = 0] = "DENSE",
        e[e.SHARED_BATCH = 1] = "SHARED_BATCH"
    }(bN || (bN = {})),
    function(e) {
        e[e.RENDER = 0] = "RENDER",
        e[e.UPLOAD = 1] = "UPLOAD",
        e[e.PIXELS = 2] = "PIXELS",
        e[e.DOWNLOAD = 3] = "DOWNLOAD"
    }(xN || (xN = {})),
    function(e) {
        e[e.UNPACKED_FLOAT16 = 0] = "UNPACKED_FLOAT16",
        e[e.UNPACKED_FLOAT32 = 1] = "UNPACKED_FLOAT32",
        e[e.PACKED_4X1_UNSIGNED_BYTE = 2] = "PACKED_4X1_UNSIGNED_BYTE",
        e[e.PACKED_2X2_FLOAT32 = 3] = "PACKED_2X2_FLOAT32",
        e[e.PACKED_2X2_FLOAT16 = 4] = "PACKED_2X2_FLOAT16"
    }(wN || (wN = {}));
    function TN(e) {
        return !!(ie().getBool("WEBGL_RENDER_FLOAT32_ENABLED") || 0 === e || 5.96e-8 < Math.abs(e) && Math.abs(e) < 65504)
    }
    function CN(e, t) {
        return MN(e, (()=>e.getExtension(t)), 'Extension "' + t + '" not supported on this browser.')
    }
    const $N = /ERROR: [0-9]+:([0-9]+):/g;
    function EN(e, t) {
        const n = $N.exec(t);
        if (null == n)
            return console.log(`Couldn't parse line number in error: ${t}`),
            void console.log(e);
        const s = +n[1]
          , r = e.split("\n")
          , a = r.length.toString().length + 2
          , i = r.map(((e,t)=>Hs.rightPad((t + 1).toString(), a) + e));
        let o = 0;
        for (let e = 0; e < i.length; e++)
            o = Math.max(i[e].length, o);
        const l = i.slice(0, s - 1)
          , u = i.slice(s - 1, s)
          , c = i.slice(s);
        console.log(l.join("\n")),
        console.log(t.split("\n")[0]),
        console.log(`%c ${Hs.rightPad(u[0], o)}`, "border:1px solid red; background-color:#e3d2d2; color:#a61717"),
        console.log(c.join("\n"))
    }
    function AN(e, t) {
        if (NN(e, (()=>e.validateProgram(t))),
        !1 === e.getProgramParameter(t, e.VALIDATE_STATUS))
            throw console.log(e.getProgramInfoLog(t)),
            new Error("Shader program validation failed.")
    }
    function RN(e, t, n, s, r, a, i) {
        const o = e.getAttribLocation(t, n);
        return -1 !== o && (NN(e, (()=>e.bindBuffer(e.ARRAY_BUFFER, s))),
        NN(e, (()=>e.vertexAttribPointer(o, r, e.FLOAT, !1, a, i))),
        NN(e, (()=>e.enableVertexAttribArray(o))),
        !0)
    }
    function FN(e, t, n, s) {
        NN(e, (()=>function(e, t, n) {
            LN(e, n),
            NN(e, (()=>e.activeTexture(e.TEXTURE0 + n))),
            NN(e, (()=>e.bindTexture(e.TEXTURE_2D, t)))
        }(e, t, s))),
        NN(e, (()=>e.uniform1i(n, s)))
    }
    function DN(e, t, n) {
        NN(e, (()=>e.bindFramebuffer(e.FRAMEBUFFER, n))),
        NN(e, (()=>e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, t, 0)))
    }
    function _N(e, t) {
        NN(e, (()=>e.bindFramebuffer(e.FRAMEBUFFER, t))),
        NN(e, (()=>e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, null, 0)))
    }
    function ON(e) {
        const t = e.checkFramebufferStatus(e.FRAMEBUFFER);
        if (t !== e.FRAMEBUFFER_COMPLETE)
            throw new Error("Error binding framebuffer: " + function(e, t) {
                switch (t) {
                case e.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:
                    return "FRAMEBUFFER_INCOMPLETE_ATTACHMENT";
                case e.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:
                    return "FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT";
                case e.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:
                    return "FRAMEBUFFER_INCOMPLETE_DIMENSIONS";
                case e.FRAMEBUFFER_UNSUPPORTED:
                    return "FRAMEBUFFER_UNSUPPORTED";
                default:
                    return `unknown error ${t}`
                }
            }(e, t))
    }
    function MN(e, t, n) {
        const s = NN(e, (()=>t()));
        if (null == s)
            throw new Error(n);
        return s
    }
    function LN(e, t) {
        const n = e.MAX_COMBINED_TEXTURE_IMAGE_UNITS - 1
          , s = t + e.TEXTURE0;
        if (s < e.TEXTURE0 || s > n) {
            throw new Error(`textureUnit must be in ${`[gl.TEXTURE0, gl.TEXTURE${n}]`}.`)
        }
    }
    function zN(e, t=2) {
        return Hs.sizeFromShape(e.slice(0, e.length - t))
    }
    function BN(e) {
        if (0 === e.length)
            throw Error("Cannot get rows and columns of an empty shape array.");
        return [e.length > 1 ? e[e.length - 2] : 1, e[e.length - 1]]
    }
    function PN(e) {
        let t = [1, 1, 1];
        return 0 === e.length || 1 === e.length && 1 === e[0] || (t = [zN(e), ...BN(e)]),
        t
    }
    function WN(e) {
        return e % 2 == 0
    }
    function UN(e, t) {
        if (e = e.slice(-2),
        t = t.slice(-2),
        Hs.arraysEqual(e, t))
            return !0;
        if (!e.length || !t.length)
            return !0;
        if (0 === e[0] || 0 === e[1] || 0 === t[0] || 0 === t[1])
            return !0;
        if (e.length !== t.length) {
            const n = e.slice(-1)[0]
              , s = t.slice(-1)[0];
            if (n === s)
                return !0;
            if (WN(n) && WN(s) && (1 === e[0] || 1 === t[0]))
                return !0
        }
        return e[1] === t[1] && WN(e[0]) && WN(t[0])
    }
    let VN, GN;
    function HN(e, t) {
        return null != e.getExtension(t)
    }
    function jN(e) {
        try {
            if (null != yN(e))
                return !0
        } catch (e) {
            return console.log("Error when getting WebGL context: ", e),
            !1
        }
        return !1
    }
    function qN(e) {
        if (0 === e)
            return !1;
        const t = yN(e);
        if (1 !== e) {
            if (HN(t, "EXT_color_buffer_float"))
                return KN(t);
            const e = "EXT_color_buffer_half_float";
            if (HN(t, e)) {
                const n = t.getExtension(e);
                return function(e, t) {
                    const n = SN(e, t)
                      , s = e.createTexture();
                    e.bindTexture(e.TEXTURE_2D, s);
                    const r = 1
                      , a = 1;
                    e.texImage2D(e.TEXTURE_2D, 0, n.internalFormatHalfFloat, r, a, 0, n.textureFormatFloat, n.textureTypeHalfFloat, null);
                    const i = e.createFramebuffer();
                    e.bindFramebuffer(e.FRAMEBUFFER, i),
                    e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, s, 0);
                    const o = e.checkFramebufferStatus(e.FRAMEBUFFER) === e.FRAMEBUFFER_COMPLETE;
                    return e.bindTexture(e.TEXTURE_2D, null),
                    e.bindFramebuffer(e.FRAMEBUFFER, null),
                    e.deleteTexture(s),
                    e.deleteFramebuffer(i),
                    o
                }(t, n)
            }
            return !1
        }
        if (!HN(t, "OES_texture_float"))
            return !1;
        if (!HN(t, "WEBGL_color_buffer_float"))
            return !1;
        return KN(t)
    }
    function KN(e) {
        const t = SN(e)
          , n = e.createTexture();
        e.bindTexture(e.TEXTURE_2D, n);
        e.texImage2D(e.TEXTURE_2D, 0, t.internalFormatFloat, 1, 1, 0, t.textureFormatFloat, t.textureTypeFloat, null);
        const s = e.createFramebuffer();
        e.bindFramebuffer(e.FRAMEBUFFER, s),
        e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, n, 0);
        const r = e.checkFramebufferStatus(e.FRAMEBUFFER) === e.FRAMEBUFFER_COMPLETE;
        return e.bindTexture(e.TEXTURE_2D, null),
        e.bindFramebuffer(e.FRAMEBUFFER, null),
        e.deleteTexture(n),
        e.deleteFramebuffer(s),
        r
    }
    function XN(e, t) {
        Array.isArray(e) || (e = [e]),
        e.forEach((e=>{
            null != e && Hs.assert("complex64" !== e.dtype, (()=>`${t} does not support complex64 tensors in the WebGL backend.`))
        }
        ))
    }
    function YN(e, t, n, s) {
        const r = n.map(((e,n)=>{
            const s = {
                logicalShape: e.shape,
                texShape: e.isUniform ? null : e.texData.texShape,
                isUniform: e.isUniform,
                isPacked: !e.isUniform && e.texData.isPacked,
                flatOffset: null
            };
            return null != e.texData && null != e.texData.slice && e.texData.slice.flatOffset > 0 && (s.flatOffset = e.texData.slice.flatOffset),
            {
                name: t.variableNames[n],
                shapeInfo: s
            }
        }
        ))
          , a = r.map((e=>e.shapeInfo))
          , i = {
            logicalShape: s.shape,
            texShape: s.texData.texShape,
            isUniform: !1,
            isPacked: s.texData.isPacked,
            flatOffset: null
        }
          , o = tN(r, i, t)
          , l = function(e, t) {
            const n = MN(e, (()=>e.createShader(e.FRAGMENT_SHADER)), "Unable to create fragment WebGLShader.");
            if (NN(e, (()=>e.shaderSource(n, t))),
            NN(e, (()=>e.compileShader(n))),
            ie().get("ENGINE_COMPILE_ONLY"))
                return n;
            if (!1 === e.getShaderParameter(n, e.COMPILE_STATUS))
                throw EN(t, e.getShaderInfoLog(n)),
                new Error("Failed to compile fragment shader.");
            return n
        }(e.gl, o)
          , u = e.createProgram(l);
        return ie().get("ENGINE_COMPILE_ONLY") ? {
            program: t,
            fragmentShader: l,
            source: o,
            webGLProgram: u,
            inShapeInfos: a,
            outShapeInfo: i,
            uniformLocations: null,
            customUniformLocations: null,
            infLoc: null,
            nanLoc: null,
            inShapesLocations: null,
            inTexShapesLocations: null,
            outShapeLocation: null,
            outShapeStridesLocation: null,
            outTexShapeLocation: null
        } : Object.assign({
            program: t,
            fragmentShader: l,
            source: o,
            webGLProgram: u,
            inShapeInfos: a,
            outShapeInfo: i
        }, ZN(e, t, u))
    }
    function ZN(e, t, n) {
        const s = {}
          , r = {}
          , a = {}
          , i = [];
        let o, l, u, c = null, h = null;
        h = e.getUniformLocation(n, "NAN", !1),
        1 === ie().getNumber("WEBGL_VERSION") && (c = e.getUniformLocation(n, "INFINITY", !1));
        const p = !1;
        for (let i = 0; i < t.variableNames.length; i++) {
            const o = t.variableNames[i];
            s[o] = e.getUniformLocation(n, o, p),
            s[`offset${o}`] = e.getUniformLocation(n, `offset${o}`, p),
            t.enableShapeUniforms && (r[`${o}Shape`] = e.getUniformLocation(n, `${o}Shape`, p),
            a[`${o}TexShape`] = e.getUniformLocation(n, `${o}TexShape`, p))
        }
        return t.enableShapeUniforms && (o = e.getUniformLocation(n, "outShape", p),
        u = e.getUniformLocation(n, "outShapeStrides", p),
        l = e.getUniformLocation(n, "outTexShape", p)),
        t.customUniforms && t.customUniforms.forEach(((t,s)=>{
            i[s] = e.getUniformLocation(n, t.name, p)
        }
        )),
        {
            uniformLocations: s,
            customUniformLocations: i,
            infLoc: c,
            nanLoc: h,
            inShapesLocations: r,
            inTexShapesLocations: a,
            outShapeLocation: o,
            outShapeStridesLocation: u,
            outTexShapeLocation: l
        }
    }
    function JN(e, t) {
        if (e.length !== t.length)
            throw Error(`Binary was compiled with ${e.length} inputs, but was executed with ${t.length} inputs`);
        e.forEach(((e,n)=>{
            const s = e.logicalShape
              , r = t[n]
              , a = r.shape;
            if (!Hs.arraysEqual(s, a))
                throw Error(`Binary was compiled with different shapes than the current args. Shapes ${s} and ${a} must match`);
            if (e.isUniform && r.isUniform)
                return;
            const i = e.texShape
              , o = r.isUniform ? null : r.texData.texShape;
            if (!Hs.arraysEqual(i, o))
                throw Error(`Binary was compiled with different texture shapes than the current args. Shape ${i} and ${o} must match`)
        }
        ))
    }
    function QN(e) {
        return ie().getBool("WEBGL_USE_SHAPES_UNIFORMS") && e <= 4
    }
    class eT {
        constructor(e, t, n) {
            this.variableNames = ["A", "B"],
            this.outputShape = dm.assertAndGetBroadcastShape(t, n),
            this.enableShapeUniforms = QN(this.outputShape.length),
            this.userCode = `\n      float binaryOperation(float a, float b) {\n        ${e}\n      }\n\n      void main() {\n        float a = getAAtOutCoords();\n        float b = getBAtOutCoords();\n        setOutput(binaryOperation(a, b));\n      }\n    `
        }
    }
    function tT(e, t) {
        return ["x", "y", "z", "w", "u", "v"].slice(0, t).map((t=>`${e}.${t}`))
    }
    function nT(e, t) {
        return 1 === t ? [e] : tT(e, t)
    }
    class sT {
        constructor(e, t, n, s=!1) {
            this.variableNames = ["A", "B"],
            this.supportsBroadcasting = !0,
            this.packedInputs = !0,
            this.packedOutput = !0,
            this.outputShape = dm.assertAndGetBroadcastShape(t, n);
            const r = this.outputShape.length;
            this.enableShapeUniforms = QN(r);
            let a = "";
            if (s)
                if (0 === r || 1 === Hs.sizeFromShape(this.outputShape))
                    a = "\n          result.y = 0.;\n          result.z = 0.;\n          result.w = 0.;\n        ";
                else {
                    if (a = `\n          ${hN(r)} coords = getOutputCoords();\n        `,
                    1 === r)
                        this.enableShapeUniforms ? a += "\n            result.y = (coords + 1) >= outShape ? 0. : result.y;\n            result.z = 0.;\n            result.w = 0.;\n          " : a += `\n            result.y = (coords + 1) >= ${this.outputShape[0]} ? 0. : result.y;\n            result.z = 0.;\n            result.w = 0.;\n          `;
                    else {
                        const e = nT("coords", r);
                        this.enableShapeUniforms ? a += `\n            bool nextRowOutOfBounds =\n              (${e[r - 2]} + 1) >= outShape[${r} - 2];\n            bool nextColOutOfBounds =\n              (${e[r - 1]} + 1) >= outShape[${r} - 1];\n            result.y = nextColOutOfBounds ? 0. : result.y;\n            result.z = nextRowOutOfBounds ? 0. : result.z;\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\n          ` : a += `\n            bool nextRowOutOfBounds =\n              (${e[r - 2]} + 1) >= ${this.outputShape[r - 2]};\n            bool nextColOutOfBounds =\n              (${e[r - 1]} + 1) >= ${this.outputShape[r - 1]};\n            result.y = nextColOutOfBounds ? 0. : result.y;\n            result.z = nextRowOutOfBounds ? 0. : result.z;\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\n          `
                    }
                }
            this.userCode = `\n      vec4 binaryOperation(vec4 a, vec4 b) {\n        ${e}\n      }\n\n      void main() {\n        vec4 a = getAAtOutCoords();\n        vec4 b = getBAtOutCoords();\n\n        vec4 result = binaryOperation(a, b);\n        ${a}\n\n        setOutput(result);\n      }\n    `
        }
    }
    function rT(e) {
        const {inputs: t, backend: n} = e
          , {x: s} = t;
        return n.incRef(s.dataId),
        {
            dataId: s.dataId,
            shape: s.shape,
            dtype: s.dtype
        }
    }
    const aT = {
        kernelName: Bt,
        backendName: "webgl",
        kernelFunc: rT
    };
    function iT(e) {
        const {inputs: t, backend: n} = e
          , {real: s, imag: r} = t
          , a = n.makeTensorInfo(s.shape, "complex64")
          , i = n.texData.get(a.dataId)
          , o = rT({
            inputs: {
                x: s
            },
            backend: n
        })
          , l = rT({
            inputs: {
                x: r
            },
            backend: n
        });
        return i.complexTensorInfos = {
            real: o,
            imag: l
        },
        a
    }
    const oT = {
        kernelName: Ze,
        backendName: "webgl",
        kernelFunc: iT
    }
      , lT = "return (a < 0.) ? b * a : a;"
      , uT = "\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n";
    const cT = {
        kernelName: Ht,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {alpha: a} = s
              , i = n.makeTensorInfo([], "float32", Hs.createScalarValue(a, "float32"))
              , o = ie().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new sT(uT,r.shape,i.shape) : new eT(lT,r.shape,i.shape)
              , l = n.runWebGLProgram(o, [r, i], "float32");
            return n.disposeIntermediateTensorInfo(i),
            l
        }
    }
      , hT = "return (a < 0.) ? b * a : a;"
      , pT = "\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n";
    const dT = {
        kernelName: Cn,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {x: s, alpha: r} = t
              , a = ie().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new sT(pT,s.shape,r.shape) : new eT(hT,s.shape,r.shape);
            return n.runWebGLProgram(a, [s, r], "float32")
        }
    };
    class fT {
        constructor(e, t) {
            this.variableNames = ["A"],
            this.outputShape = e,
            this.enableShapeUniforms = QN(this.outputShape.length),
            this.userCode = `\n      float unaryOperation(float x) {\n        ${t}\n      }\n\n      void main() {\n        float x = getAAtOutCoords();\n        float y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    `
        }
    }
    const mT = "return abs(x);";
    const gT = "return x;";
    class yT {
        constructor(e, t) {
            this.variableNames = ["A"],
            this.packedInputs = !0,
            this.packedOutput = !0,
            this.outputShape = e,
            this.enableShapeUniforms = QN(this.outputShape.length),
            this.userCode = `\n      vec4 unaryOperation(vec4 x) {\n        ${t}\n      }\n\n      void main() {\n        vec4 x = getAAtOutCoords();\n        vec4 y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    `
        }
    }
    function bT({opSnippet: e, packedOpSnippet: t, cpuKernelImpl: n, dtype: s}) {
        return ({inputs: r, backend: a})=>{
            const {x: i} = r
              , o = a
              , l = s || i.dtype;
            if (o.shouldExecuteOnCPU([i]) && null != n) {
                const e = o.texData.get(i.dataId)
                  , t = n(e.values, l);
                return o.makeTensorInfo(i.shape, l, t)
            }
            let u;
            return u = ie().getBool("WEBGL_PACK_UNARY_OPERATIONS") && null != t ? new yT(i.shape,t) : new fT(i.shape,e),
            o.runWebGLProgram(u, [i], l)
        }
    }
    function xT({opSnippet: e, packedOpSnippet: t, checkOutOfBounds: n=!1, supportsComplex: s=!1, cpuKernelImpl: r, dtype: a}) {
        return ({inputs: i, backend: o})=>{
            const {a: l, b: u} = i
              , c = o;
            if (s && "complex64" === l.dtype) {
                const t = c.texData.get(l.dataId)
                  , n = c.texData.get(u.dataId)
                  , [s,r] = [[t.complexTensorInfos.real, n.complexTensorInfos.real], [t.complexTensorInfos.imag, n.complexTensorInfos.imag]].map((t=>{
                    const [n,s] = t
                      , r = {
                        dataId: n.dataId,
                        dtype: n.dtype,
                        shape: l.shape
                    }
                      , a = {
                        dataId: s.dataId,
                        dtype: s.dtype,
                        shape: u.shape
                    }
                      , i = new eT(e,l.shape,u.shape);
                    return c.runWebGLProgram(i, [r, a], ha(n.dtype, s.dtype))
                }
                ))
                  , a = iT({
                    inputs: {
                        real: s,
                        imag: r
                    },
                    backend: c
                });
                return c.disposeIntermediateTensorInfo(s),
                c.disposeIntermediateTensorInfo(r),
                a
            }
            const h = a || ha(l.dtype, u.dtype);
            if (("string" === l.dtype || "string" === u.dtype || c.shouldExecuteOnCPU([l, u])) && null != r) {
                const e = c.texData.get(l.dataId).values
                  , t = c.texData.get(u.dataId).values
                  , n = "string" === l.dtype ? dm.fromUint8ToStringArray(e) : e
                  , s = "string" === l.dtype ? dm.fromUint8ToStringArray(t) : t
                  , [a,i] = r(l.shape, u.shape, n, s, h)
                  , o = c.makeTensorInfo(i, h);
                return c.texData.get(o.dataId).values = a,
                o
            }
            let p;
            return p = ie().getBool("WEBGL_PACK_BINARY_OPERATIONS") && null != t ? new sT(t,l.shape,u.shape,n) : new eT(e,l.shape,u.shape),
            c.runWebGLProgram(p, [l, u], h)
        }
    }
    function wT(e, t=!1) {
        if ("linear" === e)
            return "return x;";
        if ("relu" === e)
            return t ? "\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n" : "if (isnan(x)) return x;\n  return (x < 0.0) ? 0.0 : x;\n";
        if ("elu" === e)
            return t ? "\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n" : "return (x >= 0.0) ? x : (exp(x) - 1.0);";
        if ("relu6" === e)
            return t ? "\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n" : "if (isnan(x)) return x;\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n";
        if ("prelu" === e)
            return t ? pT : hT;
        if ("leakyrelu" === e)
            return t ? uT : lT;
        if ("sigmoid" === e)
            return "return 1.0 / (1.0 + exp(-1.0 * x));";
        throw new Error(`Activation ${e} has not been implemented for the WebGL backend.`)
    }
    class vT {
        constructor(e, t, n, s=!1, r=!1, a=!1, i=null, o=!1, l=!1) {
            this.variableNames = ["matrixA", "matrixB"],
            this.packedInputs = !0,
            this.packedOutput = !0,
            this.outputShape = n,
            this.enableShapeUniforms = QN(this.outputShape.length);
            const u = s ? e[1] : e[2]
              , c = Math.ceil(u / 2)
              , h = s ? "i * 2, rc.y" : "rc.y, i * 2"
              , p = r ? "rc.z, i * 2" : "i * 2, rc.z"
              , d = s ? ["a.xxyy", "a.zzww"] : ["a.xxzz", "a.yyww"]
              , f = r ? ["b.xzxz", "b.ywyw"] : ["b.xyxy", "b.zwzw"];
            let m = ""
              , g = "";
            i && (m = o ? `vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${i}\n        }` : l ? `vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ${i}\n        }` : `vec4 activation(vec4 x) {\n          ${i}\n        }`,
            g = "result = activation(result);");
            const y = a ? "result += getBiasAtOutCoords();" : "";
            a && this.variableNames.push("bias"),
            o && this.variableNames.push("preluActivationWeights"),
            l && this.variableNames.push("leakyreluAlpha");
            let b = "rc.x"
              , x = "rc.x";
            e[0] < t[0] ? b = `imod(rc.x, ${e[0]})` : t[0] < e[0] && (x = `imod(rc.x, ${t[0]})`),
            this.userCode = `\n      ${m}\n      // Don't use uniform for sharedDimensionPacked for performance.\n      const float sharedDimension = ${c}.0;\n\n      vec4 dot2x2ARowBCol(ivec3 rc) {\n        vec4 result = vec4(0);\n        int batchA = ${b};\n        int batchB = ${x};\n        for (int i = 0; i < ${c}; i++) {\n          vec4 a = getMatrixA(batchA, ${h});\n          vec4 b = getMatrixB(batchB, ${p});\n\n          // These swizzled products need to be separately added.\n          // See: https://github.com/tensorflow/tfjs/issues/1735\n          result += (${d[0]} * ${f[0]});\n          result += (${d[1]} * ${f[1]});\n        }\n        return result;\n      }\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n        vec4 result = dot2x2ARowBCol(rc);\n\n        ${y}\n\n        ${g}\n\n        setOutput(result);\n      }\n    `
        }
    }
    const kT = "return areal * breal - aimag * bimag;"
      , IT = "return areal * bimag + aimag * breal;";
    class ST {
        constructor(e, t, n) {
            this.variableNames = ["AReal", "AImag", "BReal", "BImag"],
            this.outputShape = dm.assertAndGetBroadcastShape(t, n),
            this.userCode = `\n      float binaryOpComplex(\n          float areal, float aimag, float breal, float bimag) {\n        ${e}\n      }\n\n      void main() {\n        float areal = getARealAtOutCoords();\n        float aimag = getAImagAtOutCoords();\n        float breal = getBRealAtOutCoords();\n        float bimag = getBImagAtOutCoords();\n        setOutput(binaryOpComplex(areal, aimag, breal, bimag));\n      }\n    `
        }
    }
    var NT = {};
    t(NT, "simpleAbsImpl", (()=>fx)),
    t(NT, "addImpl", (()=>ax)),
    t(NT, "bincountImpl", (()=>Zx)),
    t(NT, "bincountReduceImpl", (()=>Jx)),
    t(NT, "castImpl", (()=>ex)),
    t(NT, "ceilImpl", (()=>tw)),
    t(NT, "concatImpl", (()=>ow)),
    t(NT, "equalImpl", (()=>Gw)),
    t(NT, "expImpl", (()=>tv)),
    t(NT, "expm1Impl", (()=>iv)),
    t(NT, "floorImpl", (()=>Iv)),
    t(NT, "gatherNdImpl", (()=>Rv)),
    t(NT, "gatherV2Impl", (()=>Dv)),
    t(NT, "greaterImpl", (()=>Ov)),
    t(NT, "greaterEqualImpl", (()=>zv)),
    t(NT, "lessImpl", (()=>Kv)),
    t(NT, "lessEqualImpl", (()=>Zv)),
    t(NT, "linSpaceImpl", (()=>ek)),
    t(NT, "logImpl", (()=>nk)),
    t(NT, "maxImpl", (()=>yk)),
    t(NT, "maximumImpl", (()=>wk)),
    t(NT, "minimumImpl", (()=>Ak)),
    t(NT, "multiplyImpl", (()=>Mw)),
    t(NT, "negImpl", (()=>Pk)),
    t(NT, "notEqualImpl", (()=>Kk)),
    t(NT, "prodImpl", (()=>oI)),
    t(NT, "raggedGatherImpl", (()=>pI)),
    t(NT, "raggedRangeImpl", (()=>mI)),
    t(NT, "raggedTensorToTensorImpl", (()=>vI)),
    t(NT, "rangeImpl", (()=>II)),
    t(NT, "rsqrtImpl", (()=>OI)),
    t(NT, "scatterImpl", (()=>zI)),
    t(NT, "sigmoidImpl", (()=>Hb)),
    t(NT, "sliceImpl", (()=>qx)),
    t(NT, "sparseFillEmptyRowsImpl", (()=>rS)),
    t(NT, "sparseReshapeImpl", (()=>iS)),
    t(NT, "sparseSegmentReductionImpl", (()=>lS)),
    t(NT, "sqrtImpl", (()=>dS)),
    t(NT, "squaredDifferenceImpl", (()=>yS)),
    t(NT, "stridedSliceImpl", (()=>kS)),
    t(NT, "stringNGramsImpl", (()=>NS)),
    t(NT, "stringSplitImpl", (()=>$S)),
    t(NT, "stringToHashBucketFastImpl", (()=>AS)),
    t(NT, "subImpl", (()=>pv)),
    t(NT, "tileImpl", (()=>OS)),
    t(NT, "topKImpl", (()=>zS)),
    t(NT, "transposeImpl", (()=>vx)),
    t(NT, "uniqueImpl", (()=>GS));
    const {addImpl: TT, bincountImpl: CT, bincountReduceImpl: $T, castImpl: ET, ceilImpl: AT, concatImpl: RT, equalImpl: FT, expImpl: DT, expm1Impl: _T, floorImpl: OT, gatherNdImpl: MT, gatherV2Impl: LT, greaterImpl: zT, greaterEqualImpl: BT, lessImpl: PT, lessEqualImpl: WT, linSpaceImpl: UT, logImpl: VT, maxImpl: GT, maximumImpl: HT, minimumImpl: jT, multiplyImpl: qT, negImpl: KT, notEqualImpl: XT, prodImpl: YT, raggedGatherImpl: ZT, raggedRangeImpl: JT, raggedTensorToTensorImpl: QT, rangeImpl: eC, rsqrtImpl: tC, scatterImpl: nC, sigmoidImpl: sC, simpleAbsImpl: rC, sliceImpl: aC, sparseFillEmptyRowsImpl: iC, sparseReshapeImpl: oC, sparseSegmentReductionImpl: lC, sqrtImpl: uC, stridedSliceImpl: cC, stringNGramsImpl: hC, stringSplitImpl: pC, stringToHashBucketFastImpl: dC, subImpl: fC, tileImpl: mC, topKImpl: gC, transposeImpl: yC, uniqueImpl: bC} = NT
      , xC = "return a * b;";
    function wC(e) {
        const {inputs: t, backend: n} = e
          , {a: s, b: r} = t
          , a = dm.upcastType(s.dtype, r.dtype);
        if ("complex64" === s.dtype) {
            const e = n.texData.get(s.dataId)
              , t = n.texData.get(r.dataId)
              , a = new ST(kT,s.shape,r.shape)
              , i = new ST(IT,s.shape,r.shape)
              , o = [{
                dataId: e.complexTensorInfos.real.dataId,
                dtype: e.complexTensorInfos.real.dtype,
                shape: s.shape
            }, {
                dataId: e.complexTensorInfos.imag.dataId,
                dtype: e.complexTensorInfos.imag.dtype,
                shape: s.shape
            }, {
                dataId: t.complexTensorInfos.real.dataId,
                dtype: t.complexTensorInfos.real.dtype,
                shape: r.shape
            }, {
                dataId: t.complexTensorInfos.imag.dataId,
                dtype: t.complexTensorInfos.imag.dtype,
                shape: r.shape
            }]
              , l = n.runWebGLProgram(a, o, "float32")
              , u = n.runWebGLProgram(i, o, "float32")
              , c = iT({
                inputs: {
                    real: l,
                    imag: u
                },
                backend: n
            });
            return n.disposeIntermediateTensorInfo(l),
            n.disposeIntermediateTensorInfo(u),
            c
        }
        if (n.shouldExecuteOnCPU([s, r])) {
            const e = n.texData.get(s.dataId)
              , t = n.texData.get(r.dataId)
              , [i,o] = qT(s.shape, r.shape, e.values, t.values, a)
              , l = n.makeTensorInfo(o, a);
            return n.texData.get(l.dataId).values = i,
            l
        }
        let i;
        return i = ie().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new sT(xC,s.shape,r.shape) : new eT(xC,s.shape,r.shape),
        n.runWebGLProgram(i, [s, r], a)
    }
    const vC = {
        kernelName: gn,
        backendName: "webgl",
        kernelFunc: wC
    };
    class kC {
        constructor(e, t) {
            this.variableNames = ["A"],
            this.packedInputs = !0,
            this.packedOutput = !0,
            this.customUniforms = [{
                name: "inputShape",
                type: "ivec3"
            }],
            this.outputShape = e,
            this.enableShapeUniforms = QN(this.outputShape.length);
            let n = "";
            for (let e = 0; e < 4; e++) {
                let t = "thisRC = rc;";
                e % 2 == 1 && (t += "thisRC.z += 1;"),
                e > 1 && (t += "thisRC.y += 1;"),
                n += `\n        ${t}\n        ${e > 0 ? "if(thisRC.y < rows && thisRC.z < cols){" : ""}\n          int flatIndex = getFlatIndex(thisRC);\n\n          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);\n          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));\n\n          result[${e}] =\n            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);\n        ${e > 0 ? "}" : ""}\n      `
            }
            var s, r;
            this.userCode = `\n      ${s = t,
            r = this.enableShapeUniforms,
            `\n    ivec3 inputCoordsFromReshapedOutCoords(int index) {\n      ${r ? ZS(["r", "c", "d"], "inputShape") : XS(["r", "c", "d"], s)}\n      return ivec3(r, c, d);\n    }\n  `}\n      ${this.enableShapeUniforms ? "\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * outShapeStrides[0] + coords.y * outShapeStrides[1] + coords.z;\n  }\n" : JS(e)}\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n\n        vec4 result = vec4(0.);\n\n        ivec3 thisRC;\n        int rows = ${this.enableShapeUniforms ? "outShape[1]" : e[1]};\n        int cols = ${this.enableShapeUniforms ? "outShape[2]" : e[2]};\n\n        ${n}\n\n        setOutput(result);\n      }\n    `
        }
    }
    function IC(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {x: r} = t
          , {shape: a} = s
          , i = n
          , o = Hs.sizeFromShape(r.shape)
          , l = Hs.inferFromImplicitShape(a, o)
          , u = Hs.sizeFromShape(l);
        Hs.assert(o === u, (()=>`The new shape (${l}) has ${u} elements and the old shape (${r.shape}) has ${o} elements. The new shape and old shape must have the same number of elements.`));
        const c = i.texData.get(r.dataId);
        return !c.isPacked || UN(r.shape, l) || null !== c.texture && UN(c.shape, l) ? (i.incRef(r.dataId),
        {
            dataId: r.dataId,
            shape: l,
            dtype: r.dtype
        }) : function(e, t, n) {
            const s = [zN(e.shape), ...BN(e.shape)]
              , r = {
                dtype: e.dtype,
                shape: s,
                dataId: e.dataId
            }
              , a = [zN(t), ...BN(t)]
              , i = new kC(a,s)
              , o = [s]
              , l = n.runWebGLProgram(i, [r], e.dtype, o, !0);
            return {
                dataId: l.dataId,
                shape: t,
                dtype: l.dtype
            }
        }(r, l, i)
    }
    const SC = {
        kernelName: Mn,
        backendName: "webgl",
        kernelFunc: IC
    };
    class NC {
        constructor(e, t) {
            this.variableNames = ["x"];
            const {windowSize: n, batchSize: s, inSize: r, outSize: a} = e;
            this.outputShape = [s, a];
            const i = 4 * Math.floor(n / 4)
              , o = n % 4;
            let l = "sumValue += dot(values, ones);";
            if (null != t) {
                const e = 1 / t;
                l = `sumValue += dot(values * ${Hs.isInt(e) ? e.toPrecision(2) : e}, ones);`
            }
            let u = "";
            r % n > 0 && (u = `\n        if (inIdx < 0 || inIdx >= ${r}) {\n          return 0.0;\n        }\n      `),
            this.userCode = `\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ${u}\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${n};\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ${i}; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ${l}\n        }\n\n        int inIdx = inOffset + ${i};\n        if (${1 === o}) {\n          vec4 values = vec4(getValue(batch, inIdx), 0.0, 0.0, 0.0);\n\n          ${l}\n        } else if (${2 === o}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1), 0.0, 0.0);\n\n          ${l}\n        } else if (${3 === o}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2), 0.0);\n\n          ${l}\n        }\n        setOutput(sumValue);\n      }\n    `
        }
    }
    class TC {
        constructor(e, t) {
            this.variableNames = ["x"];
            const {windowSize: n, batchSize: s, inSize: r, outSize: a} = e;
            this.outputShape = [s, a];
            let i = "0.0"
              , o = "";
            "prod" === t ? i = "1.0" : "min" === t ? (i = "1.0 / 1e-20",
            o = "min") : "max" === t && (i = "-1.0 / 1e-20",
            o = "max");
            let l = `${t}(${t}(${t}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
            "sum" === t ? l = "sumValue" : "prod" === t ? l = "prodValue" : "all" === t ? l = "allValue" : "any" === t && (l = "anyValue");
            const u = 4 * Math.floor(n / 4)
              , c = n % 4;
            let h = `\n      if (${"sum" === t}) {\n        sumValue += dot(values, ones);\n      } else if (${"prod" === t}) {\n        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);\n        prodValue *= tmp[0] * tmp[1];\n      } else {\n        minMaxValue = ${o}(values, minMaxValue);\n        if (${"min" === t} || ${"max" === t}) {\n          minMaxValue = ${o}(values, minMaxValue);\n          bvec4 isNaN = isnan(values);\n          if (isNaN.r || isNaN.g || isNaN.b || isNaN.a) {\n            minMaxValue = vec4(NAN);\n          }\n        }\n      }\n    `
              , p = "vec4";
            "all" === t ? (i = "1.0",
            h = "\n        bool reducedAllValue = all(values);\n        float floatedReducedAllValue = float(reducedAllValue);\n        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);\n      ",
            p = "bvec4") : "any" === t && (i = "0.0",
            h = "\n        bool reducedAnyValue = any(values);\n        float floatedReducedAnyValue = float(reducedAnyValue);\n        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);\n      ",
            p = "bvec4");
            let d = "";
            r % n > 0 && (d = `\n        if (inIdx < 0 || inIdx >= ${r}) {\n          return initializationValue;\n        }\n      `),
            this.userCode = `\n      const float initializationValue = ${i};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ${d}\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${n};\n\n        vec4 minMaxValue = vec4(${i});\n        float prodValue = 1.0;\n        float sumValue = 0.0;\n        float allValue = 1.0;\n        float anyValue = 0.0;\n\n        for (int i = 0; i < ${u}; i += 4) {\n          int inIdx = inOffset + i;\n          ${p} values = ${p}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ${h}\n        }\n\n        int inIdx = inOffset + ${u};\n        if (${1 === c}) {\n          ${p} values = ${p}(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          ${h}\n        } else if (${2 === c}) {\n          ${p} values = ${p}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          ${h}\n        } else if (${3 === c}) {\n          ${p} values = ${p}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          ${h}\n        }\n        setOutput(${l});\n      }\n    `
        }
    }
    function CC(e, t, n, s) {
        const r = function(e) {
            const t = [];
            for (; 0 === t.length || 1 !== t[t.length - 1].outSize; ) {
                const n = t.length ? t[t.length - 1].outSize : e[1]
                  , s = dm.computeOptimalWindowSize(n);
                t.push({
                    inSize: n,
                    windowSize: s,
                    outSize: Math.ceil(n / s)
                })
            }
            return t
        }(e.shape);
        let a = e;
        for (let i = 0; i < r.length; i++) {
            const {inSize: o, windowSize: l, outSize: u} = r[i];
            let c, h;
            c = "mean" === n ? 0 === i ? new NC({
                windowSize: l,
                inSize: o,
                batchSize: e.shape[0],
                outSize: u
            },o) : new NC({
                windowSize: l,
                inSize: o,
                batchSize: e.shape[0],
                outSize: u
            }) : new TC({
                windowSize: l,
                inSize: o,
                batchSize: e.shape[0],
                outSize: u
            },n),
            h = a,
            a = s.runWebGLProgram(c, [a], t),
            h.dataId !== e.dataId && s.disposeIntermediateTensorInfo(h)
        }
        return a
    }
    class $C {
        constructor(e, t) {
            this.variableNames = ["A"];
            const n = new Array(e.length);
            for (let s = 0; s < n.length; s++)
                n[s] = e[t[s]];
            this.outputShape = n,
            this.rank = n.length;
            const s = hN(this.rank)
              , r = function(e) {
                const t = e.length;
                if (t > 6)
                    throw Error(`Transpose for rank ${t} is not yet supported`);
                const n = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u", "resRC.v"]
                  , s = new Array(t);
                for (let t = 0; t < e.length; t++)
                    s[e[t]] = n[t];
                return s.join()
            }(t);
            this.userCode = `\n    void main() {\n      ${s} resRC = getOutputCoords();\n      setOutput(getA(${r}));\n    }\n    `
        }
    }
    class EC {
        constructor(e, t) {
            this.variableNames = ["A"],
            this.packedInputs = !0,
            this.packedOutput = !0;
            const n = new Array(e.length);
            for (let s = 0; s < n.length; s++)
                n[s] = e[t[s]];
            if (this.outputShape = n,
            this.rank = n.length,
            this.rank > 6)
                throw Error(`Packed transpose for rank ${this.rank} is not yet supported.`);
            const s = hN(this.rank)
              , r = tT("rc", this.rank)
              , a = new Array(this.rank);
            for (let e = 0; e < t.length; e++)
                a[t[e]] = r[e];
            const i = `vec2(${a.slice(-2).join()})`
              , o = `++${r[this.rank - 1]} < ${n[this.rank - 1]}`
              , l = `getChannel(getA(${a.join()}), ${i})`;
            this.userCode = `\n    void main() {\n      ${s} rc = getOutputCoords();\n      vec4 result = vec4(0.);\n      result[0] = ${l};\n      if(${o}) {\n        result[1] = ${l};\n      }\n      --${r[this.rank - 1]};\n      if(++${r[this.rank - 2]} < ${n[this.rank - 2]}) {\n        result[2] = ${l};\n        if(${o}) {\n          result[3] = ${l};\n        }\n      }\n      setOutput(result);\n    }\n    `
        }
    }
    function AC(e, t, n) {
        const s = ie().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new EC(e.shape,t) : new $C(e.shape,t);
        return n.runWebGLProgram(s, [e], e.dtype)
    }
    function RC(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {x: r} = t
          , {axis: a, keepDims: i} = s;
        return function(e, t, n, s) {
            const r = t
              , a = e.shape.length
              , i = Hs.parseAxisParam(r, e.shape);
            let o = i;
            const l = dm.getAxesPermutation(o, a)
              , u = null != l;
            let c = e;
            u && (c = AC(e, l, s),
            o = dm.getInnerMostAxes(o.length, a)),
            dm.assertAxesAreInnerMostDims("sum", o, a);
            const [h,p] = dm.computeOutAndReduceShapes(c.shape, o);
            let d = h;
            n && (d = dm.expandShapeToKeepDim(h, i));
            const f = Hs.sizeFromShape(p)
              , m = IC({
                inputs: {
                    x: c
                },
                attrs: {
                    shape: [Hs.sizeFromShape(e.shape) / f, f]
                },
                backend: s
            })
              , g = CC(m, pa(e.dtype), "sum", s)
              , y = IC({
                inputs: {
                    x: g
                },
                attrs: {
                    shape: d
                },
                backend: s
            });
            return s.disposeIntermediateTensorInfo(m),
            s.disposeIntermediateTensorInfo(g),
            u && s.disposeIntermediateTensorInfo(c),
            y
        }(r, a, i, n)
    }
    const FC = {
        kernelName: ns,
        backendName: "webgl",
        kernelFunc: RC
    };
    function DC(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {x: r} = t
          , {perm: a} = s
          , i = n
          , o = r.shape.length
          , l = new Array(o);
        for (let e = 0; e < l.length; e++)
            l[e] = r.shape[a[e]];
        let u;
        if (i.shouldExecuteOnCPU([r])) {
            const e = i.texData.get(r.dataId).values
              , t = yC(e, r.shape, r.dtype, a, l);
            u = i.makeTensorInfo(l, r.dtype);
            i.texData.get(u.dataId).values = t
        } else
            u = AC(r, a, i);
        return u
    }
    const _C = {
        kernelName: Is,
        backendName: "webgl",
        kernelFunc: DC
    };
    function OC({a: e, b: t, transposeA: n, transposeB: s, backend: r, bias: a=null, preluActivationWeights: i=null, leakyreluAlpha: o=0, activation: l=null}) {
        const u = e.shape.length
          , c = t.shape.length
          , h = n ? e.shape[u - 2] : e.shape[u - 1]
          , p = s ? t.shape[c - 1] : t.shape[c - 2]
          , d = n ? e.shape[u - 1] : e.shape[u - 2]
          , f = s ? t.shape[c - 2] : t.shape[c - 1]
          , m = e.shape.slice(0, -2)
          , g = t.shape.slice(0, -2)
          , y = Hs.sizeFromShape(m)
          , b = Hs.sizeFromShape(g)
          , x = Nl.assertAndGetBroadcastShape(e.shape.slice(0, -2), t.shape.slice(0, -2)).concat([d, f]);
        Hs.assert(h === p, (()=>`Error in matMul: inner shapes (${h}) and (${p}) of Tensors with shapes ${e.shape} and ${t.shape} and transposeA=${n} and transposeB=${s} must match.`));
        const w = n ? [y, h, d] : [y, d, h]
          , v = s ? [b, f, p] : [b, p, f]
          , k = IC({
            inputs: {
                x: e
            },
            backend: r,
            attrs: {
                shape: w
            }
        })
          , I = IC({
            inputs: {
                x: t
            },
            backend: r,
            attrs: {
                shape: v
            }
        })
          , S = [k, I]
          , N = Math.max(y, b)
          , T = n ? k.shape[1] : k.shape[2]
          , C = null != a
          , $ = null != i
          , E = "leakyrelu" === l
          , A = null != l ? wT(l, !0) : null;
        let R;
        if ((1 === d || 1 === f) && T > 1e3 && !1 === (C || $ || E || null != A)) {
            let e = k
              , t = I;
            n && (e = DC({
                inputs: {
                    x: k
                },
                backend: r,
                attrs: {
                    perm: [0, 2, 1]
                }
            }),
            S.push(e)),
            s && (t = DC({
                inputs: {
                    x: I
                },
                backend: r,
                attrs: {
                    perm: [0, 2, 1]
                }
            }),
            S.push(t));
            const a = 1 === f;
            let i = e;
            1 !== f && (i = IC({
                inputs: {
                    x: e
                },
                backend: r,
                attrs: {
                    shape: [N, T, 1]
                }
            }),
            S.push(i));
            const o = 1 === f ? 2 : 1;
            let l = t;
            a && (l = IC({
                inputs: {
                    x: t
                },
                backend: r,
                attrs: {
                    shape: [N, 1, T]
                }
            }),
            S.push(l));
            const u = wC({
                inputs: {
                    a: i,
                    b: l
                },
                backend: r
            });
            R = RC({
                inputs: {
                    x: u
                },
                backend: r,
                attrs: {
                    axis: o,
                    keepDims: !0
                }
            }),
            S.push(u)
        } else {
            const l = ha(e.dtype, t.dtype)
              , u = new vT(w,v,[N, d, f],n,s,C,A,$,E)
              , c = [k, I];
            if (null != a && c.push(a),
            $ && c.push(i),
            E) {
                const e = r.makeTensorInfo([], "float32", Hs.createScalarValue(o, "float32"));
                c.push(e),
                S.push(e)
            }
            R = r.runWebGLProgram(u, c, l)
        }
        const F = IC({
            inputs: {
                x: R
            },
            backend: r,
            attrs: {
                shape: x
            }
        });
        S.push(R);
        for (const e of S)
            r.disposeIntermediateTensorInfo(e);
        return F
    }
    const MC = {
        kernelName: Rs,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {a: r, b: a, bias: i, preluActivationWeights: o} = t
              , {transposeA: l, transposeB: u, activation: c, leakyreluAlpha: h} = s;
            return OC({
                a: r,
                b: a,
                transposeA: l,
                transposeB: u,
                backend: n,
                bias: i,
                preluActivationWeights: o,
                leakyreluAlpha: h,
                activation: c
            })
        }
    }
      , LC = "return abs(x);";
    const zC = {
        kernelName: Te,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {x: s} = t;
            if (n.shouldExecuteOnCPU([s]) && "complex64" !== s.dtype) {
                const e = n.texData.get(s.dataId)
                  , t = rC(e.values);
                return n.makeTensorInfo(s.shape, s.dtype, t)
            }
            let r;
            return r = ie().getBool("WEBGL_PACK_UNARY_OPERATIONS") ? new yT(s.shape,LC) : new fT(s.shape,LC),
            n.runWebGLProgram(r, [s], s.dtype)
        }
    }
      , BC = bT({
        opSnippet: "if (isnan(x)) return x;\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return acos(x);\n"
    })
      , PC = {
        kernelName: Ce,
        backendName: "webgl",
        kernelFunc: BC
    }
      , WC = bT({
        opSnippet: "if (isnan(x)) return x;\n  if (x < 1.0) return NAN;\nreturn log(x + sqrt(x * x - 1.0));"
    })
      , UC = {
        kernelName: $e,
        backendName: "webgl",
        kernelFunc: WC
    }
      , VC = "return a + b;"
      , GC = xT({
        opSnippet: VC,
        packedOpSnippet: VC,
        supportsComplex: !0,
        cpuKernelImpl: TT
    })
      , HC = {
        kernelName: Ee,
        backendName: "webgl",
        kernelFunc: GC
    };
    class jC {
        constructor(e, t) {
            this.outputShape = [],
            this.outputShape = e,
            this.variableNames = t.map(((e,t)=>`T${t}`));
            const n = [];
            this.variableNames.forEach((e=>{
                n.push(`float v${e} = get${e}AtOutCoords();`)
            }
            ));
            const s = this.variableNames.map((e=>`v${e}`)).join(" + ");
            this.userCode = `\n      void main() {\n        ${n.join("\n        ")}\n\n        float result = ${s};\n        setOutput(result);\n      }\n    `
        }
    }
    class qC {
        constructor(e, t) {
            this.outputShape = [],
            this.packedInputs = !0,
            this.packedOutput = !0,
            this.outputShape = e,
            this.variableNames = t.map(((e,t)=>`T${t}`));
            const n = [];
            this.variableNames.forEach((e=>{
                n.push(`vec4 v${e} = get${e}AtOutCoords();`)
            }
            ));
            const s = this.variableNames.map((e=>`v${e}`)).join(" + ");
            this.userCode = `\n      void main() {\n        ${n.join("\n        ")}\n\n        vec4 result = ${s};\n        setOutput(result);\n      }\n    `
        }
    }
    const KC = {
        kernelName: Ae,
        backendName: "webgl",
        kernelFunc: function e(t) {
            const {inputs: n, backend: s} = t
              , r = n;
            if (1 === r.length)
                return rT({
                    inputs: {
                        x: r[0]
                    },
                    backend: s
                });
            if (r.length > ie().get("WEBGL_MAX_TEXTURES_IN_SHADER")) {
                const t = Math.floor(r.length / 2)
                  , n = e({
                    inputs: r.slice(0, t),
                    backend: s
                })
                  , a = e({
                    inputs: r.slice(t),
                    backend: s
                });
                return e({
                    inputs: [n, a],
                    backend: s
                })
            }
            const a = r.map((e=>e.dtype)).reduce(((e,t)=>ha(e, t)))
              , i = r.map((e=>e.shape))
              , o = ie().getBool("WEBGL_PACK") ? new qC(r[0].shape,i) : new jC(r[0].shape,i);
            return s.runWebGLProgram(o, r, a)
        }
    };
    const XC = {
        kernelName: Re,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {axis: a, keepDims: i} = s
              , o = r.shape.length
              , l = Hs.parseAxisParam(a, r.shape);
            let u = l;
            const c = dm.getAxesPermutation(u, o);
            let h = r;
            null != c && (h = DC({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    perm: c
                }
            }),
            u = dm.getInnerMostAxes(u.length, o)),
            dm.assertAxesAreInnerMostDims("all", u, o);
            const [p,d] = dm.computeOutAndReduceShapes(h.shape, u)
              , f = IC({
                inputs: {
                    x: h
                },
                backend: n,
                attrs: {
                    shape: [-1, Hs.sizeFromShape(d)]
                }
            })
              , m = CC(f, f.dtype, "all", n);
            let g;
            if (i) {
                g = IC({
                    inputs: {
                        x: m
                    },
                    backend: n,
                    attrs: {
                        shape: dm.expandShapeToKeepDim(p, l)
                    }
                })
            } else
                g = IC({
                    inputs: {
                        x: m
                    },
                    backend: n,
                    attrs: {
                        shape: p
                    }
                });
            return n.disposeIntermediateTensorInfo(f),
            n.disposeIntermediateTensorInfo(m),
            null != c && n.disposeIntermediateTensorInfo(h),
            g
        }
    };
    const YC = {
        kernelName: Fe,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {axis: a, keepDims: i} = s
              , o = r.shape.length
              , l = Hs.parseAxisParam(a, r.shape);
            let u = l;
            const c = dm.getAxesPermutation(u, o);
            let h = r;
            null != c && (h = DC({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    perm: c
                }
            }),
            u = dm.getInnerMostAxes(u.length, o)),
            dm.assertAxesAreInnerMostDims("any", u, o);
            const [p,d] = dm.computeOutAndReduceShapes(h.shape, u)
              , f = IC({
                inputs: {
                    x: h
                },
                backend: n,
                attrs: {
                    shape: [-1, Hs.sizeFromShape(d)]
                }
            })
              , m = CC(f, f.dtype, "any", n);
            let g;
            if (i) {
                g = IC({
                    inputs: {
                        x: m
                    },
                    backend: n,
                    attrs: {
                        shape: dm.expandShapeToKeepDim(p, l)
                    }
                })
            } else
                g = IC({
                    inputs: {
                        x: m
                    },
                    backend: n,
                    attrs: {
                        shape: p
                    }
                });
            return n.disposeIntermediateTensorInfo(f),
            n.disposeIntermediateTensorInfo(m),
            null != c && n.disposeIntermediateTensorInfo(h),
            g
        }
    };
    class ZC {
        constructor(e, t, n) {
            this.variableNames = ["A"];
            const {windowSize: s, batchSize: r, outSize: a} = e;
            n || this.variableNames.push("bestIndicesA"),
            this.outputShape = [r, a];
            const i = "max" === t ? ">" : "<"
              , o = n ? "inOffset + i;" : "round(getBestIndicesA(batch, inOffset + i));";
            this.userCode = `\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${s};\n\n        int bestIndex = inOffset;\n        float bestValue = getA(batch, bestIndex);\n\n        for (int i = 0; i < ${s}; i++) {\n          int inIdx = ${o};\n          float candidate = getA(batch, inIdx);\n          if (candidate ${i} bestValue) {\n            bestValue = candidate;\n            bestIndex = inIdx;\n          }\n        }\n        setOutput(float(bestIndex));\n      }\n    `
        }
    }
    class JC {
        constructor(e, t, n, s) {
            this.variableNames = ["A"],
            this.packedInputs = !0,
            this.packedOutput = !0,
            Hs.assert(e.length > 2, (()=>`Packed arg${n.charAt(0).toUpperCase() + n.slice(1)} supports only inputs with rank above 2.`));
            const r = e[e.length - 1]
              , a = Math.ceil(r / t);
            this.outputShape = e.slice(0, -1),
            a > 1 && this.outputShape.push(a),
            s || this.variableNames.push("bestIndicesA");
            const i = this.outputShape
              , o = i.length
              , l = hN(o)
              , u = nT("coords", o);
            let c, h;
            if (1 === a) {
                h = o + 1;
                const e = hN(h);
                c = `\n        ${e} sourceLocR = ${e}(${u.join()}, 0);\n        ++${u[o - 1]};\n        ${e} sourceLocG = ${e}(${u.join()}, 0);\n        ++${u[o - 2]};\n        ${e} sourceLocA = ${e}(${u.join()}, 0);\n        --${u[o - 1]};\n        ${e} sourceLocB = ${e}(${u.join()}, 0);\n        --${u[o - 2]};`
            } else
                h = o,
                c = `\n        ${l} sourceLocR = coords;\n        ++${u[o - 1]};\n        ${l} sourceLocG = coords;\n        ++${u[o - 2]};\n        ${l} sourceLocA = coords;\n        --${u[o - 1]};\n        ${l} sourceLocB = coords;\n        --${u[o - 2]};`;
            const p = ["x", "y", "z", "w", "u", "v"].slice(0, h)
              , d = "." + p[h - 1]
              , f = p.map((e=>"int " + e))
              , m = nT("sourceLocR", h - 1).concat("inIdx.r")
              , g = nT("sourceLocG", h - 1).concat("inIdx.g")
              , y = nT("sourceLocB", h - 1).concat("inIdx.b")
              , b = nT("sourceLocA", h - 1).concat("inIdx.a")
              , x = "max" === n ? "greaterThan" : "lessThan"
              , w = s ? "" : `\n          inIdx = round(vec4(getBestIndicesAChannel(${m.join()}),\n                             getBestIndicesAChannel(${g.join()}),\n                             getBestIndicesAChannel(${y.join()}),\n                             getBestIndicesAChannel(${b.join()})));`
              , v = `vec4(\n            getAChannel(${m.join()}),\n            hasNextCol ? getAChannel(${g.join()}) : 0.,\n            hasNextRow ? getAChannel(${y.join()}) : 0.,\n            hasNextRow && hasNextCol ? getAChannel(${b.join()}) : 0.)`
              , k = s ? "" : `\n      float getBestIndicesAChannel(${f.join()}) {\n        return getChannel(getBestIndicesA(${p.join()}),\n                                          vec2(${p.slice(-2).join()}));\n      }`;
            this.userCode = `\n      float getAChannel(${f.join()}) {\n        return getChannel(getA(${p.join()}),\n                               vec2(${p.slice(-2).join()}));\n      }\n      ${k}\n      void main() {\n        ${l} coords = getOutputCoords();\n        bool hasNextCol = ${u[o - 1]} < ${i[o - 1] - 1};\n        bool hasNextRow = ${u[o - 2]} < ${i[o - 2] - 1};\n        ${c}\n        ivec4 srcIdx = ivec4(sourceLocR${d}, sourceLocG${d},\n          sourceLocB${d}, sourceLocA${d}) * ${t};\n        ivec4 inIdx = srcIdx;\n        vec4 bestIndex = vec4(inIdx);\n        vec4 bestValue = ${v};\n\n        for (int i = 0; i < ${t}; i++) {\n          inIdx = srcIdx;\n          ${w}\n          vec4 candidate = ${v};\n          bvec4 nan = isnan(candidate);\n          bvec4 replace = bvec4(\n            vec4(${x}(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));\n\n          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,\n                           replace.y  ? candidate.y : bestValue.y,\n                           replace.z  ? candidate.z : bestValue.z,\n                           replace.w  ? candidate.w : bestValue.w);\n          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));\n          srcIdx++;\n        }\n        setOutput(bestIndex);\n      }\n    `
        }
    }
    function QC(e, t, n, s=null) {
        let r = t.shape[0]
          , a = t.shape[1];
        null != s && (r = s.shape[0],
        a = s.shape[1]);
        const i = dm.computeOptimalWindowSize(a)
          , o = {
            windowSize: i,
            inSize: a,
            batchSize: r,
            outSize: Math.ceil(a / i)
        }
          , l = new ZC(o,n,null == s)
          , u = [t];
        null != s && u.push(s);
        const c = e.runWebGLProgram(l, u, "int32");
        if (1 === c.shape[1])
            return c;
        const h = QC(e, t, n, c);
        return e.disposeIntermediateTensorInfo(c),
        h
    }
    function e$(e, t, n, s=null) {
        const r = null != s ? s.shape : t.shape
          , a = r[r.length - 1]
          , i = dm.computeOptimalWindowSize(a)
          , o = new JC(r,i,n,null == s)
          , l = null == s ? [t] : [t, s]
          , u = e.runWebGLProgram(o, l, "int32");
        if (u.shape.length === t.shape.length) {
            const s = e$(e, t, n, u);
            return e.disposeIntermediateTensorInfo(u),
            s
        }
        return u
    }
    function t$(e, t, n, s) {
        const r = [n];
        if (dm.assertAxesAreInnerMostDims("arg" + s.charAt(0).toUpperCase() + s.slice(1), r, t.shape.length),
        !ie().getBool("WEBGL_PACK_REDUCE") || t.shape.length <= 2) {
            const n = []
              , a = e.texData.get(t.dataId);
            let i = t;
            null !== a && a.isPacked && (i = e.unpackTensor(t),
            n.push(i));
            const [o,l] = dm.computeOutAndReduceShapes(i.shape, r)
              , u = Hs.sizeFromShape(l)
              , c = IC({
                inputs: {
                    x: i
                },
                backend: e,
                attrs: {
                    shape: [-1, u]
                }
            });
            n.push(c);
            const h = QC(e, c, s);
            n.push(h);
            const p = IC({
                inputs: {
                    x: h
                },
                backend: e,
                attrs: {
                    shape: o
                }
            });
            return n.forEach((t=>e.disposeIntermediateTensorInfo(t))),
            p
        }
        return e$(e, t, s)
    }
    const n$ = {
        kernelName: De,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {axis: a} = s;
            let i = Hs.parseAxisParam(a, r.shape);
            const o = dm.getAxesPermutation(i, r.shape.length);
            let l = r;
            const u = [];
            null != o && (l = DC({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    perm: o
                }
            }),
            u.push(l),
            i = dm.getInnerMostAxes(i.length, l.shape.length)),
            dm.assertAxesAreInnerMostDims("argMax", [i[0]], l.shape.length);
            const c = t$(n, l, i[0], "max");
            return u.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            c
        }
    };
    const s$ = {
        kernelName: _e,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {axis: a} = s;
            let i = Hs.parseAxisParam(a, r.shape);
            const o = dm.getAxesPermutation(i, r.shape.length);
            let l = r;
            const u = [];
            null != o && (l = DC({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    perm: o
                }
            }),
            u.push(l),
            i = dm.getInnerMostAxes(i.length, l.shape.length)),
            dm.assertAxesAreInnerMostDims("argMin", [i[0]], l.shape.length);
            const c = t$(n, l, i[0], "min");
            return u.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            c
        }
    }
      , r$ = bT({
        opSnippet: "if (isnan(x)) return x;\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return asin(x);\n"
    })
      , a$ = {
        kernelName: Oe,
        backendName: "webgl",
        kernelFunc: r$
    }
      , i$ = bT({
        opSnippet: "if (isnan(x)) return x;return log(x + sqrt(x * x + 1.0));"
    })
      , o$ = {
        kernelName: Me,
        backendName: "webgl",
        kernelFunc: i$
    }
      , l$ = bT({
        opSnippet: "if (isnan(x)) return x;\n  return atan(x);\n"
    })
      , u$ = {
        kernelName: Le,
        backendName: "webgl",
        kernelFunc: l$
    }
      , c$ = xT({
        opSnippet: "\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n\n  return atan(a, b);\n",
        packedOpSnippet: "\n  vec4 result = atan(a, b);\n  bvec4 isNaNA = isnan(a);\n  bvec4 isNaNB = isnan(b);\n  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);\n  \n  result.r = isNaN.r ? NAN : result.r;\n  result.g = isNaN.g ? NAN : result.g;\n  result.b = isNaN.b ? NAN : result.b;\n  result.a = isNaN.a ? NAN : result.a;\n\n  return result;\n"
    })
      , h$ = {
        kernelName: Be,
        backendName: "webgl",
        kernelFunc: c$
    }
      , p$ = bT({
        opSnippet: "if (isnan(x)) return x;\n  if ((x < -1.0) || (x > 1.0)) return NAN;\nreturn (log(1.0 + x) - log(1.0 - x)) / 2.0;"
    })
      , d$ = {
        kernelName: ze,
        backendName: "webgl",
        kernelFunc: p$
    };
    class f$ {
        constructor(e, t, n, s=!1, r=!1) {
            if (this.variableNames = ["x"],
            "avg" === t && n)
                throw new Error("Cannot compute positions for average pool.");
            const a = e.filterWidth
              , i = e.strideHeight
              , o = e.strideWidth
              , l = e.dilationHeight
              , u = e.dilationWidth
              , c = e.effectiveFilterHeight
              , h = e.effectiveFilterWidth
              , p = e.padInfo.top
              , d = e.padInfo.left;
            this.outputShape = e.outShape;
            const f = "avg" === t
              , m = `((batch  * ${e.inHeight} + xR) * ${e.inWidth} + xC) * ${e.inChannels} + d`
              , g = `(xR * ${e.inWidth} + xC) * ${e.inChannels} + d`;
            let y = "0.0";
            if (f || (y = "-1.0 / 1e-20"),
            n) {
                const t = ">=";
                return void (this.userCode = `\n        const ivec2 strides = ivec2(${i}, ${o});\n        const ivec2 pads = ivec2(${p}, ${d});\n\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int batch = coords[0];\n          int d = coords[3];\n\n          ivec2 xRCCorner = coords.yz * strides - pads;\n          int xRCorner = xRCCorner.x;\n          int xCCorner = xRCCorner.y;\n\n          // max/min x(?, ?, d) to get y(yR, yC, d).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n          float avgValue = 0.0;\n\n          for (int wR = 0; wR < ${c};\n              wR += ${l}) {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${h};\n                wC += ${u}) {\n              int xC = xCCorner + wC;\n\n              if (xC < 0 || xC >= ${e.inWidth}) {\n                continue;\n              }\n\n              float value = getX(batch, xR, xC, d);\n\n              // If a min / max value has already been found, use it. If not,\n              // use the current value.\n              float currMinMaxValue = mix(\n                  value, minMaxValue, minMaxValueFound);\n              if (value ${t} currMinMaxValue) {\n                minMaxValue = value;\n                minMaxValueFound = 1.0;\n                minMaxPosition = ${s ? r ? m : g : `wR * ${h} + wC`};\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      `)
            }
            let b = `${t}(${t}(${t}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
            "avg" === t && (b = "avgValue / max(count, 1.0)");
            const x = 4 * Math.floor(a / 4)
              , w = a % 4
              , v = `\n      if (${f}) {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = max(values, minMaxValue);\n      }\n    `;
            this.userCode = `\n      const ivec2 strides = ivec2(${i}, ${o});\n      const ivec2 pads = ivec2(${p}, ${d});\n      const float initializationValue = ${y};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xR, int xC, int d) {\n        if (xC < 0 || xC >= ${e.inWidth}) {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xR, xC, d);\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d = coords[3];\n\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // max/min x(?, ?, d) to get y(yR, yC, d).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(${y});\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wR = 0; wR < ${c};\n            wR += ${l}) {\n          int xR = xRCorner + wR;\n\n          if (xR < 0 || xR >= ${e.inHeight}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${x}; wC += 4) {\n            int xC = xCCorner + wC * ${u};\n\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${u}, d),\n              getValue(batch, xR, xC + 2 * ${u}, d),\n              getValue(batch, xR, xC + 3 * ${u}, d)\n            );\n\n            ${v}\n          }\n\n          int xC = xCCorner + ${x};\n          if (${1 === w}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              initializationValue,\n              initializationValue,\n              initializationValue\n            );\n\n            ${v}\n          } else if (${2 === w}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${u}, d),\n              initializationValue,\n              initializationValue\n            );\n\n            ${v}\n          } else if (${3 === w}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${u}, d),\n              getValue(batch, xR, xC + 2 * ${u}, d),\n              initializationValue\n            );\n\n            ${v}\n          }\n        }\n        setOutput(${b});\n      }\n    `
        }
    }
    class m$ {
        constructor(e, t, n, s=!1, r=!1) {
            if (this.variableNames = ["x"],
            "avg" === t && n)
                throw new Error("Cannot compute positions for average pool.");
            const a = e.filterWidth
              , i = e.strideDepth
              , o = e.strideHeight
              , l = e.strideWidth
              , u = e.dilationDepth
              , c = e.dilationHeight
              , h = e.dilationWidth
              , p = e.effectiveFilterDepth
              , d = e.effectiveFilterHeight
              , f = e.effectiveFilterWidth
              , m = e.padInfo.front
              , g = e.padInfo.top
              , y = e.padInfo.left;
            this.outputShape = e.outShape;
            const b = "avg" === t;
            let x = "0.0";
            if (b || (x = "-1.0 / 1e-20"),
            n) {
                const t = ">=";
                return void (this.userCode = `\n        const ivec3 strides =\n            ivec3(${i}, ${o}, ${l});\n        const ivec3 pads = ivec3(${m}, ${g}, ${y});\n\n        void main() {\n          ivec5 coords = getOutputCoords();\n          int batch = coords.x;\n          int ch = coords.u;\n\n          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n          int xDCorner = xCorner.x;\n          int xRCorner = xCorner.y;\n          int xCCorner = xCorner.z;\n\n          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n\n          for (int wD = 0; wD < ${p};\n              wD += ${u}) {\n            int xD = xDCorner + wD;\n\n            if (xD < 0 || xD >= ${e.inDepth}) {\n              continue;\n            }\n\n            for (int wR = 0; wR < ${d};\n                wR += ${c}) {\n              int xR = xRCorner + wR;\n\n              if (xR < 0 || xR >= ${e.inHeight}) {\n                continue;\n              }\n\n              for (int wC = 0; wC < ${f};\n                  wC += ${h}) {\n                int xC = xCCorner + wC;\n\n                if (xC < 0 || xC >= ${e.inWidth}) {\n                  continue;\n                }\n\n                float value = getX(batch, xD, xR, xC, ch);\n\n                // If a min / max value has already been found, use it. If not,\n                // use the current value.\n                float currMinMaxValue = mix(\n                    value, minMaxValue, minMaxValueFound);\n                if (value ${t} currMinMaxValue) {\n                  minMaxValue = value;\n                  minMaxValueFound = 1.0;\n                  minMaxPosition = ${s ? r ? `(((batch * ${e.inDepth} + xD) * ${e.inHeight} + xR) * ${e.inWidth} + xC) * ${e.inChannels} + ch` : `((xD * ${e.inHeight} + xR) * ${e.inWidth} + xC) * ${e.inChannels} + ch` : `wD * ${d} * ${f} +\n                      wR * ${f} + wC`};\n                }\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      `)
            }
            let w = `${t}(${t}(${t}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
            "avg" === t && (w = "avgValue / max(count, 1.0)");
            const v = 4 * Math.floor(a / 4)
              , k = a % 4
              , I = `\n      if (${b}) {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = max(values, minMaxValue);\n      }\n    `;
            this.userCode = `\n      const ivec3 strides =\n        ivec3(${i}, ${o}, ${l});\n      const ivec3 pads = ivec3(${m}, ${g}, ${y});\n      const float initializationValue = ${x};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xD, int xR, int xC, int ch) {\n        if (xC < 0 || xC >= ${e.inWidth}) {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xD, xR, xC, ch);\n      }\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xDCorner = xCorner.x;\n        int xRCorner = xCorner.y;\n        int xCCorner = xCorner.z;\n\n        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(${x});\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wD = 0; wD < ${p};\n            wD += ${u}) {\n          int xD = xDCorner + wD;\n\n          if (xD < 0 || xD >= ${e.inDepth}) {\n            continue;\n          }\n\n          for (int wR = 0; wR < ${d};\n            wR += ${c}) {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${v}; wC += 4) {\n              int xC = xCCorner + wC * ${h};\n\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${h}, ch),\n                getValue(batch, xD, xR, xC + 2 * ${h}, ch),\n                getValue(batch, xD, xR, xC + 3 * ${h}, ch)\n              );\n\n              ${I}\n            }\n\n            int xC = xCCorner + ${v};\n            if (${1 === k}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                initializationValue,\n                initializationValue,\n                initializationValue\n              );\n\n              ${I}\n            } else if (${2 === k}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${h}, ch),\n                initializationValue,\n                initializationValue\n              );\n\n              ${I}\n            } else if (${3 === k}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${h}, ch),\n                getValue(batch, xD, xR, xC + 2 * ${h}, ch),\n                initializationValue\n              );\n\n              ${I}\n            }\n          }\n        }\n        setOutput(${w});\n      }\n    `
        }
    }
    const g$ = {
        kernelName: Pe,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t;
            XN(r, "avgPool");
            const {filterSize: a, strides: i, pad: o, dimRoundingMode: l} = s;
            Hs.assert(dm.eitherStridesOrDilationsAreOne(i, 1), (()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${i} and dilations '1'`));
            const u = dm.computePool2DInfo(r.shape, a, i, 1, o, l);
            if (1 === u.filterWidth && 1 === u.filterHeight && Hs.arraysEqual(u.inShape, u.outShape))
                return rT({
                    inputs: {
                        x: r
                    },
                    backend: n
                });
            const c = new f$(u,"avg",!1);
            return n.runWebGLProgram(c, [r], "float32")
        }
    };
    const y$ = {
        kernelName: Ue,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {filterSize: a, strides: i, pad: o, dimRoundingMode: l, dataFormat: u} = s
              , c = dm.computePool3DInfo(r.shape, a, i, [1, 1, 1], o, l, u)
              , h = new m$(c,"avg",!1);
            return n.runWebGLProgram(h, [r], "float32")
        }
    };
    class b$ {
        constructor(e) {
            this.variableNames = ["dy"],
            this.outputShape = e.inShape;
            const t = e.filterHeight
              , n = e.filterWidth
              , s = e.strideHeight
              , r = e.strideWidth
              , a = e.dilationHeight
              , i = e.dilationWidth
              , o = e.effectiveFilterHeight
              , l = e.effectiveFilterWidth
              , u = o - 1 - e.padInfo.top
              , c = l - 1 - e.padInfo.left
              , h = 1 / (t * n);
            this.userCode = `\n      const ivec2 pads = ivec2(${u}, ${c});\n      const float avgMultiplier = float(${h});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${o};\n            wR += ${a}) {\n          float dyR = float(dyRCorner + wR) / ${s}.0;\n\n          if (dyR < 0.0 || dyR >= ${e.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ${l};\n            wC+= ${i}) {\n            float dyC = float(dyCCorner + wC) / ${r}.0;\n\n            if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n\n            dotProd += dyValue * avgMultiplier;\n          }\n        }\n        setOutput(dotProd);\n      }\n    `
        }
    }
    class x$ {
        constructor(e) {
            this.variableNames = ["dy"],
            this.outputShape = e.inShape;
            const t = e.filterDepth
              , n = e.filterHeight
              , s = e.filterWidth
              , r = e.strideDepth
              , a = e.strideHeight
              , i = e.strideWidth
              , o = e.dilationDepth
              , l = e.dilationHeight
              , u = e.dilationWidth
              , c = e.effectiveFilterDepth
              , h = e.effectiveFilterHeight
              , p = e.effectiveFilterWidth
              , d = c - 1 - e.padInfo.front
              , f = h - 1 - e.padInfo.top
              , m = p - 1 - e.padInfo.left
              , g = 1 / (t * n * s);
            this.userCode = `\n      const ivec3 pads = ivec3(${d}, ${f}, ${m});\n      const float avgMultiplier = float(${g});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ${c};\n            wD += ${o}) {\n          float dyD = float(dyDCorner + wD) / ${r}.0;\n\n          if (dyD < 0.0 || dyD >= ${e.outDepth}.0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ${h};\n              wR += ${l}) {\n            float dyR = float(dyRCorner + wR) / ${a}.0;\n\n            if (dyR < 0.0 || dyR >= ${e.outHeight}.0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ${p};\n                wC += ${u}) {\n              float dyC = float(dyCCorner + wC) / ${i}.0;\n\n              if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n\n              dotProd += dyValue * avgMultiplier;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `
        }
    }
    const w$ = {
        kernelName: Ve,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {dy: r, input: a} = t
              , i = a
              , {filterSize: o, strides: l, pad: u, dimRoundingMode: c} = s
              , h = dm.computePool3DInfo(i.shape, o, l, [1, 1, 1], u, c)
              , p = new x$(h);
            return n.runWebGLProgram(p, [r], i.dtype)
        }
    };
    const v$ = {
        kernelName: We,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {dy: r, input: a} = t
              , i = a;
            XN([r, a], "avgPoolGrad");
            const {filterSize: o, strides: l, pad: u} = s
              , c = dm.computePool2DInfo(i.shape, o, l, 1, u)
              , h = new b$(c);
            return n.runWebGLProgram(h, [r], i.dtype)
        }
    };
    const k$ = {
        kernelName: Ge,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {a: r, b: a} = t
              , {transposeA: i, transposeB: o} = s;
            return OC({
                a: r,
                b: a,
                transposeA: i,
                transposeB: o,
                backend: n
            })
        }
    };
    class I$ {
        constructor(e, t, n, s, r, a) {
            this.outputShape = [],
            this.variableNames = ["x", "mean", "variance"],
            dm.assertAndGetBroadcastShape(e, t),
            dm.assertAndGetBroadcastShape(e, n);
            let i = "0.0";
            null != s && (dm.assertAndGetBroadcastShape(e, s),
            this.variableNames.push("offset"),
            i = "getOffsetAtOutCoords()");
            let o = "1.0";
            null != r && (dm.assertAndGetBroadcastShape(e, r),
            this.variableNames.push("scale"),
            o = "getScaleAtOutCoords()"),
            this.outputShape = e,
            this.userCode = `\n      void main() {\n        float x = getXAtOutCoords();\n        float mean = getMeanAtOutCoords();\n        float variance = getVarianceAtOutCoords();\n        float offset = ${i};\n        float scale = ${o};\n        float inv = scale * inversesqrt(variance + float(${a}));\n        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));\n      }\n    `
        }
    }
    class S$ {
        constructor(e, t, n, s, r, a) {
            this.packedInputs = !0,
            this.packedOutput = !0,
            this.variableNames = ["x", "mean", "variance"],
            dm.assertAndGetBroadcastShape(e, t),
            dm.assertAndGetBroadcastShape(e, n);
            let i = "vec4(0.0)";
            null != s && (dm.assertAndGetBroadcastShape(e, s),
            this.variableNames.push("offset"),
            i = "getOffsetAtOutCoords()");
            let o = "vec4(1.0)";
            null != r && (dm.assertAndGetBroadcastShape(e, r),
            this.variableNames.push("scale"),
            o = "getScaleAtOutCoords()"),
            this.outputShape = e,
            this.userCode = `\n      void main() {\n        vec4 offset = ${i};\n        vec4 scale = ${o};\n\n        vec4 x = getXAtOutCoords();\n        vec4 mean = getMeanAtOutCoords();\n        vec4 variance = getVarianceAtOutCoords();\n\n        vec4 inv = scale * inversesqrt(variance + vec4(${a}));\n\n        setOutput((x - mean) * inv + offset);\n      }\n    `
        }
    }
    const N$ = {
        kernelName: _t,
        backendName: "webgl",
        kernelFunc: ({inputs: e, backend: t, attrs: n})=>{
            const {x: s, mean: r, variance: a, offset: i, scale: o} = e;
            Hs.assert(r.shape.length === a.shape.length, (()=>"Batch normalization gradient requires mean and variance to have equal ranks.")),
            Hs.assert(null == i || r.shape.length === i.shape.length, (()=>"Batch normalization gradient requires mean and offset to have equal ranks.")),
            Hs.assert(null == o || r.shape.length === o.shape.length, (()=>"Batch normalization gradient requires mean and scale to have equal ranks."));
            let {varianceEpsilon: l} = n;
            null == l && (l = .001);
            const u = [s, r, a];
            let c = null;
            null != i && (c = i.shape,
            u.push(i));
            let h = null;
            null != o && (h = o.shape,
            u.push(o));
            const p = ie().getBool("WEBGL_PACK_NORMALIZATION") ? new S$(s.shape,r.shape,a.shape,c,h,l) : new I$(s.shape,r.shape,a.shape,c,h,l);
            return t.runWebGLProgram(p, u, u[0].dtype)
        }
    };
    class T$ {
        constructor(e) {
            this.variableNames = ["source"],
            this.outputShape = e,
            this.rank = e.length;
            const t = hN(this.rank);
            this.customUniforms = [{
                name: "start",
                arrayIndex: this.rank,
                type: "int"
            }];
            const n = function(e) {
                if (1 === e)
                    return "sourceLoc";
                if (e <= 6)
                    return C$.slice(0, e).map((e=>"sourceLoc." + e)).join(",");
                throw Error(`Slicing for rank ${e} is not yet supported`)
            }(this.rank);
            let s;
            s = `\n        ${t} sourceLoc;\n        ${t} coords = getOutputCoords();\n        ${e.map(((e,t)=>`sourceLoc.${C$[t]} = start[${t}] + coords.${C$[t]};`)).join("\n")}\n      `,
            this.userCode = `\n      void main() {\n        ${s}\n        setOutput(getSource(${n}));\n      }\n    `
        }
    }
    const C$ = ["x", "y", "z", "w", "u", "v"];
    class $$ {
        constructor(e) {
            this.variableNames = ["source"],
            this.packedInputs = !0,
            this.packedOutput = !0,
            this.outputShape = e,
            this.rank = e.length,
            this.customUniforms = [{
                name: "start",
                arrayIndex: this.rank,
                type: "int"
            }];
            const t = hN(this.rank)
              , n = nT("coords", this.rank)
              , s = nT("sourceLoc", this.rank)
              , r = 1 === this.rank ? "sourceLoc" : `vec2(${s.slice(-2).join()})`
              , a = `getChannel(getSource(${s.join()}), ${r})`
              , i = `\n      result.x = ${a};\n      if (++${n[this.rank - 1]} < ${e[this.rank - 1]}) {\n        ++${s[this.rank - 1]};\n        result.y = ${a};\n        --${s[this.rank - 1]};\n      }\n    `
              , o = 1 === this.rank ? "" : `\n      --${n[this.rank - 1]};\n      if (++${n[this.rank - 2]} < ${e[this.rank - 2]}) {\n        ++${s[this.rank - 2]};\n        result.z = ${a};\n        if (++${n[this.rank - 1]} < ${e[this.rank - 1]}) {\n          ++${s[this.rank - 1]};\n          result.w = ${a};\n        }\n      }\n    `
              , l = this.rank <= 4 ? `sourceLoc = coords +\n            ${t}(${e.map(((e,t)=>`start[${t}]`)).join()});` : e.map(((e,t)=>`${s[t]} = ${n[t]} + start[${t}];`)).join("\n");
            this.userCode = `\n      void main() {\n        ${t} coords = getOutputCoords();\n        ${t} sourceLoc;\n        ${l}\n        vec4 result = vec4(0.);\n        ${i}\n        ${o}\n        setOutput(result);\n      }\n    `
        }
    }
    function E$(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {x: r} = t
          , {begin: a, size: i} = s
          , [o,l] = Xf.parseSliceParams(r, a, i);
        if (Xf.assertParamsValid(r, o, l),
        0 === Hs.sizeFromShape(l))
            return n.makeTensorInfo(l, r.dtype, []);
        if (n.shouldExecuteOnCPU([r]) || "string" === r.dtype) {
            const e = n.texData.get(r.dataId)
              , t = aC(e.values, o, l, r.shape, r.dtype);
            return n.makeTensorInfo(l, r.dtype, t)
        }
        const {isPacked: u} = n.texData.get(r.dataId)
          , c = Xf.isSliceContinous(r.shape, o, l);
        if (u || !c) {
            const e = ie().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new $$(l) : new T$(l)
              , t = [o];
            return n.runWebGLProgram(e, [r], r.dtype, t)
        }
        return n.uploadToGPU(r.dataId),
        function(e, t, n, s) {
            const r = s.texData.get(e.dataId)
              , a = s.makeTensorInfo(n, e.dtype)
              , i = s.texData.get(a.dataId);
            Object.assign(i, r),
            i.refCount = 1,
            i.shape = n,
            i.dtype = e.dtype;
            let o = Xf.computeFlatOffset(t, Hs.computeStrides(e.shape));
            r.slice && (o += r.slice.flatOffset),
            i.slice = {
                flatOffset: o,
                origDataId: r.slice && r.slice.origDataId || e.dataId
            };
            const l = s.dataRefCount.get(i.slice.origDataId) || 1;
            return s.dataRefCount.set(i.slice.origDataId, l + 1),
            a
        }(r, o, l, n)
    }
    const A$ = {
        kernelName: Xn,
        backendName: "webgl",
        kernelFunc: E$
    }
      , R$ = {
        kernelName: He,
        backendName: "webgl",
        kernelFunc: e=>{
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {blockShape: a, crops: i} = s;
            Hs.assert(r.shape.length <= 4, (()=>"batchToSpaceND for rank > 4 with a WebGL backend not implemented yet"));
            const o = a.reduce(((e,t)=>e * t))
              , l = dm.getReshaped(r.shape, a, o)
              , u = dm.getPermuted(l.length, a.length)
              , c = dm.getReshapedPermuted(r.shape, a, o)
              , h = dm.getSliceBeginCoords(i, a.length)
              , p = dm.getSliceSize(c, i, a.length)
              , d = []
              , f = IC({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    shape: l
                }
            })
              , m = DC({
                inputs: {
                    x: f
                },
                backend: n,
                attrs: {
                    perm: u
                }
            })
              , g = IC({
                inputs: {
                    x: m
                },
                backend: n,
                attrs: {
                    shape: c
                }
            })
              , y = E$({
                inputs: {
                    x: g
                },
                backend: n,
                attrs: {
                    begin: h,
                    size: p
                }
            });
            return d.push(f),
            d.push(m),
            d.push(g),
            d.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            y
        }
    };
    const F$ = {
        kernelName: je,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, weights: a} = t
              , {size: i} = s
              , o = n.readSync(r.dataId)
              , l = n.readSync(a.dataId)
              , u = CT(o, l, a.dtype, a.shape, i);
            return n.makeTensorInfo([i], a.dtype, u)
        }
    };
    const D$ = {
        kernelName: qe,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {s0: s, s1: r} = t
              , a = n.readSync(s.dataId)
              , i = n.readSync(r.dataId)
              , o = dm.assertAndGetBroadcastShape(Array.from(a), Array.from(i));
            return n.makeTensorInfo([o.length], "int32", Int32Array.from(o))
        }
    }
      , _$ = xT({
        opSnippet: "return float(a != b);",
        cpuKernelImpl: XT,
        dtype: "bool"
    })
      , O$ = {
        kernelName: bn,
        backendName: "webgl",
        kernelFunc: _$
    };
    function M$(e) {
        const {inputs: t, backend: n} = e
          , {input: s} = t;
        return rT({
            inputs: {
                x: n.texData.get(s.dataId).complexTensorInfos.real
            },
            backend: n
        })
    }
    const L$ = {
        kernelName: Dn,
        backendName: "webgl",
        kernelFunc: M$
    };
    const z$ = {
        kernelName: Ke,
        backendName: "webgl",
        kernelFunc: function e(t) {
            const {inputs: n, backend: s, attrs: r} = t
              , {x: a} = n
              , {dtype: i} = r;
            if ("complex64" === i) {
                if ("complex64" === a.dtype)
                    return rT({
                        inputs: {
                            x: a
                        },
                        backend: s
                    });
                const t = fl(a.shape)
                  , n = e({
                    inputs: {
                        x: a
                    },
                    backend: s,
                    attrs: {
                        dtype: "float32"
                    }
                })
                  , r = iT({
                    inputs: {
                        real: n,
                        imag: t
                    },
                    backend: s
                });
                return t.dispose(),
                s.disposeIntermediateTensorInfo(n),
                r
            }
            if ("complex64" === a.dtype) {
                const t = M$({
                    inputs: {
                        input: a
                    },
                    backend: s
                })
                  , n = e({
                    inputs: {
                        x: t
                    },
                    backend: s,
                    attrs: {
                        dtype: i
                    }
                });
                return s.disposeIntermediateTensorInfo(t),
                n
            }
            if (!Hs.hasEncodingLoss(a.dtype, i)) {
                const e = rT({
                    inputs: {
                        x: a
                    },
                    backend: s
                });
                return {
                    dataId: e.dataId,
                    shape: e.shape,
                    dtype: i
                }
            }
            if (s.shouldExecuteOnCPU([a])) {
                const e = s.texData.get(a.dataId).values
                  , [t,n,r] = ET(e, a.shape, a.dtype, i);
                return s.makeTensorInfo(t, n, r)
            }
            if ("int32" === i)
                return function(e, t) {
                    const n = new fT(e.shape,"return float(int(x));")
                      , s = t.runWebGLProgram(n, [e], "int32");
                    return {
                        dataId: s.dataId,
                        shape: s.shape,
                        dtype: s.dtype
                    }
                }(a, s);
            if ("bool" === i) {
                const e = s.makeTensorInfo([], "bool", Hs.getTypedArrayFromDType("bool", 1))
                  , t = _$({
                    inputs: {
                        a: a,
                        b: e
                    },
                    backend: s
                });
                return s.disposeIntermediateTensorInfo(e),
                t
            }
            throw new Error(`Error in Cast: failed to cast ${a.dtype} to ${i}`)
        }
    }
      , B$ = "return ceil(x);"
      , P$ = bT({
        opSnippet: B$,
        packedOpSnippet: B$,
        cpuKernelImpl: AT
    })
      , W$ = {
        kernelName: Xe,
        backendName: "webgl",
        kernelFunc: P$
    };
    class U$ {
        constructor(e) {
            this.variableNames = ["A"],
            this.customUniforms = [{
                name: "minVal",
                type: "float"
            }, {
                name: "maxVal",
                type: "float"
            }],
            this.outputShape = e,
            this.userCode = "\n\n      void main() {\n        float value = getAAtOutCoords();\n        if (isnan(value)) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, minVal, maxVal));\n      }\n    "
        }
    }
    class V$ {
        constructor(e) {
            this.variableNames = ["A"],
            this.packedInputs = !0,
            this.packedOutput = !0,
            this.customUniforms = [{
                name: "minVal",
                type: "float"
            }, {
                name: "maxVal",
                type: "float"
            }],
            this.outputShape = e,
            this.userCode = "\n      void main() {\n        vec4 value = getAAtOutCoords();\n\n        if (any(isnan(value))) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));\n      }\n    "
        }
    }
    const G$ = {
        kernelName: Ye,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {clipValueMin: a, clipValueMax: i} = s;
            let o;
            o = ie().getBool("WEBGL_PACK_CLIP") ? new V$(r.shape) : new U$(r.shape);
            const l = [[a], [i]];
            return n.runWebGLProgram(o, [r], r.dtype, l)
        }
    };
    class H$ {
        constructor(e) {
            this.variableNames = ["real", "imag"],
            this.outputShape = e,
            this.userCode = "\n      void main() {\n        float re = abs(getRealAtOutCoords());\n        float im = abs(getImagAtOutCoords());\n        float mx = max(re, im);\n\n        // sadly the length function in glsl is not underflow-safe\n        // (at least not on Intel GPUs). So the safe solution is\n        // to ensure underflow-safety in all cases.\n        setOutput(\n          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))\n        );\n      }\n    "
        }
    }
    function j$(e, t) {
        return {
            dataId: t.dataId,
            dtype: t.dtype,
            shape: e.shape
        }
    }
    const q$ = {
        kernelName: Je,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {x: s} = t
              , r = n.texData.get(s.dataId)
              , a = new H$(s.shape)
              , i = [j$(s, r.complexTensorInfos.real), j$(s, r.complexTensorInfos.imag)];
            return n.runWebGLProgram(a, i, i[0].dtype)
        }
    };
    class K$ {
        constructor(e) {
            this.outputShape = [],
            this.outputShape = dm.computeOutShape(e, 1),
            this.variableNames = e.map(((e,t)=>`T${t}`));
            const t = new Array(e.length - 1);
            t[0] = e[0][1];
            for (let n = 1; n < t.length; n++)
                t[n] = t[n - 1] + e[n][1];
            const n = [`if (yC < ${t[0]}) setOutput(getT0(yR, yC));`];
            for (let e = 1; e < t.length; e++) {
                const s = t[e - 1];
                n.push(`else if (yC < ${t[e]}) setOutput(getT${e}(yR, yC-${s}));`)
            }
            const s = t.length
              , r = t[t.length - 1];
            n.push(`else setOutput(getT${s}(yR, yC-${r}));`),
            this.userCode = `\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int yR = coords.x;\n        int yC = coords.y;\n\n        ${n.join("\n        ")}\n      }\n    `
        }
    }
    class X$ {
        constructor(e, t) {
            this.packedInputs = !0,
            this.packedOutput = !0,
            this.outputShape = [],
            this.outputShape = dm.computeOutShape(e, t);
            const n = this.outputShape
              , s = n.length
              , r = hN(s)
              , a = nT("coords", s)
              , i = ["x", "y", "z", "w", "u", "v"].slice(0, s);
            this.variableNames = e.map(((e,t)=>`T${t}`));
            const o = new Array(e.length - 1);
            o[0] = e[0][t];
            for (let n = 1; n < o.length; n++)
                o[n] = o[n - 1] + e[n][t];
            const l = i[t]
              , u = i.slice(-2)
              , c = i.join();
            let h = `if (${l} < ${o[0]}) {\n        return getChannel(\n            getT0(${c}), vec2(${u.join()}));\n        }`;
            for (let e = 1; e < o.length; e++) {
                const t = o[e - 1];
                h += `\n        if (${l} < ${o[e]}  && ${l} >= ${o[e - 1]}) {\n          return getChannel(\n            getT${e}(${Y$(i, l, t)}),\n            vec2(${Y$(u, l, t)}));\n        }`
            }
            const p = o.length
              , d = o[o.length - 1];
            h += `\n        return getChannel(\n          getT${p}(${Y$(i, l, d)}),\n          vec2(${Y$(u, l, d)}));`,
            this.userCode = `\n      float getValue(${i.map((e=>"int " + e))}) {\n        ${h}\n      }\n\n      void main() {\n        ${r} coords = getOutputCoords();\n        vec4 result = vec4(getValue(${a}), 0., 0., 0.);\n\n        ${a[s - 1]} = ${a[s - 1]} + 1;\n        if (${a[s - 1]} < ${n[s - 1]}) {\n          result.g = getValue(${a});\n        }\n\n        ${a[s - 2]} = ${a[s - 2]} + 1;\n        if (${a[s - 2]} < ${n[s - 2]}) {\n          result.a = getValue(${a});\n        }\n\n        ${a[s - 1]} = ${a[s - 1]} - 1;\n        if (${a[s - 2]} < ${n[s - 2]} &&\n            ${a[s - 1]} < ${n[s - 1]}) {\n          result.b = getValue(${a});\n        }\n        setOutput(result);\n      }\n    `
        }
    }
    function Y$(e, t, n) {
        const s = e.indexOf(t);
        return e.map(((e,t)=>t === s ? `${e} - ${n}` : e)).join()
    }
    function Z$(e) {
        const {inputs: t, backend: n} = e
          , {input: s} = t;
        return rT({
            inputs: {
                x: n.texData.get(s.dataId).complexTensorInfos.imag
            },
            backend: n
        })
    }
    const J$ = {
        kernelName: Wt,
        backendName: "webgl",
        kernelFunc: Z$
    };
    function Q$(e, t, n) {
        const s = e[0].dtype;
        if ("complex64" === s) {
            const s = e.map((e=>M$({
                inputs: {
                    input: e
                },
                backend: n
            })))
              , r = e.map((e=>Z$({
                inputs: {
                    input: e
                },
                backend: n
            })))
              , a = Q$(s, t, n)
              , i = Q$(r, t, n)
              , o = iT({
                inputs: {
                    real: a,
                    imag: i
                },
                backend: n
            });
            return s.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            r.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            n.disposeIntermediateTensorInfo(a),
            n.disposeIntermediateTensorInfo(i),
            o
        }
        let r = n.shouldExecuteOnCPU(e);
        if ("string" === s && (r = !0),
        r) {
            const r = e.map((e=>{
                const s = Hs.sizeFromShape(e.shape.slice(t));
                return IC({
                    inputs: {
                        x: e
                    },
                    backend: n,
                    attrs: {
                        shape: [-1, s]
                    }
                })
            }
            ))
              , a = r.map((e=>({
                vals: n.readSync(e.dataId),
                shape: e.shape
            })))
              , i = dm.computeOutShape(r.map((e=>e.shape)), 1)
              , o = 1 === r[0].shape[0]
              , l = RT(a, i, s, o)
              , u = dm.computeOutShape(e.map((e=>e.shape)), t)
              , c = n.makeTensorInfo(u, s, l);
            return r.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            c
        }
        const a = e.filter((e=>Hs.sizeFromShape(e.shape) > 0))
          , i = ie().getBool("WEBGL_PACK_ARRAY_OPERATIONS") && a[0].shape.length > 1;
        if (1 === a.length) {
            const t = i ? new fT(e[0].shape,gT) : new yT(e[0].shape,gT);
            return n.runWebGLProgram(t, e, s)
        }
        const o = ie().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER");
        if (a.length > o) {
            const e = [];
            for (let s = 0; s < a.length; s += o) {
                const r = a.slice(s, s + o);
                e.push(Q$(r, t, n))
            }
            const s = Q$(e, t, n);
            for (const t of e)
                n.disposeIntermediateTensorInfo(t);
            return s
        }
        if (i) {
            const e = new X$(a.map((e=>e.shape)),t);
            return n.runWebGLProgram(e, a, s)
        }
        const {tensors2D: l, outShape: u} = function(e, t, n) {
            const s = dm.computeOutShape(e.map((e=>e.shape)), t);
            return {
                tensors2D: e.map((e=>IC({
                    inputs: {
                        x: e
                    },
                    attrs: {
                        shape: [-1, Hs.sizeFromShape(e.shape.slice(t))]
                    },
                    backend: n
                }))),
                outShape: s
            }
        }(a, t, n)
          , c = new K$(l.map((e=>e.shape)))
          , h = n.runWebGLProgram(c, l, s);
        l.forEach((e=>n.disposeIntermediateTensorInfo(e)));
        const p = IC({
            inputs: {
                x: h
            },
            attrs: {
                shape: u
            },
            backend: n
        });
        return n.disposeIntermediateTensorInfo(h),
        p
    }
    function eE(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {axis: r} = s
          , a = Hs.parseAxisParam(r, t[0].shape)[0]
          , i = t.map((e=>e.shape));
        dm.assertParamsConsistent(i, a);
        const o = dm.computeOutShape(t.map((e=>e.shape)), a);
        if (0 === Hs.sizeFromShape(o))
            return n.makeTensorInfo(o, t[0].dtype, []);
        const l = t.filter((e=>Hs.sizeFromShape(e.shape) > 0));
        return 1 === l.length ? rT({
            inputs: {
                x: l[0]
            },
            backend: n
        }) : Q$(l, a, n)
    }
    const tE = {
        kernelName: Qe,
        backendName: "webgl",
        kernelFunc: eE
    };
    class nE {
        constructor(e, t=!1, n=null, s=!1, r=!1) {
            this.variableNames = ["x", "W"],
            this.outputShape = e.outShape;
            const a = e.padInfo.top
              , i = e.padInfo.left
              , o = e.strideHeight
              , l = e.strideWidth
              , u = e.dilationHeight
              , c = e.dilationWidth
              , h = e.filterHeight
              , p = e.filterWidth
              , d = 4 * Math.floor(e.inChannels / 4)
              , f = e.inChannels % 4
              , m = "channelsLast" === e.dataFormat
              , g = m ? 1 : 2
              , y = m ? 2 : 3
              , b = m ? 3 : 1;
            let x = ""
              , w = "";
            n && (x = s ? `float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ${n}\n        }` : r ? `float activation(float a) {\n          float b = getLeakyreluAlphaAtOutCoords();\n          ${n}\n        }` : `\n          float activation(float x) {\n            ${n}\n          }\n        `,
            w = "result = activation(result);");
            const v = t ? "result += getBiasAtOutCoords();" : "";
            t && this.variableNames.push("bias"),
            s && this.variableNames.push("preluActivationWeights"),
            r && this.variableNames.push("leakyreluAlpha"),
            this.userCode = `\n      ${x}\n\n      const ivec2 strides = ivec2(${o}, ${l});\n      const ivec2 pads = ivec2(${a}, ${i});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d2 = coords[${b}];\n\n        ivec2 xRCCorner =\n            ivec2(coords[${g}], coords[${y}]) * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${h}; wR++) {\n          int xR = xRCorner + wR * ${u};\n\n          if (xR < 0 || xR >= ${e.inHeight}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${p}; wC++) {\n            int xC = xCCorner + wC * ${c};\n\n            if (xC < 0 || xC >= ${e.inWidth}) {\n              continue;\n            }\n\n            for (int d1 = 0; d1 < ${d}; d1 += 4) {\n              vec4 wValues = vec4(\n                getW(wR, wC, d1, d2),\n                getW(wR, wC, d1 + 1, d2),\n                getW(wR, wC, d1 + 2, d2),\n                getW(wR, wC, d1 + 3, d2)\n              );\n\n              if (${m}) {\n                vec4 xValues = vec4(\n                  getX(batch, xR, xC, d1),\n                  getX(batch, xR, xC, d1 + 1),\n                  getX(batch, xR, xC, d1 + 2),\n                  getX(batch, xR, xC, d1 + 3)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec4 xValues = vec4(\n                  getX(batch, d1, xR, xC),\n                  getX(batch, d1 + 1, xR, xC),\n                  getX(batch, d1 + 2, xR, xC),\n                  getX(batch, d1 + 3, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n\n            if (${1 === f}) {\n\n              if (${m}) {\n                dotProd +=\n                    getX(batch, xR, xC, ${d}) *\n                    getW(wR, wC, ${d}, d2);\n              } else {\n                dotProd +=\n                    getX(batch, ${d}, xR, xC) *\n                    getW(wR, wC, ${d}, d2);\n              }\n\n            } else if (${2 === f}) {\n              vec2 wValues = vec2(\n                getW(wR, wC, ${d}, d2),\n                getW(wR, wC, ${d} + 1, d2)\n              );\n\n              if (${m}) {\n                vec2 xValues = vec2(\n                  getX(batch, xR, xC, ${d}),\n                  getX(batch, xR, xC, ${d} + 1)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec2 xValues = vec2(\n                  getX(batch, ${d}, xR, xC),\n                  getX(batch, ${d} + 1, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            } else if (${3 === f}) {\n              vec3 wValues = vec3(\n                getW(wR, wC, ${d}, d2),\n                getW(wR, wC, ${d} + 1, d2),\n                getW(wR, wC, ${d} + 2, d2)\n              );\n\n              if (${m}) {\n                vec3 xValues = vec3(\n                  getX(batch, xR, xC, ${d}),\n                  getX(batch, xR, xC, ${d} + 1),\n                  getX(batch, xR, xC, ${d} + 2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec3 xValues = vec3(\n                  getX(batch, ${d}, xR, xC),\n                  getX(batch, ${d} + 1, xR, xC),\n                  getX(batch, ${d} + 2, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            }\n          }\n        }\n\n        float result = dotProd;\n        ${v}\n        ${w}\n        setOutput(result);\n      }\n    `
        }
    }
    class sE {
        constructor(e) {
            this.variableNames = ["x", "W"],
            this.outputShape = e.outShape;
            const t = e.padInfo.front
              , n = e.padInfo.top
              , s = e.padInfo.left
              , r = e.strideDepth
              , a = e.strideHeight
              , i = e.strideWidth
              , o = e.dilationDepth
              , l = e.dilationHeight
              , u = e.dilationWidth
              , c = e.filterDepth
              , h = e.filterHeight
              , p = e.filterWidth
              , d = 4 * Math.floor(e.inChannels / 4)
              , f = e.inChannels % 4;
            this.userCode = `\n      const ivec3 strides = ivec3(${r}, ${a}, ${i});\n      const ivec3 pads = ivec3(${t}, ${n}, ${s});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d2 = coords.u;\n\n        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xFCorner = xFRCCorner.x;\n        int xRCorner = xFRCCorner.y;\n        int xCCorner = xFRCCorner.z;\n\n        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get\n        // y(yF, yR, yC, d2). ? = to be determined. : = across all\n        // values in that axis.\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ${c}; wF++) {\n          int xF = xFCorner + wF * ${o};\n\n          if (xF < 0 || xF >= ${e.inDepth}) {\n            continue;\n          }\n\n          for (int wR = 0; wR < ${h}; wR++) {\n            int xR = xRCorner + wR * ${l};\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${p}; wC++) {\n              int xC = xCCorner + wC * ${u};\n\n              if (xC < 0 || xC >= ${e.inWidth}) {\n                continue;\n              }\n\n              for (int d1 = 0; d1 < ${d}; d1 += 4) {\n                vec4 xValues = vec4(\n                  getX(batch, xF, xR, xC, d1),\n                  getX(batch, xF, xR, xC, d1 + 1),\n                  getX(batch, xF, xR, xC, d1 + 2),\n                  getX(batch, xF, xR, xC, d1 + 3)\n                );\n                vec4 wValues = vec4(\n                  getW(wF, wR, wC, d1, d2),\n                  getW(wF, wR, wC, d1 + 1, d2),\n                  getW(wF, wR, wC, d1 + 2, d2),\n                  getW(wF, wR, wC, d1 + 3, d2)\n                );\n\n                dotProd += dot(xValues, wValues);\n              }\n\n              if (${1 === f}) {\n                dotProd +=\n                  getX(batch, xF, xR, xC, ${d}) *\n                  getW(wF, wR, wC, ${d}, d2);\n              } else if (${2 === f}) {\n                vec2 xValues = vec2(\n                  getX(batch, xF, xR, xC, ${d}),\n                  getX(batch, xF, xR, xC, ${d} + 1)\n                );\n                vec2 wValues = vec2(\n                  getW(wF, wR, wC, ${d}, d2),\n                  getW(wF, wR, wC, ${d} + 1, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else if (${3 === f}) {\n                vec3 xValues = vec3(\n                  getX(batch, xF, xR, xC, ${d}),\n                  getX(batch, xF, xR, xC, ${d} + 1),\n                  getX(batch, xF, xR, xC, ${d} + 2)\n                );\n                vec3 wValues = vec3(\n                  getW(wF, wR, wC, ${d}, d2),\n                  getW(wF, wR, wC, ${d} + 1, d2),\n                  getW(wF, wR, wC, ${d} + 2, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `
        }
    }
    class rE {
        constructor(e, t=!1, n=null, s=!1, r=!1) {
            this.variableNames = ["x", "W"],
            this.packedInputs = !0,
            this.packedOutput = !0,
            this.customUniforms = [{
                name: "pads",
                type: "ivec2"
            }, {
                name: "strides",
                type: "ivec2"
            }, {
                name: "dilations",
                type: "ivec2"
            }, {
                name: "inDims",
                type: "ivec2"
            }],
            this.outputShape = e.outShape,
            this.enableShapeUniforms = QN(this.outputShape.length);
            const a = e.padInfo.left
              , i = e.strideWidth
              , o = e.dilationWidth
              , l = e.filterHeight
              , u = e.filterWidth
              , c = u;
            let h = "\n       int xR; int xC; int xCOffset;\n       vec4 wTexel; vec4 previous; vec4 final;";
            for (let e = 0; e < u; e++)
                h += `\n           vec4 xTexelC${2 * e};\n           int xTexelC${2 * e}Ready;\n           vec4 xTexelC${2 * e + 1};\n           int xTexelC${2 * e + 1}Ready;\n           vec4 xC${e};`;
            h += `\n     for (int r = 0; r < ${l}; r++) {\n      for (int d1 = 0; d1 < ${e.inChannels}; d1 += 2) {\n       `;
            for (let e = 0; e < u; e++)
                h += `\n           xTexelC${2 * e} = vec4(0.0);\n           xTexelC${2 * e}Ready = 0;\n           xTexelC${2 * e + 1} = vec4(0.0);\n           xTexelC${2 * e + 1}Ready = 0;\n           xC${e} = vec4(0.0);`;
            h += "\n         xR = xRCorner + r * dilations[0];\n         if (xR >=0 && xR < inDims[0]) {\n       ";
            for (let t = 0; t < (c + 1) / 2; t++) {
                const n = 2 * t;
                if (h += `\n           xC = xCCorner + ${n * o};\n           `,
                1 === i) {
                    if (n < u && (a % 2 == 1 ? (h += `\n                 xCOffset = xC + 1;\n                 if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${n}Ready == 0) {\n                   xTexelC${n} = getX(batch, xR, xCOffset, d1);\n\n                   // Need to manually clear unused channels in case\n                   // we're reading from recycled texture.\n                   if (xCOffset + 1 >= inDims[1]) {\n                     xTexelC${n}.zw = vec2(0.0);\n                   }\n                   xTexelC${n}Ready = 1;\n                 }\n               `,
                    h += 1 === o && n > 0 ? `\n                 xC${n} = vec4(xTexelC${n - 2}.zw, xTexelC${n}.xy);\n                 ` : `\n                   xCOffset = xC + 1 - 2;\n\n                   if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                     previous = getX(batch, xR, xCOffset, d1);\n\n                     // Need to manually clear unused channels in case\n                     // we're reading from recycled texture.\n                     if (xCOffset + 1 >= inDims[1]) {\n                       previous.zw = vec2(0.0);\n                     }\n\n                     xC${n} = vec4(previous.zw, xTexelC${n}.xy);\n                   } else {\n                     xC${n} = vec4(0.0, 0.0, xTexelC${n}.xy);\n                   }\n                   `) : h += `\n                 if (xC >= 0 && xC < inDims[1] && xTexelC${n}Ready == 0) {\n                   xTexelC${n} = getX(batch, xR, xC, d1);\n                   if (xC + 1 >= inDims[1]) {\n                     xTexelC${n}.zw = vec2(0.0);\n                   }\n                   xTexelC${n}Ready = 1;\n                 }\n\n                 xC${n} = xTexelC${n};\n                 `,
                    n + 1 < u)) {
                        const e = a % 2 == 0 ? Hs.nearestLargerEven(o) : o;
                        o % 2 == 0 && a % 2 == 1 || o % 2 != 0 && a % 2 != 1 ? (h += `\n                   xCOffset = xC + imod(pads[1], 2) + ${e};\n\n                   if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${n + 1}Ready == 0) {\n                     xTexelC${n + 1} = getX(batch, xR, xCOffset, d1);\n\n                     // Need to manually clear unused channels in case\n                     // we're reading from recycled texture.\n                     if (xCOffset + 1 >= inDims[1]) {\n                       xTexelC${n + 1}.zw = vec2(0.0);\n                     }\n                     xTexelC${n + 1}Ready = 1;\n                   }\n                   `,
                        h += o > 1 ? `\n                     xCOffset -= 2;\n                     if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                      previous = getX(batch, xR, xCOffset, d1);\n                      xC${n + 1} = vec4(previous.zw, xTexelC${n + 1}.xy);\n                     } else {\n                      xC${n + 1} = vec4(0.0, 0.0, xTexelC${n + 1}.xy);\n                     }\n                     ` : `\n                     xC${n + 1} = vec4(xTexelC${n}.zw, xTexelC${n + 1}.xy);\n                     `) : h += 1 === e ? `\n                     xC${n + 1} = xTexelC${n};\n                     ` : `\n                     xCOffset = xC + ${e};\n\n                     if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${n + 1}Ready == 0) {\n                       xTexelC${n + 1} = getX(batch, xR, xCOffset, d1);\n                       if (xCOffset + 1 >= inDims[1]) {\n                         xTexelC${n + 1}.zw = vec2(0.0);\n                       }\n                       xTexelC${n + 1}Ready = 1;\n                     }\n\n                     xC${n + 1} = xTexelC${n + 1};\n                     `
                    }
                } else
                    n < u && (a % 2 == 1 ? (h += `\n                 xCOffset = xC + 1 - strides[1];\n                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${n}Ready == 0) {\n                   xTexelC${n} = getX(batch, xR, xCOffset, d1);\n                   // Need to manually clear unused channels in case\n                   // we're reading from recycled texture.\n                   if (xCOffset + 1 >= inDims[1]) {\n                     xTexelC${n}.zw = vec2(0.0);\n                   }\n                   xTexelC${n}Ready = 1;\n                 }\n\n                 if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC${n + 1}Ready == 0) {\n                   xTexelC${n + 1} = getX(batch, xR, xC + 1, d1);\n                   // Need to manually clear unused channels in case\n                   // we're reading from recycled texture.\n                   if (xC + 2 >= inDims[1]) {\n                     xTexelC${n + 1}.zw = vec2(0.0);\n                   }\n                   xTexelC${n + 1}Ready = 1;\n                 }\n\n                 xC${n} = vec4(xTexelC${n}.zw, xTexelC${n + 1}.zw);\n               `,
                    n + 1 < u && (h += `\n                   final = vec4(0.0);\n                   xCOffset = xC + 1 + strides[1];\n                   if(xCOffset >= 0 && xCOffset < inDims[1]) {\n                     final = getX(batch, xR, xCOffset, d1);\n                   }\n                   xC${n + 1} = vec4(xTexelC${n + 1}.xy, final.xy);\n                 `)) : (h += `\n                 if(xC >= 0 && xC < inDims[1] && xTexelC${n}Ready == 0) {\n                   xTexelC${n} = getX(batch, xR, xC, d1);\n                   if (xC + 1 >= inDims[1]) {\n                     xTexelC${n}.zw = vec2(0.0);\n                   }\n                   xTexelC${n}Ready = 1;\n                 }\n\n                 xCOffset = xC + strides[1];\n                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${n + 1}Ready == 0) {\n                   xTexelC${n + 1} = getX(batch, xR, xCOffset, d1);\n                   if (xCOffset + 1 >= inDims[1]) {\n                     xTexelC${n + 1}.zw = vec2(0.);\n                   }\n                   xTexelC${n + 1}Ready = 1;\n                 }\n\n                 xC${n} = vec4(\n                   xTexelC${n}.xy, xTexelC${n + 1}.xy);\n               `,
                    n + 1 < u && (h += `\n                   xC${n + 1} = vec4(xTexelC${n}.zw, xTexelC${n + 1}.zw);\n                 `)));
                n < u && (h += `\n             wTexel = getW(r, ${n}, d1, d2);\n             dotProd += xC${n}.xxzz * vec4(wTexel.xy, wTexel.xy);\n             if(d1 + 1 < ${e.inChannels}) {\n               dotProd += xC${n}.yyww * vec4(wTexel.zw, wTexel.zw);\n             }\n           `,
                n + 1 < u && (h += `\n               wTexel = getW(r, ${n + 1}, d1, d2);\n               dotProd += xC${n + 1}.xxzz * vec4(wTexel.xy, wTexel.xy);\n               if(d1 + 1 < ${e.inChannels}) {\n                 dotProd += xC${n + 1}.yyww * vec4(wTexel.zw, wTexel.zw);\n               }\n             `))
            }
            h += "\n     }\n   ",
            h += "\n     }\n   ",
            h += "\n     }\n   ";
            let p = ""
              , d = "";
            n && (p = s ? `vec4 activation(vec4 a) {\n           vec4 b = getPreluActivationWeightsAtOutCoords();\n           ${n}\n         }` : r ? `vec4 activation(vec4 a) {\n           vec4 b = getLeakyreluAlphaAtOutCoords();\n           ${n}\n         }` : `vec4 activation(vec4 x) {\n           ${n}\n         }`,
            d = "result = activation(result);");
            const f = t ? "result += getBiasAtOutCoords();" : "";
            t && this.variableNames.push("bias"),
            s && this.variableNames.push("preluActivationWeights"),
            r && this.variableNames.push("leakyreluAlpha"),
            this.userCode = `\n       ${p}\n\n       void main() {\n         ivec4 coords = getOutputCoords();\n         int batch = coords.x;\n         ivec2 xRCCorner = coords.yz * strides - pads;\n         int d2 = coords.w;\n         int xRCorner = xRCCorner.x;\n         int xCCorner = xRCCorner.y;\n\n         //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\n         vec4 dotProd = vec4(0.000000000000001);\n\n         ${h}\n\n         vec4 result = dotProd - vec4(0.000000000000001);\n         ${f}\n         ${d}\n         setOutput(result);\n       }\n     `
        }
    }
    class aE {
        constructor(e, t) {
            this.variableNames = ["A"],
            this.packedInputs = !0,
            this.packedOutput = !0,
            this.customUniforms = [{
                name: "inputShape",
                type: "ivec4"
            }, {
                name: "pad",
                type: "ivec2"
            }, {
                name: "stride",
                type: "ivec2"
            }, {
                name: "dilation",
                type: "ivec2"
            }, {
                name: "inChannels",
                type: "int"
            }, {
                name: "itemsPerBlockRow",
                type: "int"
            }, {
                name: "outWidth",
                type: "int"
            }],
            this.outputShape = e,
            this.enableShapeUniforms = QN(this.outputShape.length);
            const {dataFormat: n} = t
              , s = KS()
              , r = "channelsLast" === n
              , a = r ? 1 : 2
              , i = r ? 2 : 3
              , o = this.enableShapeUniforms ? "if(blockIndex < outShape[2] && pos < outShape[1]) {" : `if(blockIndex < ${e[2]} && pos < ${e[1]}) {`;
            let l = "";
            for (let e = 0; e <= 1; e++)
                for (let t = 0; t <= 1; t++)
                    l += `\n          blockIndex = rc.z + ${t};\n          pos = rc.y + ${e};\n\n          ${o}\n            offsetY = int(blockIndex / outWidth) * stride[0] - pad[0];\n            d0 = offsetY + dilation[0] * (pos / itemsPerBlockRow);\n\n            if(d0 < inputShape[${a}] && d0 >= 0) {\n              // Use custom imod instead mod. On Intel GPU, mod may generate\n              // unexpected value.\n              // https://github.com/tensorflow/tfjs/issues/5447\n              offsetX = imod(blockIndex, outWidth) * stride[1] - pad[1];\n              d1 = offsetX + dilation[1] * (imod(pos, itemsPerBlockRow) /\n                  inChannels);\n\n              if(d1 < inputShape[${i}] && d1 >= 0) {\n\n                ch = imod(pos, inChannels);\n\n                if (${r}) {\n                  innerDims = vec2(d1, ch);\n                  result[${2 * e + t}] = getChannel(\n                    getA(rc.x, d0, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                } else {\n                  innerDims = vec2(d0, d1);\n                  result[${2 * e + t}] = getChannel(\n                    getA(rc.x, ch, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                }\n              }\n            }\n          }\n        `;
            this.userCode = `\n      void main() {\n        ivec3 rc = getOutputCoords();\n\n        vec4 result = vec4(0);\n\n        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;\n        vec2 innerDims;\n\n        ${l}\n\n        ${s.output} = result;\n      }\n    `
        }
    }
    function iE(e, t) {
        const n = e.length;
        return n >= 3 ? t ? [...e.slice(0, -3), e[n - 3] * e[n - 2], e[n - 1]] : [...e.slice(0, -3), e[n - 3], e[n - 2] * e[n - 1]] : !t && 1 === n && e[0] > 1 ? [e[0], 1] : null
    }
    function oE({x: e, filter: t, convInfo: n, backend: s, bias: r=null, preluActivationWeights: a=null, leakyreluAlpha: i=0, activation: o=null}) {
        const l = e.shape
          , u = s.texData.get(e.dataId)
          , c = n.inChannels
          , h = l[0] * l[1] * l[2]
          , p = n.outChannels
          , d = "channelsLast" === n.dataFormat;
        let f;
        const m = [];
        if (null != a) {
            const e = iE(a.shape, d);
            null != e && (a = IC({
                inputs: {
                    x: a
                },
                backend: s,
                attrs: {
                    shape: e
                }
            }),
            m.push(a))
        }
        if (null != r) {
            const e = iE(r.shape, d);
            null != e && (r = IC({
                inputs: {
                    x: r
                },
                backend: s,
                attrs: {
                    shape: e
                }
            }),
            m.push(r))
        }
        if (!((1 === h || 1 === p) && c > 1e3) && u.isPacked && d && null != u.texture && l[2] % 2 != 0 && Hs.arraysEqual(u.shape.slice(-3), l.slice(-3))) {
            const c = l[0] * l[1] * (l[2] + 1)
              , h = {
                dataId: e.dataId,
                shape: [1, c, n.inChannels],
                dtype: e.dtype
            }
              , p = u.shape;
            u.shape = u.shape.slice(),
            u.shape[u.shape.length - 2]++,
            Hs.assert(UN(u.shape, h.shape), (()=>`packed reshape ${u.shape} to ${h.shape} isn't free`));
            const d = IC({
                inputs: {
                    x: t
                },
                backend: s,
                attrs: {
                    shape: [1, n.inChannels, n.outChannels]
                }
            });
            m.push(d);
            const g = OC({
                a: h,
                b: d,
                backend: s,
                transposeA: false,
                transposeB: false,
                bias: r,
                activation: o,
                preluActivationWeights: a,
                leakyreluAlpha: i
            })
              , y = s.texData.get(g.dataId);
            Hs.assert(y.isPacked, (()=>"batchMatMul result is expected to be packed")),
            u.shape = p,
            y.shape = n.outShape,
            f = rT({
                inputs: {
                    x: g
                },
                backend: s
            }),
            f.shape = n.outShape,
            m.push(g)
        } else {
            const l = n.outHeight * n.outWidth
              , u = IC({
                inputs: {
                    x: e
                },
                backend: s,
                attrs: {
                    shape: d ? [n.batchSize, l, n.inChannels] : [n.batchSize, n.inChannels, l]
                }
            })
              , c = IC({
                inputs: {
                    x: t
                },
                backend: s,
                attrs: {
                    shape: [1, n.inChannels, n.outChannels]
                }
            })
              , h = OC({
                a: d ? u : c,
                b: d ? c : u,
                transposeA: !d,
                transposeB: false,
                backend: s,
                bias: r,
                activation: o,
                preluActivationWeights: a,
                leakyreluAlpha: i
            });
            f = IC({
                inputs: {
                    x: h
                },
                backend: s,
                attrs: {
                    shape: n.outShape
                }
            }),
            m.push(u),
            m.push(c),
            m.push(h)
        }
        for (const e of m)
            s.disposeIntermediateTensorInfo(e);
        return f
    }
    function lE({x: e, filter: t, convInfo: n, backend: s, bias: r=null, preluActivationWeights: a=null, leakyreluAlpha: i=0, activation: o=null}) {
        const {filterWidth: l, filterHeight: u, inChannels: c, outWidth: h, outHeight: p, dataFormat: d} = n
          , f = "channelsLast" === d
          , m = l * u * c
          , g = p * h
          , y = [n.batchSize, m, g]
          , b = [];
        if (null != a) {
            const e = iE(a.shape, f);
            null != e && (a = IC({
                inputs: {
                    x: a
                },
                backend: s,
                attrs: {
                    shape: e
                }
            }),
            b.push(a))
        }
        if (null != r) {
            const e = iE(r.shape, f);
            null != e && (r = IC({
                inputs: {
                    x: r
                },
                backend: s,
                attrs: {
                    shape: e
                }
            }),
            b.push(r))
        }
        const x = IC({
            inputs: {
                x: t
            },
            backend: s,
            attrs: {
                shape: [1, m, Hs.sizeFromShape(t.shape) / m]
            }
        });
        b.push(x);
        const w = new aE(y,n)
          , v = [e.shape, [n.padInfo.top, n.padInfo.left], [n.strideHeight, n.strideWidth], [n.dilationHeight, n.dilationWidth], [n.inChannels], [n.filterWidth * n.inChannels], [n.outWidth]]
          , k = s.runWebGLProgram(w, [e], "float32", v)
          , I = IC({
            inputs: {
                x: k
            },
            backend: s,
            attrs: {
                shape: y
            }
        });
        b.push(k),
        b.push(I);
        const S = null != r
          , N = null != a
          , T = "leakyrelu" === o
          , C = o ? wT(o, !0) : null
          , $ = new vT(f ? I.shape : x.shape,f ? x.shape : I.shape,f ? [n.batchSize, g, n.outChannels] : [n.batchSize, n.outChannels, g],!0,!1,S,C,N,T)
          , E = f ? [I, x] : [x, I];
        if (r && E.push(r),
        N && E.push(a),
        T) {
            const e = s.makeTensorInfo([], "float32", Hs.createScalarValue(i, "float32"));
            E.push(e),
            b.push(e)
        }
        const A = s.runWebGLProgram($, E, "float32")
          , R = IC({
            inputs: {
                x: A
            },
            backend: s,
            attrs: {
                shape: n.outShape
            }
        });
        b.push(A);
        for (const e of b)
            s.disposeIntermediateTensorInfo(e);
        return R
    }
    const uE = {
        kernelName: et,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, filter: a} = t
              , {strides: i, pad: o, dataFormat: l, dilations: u, dimRoundingMode: c} = s
              , h = dm.convertConv2DDataFormat(l)
              , p = dm.computeConv2DInfo(r.shape, a.shape, i, u, o, c, !1, h);
            let d;
            if (1 !== p.filterHeight || 1 !== p.filterWidth || 1 !== p.dilationHeight || 1 !== p.dilationWidth || 1 !== p.strideHeight || 1 !== p.strideWidth || "SAME" !== p.padInfo.type && "VALID" !== p.padInfo.type)
                if (p.strideWidth <= 2 && "channelsLast" === h && ie().getBool("WEBGL_EXP_CONV")) {
                    const e = new rE(p)
                      , t = [[p.padInfo.top, p.padInfo.left], [p.strideHeight, p.strideWidth], [p.dilationHeight, p.dilationWidth], [p.inHeight, p.inWidth]];
                    d = n.runWebGLProgram(e, [r, a], "float32", t)
                } else if (ie().getBool("WEBGL_CONV_IM2COL"))
                    d = lE({
                        x: r,
                        filter: a,
                        convInfo: p,
                        backend: n
                    });
                else {
                    const e = new nE(p);
                    d = n.runWebGLProgram(e, [r, a], "float32")
                }
            else
                d = oE({
                    x: r,
                    filter: a,
                    convInfo: p,
                    backend: n
                });
            const f = IC({
                inputs: {
                    x: d
                },
                backend: n,
                attrs: {
                    shape: p.outShape
                }
            });
            return n.disposeIntermediateTensorInfo(d),
            f
        }
    };
    class cE {
        constructor(e) {
            this.variableNames = ["x", "dy"],
            this.outputShape = e.filterShape;
            const t = e.strideHeight
              , n = e.strideWidth
              , s = e.padInfo.top
              , r = e.padInfo.left
              , a = "channelsLast" === e.dataFormat;
            this.userCode = `\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int d2 = coords.w;\n\n        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ${e.batchSize}; b++) {\n          for (int yR = 0; yR < ${e.outHeight}; yR++) {\n            int xR = wR + yR * ${t} - ${s};\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int yC = 0; yC < ${e.outWidth}; yC++) {\n              int xC = wC + yC * ${n} - ${r};\n\n              if (xC < 0 || xC >= ${e.inWidth}) {\n                continue;\n              }\n\n              if (${a}) {\n                float dyValue = getDy(b, yR, yC, d2);\n                float xValue = getX(b, xR, xC, d1);\n                dotProd += (xValue * dyValue);\n              } else {\n                float dyValue = getDy(b, d2, yR, yC);\n                float xValue = getX(b, d1, xR, xC);\n                dotProd += (xValue * dyValue);\n              }\n\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `
        }
    }
    class hE {
        constructor(e) {
            this.variableNames = ["dy", "W"],
            this.outputShape = e.inShape;
            const t = e.filterHeight
              , n = e.filterWidth
              , s = e.strideHeight
              , r = e.strideWidth
              , a = "channelsLast" === e.dataFormat
              , i = t - 1 - e.padInfo.top
              , o = n - 1 - e.padInfo.left
              , l = a ? 1 : 2
              , u = a ? 2 : 3
              , c = a ? 3 : 1;
            this.userCode = `\n      const ivec2 pads = ivec2(${i}, ${o});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[${c}];\n\n        ivec2 dyCorner = ivec2(coords[${l}], coords[${u}]) - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${t}; wR++) {\n          float dyR = float(dyRCorner + wR) / ${s}.0;\n\n          if (dyR < 0.0 || dyR >= ${e.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ${t} - 1 - wR;\n\n          for (int wC = 0; wC < ${n}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${r}.0;\n\n            if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ${n} - 1 - wC;\n\n            for (int d2 = 0; d2 < ${e.outChannels}; d2++) {\n\n              if (${a}) {\n                float xValue = getDy(batch, idyR, idyC, d2);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              } else {\n                float xValue = getDy(batch, d2, idyR, idyC);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `
        }
    }
    class pE {
        constructor(e) {
            this.variableNames = ["x", "dy"],
            this.outputShape = e.filterShape;
            const t = e.strideDepth
              , n = e.strideHeight
              , s = e.strideWidth
              , r = e.padInfo.front
              , a = e.padInfo.top
              , i = e.padInfo.left;
            this.userCode = `\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int wF = coords.x;\n        int wR = coords.y;\n        int wC = coords.z;\n        int d1 = coords.w;\n        int d2 = coords.u;\n\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ${e.batchSize}; b++) {\n          for (int yF = 0; yF < ${e.outDepth}; yF++) {\n            int xF = wF + yF * ${t} - ${r};\n\n            if (xF < 0 || xF >= ${e.inDepth}) {\n              continue;\n            }\n\n            for (int yR = 0; yR < ${e.outHeight}; yR++) {\n              int xR = wR + yR * ${n} - ${a};\n\n              if (xR < 0 || xR >= ${e.inHeight}) {\n                continue;\n              }\n\n              for (int yC = 0; yC < ${e.outWidth}; yC++) {\n                int xC = wC + yC * ${s} - ${i};\n\n                if (xC < 0 || xC >= ${e.inWidth}) {\n                  continue;\n                }\n\n                float dyValue = getDy(b, yF, yR, yC, d2);\n                float xValue = getX(b, xF, xR, xC, d1);\n                dotProd += (xValue * dyValue);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `
        }
    }
    class dE {
        constructor(e) {
            this.variableNames = ["dy", "W"],
            this.outputShape = e.inShape;
            const t = e.filterDepth
              , n = e.filterHeight
              , s = e.filterWidth
              , r = e.strideDepth
              , a = e.strideHeight
              , i = e.strideWidth
              , o = t - 1 - e.padInfo.front
              , l = n - 1 - e.padInfo.top
              , u = s - 1 - e.padInfo.left;
            this.userCode = `\n      const ivec3 pads = ivec3(${o}, ${l}, ${u});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.u;\n\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyFCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ${t}; wF++) {\n          float dyF = float(dyFCorner + wF) / ${r}.0;\n\n          if (dyF < 0.0 || dyF >= ${e.outDepth}.0 || fract(dyF) > 0.0) {\n            continue;\n          }\n          int idyF = int(dyF);\n\n          int wFPerm = ${t} - 1 - wF;\n\n          for (int wR = 0; wR < ${n}; wR++) {\n            float dyR = float(dyRCorner + wR) / ${a}.0;\n\n            if (dyR < 0.0 || dyR >= ${e.outHeight}.0 ||\n              fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            int wRPerm = ${n} - 1 - wR;\n\n            for (int wC = 0; wC < ${s}; wC++) {\n              float dyC = float(dyCCorner + wC) / ${i}.0;\n\n              if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              int wCPerm = ${s} - 1 - wC;\n\n              for (int d2 = 0; d2 < ${e.outChannels}; d2++) {\n                float xValue = getDy(batch, idyF, idyR, idyC, d2);\n                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `
        }
    }
    const fE = {
        kernelName: tt,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, dy: a} = t
              , {strides: i, pad: o, dataFormat: l, dimRoundingMode: u, filterShape: c} = s
              , h = dm.convertConv2DDataFormat(l)
              , p = dm.computeConv2DInfo(r.shape, c, i, 1, o, u, !1, h)
              , d = new cE(p);
            return n.runWebGLProgram(d, [r, a], "float32")
        }
    };
    const mE = {
        kernelName: nt,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {dy: r, filter: a} = t
              , {inputShape: i, strides: o, pad: l, dataFormat: u, dimRoundingMode: c} = s
              , h = dm.convertConv2DDataFormat(u)
              , p = dm.computeConv2DInfo(i, a.shape, o, 1, l, c, !1, h)
              , d = new hE(p);
            return n.runWebGLProgram(d, [r, a], "float32")
        }
    };
    const gE = {
        kernelName: st,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, filter: a} = t
              , {strides: i, pad: o, dilations: l} = s
              , u = dm.computeConv3DInfo(r.shape, a.shape, i, l, o)
              , c = new sE(u);
            return n.runWebGLProgram(c, [r, a], "float32")
        }
    };
    const yE = {
        kernelName: rt,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, dy: a} = t
              , {strides: i, pad: o, filterShape: l} = s
              , u = dm.computeConv3DInfo(r.shape, l, i, 1, o)
              , c = new pE(u);
            return n.runWebGLProgram(c, [r, a], "float32")
        }
    };
    const bE = {
        kernelName: at,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {dy: r, filter: a} = t
              , {pad: i, strides: o, inputShape: l} = s
              , u = dm.computeConv3DInfo(l, a.shape, o, 1, i)
              , c = new dE(u);
            return n.runWebGLProgram(c, [r, a], "float32")
        }
    }
      , xE = bT({
        opSnippet: "if (isnan(x)) return x;\n  return cos(x);\n"
    })
      , wE = {
        kernelName: it,
        backendName: "webgl",
        kernelFunc: xE
    }
      , vE = bT({
        opSnippet: "\n  float e2x = exp(-x);\n  return (e2x + 1.0 / e2x) / 2.0;\n"
    })
      , kE = {
        kernelName: ot,
        backendName: "webgl",
        kernelFunc: vE
    };
    class IE {
        constructor(e, t, n, s, r) {
            this.variableNames = ["Image", "Boxes", "BoxInd"],
            this.outputShape = [];
            const [a,i,o,l] = e
              , [u] = t
              , [c,h] = n;
            this.outputShape = [u, c, h, l];
            const p = "bilinear" === s ? 1 : 0
              , [d,f] = [i - 1 + ".0", o - 1 + ".0"]
              , [m,g,y] = c > 1 ? ["" + (i - 1) / (c - 1), "(y2-y1) * height_ratio", `y1*${d} + float(y)*(height_scale)`] : ["0.0", "0.0", `0.5 * (y1+y2) * ${d}`]
              , [b,x,w] = h > 1 ? ["" + (o - 1) / (h - 1), "(x2-x1) * width_ratio", `x1*${f} + float(x)*(width_scale)`] : ["0.0", "0.0", `0.5 * (x1+x2) * ${f}`];
            this.userCode = `\n      const float height_ratio = float(${m});\n      const float width_ratio = float(${b});\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int y = coords[1];\n        int x = coords[2];\n        int d = coords[3];\n\n        // get box vals\n        float y1 = getBoxes(b,0);\n        float x1 = getBoxes(b,1);\n        float y2 = getBoxes(b,2);\n        float x2 = getBoxes(b,3);\n\n        // get image in batch index\n        int bInd = round(getBoxInd(b));\n        if(bInd < 0 || bInd >= ${a}) {\n          return;\n        }\n\n        float height_scale = ${g};\n        float width_scale = ${x};\n\n        float in_y = ${y};\n        if( in_y < 0.0 || in_y > ${d} ) {\n          setOutput(float(${r}));\n          return;\n        }\n        float in_x = ${w};\n        if( in_x < 0.0 || in_x > ${f} ) {\n          setOutput(float(${r}));\n          return;\n        }\n\n        vec2 sourceFracIndexCR = vec2(in_x,in_y);\n        if(${p} == 1) {\n          // Compute the four integer indices.\n          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);\n          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));\n\n          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);\n          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);\n          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);\n          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);\n\n          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);\n\n          float top = topLeft + (topRight - topLeft) * fracCR.x;\n          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;\n          float newValue = top + (bottom - top) * fracCR.y;\n          setOutput(newValue);\n        } else {\n          // Compute the coordinators of nearest neighbor point.\n          ivec2 sourceNearestCR = ivec2(floor(\n            sourceFracIndexCR + vec2(0.5,0.5)));\n          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);\n          setOutput(newValue);\n        }\n      }\n    `
        }
    }
    const SE = {
        kernelName: ct,
        backendName: "webgl",
        kernelFunc: e=>{
            const {inputs: t, backend: n, attrs: s} = e
              , {image: r, boxes: a, boxInd: i} = t
              , {cropSize: o, method: l, extrapolationValue: u} = s
              , c = new IE(r.shape,a.shape,o,l,u);
            return n.runWebGLProgram(c, [r, a, i], "float32")
        }
    };
    var NE;
    !function(e) {
        e.Prod = "*",
        e.Sum = "+"
    }(NE || (NE = {}));
    class TE {
        constructor(e, t, n, s) {
            this.op = e,
            this.outputShape = t,
            this.variableNames = ["x"],
            this.customUniforms = [{
                name: "index",
                type: "float"
            }];
            const r = this.outputShape.length
              , a = this.op === NE.Prod ? "1.0" : "0.0"
              , i = n ? a : `getX(${CE(r, "coords", this.op)})`
              , o = this.outputShape[this.outputShape.length - 1];
            let l = ""
              , u = "";
            n ? (l = s ? "end != " + (o - 1) : "end != 0",
            u = s ? "end + 1" : "end - 1") : (l = s ? `end + pow2 < ${o}` : "end >= pow2",
            u = s ? "end + pow2" : "end - pow2"),
            this.userCode = `\n      void main() {\n        ${hN(r)} coords = getOutputCoords();\n        int end = ${$E(r, "coords", this.op)};\n        float val = ${i};\n        int pow2 = int(pow(2.0, index));\n        if (${l}) {\n          int idx = ${u};\n          ${$E(r, "coords", this.op)} = idx;\n          val ${this.op}= getX(${CE(r, "coords", this.op)});\n        }\n        setOutput(val);\n      }\n    `
        }
    }
    function CE(e, t, n) {
        if (1 === e)
            return `${t}`;
        if (2 === e)
            return `${t}.x, ${t}.y`;
        if (3 === e)
            return `${t}.x, ${t}.y, ${t}.z`;
        if (4 === e)
            return `${t}.x, ${t}.y, ${t}.z, ${t}.w`;
        throw new Error(`Cumulative ${n} for rank ${e} is not yet supported`)
    }
    function $E(e, t, n) {
        if (1 === e)
            return `${t}`;
        if (2 === e)
            return `${t}.y`;
        if (3 === e)
            return `${t}.z`;
        if (4 === e)
            return `${t}.w`;
        throw new Error(`Cumulative ${n} for rank ${e} is not yet supported`)
    }
    function EE(e, t, n, s, r, a) {
        const i = t.shape.length
          , o = dm.getAxesPermutation([s], i);
        let l = t;
        null != o && (l = DC({
            inputs: {
                x: t
            },
            backend: n,
            attrs: {
                perm: o
            }
        }));
        const u = dm.getInnerMostAxes(1, i)[0];
        if (u !== i - 1)
            throw new Error(`WebGL cumprod shader expects an inner-most axis=${t.shape.length - 1} but got axis=${s}`);
        const c = l.shape[u];
        let h = rT({
            inputs: {
                x: l
            },
            backend: n
        });
        for (let t = 0; t <= Math.ceil(Math.log2(c)) - 1; t++) {
            const s = new TE(e,l.shape,!1,a)
              , r = [[t]]
              , i = h;
            h = n.runWebGLProgram(s, [h], h.dtype, r),
            n.disposeIntermediateTensorInfo(i)
        }
        if (r) {
            const t = new TE(e,l.shape,r,a)
              , s = h;
            h = n.runWebGLProgram(t, [h], h.dtype),
            n.disposeIntermediateTensorInfo(s)
        }
        if (null != o) {
            const e = DC({
                inputs: {
                    x: h
                },
                backend: n,
                attrs: {
                    perm: dm.getUndoAxesPermutation(o)
                }
            });
            return n.disposeIntermediateTensorInfo(h),
            n.disposeIntermediateTensorInfo(l),
            e
        }
        return h
    }
    const AE = {
        kernelName: lt,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {axis: a, exclusive: i, reverse: o} = s;
            return EE(NE.Prod, r, n, a, i, o)
        }
    };
    const RE = {
        kernelName: ut,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {axis: a, exclusive: i, reverse: o} = s;
            return EE(NE.Sum, r, n, a, i, o)
        }
    };
    const FE = {
        kernelName: ht,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, weights: a} = t
              , {size: i, binaryOutput: o} = s;
            if (1 === r.shape.length) {
                const e = n.readSync(r.dataId)
                  , t = n.readSync(a.dataId)
                  , s = CT(e, t, a.dtype, a.shape, i);
                return n.makeTensorInfo([i], a.dtype, s)
            }
            if (2 === r.shape.length) {
                const e = n.bufferSync(r)
                  , t = n.bufferSync(a)
                  , s = $T(e, t, i, o);
                return n.makeTensorInfo(s.shape, a.dtype, s.values)
            }
            throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${r.shape.length}.`)
        }
    };
    class DE {
        constructor(e, t, n) {
            this.variableNames = ["x"],
            this.outputShape = [],
            this.outputShape = e,
            this.blockSize = t,
            this.dataFormat = n,
            this.userCode = `\n    void main() {\n      ivec4 coords = getOutputCoords();\n      int b = coords[0];\n      int h = ${this.getHeightCoordString()};\n      int w = ${this.getWidthCoordString()};\n      int d = ${this.getDepthCoordString()};\n\n      int in_h = h / ${t};\n      int offset_h = imod(h, ${t});\n      int in_w = w / ${t};\n      int offset_w = imod(w, ${t});\n      int offset_d = (offset_h * ${t} + offset_w) *\n        ${this.getOutputDepthSize()};\n      int in_d = d + offset_d;\n\n      float result = ${this.getInputSamplingString()};\n      setOutput(result);\n    }\n  `
        }
        getHeightCoordString() {
            return "NHWC" === this.dataFormat ? "coords[1]" : "coords[2]"
        }
        getWidthCoordString() {
            return "NHWC" === this.dataFormat ? "coords[2]" : "coords[3]"
        }
        getDepthCoordString() {
            return "NHWC" === this.dataFormat ? "coords[3]" : "coords[1]"
        }
        getOutputDepthSize() {
            return "NHWC" === this.dataFormat ? this.outputShape[3] : this.outputShape[1]
        }
        getInputSamplingString() {
            return "NHWC" === this.dataFormat ? "getX(b, in_h, in_w, in_d)" : "getX(b, in_d, in_h, in_w)"
        }
    }
    const _E = {
        kernelName: pt,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {blockSize: a, dataFormat: i} = s
              , o = r.shape[0]
              , l = ("NHWC" === i ? r.shape[1] : r.shape[2]) * a
              , u = ("NHWC" === i ? r.shape[2] : r.shape[3]) * a
              , c = ("NHWC" === i ? r.shape[3] : r.shape[1]) / (a * a)
              , h = new DE("NHWC" === i ? [o, l, u, c] : [o, c, l, u],a,i);
            return n.runWebGLProgram(h, [r], r.dtype)
        }
    };
    class OE {
        constructor(e, t=!1, n=null, s=!1, r=!1) {
            this.variableNames = ["x", "W"],
            this.customUniforms = [{
                name: "pads",
                type: "ivec2"
            }, {
                name: "strides",
                type: "ivec2"
            }, {
                name: "dilations",
                type: "ivec2"
            }, {
                name: "inDims",
                type: "ivec2"
            }],
            this.outputShape = e.outShape,
            this.enableShapeUniforms = QN(this.outputShape.length);
            const a = e.filterHeight
              , i = e.filterWidth
              , o = e.outChannels / e.inChannels;
            let l = ""
              , u = "";
            n && (l = s ? `float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ${n}\n        }` : r ? `float activation(float a) {\n          float b = getLeakyreluAlphaAtOutCoords();\n          ${n}\n        }` : `\n          float activation(float x) {\n            ${n}\n          }\n        `,
            u = "result = activation(result);");
            const c = t ? "result += getBiasAtOutCoords();" : "";
            t && this.variableNames.push("bias"),
            s && this.variableNames.push("preluActivationWeights"),
            r && this.variableNames.push("leakyreluAlpha"),
            this.userCode = `\n      ${l}\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ${o};\n        int q = d2 - d1 * ${o};\n\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.\n        for (int wR = 0; wR < ${a}; wR++) {\n          int xR = xRCorner + wR * dilations[0];\n\n          if (xR < 0 || xR >= inDims[0]) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${i}; wC++) {\n            int xC = xCCorner + wC * dilations[1];\n\n            if (xC < 0 || xC >= inDims[1]) {\n              continue;\n            }\n\n            float xVal = getX(batch, xR, xC, d1);\n            float wVal = getW(wR, wC, d1, q);\n            dotProd += xVal * wVal;\n          }\n        }\n\n        float result = dotProd;\n        ${c}\n        ${u}\n        setOutput(result);\n      }\n    `
        }
    }
    class ME {
        constructor(e, t=!1, n=null, s=!1, r=!1) {
            this.variableNames = ["x", "W"],
            this.packedInputs = !0,
            this.packedOutput = !0,
            this.customUniforms = [{
                name: "pads",
                type: "ivec2"
            }, {
                name: "strides",
                type: "ivec2"
            }, {
                name: "dilations",
                type: "ivec2"
            }, {
                name: "inDims",
                type: "ivec2"
            }],
            this.outputShape = e.outShape,
            this.enableShapeUniforms = QN(this.outputShape.length);
            const a = e.outChannels / e.inChannels
              , i = e.padInfo.left
              , o = e.strideWidth
              , l = e.dilationWidth
              , u = e.filterHeight
              , c = e.filterWidth
              , h = c;
            let p = "\n      int xR; int xC; int xCOffset;\n      vec4 wTexel; vec4 previous; vec4 final;";
            for (let e = 0; e < c; e++)
                p += `\n          vec4 xTexelC${2 * e};\n          int xTexelC${2 * e}Ready;\n          vec4 xTexelC${2 * e + 1};\n          int xTexelC${2 * e + 1}Ready;\n          vec4 xC${e};`;
            p += `\n    for (int r = 0; r < ${u}; r++) {\n      `;
            for (let e = 0; e < c; e++)
                p += `\n          xTexelC${2 * e} = vec4(0.0);\n          xTexelC${2 * e}Ready = 0;\n          xTexelC${2 * e + 1} = vec4(0.0);\n          xTexelC${2 * e + 1}Ready = 0;\n          xC${e} = vec4(0.0);`;
            p += "\n        xR = xRCorner + r * dilations[0];\n        if (xR >=0 && xR < inDims[0]) {\n      ";
            for (let e = 0; e < (h + 1) / 2; e++) {
                const t = 2 * e;
                if (p += `\n          xC = xCCorner + ${t * l};\n          `,
                1 === o) {
                    if (t < c && (i % 2 == 1 ? (p += `\n                xCOffset = xC + 1;\n                if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${t}Ready == 0) {\n                  xTexelC${t} = getX(batch, xR, xCOffset, d1);\n\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= inDims[1]) {\n                    xTexelC${t}.zw = vec2(0.0);\n                  }\n                  xTexelC${t}Ready = 1;\n                }\n              `,
                    p += 1 === l && t > 0 ? `\n                xC${t} = vec4(xTexelC${t - 2}.zw, xTexelC${t}.xy);\n                ` : `\n                  xCOffset = xC + 1 - 2;\n\n                  if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                    previous = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= inDims[1]) {\n                      previous.zw = vec2(0.0);\n                    }\n\n                    xC${t} = vec4(previous.zw, xTexelC${t}.xy);\n                  } else {\n                    xC${t} = vec4(0.0, 0.0, xTexelC${t}.xy);\n                  }\n                  `) : p += `\n                if (xC >= 0 && xC < inDims[1] && xTexelC${t}Ready == 0) {\n                  xTexelC${t} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= inDims[1]) {\n                    xTexelC${t}.zw = vec2(0.0);\n                  }\n                  xTexelC${t}Ready = 1;\n                }\n\n                xC${t} = xTexelC${t};\n                `,
                    t + 1 < c)) {
                        const e = i % 2 == 0 ? Hs.nearestLargerEven(l) : l;
                        l % 2 == 0 && i % 2 == 1 || l % 2 != 0 && i % 2 != 1 ? (p += `\n                  xCOffset = xC + imod(pads[1], 2) + ${e};\n\n                  if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${t + 1}Ready == 0) {\n                    xTexelC${t + 1} = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= inDims[1]) {\n                      xTexelC${t + 1}.zw = vec2(0.0);\n                    }\n                    xTexelC${t + 1}Ready = 1;\n                  }\n                  `,
                        p += l > 1 ? `\n                    xCOffset -= 2;\n                    if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                     previous = getX(batch, xR, xCOffset, d1);\n                     xC${t + 1} = vec4(previous.zw, xTexelC${t + 1}.xy);\n                    } else {\n                     xC${t + 1} = vec4(0.0, 0.0, xTexelC${t + 1}.xy);\n                    }\n                    ` : `\n                    xC${t + 1} = vec4(xTexelC${t}.zw, xTexelC${t + 1}.xy);\n                    `) : p += 1 === e ? `\n                    xC${t + 1} = xTexelC${t};\n                    ` : `\n                    xCOffset = xC + ${e};\n\n                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${t + 1}Ready == 0) {\n                      xTexelC${t + 1} = getX(batch, xR, xCOffset, d1);\n                      if (xCOffset + 1 >= inDims[1]) {\n                        xTexelC${t + 1}.zw = vec2(0.0);\n                      }\n                      xTexelC${t + 1}Ready = 1;\n                    }\n\n                    xC${t + 1} = xTexelC${t + 1};\n                    `
                    }
                } else
                    t < c && (i % 2 == 1 ? (p += `\n                xCOffset = xC + 1 - strides[1];\n                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${t}Ready == 0) {\n                  xTexelC${t} = getX(batch, xR, xCOffset, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= inDims[1]) {\n                    xTexelC${t}.zw = vec2(0.0);\n                  }\n                  xTexelC${t}Ready = 1;\n                }\n\n                if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC${t + 1}Ready == 0) {\n                  xTexelC${t + 1} = getX(batch, xR, xC + 1, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xC + 2 >= inDims[1]) {\n                    xTexelC${t + 1}.zw = vec2(0.0);\n                  }\n                  xTexelC${t + 1}Ready = 1;\n                }\n\n                xC${t} = vec4(xTexelC${t}.zw, xTexelC${t + 1}.zw);\n              `,
                    t + 1 < c && (p += `\n                  final = vec4(0.0);\n                  xCOffset = xC + 1 + strides[1];\n                  if(xCOffset >= 0 && xCOffset < inDims[1]) {\n                    final = getX(batch, xR, xCOffset, d1);\n                  }\n                  xC${t + 1} = vec4(xTexelC${t + 1}.xy, final.xy);\n                `)) : (p += `\n                if(xC >= 0 && xC < inDims[1] && xTexelC${t}Ready == 0) {\n                  xTexelC${t} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= inDims[1]) {\n                    xTexelC${t}.zw = vec2(0.0);\n                  }\n                  xTexelC${t}Ready = 1;\n                }\n\n                xCOffset = xC + strides[1];\n                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${t + 1}Ready == 0) {\n                  xTexelC${t + 1} = getX(batch, xR, xCOffset, d1);\n                  if (xCOffset + 1 >= inDims[1]) {\n                    xTexelC${t + 1}.zw = vec2(0.);\n                  }\n                  xTexelC${t + 1}Ready = 1;\n                }\n\n                xC${t} = vec4(\n                  xTexelC${t}.xy, xTexelC${t + 1}.xy);\n              `,
                    t + 1 < c && (p += `\n                  xC${t + 1} = vec4(xTexelC${t}.zw, xTexelC${t + 1}.zw);\n                `)));
                t < c && (p += `\n            wTexel = getW(r, ${t}, d1, q);\n            dotProd += xC${t} * vec4(wTexel.xz, wTexel.xz);\n          `,
                t + 1 < c && (p += `\n              wTexel = getW(r, ${t + 1}, d1, q);\n              dotProd += xC${t + 1} * vec4(wTexel.xz, wTexel.xz);\n            `))
            }
            p += "\n    }\n  ",
            p += "\n      }\n    ";
            let d = ""
              , f = "";
            n && (d = s ? `vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${n}\n        }` : r ? `vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ${n}\n        }` : `vec4 activation(vec4 x) {\n          ${n}\n        }`,
            f = "result = activation(result);");
            const m = t ? "result += getBiasAtOutCoords();" : "";
            t && this.variableNames.push("bias"),
            s && this.variableNames.push("preluActivationWeights"),
            r && this.variableNames.push("leakyreluAlpha"),
            this.userCode = `\n      ${d}\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ${a};\n        int q = d2 - d1 * ${a};\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\n        vec4 dotProd = vec4(0.000000000000001);\n\n        ${p}\n\n        vec4 result = dotProd - vec4(0.000000000000001);\n        ${m}\n        ${f}\n        setOutput(result);\n      }\n    `
        }
    }
    const LE = {
        kernelName: dt,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, filter: a} = t
              , {strides: i, pad: o, dilations: l, dimRoundingMode: u} = s;
            let c = l;
            null == c && (c = [1, 1]),
            Hs.assert(dm.eitherStridesOrDilationsAreOne(i, c), (()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${i} and dilations '${c}'`));
            const h = dm.computeConv2DInfo(r.shape, a.shape, i, c, o, u, !0);
            let p;
            p = ie().getBool("WEBGL_PACK_DEPTHWISECONV") && h.strideWidth <= 2 && h.outChannels / h.inChannels == 1 ? new ME(h) : new OE(h);
            const d = [[h.padInfo.top, h.padInfo.left], [h.strideHeight, h.strideWidth], [h.dilationHeight, h.dilationWidth], [h.inHeight, h.inWidth]];
            return n.runWebGLProgram(p, [r, a], "float32", d)
        }
    };
    class zE {
        constructor(e) {
            this.variableNames = ["x", "dy"],
            this.outputShape = e.filterShape;
            const t = e.strideHeight
              , n = e.strideWidth
              , s = e.padInfo.top
              , r = e.padInfo.left
              , a = e.outChannels / e.inChannels;
            this.userCode = `\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int dm = coords.w;\n        int d2 = d1 * ${a} + dm;\n\n        float dotProd = 0.0;\n\n        // TO DO: Vec4 over the batch size\n        for (int b = 0; b < ${e.batchSize}; b++) {\n          for (int yR = 0; yR < ${e.outHeight}; yR++) {\n            int xR = wR + yR * ${t} - ${s};\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int yC = 0; yC < ${e.outWidth}; yC++) {\n              int xC = wC + yC * ${n} - ${r};\n\n              if (xC < 0 || xC >= ${e.inWidth}) {\n                continue;\n              }\n\n              float dyValue = getDy(b, yR, yC, d2);\n              float xValue = getX(b, xR, xC, d1);\n              dotProd += (xValue * dyValue);\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `
        }
    }
    class BE {
        constructor(e) {
            this.variableNames = ["dy", "W"],
            this.outputShape = e.inShape;
            const t = e.filterHeight
              , n = e.filterWidth
              , s = e.strideHeight
              , r = e.strideWidth
              , a = t - 1 - e.padInfo.top
              , i = n - 1 - e.padInfo.left
              , o = e.outChannels / e.inChannels;
            this.userCode = `\n      const ivec2 pads = ivec2(${a}, ${i});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[3];\n        ivec2 dyCorner = coords.yz - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        float dotProd = 0.0;\n\n        for (int wR = 0; wR < ${t}; wR++) {\n          float dyR = float(dyRCorner + wR) / ${s}.0;\n\n          if (dyR < 0.0 || dyR >= ${e.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ${t} - 1 - wR;\n\n          for (int wC = 0; wC < ${n}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${r}.0;\n\n            if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ${n} - 1 - wC;\n\n            // TO DO: Vec4 over the channelMul\n            for (int dm = 0; dm < ${o}; dm++) {\n              int d2 = d1 * ${o} + dm;\n              float xValue = getDy(batch, idyR, idyC, d2);\n              float wValue = getW(wRPerm, wCPerm, d1, dm);\n              dotProd += xValue * wValue;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `
        }
    }
    const PE = {
        kernelName: ft,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, dy: a} = t
              , {strides: i, dilations: o, pad: l, dimRoundingMode: u, filterShape: c} = s
              , h = dm.computeConv2DInfo(r.shape, c, i, o, l, u, !0)
              , p = new zE(h);
            return n.runWebGLProgram(p, [r, a], "float32")
        }
    };
    const WE = {
        kernelName: mt,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {dy: r, filter: a} = t
              , {strides: i, dilations: o, pad: l, dimRoundingMode: u, inputShape: c} = s
              , h = dm.computeConv2DInfo(c, a.shape, i, o, l, u, !0)
              , p = new BE(h);
            return n.runWebGLProgram(p, [r, a], "float32")
        }
    };
    class UE {
        constructor(e) {
            this.variableNames = ["X"],
            this.outputShape = [e, e],
            this.userCode = "\n      void main() {\n          ivec2 coords = getOutputCoords();\n          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;\n          setOutput(val);\n      }\n    "
        }
    }
    const VE = {
        kernelName: gt,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {x: s} = t
              , r = [...s.shape, ...s.shape]
              , a = Hs.sizeFromShape(s.shape)
              , i = IC({
                inputs: {
                    x: s
                },
                backend: n,
                attrs: {
                    shape: [a]
                }
            })
              , o = new UE(a)
              , l = n.runWebGLProgram(o, [i], i.dtype)
              , u = IC({
                inputs: {
                    x: l
                },
                backend: n,
                attrs: {
                    shape: r
                }
            });
            return n.disposeIntermediateTensorInfo(i),
            n.disposeIntermediateTensorInfo(l),
            u
        }
    };
    class GE {
        constructor(e) {
            this.variableNames = ["x", "W"],
            this.outputShape = e.outShape;
            const {inHeight: t, inWidth: n, padInfo: s, strideHeight: r, strideWidth: a, filterHeight: i, filterWidth: o, dilationHeight: l, dilationWidth: u} = e
              , {top: c, left: h} = s;
            this.userCode = `\n      const ivec2 strides = ivec2(${r}, ${a});\n      const ivec2 pads = ivec2(${c}, ${h});\n      const float neg_infinity = -3.4e38;\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.w;\n        ivec2 outTopLeftCorner =\n            coords.yz * strides - pads;\n        int hBeg = outTopLeftCorner.x;\n        int wBeg = outTopLeftCorner.y;\n\n        float curVal = neg_infinity;\n        for (int h = 0; h < ${i}; h++) {\n          int hIn = hBeg + h * ${l};\n\n          if (hIn >= 0 && hIn < ${t}) {\n            for (int w = 0; w < ${o}; w++) {\n              int wIn = wBeg + w * ${u};\n\n              if (wIn >= 0 && wIn < ${n}) {\n                float xVal = getX(batch, hIn, wIn, d1);\n                float wVal = getW(h, w, d1);\n\n                float val = xVal + wVal;\n                if (val > curVal) {\n                  curVal = val;\n                }\n              }\n            }\n          }\n        }\n\n        float result = curVal;\n        setOutput(result);\n      }\n    `
        }
    }
    const HE = {
        kernelName: yt,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, filter: a} = t
              , {strides: i, pad: o, dilations: l} = s
              , u = dm.computeDilation2DInfo(r.shape, a.shape, i, o, "NHWC", l);
            let c;
            const h = new GE(u);
            c = n.runWebGLProgram(h, [r, a], "float32");
            const p = IC({
                inputs: {
                    x: c
                },
                backend: n,
                attrs: {
                    shape: u.outShape
                }
            });
            return n.disposeIntermediateTensorInfo(c),
            p
        }
    };
    const jE = {
        kernelName: vt,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {equation: r} = s
              , a = t
              , {allDims: i, summedDims: o, idDims: l} = dm.decodeEinsumEquation(r, a.length);
            dm.checkEinsumDimSizes(i.length, l, a);
            const {path: u, steps: c} = dm.getEinsumComputePath(o, l)
              , h = c.length;
            let p = null
              , d = i.length;
            const f = [];
            for (let e = 0; e < h; ++e) {
                for (const t of c[e]) {
                    const {permutationIndices: e, expandDims: s} = dm.getEinsumPermutation(d, l[t]);
                    let r;
                    dm.isIdentityPermutation(e) ? r = a[t] : (r = DC({
                        inputs: {
                            x: a[t]
                        },
                        backend: n,
                        attrs: {
                            perm: e
                        }
                    }),
                    f.push(r));
                    const i = r.shape.slice();
                    for (let e = 0; e < s.length; ++e)
                        i.splice(s[e], 0, 1);
                    Hs.arraysEqual(r.shape, i) || (r = IC({
                        inputs: {
                            x: r
                        },
                        backend: n,
                        attrs: {
                            shape: i
                        }
                    }),
                    f.push(r)),
                    null === p ? p = r : (p = wC({
                        inputs: {
                            a: r,
                            b: p
                        },
                        backend: n
                    }),
                    f.push(p))
                }
                e < h - 1 && (u[e] >= 0 && (p = RC({
                    inputs: {
                        x: p
                    },
                    backend: n,
                    attrs: {
                        axis: u[e] - (i.length - d),
                        keepDims: !1
                    }
                }),
                f.push(p)),
                d--)
            }
            for (const e of f)
                e !== p && n.disposeIntermediateTensorInfo(e);
            return p
        }
    }
      , qE = bT({
        opSnippet: "return (x >= 0.0) ? x : (exp(x) - 1.0);",
        packedOpSnippet: "\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n"
    })
      , KE = {
        kernelName: kt,
        backendName: "webgl",
        kernelFunc: qE
    }
      , XE = {
        kernelName: It,
        backendName: "webgl",
        kernelFunc: e=>{
            const {inputs: t, backend: n} = e
              , {dy: s, y: r} = t
              , a = ie().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new sT("\n  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));\n  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));\n",s.shape,r.shape) : new eT("return (b >= 1.0) ? a : a * (b + 1.0);",s.shape,r.shape);
            return n.runWebGLProgram(a, [s, r], s.dtype)
        }
    }
      , YE = xT({
        opSnippet: "return float(a == b);",
        packedOpSnippet: "\n  return vec4(equal(a, b));\n",
        dtype: "bool",
        cpuKernelImpl: FT
    })
      , ZE = {
        kernelName: Nt,
        backendName: "webgl",
        kernelFunc: YE
    }
      , JE = bT({
        opSnippet: `\n  // Error function is calculated approximately with elementary function.\n  // See "Handbook of Mathematical Functions with Formulas,\n  // Graphs, and Mathematical Tables", Abramowitz and Stegun.\n  float p = ${dm.ERF_P};\n  float a1 = ${dm.ERF_A1};\n  float a2 = ${dm.ERF_A2};\n  float a3 = ${dm.ERF_A3};\n  float a4 = ${dm.ERF_A4};\n  float a5 = ${dm.ERF_A5};\n\n  float sign = sign(x);\n  x = abs(x);\n  float t = 1.0 / (1.0 + p * x);\n  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));\n`
    })
      , QE = {
        kernelName: St,
        backendName: "webgl",
        kernelFunc: JE
    }
      , eA = bT({
        opSnippet: "if (isnan(x)) return x;\n  return exp(x);\n",
        packedOpSnippet: "\n  vec4 result = exp(x);\n  bvec4 isNaN = isnan(x);\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",
        cpuKernelImpl: DT,
        dtype: "float32"
    })
      , tA = {
        kernelName: Tt,
        backendName: "webgl",
        kernelFunc: eA
    };
    function nA(e) {
        const {inputs: t, attrs: n, backend: s} = e
          , {dim: r} = n
          , {input: a} = t
          , i = a.shape.length
          , o = a.shape.slice();
        let l = r;
        return r < 0 && (Hs.assert(-(i + 1) <= r, (()=>`Axis must be in the interval [${-(i + 1)}, ${i}]`)),
        l = i + r + 1),
        o.splice(l, 0, 1),
        IC({
            inputs: {
                x: a
            },
            backend: s,
            attrs: {
                shape: o
            }
        })
    }
    const sA = {
        kernelName: Ct,
        backendName: "webgl",
        kernelFunc: nA
    }
      , rA = "return exp(x) - 1.0;"
      , aA = bT({
        opSnippet: rA,
        packedOpSnippet: rA,
        cpuKernelImpl: _T
    })
      , iA = {
        kernelName: $t,
        backendName: "webgl",
        kernelFunc: aA
    };
    class oA {
        constructor(e, t, n) {
            this.variableNames = ["real", "imag"];
            const s = t[1];
            this.outputShape = t;
            const r = n ? `2.0 * ${Math.PI}` : `-2.0 * ${Math.PI}`
              , a = n ? `${s}.0` : "1.0";
            let i;
            if ("real" === e)
                i = "return real * expR - imag * expI;";
            else {
                if ("imag" !== e)
                    throw new Error(`FFT component must be either "real" or "imag", got ${e}.`);
                i = "return real * expI + imag * expR;"
            }
            this.userCode = `\n      const float exponentMultiplier = ${r};\n\n      float unaryOpComplex(float real, float expR, float imag, float expI) {\n        ${i}\n      }\n\n      float mulMatDFT(int batch, int index) {\n        float indexRatio = float(index) / float(${s});\n        float exponentMultiplierTimesIndexRatio =\n            exponentMultiplier * indexRatio;\n\n        float result = 0.0;\n\n        for (int i = 0; i < ${s}; i++) {\n          // x = (-2|2 * PI / N) * index * i;\n          float x = exponentMultiplierTimesIndexRatio * float(i);\n          float expR = cos(x);\n          float expI = sin(x);\n          float real = getReal(batch, i);\n          float imag = getImag(batch, i);\n\n          result +=\n              unaryOpComplex(real, expR, imag, expI) / ${a};\n        }\n\n        return result;\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        setOutput(mulMatDFT(coords[0], coords[1]));\n      }\n    `
        }
    }
    function lA(e, t, n) {
        const s = n.texData.get(e.dataId)
          , r = Hs.sizeFromShape(e.shape)
          , a = e.shape[e.shape.length - 1]
          , i = IC({
            inputs: {
                x: e
            },
            backend: n,
            attrs: {
                shape: [r / a, a]
            }
        })
          , o = i.shape
          , l = new oA("real",o,t)
          , u = new oA("imag",o,t)
          , c = [{
            dataId: s.complexTensorInfos.real.dataId,
            dtype: s.complexTensorInfos.real.dtype,
            shape: o
        }, {
            dataId: s.complexTensorInfos.imag.dataId,
            dtype: s.complexTensorInfos.imag.dtype,
            shape: o
        }]
          , h = n.runWebGLProgram(l, c, "float32")
          , p = n.runWebGLProgram(u, c, "float32")
          , d = iT({
            inputs: {
                real: h,
                imag: p
            },
            backend: n
        });
        n.disposeIntermediateTensorInfo(h),
        n.disposeIntermediateTensorInfo(p);
        const f = IC({
            inputs: {
                x: d
            },
            backend: n,
            attrs: {
                shape: e.shape
            }
        });
        return n.disposeIntermediateTensorInfo(i),
        n.disposeIntermediateTensorInfo(d),
        f
    }
    const uA = {
        kernelName: Et,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {input: s} = t;
            return lA(s, !1, n)
        }
    };
    class cA {
        constructor(e, t) {
            this.outputShape = [],
            this.customUniforms = [{
                name: "value",
                type: "float"
            }],
            this.variableNames = ["x"],
            this.outputShape = e,
            this.userCode = "\n      void main() {\n        // Input can be obtained from uniform value.\n        setOutput(value);\n      }\n    "
        }
    }
    function hA(e) {
        const {backend: t, attrs: n} = e
          , {shape: s, value: r} = n;
        let {dtype: a} = n;
        if (a = a || Hs.inferDtype(r),
        "string" === a) {
            const e = Hs.getArrayFromDType(a, Hs.sizeFromShape(s));
            return e.fill(r),
            t.makeTensorInfo(s, a, e)
        }
        {
            const e = new cA(s,r)
              , n = [[r]];
            return t.runWebGLProgram(e, [], a, n)
        }
    }
    const pA = {
        kernelName: At,
        backendName: "webgl",
        kernelFunc: hA
    };
    class dA {
        constructor(e) {
            this.variableNames = ["Image"],
            this.outputShape = [];
            const t = e[2];
            this.outputShape = e,
            this.userCode = `\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n\n          int coordX = ${t} - x - 1;\n          float outputValue;\n          if(coordX >= 0 && coordX < ${t}) {\n            outputValue = getImage(coords[0], coords[1], coordX, coords[3]);\n          } else {\n            outputValue = getImage(coords[0], coords[1], coords[2], coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    `
        }
    }
    const fA = {
        kernelName: Rt,
        backendName: "webgl",
        kernelFunc: ({inputs: e, backend: t})=>{
            const {image: n} = e
              , s = t
              , r = new dA(n.shape);
            return s.runWebGLProgram(r, [n], n.dtype)
        }
    }
      , mA = "return floor(x);"
      , gA = bT({
        opSnippet: mA,
        packedOpSnippet: mA,
        cpuKernelImpl: OT
    })
      , yA = {
        kernelName: Ft,
        backendName: "webgl",
        kernelFunc: gA
    }
      , bA = xT({
        opSnippet: "\n  float s = sign(a) * sign(b);\n  int ia = round(a);\n  int ib = round(b);\n  if (ib != 0) {\n    // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n    return float(idiv(ia, ib, s));\n  } else {\n    return NAN;\n  }\n",
        packedOpSnippet: "\n  ivec4 ia = round(a);\n  ivec4 ib = round(b);\n  bvec4 cond = notEqual(ib, ivec4(0));\n  ivec4 result = ivec4(0);\n  vec4 s = sign(a) * sign(b);\n\n  // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n  if (cond[0]) {\n    result[0] = idiv(ia[0], ib[0], s[0]);\n  }\n  if (cond[1]) {\n    result[1] = idiv(ia[1], ib[1], s[1]);\n  }\n  if (cond[2]) {\n    result[2] = idiv(ia[2], ib[2], s[2]);\n  }\n  if (cond[3]) {\n    result[3] = idiv(ia[3], ib[3], s[3]);\n  }\n  return vec4(result);\n",
        dtype: "int32"
    })
      , xA = {
        kernelName: Dt,
        backendName: "webgl",
        kernelFunc: bA
    };
    class wA {
        constructor(e) {
            this.variableNames = ["A"];
            const t = KS()
              , [n,s] = e;
            this.outputShape = e,
            this.userCode = `\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${s}.0, ${n}.0);\n\n        vec4 values = ${t.texture2D}(A, uv);\n        float value;\n        if (depth == 0) {\n          value = values.r;\n        } else if (depth == 1) {\n          value = values.g;\n        } else if (depth == 2) {\n          value = values.b;\n        } else if (depth == 3) {\n          value = values.a;\n        }\n\n        setOutput(floor(value * 255.0 + 0.5));\n      }\n    `
        }
    }
    class vA {
        constructor(e) {
            this.variableNames = ["A"],
            this.packedInputs = !1,
            this.packedOutput = !0;
            const t = KS()
              , [n,s] = e;
            this.outputShape = e,
            this.userCode = `\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n\n        vec4 result = vec4(0.);\n\n        for(int row=0; row<=1; row++) {\n          for(int col=0; col<=1; col++) {\n            texC = coords[1] + row;\n            depth = coords[2] + col;\n\n            vec2 uv = (vec2(texC, texR) + halfCR) /\n                       vec2(${s}.0, ${n}.0);\n            vec4 values = ${t.texture2D}(A, uv);\n            float value;\n            if (depth == 0) {\n              value = values.r;\n            } else if (depth == 1) {\n              value = values.g;\n            } else if (depth == 2) {\n              value = values.b;\n            } else if (depth == 3) {\n              value = values.a;\n            }\n\n            result[row * 2 + col] = floor(value * 255.0 + 0.5);\n          }\n        }\n\n        ${t.output} = result;\n      }\n    `
        }
    }
    const kA = {
        kernelName: Es,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e;
            let {pixels: r} = t;
            const {numChannels: a} = s
              , i = "undefined" != typeof HTMLVideoElement && r instanceof HTMLVideoElement
              , o = "undefined" != typeof HTMLImageElement && r instanceof HTMLImageElement
              , [l,u] = i ? [r.videoWidth, r.videoHeight] : [r.width, r.height]
              , c = [u, l]
              , h = [u, l, a];
            if (o || i) {
                const e = ie().getBool("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU");
                null != IA && e === SA || (SA = e,
                IA = document.createElement("canvas").getContext("2d", {
                    willReadFrequently: SA
                })),
                IA.canvas.width = l,
                IA.canvas.height = u,
                IA.drawImage(r, 0, 0, l, u),
                r = IA.canvas
            }
            const p = n.makeTensorInfo(c, "int32");
            n.texData.get(p.dataId).usage = xN.PIXELS,
            n.gpgpu.uploadPixelDataToTexture(n.getTexture(p.dataId), r);
            const d = ie().getBool("WEBGL_PACK") ? new vA(h) : new wA(h)
              , f = n.runWebGLProgram(d, [p], "int32");
            return n.disposeData(p.dataId),
            f
        }
    };
    let IA, SA = ie().getBool("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU");
    const NA = {
        kernelName: Fs,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, filter: a, bias: i, preluActivationWeights: o} = t
              , {strides: l, pad: u, dataFormat: c, dilations: h, dimRoundingMode: p, activation: d, leakyreluAlpha: f} = s
              , m = dm.convertConv2DDataFormat(c)
              , g = dm.computeConv2DInfo(r.shape, a.shape, l, h, u, p, !1, m);
            let y;
            const b = []
              , x = null != i
              , w = null != o
              , v = "leakyrelu" === d
              , k = ()=>{
                const e = [r, a]
                  , t = (e,t)=>{
                    if ("NCHW" === t && 1 === e.shape.length && 1 !== e.shape[0]) {
                        const t = IC({
                            inputs: {
                                x: e
                            },
                            backend: n,
                            attrs: {
                                shape: [e.shape[0], 1, 1]
                            }
                        });
                        return b.push(t),
                        t
                    }
                    return e
                }
                ;
                if (x && e.push(t(i, c)),
                w && e.push(t(o, c)),
                v) {
                    const t = n.makeTensorInfo([], "float32", Hs.createScalarValue(f, "float32"));
                    e.push(t),
                    b.push(t)
                }
                return e
            }
            ;
            if (1 !== g.filterHeight || 1 !== g.filterWidth || 1 !== g.dilationHeight || 1 !== g.dilationWidth || 1 !== g.strideHeight || 1 !== g.strideWidth || "SAME" !== g.padInfo.type && "VALID" !== g.padInfo.type)
                if (g.strideWidth <= 2 && "channelsLast" === m && ie().getBool("WEBGL_EXP_CONV")) {
                    const e = d ? wT(d, !0) : null
                      , t = new rE(g,x,e,w,v)
                      , s = [[g.padInfo.top, g.padInfo.left], [g.strideHeight, g.strideWidth], [g.dilationHeight, g.dilationWidth], [g.inHeight, g.inWidth]]
                      , r = k();
                    y = n.runWebGLProgram(t, r, "float32", s)
                } else if (ie().getBool("WEBGL_CONV_IM2COL"))
                    y = lE({
                        x: r,
                        filter: a,
                        convInfo: g,
                        backend: n,
                        bias: i,
                        activation: d,
                        preluActivationWeights: o,
                        leakyreluAlpha: f
                    });
                else {
                    const e = d ? wT(d, !1) : null
                      , t = new nE(g,x,e,w,v)
                      , s = k();
                    y = n.runWebGLProgram(t, s, "float32")
                }
            else
                y = oE({
                    x: r,
                    filter: a,
                    convInfo: g,
                    backend: n,
                    bias: i,
                    activation: d,
                    preluActivationWeights: o,
                    leakyreluAlpha: f
                });
            const I = IC({
                inputs: {
                    x: y
                },
                backend: n,
                attrs: {
                    shape: g.outShape
                }
            });
            return b.push(y),
            b.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            I
        }
    };
    const TA = {
        kernelName: Ds,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, filter: a, bias: i, preluActivationWeights: o} = t
              , {strides: l, pad: u, dilations: c, dimRoundingMode: h, activation: p, leakyreluAlpha: d} = s
              , f = [];
            let m = c;
            null == m && (m = [1, 1]),
            Hs.assert(dm.eitherStridesOrDilationsAreOne(l, m), (()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${l} and dilations '${m}'`));
            const g = dm.computeConv2DInfo(r.shape, a.shape, l, m, u, h, !0)
              , y = ie().getBool("WEBGL_PACK_DEPTHWISECONV") && g.strideWidth <= 2 && g.outChannels / g.inChannels == 1
              , b = p ? wT(p, y) : null
              , x = [r, a]
              , w = null != i
              , v = null != o
              , k = "leakyrelu" === p;
            if (w && x.push(i),
            v && x.push(o),
            k) {
                const e = n.makeTensorInfo([], "float32", Hs.createScalarValue(d, "float32"));
                x.push(e),
                f.push(e)
            }
            let I;
            I = y ? new ME(g,w,b,v,k) : new OE(g,w,b,v,k);
            const S = [[g.padInfo.top, g.padInfo.left], [g.strideHeight, g.strideWidth], [g.dilationHeight, g.dilationWidth], [g.inHeight, g.inWidth]]
              , N = n.runWebGLProgram(I, x, "float32", S);
            return f.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            N
        }
    };
    class CA {
        constructor(e, t, n, s) {
            this.sliceDim = e,
            this.strides = t,
            this.paramsShape = s,
            this.variableNames = ["x", "indices"],
            this.outputShape = n;
            const r = hN(n.length);
            let a = "\n    int index;";
            for (let e = 0; e < this.sliceDim; e++)
                a += `\n          index = round(getIndices(coords[0], ${e}));\n          out_of_bounds = out_of_bounds || index < 0;\n          out_of_bounds = out_of_bounds || index >= ${this.paramsShape[e]};\n          flattenIndex += index * ${this.strides[e]};`;
            this.userCode = `\n         void main() {\n          ${r} coords = getOutputCoords();\n          int flattenIndex = 0;\n          bool out_of_bounds = false;\n\n          ${a}\n\n          setOutput(out_of_bounds ? 0.0 : getX(flattenIndex, coords[1]));\n        }\n      `
        }
    }
    const $A = {
        kernelName: Mt,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {params: s, indices: r} = t
              , a = r.shape
              , i = a[a.length - 1]
              , o = Hs.sizeFromShape(s.shape)
              , [l,u,c,h] = dm.prepareAndValidate(s, r)
              , p = IC({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    shape: [u, i]
                }
            })
              , d = IC({
                inputs: {
                    x: s
                },
                backend: n,
                attrs: {
                    shape: [Hs.sizeFromShape(s.shape) / c, c]
                }
            });
            if (n.shouldExecuteOnCPU([s, r]) || "string" === s.dtype) {
                const e = n.readSync(r.dataId)
                  , t = n.bufferSync(s)
                  , a = MT(e, t, s.dtype, u, i, c, h, s.shape, o);
                return n.makeTensorInfo(l, s.dtype, a.values)
            }
            const f = new CA(i,h,[u, c],s.shape)
              , m = n.runWebGLProgram(f, [d, p], d.dtype)
              , g = IC({
                inputs: {
                    x: m
                },
                backend: n,
                attrs: {
                    shape: l
                }
            });
            return n.disposeIntermediateTensorInfo(p),
            n.disposeIntermediateTensorInfo(d),
            n.disposeIntermediateTensorInfo(m),
            g
        }
    };
    class EA {
        constructor(e, t) {
            this.variableNames = ["A", "indices"],
            this.outputShape = t,
            this.rank = t.length;
            const n = hN(this.rank)
              , s = function(e, t) {
                const n = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"]
                  , s = [];
                for (let t = 0; t < e.length; t++)
                    2 === t ? s.push("index") : s.push(`${n[t]}`);
                return s.join()
            }(e);
            this.userCode = `\n      void main() {\n        ${n} resRC = getOutputCoords();\n        int index = int(getIndices(resRC.x, resRC.z));\n        float inBounds = (index >= 0) && (index < ${e[2]}) ? 1.0 : 0.0;\n        setOutput(inBounds * getA(${s}));\n      }\n    `
        }
    }
    function AA(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {x: r, indices: a} = t
          , {axis: i, batchDims: o} = s
          , l = Hs.parseAxisParam(i, r.shape)[0];
        if (ie().get("DEBUG")) {
            const e = n.readSync(a.dataId)
              , t = r.shape[l];
            for (let n = 0; n < e.length; ++n) {
                const s = e[n];
                Hs.assert(s <= t - 1 && s >= 0, (()=>`GatherV2: the index value ${s} is not in [0, ${t - 1}]`))
            }
        }
        const u = dm.segment_util.collectGatherOpShapeInfo(r, a, l, o)
          , c = Hs.sizeFromShape(a.shape)
          , h = []
          , p = IC({
            inputs: {
                x: r
            },
            backend: n,
            attrs: {
                shape: [u.batchSize, u.outerSize, u.dimSize, u.sliceSize]
            }
        })
          , d = IC({
            inputs: {
                x: a
            },
            backend: n,
            attrs: {
                shape: [u.batchSize, c / u.batchSize]
            }
        });
        h.push(p),
        h.push(d);
        const f = [u.batchSize, u.outerSize, c / u.batchSize, u.sliceSize];
        if (n.shouldExecuteOnCPU([r, a]) || "string" === r.dtype) {
            const e = n.bufferSync(d)
              , t = n.bufferSync(p)
              , s = LT(t, e, f);
            return h.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            n.makeTensorInfo(u.outputShape, s.dtype, s.values)
        }
        const m = new EA(p.shape,f)
          , g = n.runWebGLProgram(m, [p, d], p.dtype);
        h.push(g);
        const y = IC({
            inputs: {
                x: g
            },
            backend: n,
            attrs: {
                shape: u.outputShape
            }
        });
        return h.forEach((e=>n.disposeIntermediateTensorInfo(e))),
        y
    }
    const RA = {
        kernelName: Ot,
        backendName: "webgl",
        kernelFunc: AA
    }
      , FA = xT({
        opSnippet: "return float(a > b);",
        packedOpSnippet: "\n  return vec4(greaterThan(a, b));\n",
        cpuKernelImpl: zT,
        dtype: "bool"
    })
      , DA = {
        kernelName: Lt,
        backendName: "webgl",
        kernelFunc: FA
    }
      , _A = xT({
        opSnippet: "return float(a >= b);",
        packedOpSnippet: "\n  return vec4(greaterThanEqual(a, b));\n",
        dtype: "bool",
        cpuKernelImpl: BT
    })
      , OA = {
        kernelName: zt,
        backendName: "webgl",
        kernelFunc: _A
    };
    const MA = {
        kernelName: Pt,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {input: s} = t;
            return lA(s, !0, n)
        }
    }
      , LA = bT({
        opSnippet: "return float(!isnan(x) && !isinf(x));",
        dtype: "bool"
    })
      , zA = {
        kernelName: Ut,
        backendName: "webgl",
        kernelFunc: LA
    }
      , BA = bT({
        opSnippet: "return float(isinf(x));",
        dtype: "bool"
    })
      , PA = {
        kernelName: Vt,
        backendName: "webgl",
        kernelFunc: BA
    }
      , WA = bT({
        opSnippet: "return float(isnan(x));",
        dtype: "bool"
    })
      , UA = {
        kernelName: Gt,
        backendName: "webgl",
        kernelFunc: WA
    }
      , VA = xT({
        opSnippet: "return float(a < b);",
        packedOpSnippet: "\n  return vec4(lessThan(a, b));\n",
        cpuKernelImpl: PT,
        dtype: "bool"
    })
      , GA = {
        kernelName: jt,
        backendName: "webgl",
        kernelFunc: VA
    }
      , HA = xT({
        opSnippet: "return float(a <= b);",
        packedOpSnippet: "\n  return vec4(lessThanEqual(a, b));\n",
        cpuKernelImpl: WT,
        dtype: "bool"
    })
      , jA = {
        kernelName: qt,
        backendName: "webgl",
        kernelFunc: HA
    };
    const qA = {
        kernelName: Kt,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {backend: t, attrs: n} = e
              , {start: s, stop: r, num: a} = n
              , i = UT(s, r, a);
            return t.makeTensorInfo([i.length], "float32", i)
        }
    }
      , KA = bT({
        opSnippet: "if (isnan(x)) return x;\n  return x < 0.0 ? 0./0. : log(x);\n",
        packedOpSnippet: "\n  vec4 result = log(x);\n  bvec4 isNaN = isnan(x);\n  result.r = isNaN.r ? x.r : (x.r < 0.0 ? 0./0. : result.r);\n  result.g = isNaN.g ? x.g : (x.g < 0.0 ? 0./0. : result.g);\n  result.b = isNaN.b ? x.b : (x.b < 0.0 ? 0./0. : result.b);\n  result.a = isNaN.a ? x.a : (x.a < 0.0 ? 0./0. : result.a);\n  return result;\n",
        cpuKernelImpl: VT
    })
      , XA = {
        kernelName: Xt,
        backendName: "webgl",
        kernelFunc: KA
    }
      , YA = bT({
        opSnippet: "if (isnan(x)) return x;\n  return log(1.0 + x);\n"
    })
      , ZA = {
        kernelName: Yt,
        backendName: "webgl",
        kernelFunc: YA
    }
      , JA = xT({
        opSnippet: "return float(a >= 1.0 && b >= 1.0);",
        packedOpSnippet: "\n  return vec4(\n    vec4(greaterThanEqual(a, vec4(1.0))) *\n    vec4(greaterThanEqual(b, vec4(1.0))));\n",
        dtype: "bool"
    })
      , QA = {
        kernelName: Zt,
        backendName: "webgl",
        kernelFunc: JA
    }
      , eR = bT({
        opSnippet: "return float(!(x >= 1.0));"
    })
      , tR = {
        kernelName: Jt,
        backendName: "webgl",
        kernelFunc: eR
    }
      , nR = xT({
        opSnippet: "return float(a >= 1.0 || b >= 1.0);",
        packedOpSnippet: "\n  return min(\n    vec4(greaterThanEqual(a, vec4(1.0))) +\n    vec4(greaterThanEqual(b, vec4(1.0))),\n    vec4(1.0));\n",
        dtype: "bool"
    })
      , sR = {
        kernelName: Qt,
        backendName: "webgl",
        kernelFunc: nR
    };
    class rR {
        constructor(e, t, n, s, r) {
            this.variableNames = ["x"],
            this.outputShape = [];
            const a = t
              , i = e[3] - 1;
            let o;
            this.outputShape = e;
            const l = `float(${n}) + float(${s}) * sum`;
            o = .5 === r ? `inversesqrt(${l})` : 1 === r ? `1.0/(${l})` : `exp(log(${l}) * float(-${r}));`,
            this.userCode = `\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n        int d = coords[3];\n        float x = getX(b, r, c, d);\n        float sum = 0.0;\n        for (int j = -${a}; j <= ${a}; j++) {\n          int idx = d + j;\n          if (idx >= 0 && idx <=  ${i}) {\n            float z = getX(b, r, c, idx);\n            sum += z * z;\n          }\n        }\n        float val = x * ${o};\n        setOutput(val);\n      }\n    `
        }
    }
    class aR {
        constructor(e, t, n, s, r) {
            this.variableNames = ["x"],
            this.outputShape = [],
            this.packedInputs = !0,
            this.packedOutput = !0;
            const a = t
              , i = e[3] - 1;
            let o;
            this.outputShape = e;
            const l = `float(${n}) + float(${s}) * sum`;
            o = .5 === r ? `inversesqrt(${l})` : 1 === r ? `1.0/(${l})` : `exp(log(${l}) * float(-${r}));`,
            this.userCode = `\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords.x;\n        int r = coords.y;\n        int c = coords.z;\n        int d = coords.w;\n\n        bool hasNextCol = d < ${this.outputShape[3]};\n        bool hasNextRow = c < ${this.outputShape[2]};\n\n        vec4 sum = vec4(0.);\n        vec4 xFragAtOutputCoords = getX(b, r, c, d);\n\n        vec4 xAtOutputCoords = vec4(\n          getChannel(xFragAtOutputCoords, vec2(c, d)),\n          hasNextCol ?\n            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,\n          hasNextRow ?\n            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0\n        );\n\n        int firstChannel = d - ${a};\n        vec2 cache = vec2(0.);\n        if(firstChannel >= 0){\n          vec4 firstChannelFrag = getX(b, r, c, firstChannel);\n          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));\n            if(hasNextRow){\n              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));\n            }\n        }\n\n        ivec2 depth = ivec2(d, d + 1);\n        for (int j = - ${a}; j <= ${a}; j++) {\n          ivec2 idx = depth + j;\n          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));\n          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(${i}));\n\n          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;\n          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;\n\n          if(depthInRange || depthPlusOneInRange){\n            vec4 z = vec4(0.);\n            vec4 xFragAtCurrentDepth;\n            z.xz = cache.xy;\n            if(depthPlusOneInRange && hasNextCol){\n              xFragAtCurrentDepth = idx.y != d ?\n                getX(b, r, c, idx.y) : xFragAtOutputCoords;\n              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));\n              if(hasNextRow){\n                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));\n              }\n            }\n            cache.xy = z.yw;\n            sum += z * z;\n          }\n        }\n        vec4 result = xAtOutputCoords * ${o};\n        setOutput(result);\n      }\n    `
        }
    }
    const iR = {
        kernelName: en,
        backendName: "webgl",
        kernelFunc: e=>{
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {depthRadius: a, bias: i, alpha: o, beta: l} = s
              , u = ie().getBool("WEBGL_PACK_NORMALIZATION") ? new aR(r.shape,a,i,o,l) : new rR(r.shape,a,i,o,l);
            return n.runWebGLProgram(u, [r], r.dtype)
        }
    };
    class oR {
        constructor(e, t, n, s, r) {
            this.variableNames = ["inputImage", "outputImage", "dy"],
            this.outputShape = [],
            this.outputShape = e,
            this.depth = e[3],
            this.depthRadius = t,
            this.bias = n,
            this.alpha = s,
            this.beta = r,
            this.userCode = `\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n\n        float result = 0.0;\n        for (int d = 0; d < ${this.depth}; ++d) {\n          int depthBegin = int(max(0.0, float(d - ${t})));\n          int depthEnd = int(min(float(${this.depth}),\n              float(d + ${t} + 1)));\n\n          const int MIN_DEPTH_BEGIN = 0;\n          const int MAX_DEPTH_END = ${this.depth};\n\n          float norm = 0.0;\n          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd) {\n              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);\n            }\n            else {\n              break;\n            }\n          }\n\n          norm = float(${s}) * norm + float(${n});\n\n          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd){\n              float dyi = -2.0 * float(${s})\n                * float(${r})\n                * getInputImage(b, r, c, k) * getOutputImage(b, r, c, d)\n                / norm;\n              if (k == d) {\n                dyi += pow(norm, -1.0 * ${r});\n              }\n              if (k == coords[3]) {\n                dyi *= getDy(b, r, c, d);\n                result += dyi;\n              }\n            }\n            else {\n              break;\n            }\n          }\n      }\n      setOutput(result);\n      }\n    `
        }
    }
    const lR = {
        kernelName: tn,
        backendName: "webgl",
        kernelFunc: e=>{
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, y: a, dy: i} = t
              , {depthRadius: o, bias: l, alpha: u, beta: c} = s
              , h = new oR(r.shape,o,l,u,c);
            return n.runWebGLProgram(h, [r, a, i], r.dtype)
        }
    };
    function uR(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {x: r} = t
          , {reductionIndices: a, keepDims: i} = s
          , o = r.shape.length
          , l = Hs.parseAxisParam(a, r.shape);
        let u = l;
        const c = dm.getAxesPermutation(u, o)
          , h = null != c
          , p = n.shouldExecuteOnCPU([r]);
        let d = r;
        if (h) {
            if (p) {
                const e = n.texData.get(d.dataId).values
                  , t = new Array(o);
                for (let e = 0; e < t.length; e++)
                    t[e] = r.shape[c[e]];
                const s = yC(e, r.shape, r.dtype, c, t);
                d = n.makeTensorInfo(t, r.dtype);
                n.texData.get(d.dataId).values = s
            } else
                d = AC(r, c, n);
            u = dm.getInnerMostAxes(u.length, o)
        }
        dm.assertAxesAreInnerMostDims("max", u, o);
        const [f,m] = dm.computeOutAndReduceShapes(d.shape, u);
        let g, y = f;
        if (i && (y = dm.expandShapeToKeepDim(f, l)),
        p) {
            const e = n.texData.get(d.dataId).values
              , t = GT(e, Hs.sizeFromShape(m), y, r.dtype);
            g = n.makeTensorInfo(y, r.dtype);
            n.texData.get(g.dataId).values = t
        } else
            g = function(e, t, n, s) {
                const r = Hs.sizeFromShape(t)
                  , a = IC({
                    inputs: {
                        x: e
                    },
                    attrs: {
                        shape: [Hs.sizeFromShape(e.shape) / r, r]
                    },
                    backend: s
                })
                  , i = CC(a, e.dtype, "max", s)
                  , o = IC({
                    inputs: {
                        x: i
                    },
                    attrs: {
                        shape: n
                    },
                    backend: s
                });
                return s.disposeIntermediateTensorInfo(a),
                s.disposeIntermediateTensorInfo(i),
                o
            }(d, m, y, n);
        return h && n.disposeIntermediateTensorInfo(d),
        g
    }
    const cR = {
        kernelName: nn,
        backendName: "webgl",
        kernelFunc: uR
    }
      , hR = xT({
        opSnippet: "\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n\n  return max(a, b);\n",
        packedOpSnippet: "\n  vec4 result = vec4(max(a, b));\n  bvec4 isNaNA = isnan(a);\n  bvec4 isNaNB = isnan(b);\n  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);\n  \n  result.r = isNaN.r ? NAN : result.r;\n  result.g = isNaN.g ? NAN : result.g;\n  result.b = isNaN.b ? NAN : result.b;\n  result.a = isNaN.a ? NAN : result.a;\n\n  return result;\n",
        cpuKernelImpl: HT
    })
      , pR = {
        kernelName: sn,
        backendName: "webgl",
        kernelFunc: hR
    };
    const dR = {
        kernelName: rn,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t;
            XN(r, "maxPool");
            const {filterSize: a, strides: i, pad: o, dimRoundingMode: l} = s;
            Hs.assert(dm.eitherStridesOrDilationsAreOne(i, 1), (()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${i} and dilations '1'`));
            const u = dm.computePool2DInfo(r.shape, a, i, 1, o, l);
            if (1 === u.filterWidth && 1 === u.filterHeight && Hs.arraysEqual(u.inShape, u.outShape))
                return rT({
                    inputs: {
                        x: r
                    },
                    backend: n
                });
            const c = new f$(u,"max",!1);
            return n.runWebGLProgram(c, [r], r.dtype)
        }
    };
    const fR = {
        kernelName: on,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {filterSize: a, strides: i, pad: o, dataFormat: l, dimRoundingMode: u} = s
              , c = dm.computePool3DInfo(r.shape, a, i, [1, 1, 1], o, u, l)
              , h = new m$(c,"max",!1);
            return n.runWebGLProgram(h, [r], r.dtype)
        }
    };
    class mR {
        constructor(e) {
            this.variableNames = ["dy", "maxPos"],
            this.outputShape = e.inShape;
            const t = e.strideHeight
              , n = e.strideWidth
              , s = e.dilationHeight
              , r = e.effectiveFilterHeight
              , a = e.effectiveFilterWidth
              , i = r - 1 - e.padInfo.top
              , o = a - 1 - e.padInfo.left
              , l = r * a - 1;
            this.userCode = `\n      const ivec2 pads = ivec2(${i}, ${o});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${r};\n          wR += ${s}) {\n          float dyR = float(dyRCorner + wR) / ${t}.0;\n\n          if (dyR < 0.0 || dyR >= ${e.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ${a}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${n}.0;\n\n            if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n            int maxPosValue = ${l} - int(getMaxPos(b, idyR, idyC, d));\n\n            // Get the current value, check it against the value from the\n            // position matrix.\n            int curPosValue = wR * ${a} + wC;\n            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n            dotProd += dyValue * mask;\n          }\n        }\n        setOutput(dotProd);\n      }\n    `
        }
    }
    class gR {
        constructor(e) {
            this.variableNames = ["dy", "maxPos"],
            this.outputShape = e.inShape;
            const t = e.strideDepth
              , n = e.strideHeight
              , s = e.strideWidth
              , r = e.dilationDepth
              , a = e.dilationHeight
              , i = e.dilationWidth
              , o = e.effectiveFilterDepth
              , l = e.effectiveFilterHeight
              , u = e.effectiveFilterWidth
              , c = o - 1 - e.padInfo.front
              , h = l - 1 - e.padInfo.top
              , p = u - 1 - e.padInfo.left
              , d = o * l * u - 1;
            this.userCode = `\n      const ivec3 pads = ivec3(${c}, ${h}, ${p});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ${o};\n           wD += ${r}) {\n          float dyD = float(dyDCorner + wD) / ${t}.0;\n\n          if (dyD < 0.0 || dyD >= ${e.outDepth}.0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ${l};\n              wR += ${a}) {\n            float dyR = float(dyRCorner + wR) / ${n}.0;\n\n            if (dyR < 0.0 || dyR >= ${e.outHeight}.0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ${u};\n                wC += ${i}) {\n              float dyC = float(dyCCorner + wC) / ${s}.0;\n\n              if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n              int maxPosValue = ${d} -\n                  int(getMaxPos(batch, idyD, idyR, idyC, ch));\n\n              // Get the current value, check it against the value from the\n              // position matrix.\n              int curPosValue =\n                  wD * ${l} * ${u} +\n                  wR * ${u} + wC;\n              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n              dotProd += dyValue * mask;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `
        }
    }
    const yR = {
        kernelName: ln,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {dy: r, input: a} = t
              , i = a
              , {filterSize: o, strides: l, pad: u, dimRoundingMode: c} = s
              , h = dm.computePool3DInfo(i.shape, o, l, [1, 1, 1], u, c)
              , p = new m$(h,"max",!0)
              , d = n.runWebGLProgram(p, [i], i.dtype)
              , f = new gR(h)
              , m = n.runWebGLProgram(f, [r, d], i.dtype);
            return n.disposeIntermediateTensorInfo(d),
            m
        }
    };
    const bR = {
        kernelName: an,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {dy: r, input: a, output: i} = t
              , o = a;
            XN([a, i], "maxPoolGrad");
            const {filterSize: l, strides: u, pad: c, dimRoundingMode: h} = s
              , p = dm.computePool2DInfo(o.shape, l, u, 1, c, h)
              , d = new f$(p,"max",!0)
              , f = n.runWebGLProgram(d, [o], o.dtype)
              , m = new mR(p)
              , g = n.runWebGLProgram(m, [r, f], o.dtype);
            return n.disposeIntermediateTensorInfo(f),
            g
        }
    };
    const xR = {
        kernelName: un,
        backendName: "webgl",
        kernelFunc: ({inputs: e, attrs: t, backend: n})=>{
            const {x: s} = e
              , {filterSize: r, strides: a, pad: i, includeBatchInIndex: o} = t
              , l = n;
            Hs.assert(4 === s.shape.length, (()=>`Error in maxPool: input must be rank 4 but got rank ${s.shape.length}.`));
            const u = [1, 1];
            Hs.assert(dm.eitherStridesOrDilationsAreOne(a, u), (()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${a} and dilations '${u}'`));
            const c = dm.computePool2DInfo(s.shape, r, a, u, i)
              , [h,p] = function(e, t, n, s) {
                let r = new f$(n,"max",!1);
                const a = s.runWebGLProgram(r, [e], "float32");
                return r = new f$(n,"max",!0,!0,t),
                [a, s.runWebGLProgram(r, [e], "float32")]
            }(s, o, c, l);
            return [h, p]
        }
    };
    const wR = {
        kernelName: cn,
        backendName: "webgl",
        kernelFunc: ({inputs: e, attrs: t, backend: n})=>{
            const {x: s} = e
              , {keepDims: r, axis: a} = t
              , i = n
              , o = s.shape.length
              , l = Hs.parseAxisParam(a, s.shape);
            let u = l;
            const c = dm.getAxesPermutation(u, o)
              , h = null != c
              , p = i.shouldExecuteOnCPU([s])
              , d = [];
            let f = s;
            if (h) {
                if (p) {
                    const e = i.texData.get(f.dataId).values
                      , t = new Array(o);
                    for (let e = 0; e < t.length; e++)
                        t[e] = s.shape[c[e]];
                    const n = yC(e, s.shape, s.dtype, c, t);
                    f = i.makeTensorInfo(t, s.dtype);
                    i.texData.get(f.dataId).values = n
                } else
                    f = AC(s, c, i);
                d.push(f),
                u = dm.getInnerMostAxes(u.length, o)
            }
            dm.assertAxesAreInnerMostDims("sum", u, o);
            const [m,g] = dm.computeOutAndReduceShapes(f.shape, u);
            let y = m;
            r && (y = dm.expandShapeToKeepDim(m, l));
            const b = function(e, t, n, s) {
                const r = Hs.sizeFromShape(t)
                  , a = IC({
                    inputs: {
                        x: e
                    },
                    attrs: {
                        shape: [Hs.sizeFromShape(e.shape) / r, r]
                    },
                    backend: s
                })
                  , i = CC(a, "float32", "mean", s)
                  , o = IC({
                    inputs: {
                        x: i
                    },
                    attrs: {
                        shape: n
                    },
                    backend: s
                });
                return s.disposeIntermediateTensorInfo(a),
                s.disposeIntermediateTensorInfo(i),
                o
            }(f, g, y, i);
            for (const e of d)
                i.disposeIntermediateTensorInfo(e);
            return b
        }
    };
    const vR = {
        kernelName: hn,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {axis: a, keepDims: i} = s
              , o = r.shape.length
              , l = Hs.parseAxisParam(a, r.shape);
            let u = l;
            const c = dm.getAxesPermutation(u, o);
            let h = r;
            null != c && (h = DC({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    perm: c
                }
            }),
            u = dm.getInnerMostAxes(u.length, r.shape.length)),
            dm.assertAxesAreInnerMostDims("min", u, o);
            const [p,d] = dm.computeOutAndReduceShapes(h.shape, u)
              , f = IC({
                inputs: {
                    x: h
                },
                backend: n,
                attrs: {
                    shape: [-1, Hs.sizeFromShape(d)]
                }
            })
              , m = CC(f, f.dtype, "min", n);
            let g;
            if (i) {
                g = IC({
                    inputs: {
                        x: m
                    },
                    backend: n,
                    attrs: {
                        shape: dm.expandShapeToKeepDim(p, l)
                    }
                })
            } else
                g = IC({
                    inputs: {
                        x: m
                    },
                    backend: n,
                    attrs: {
                        shape: p
                    }
                });
            return n.disposeIntermediateTensorInfo(f),
            n.disposeIntermediateTensorInfo(m),
            null != c && n.disposeIntermediateTensorInfo(h),
            g
        }
    }
      , kR = xT({
        opSnippet: "\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n\n  return min(a, b);\n",
        packedOpSnippet: "\n  vec4 result = vec4(min(a, b));\n  bvec4 isNaNA = isnan(a);\n  bvec4 isNaNB = isnan(b);\n  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);\n  \n  result.r = isNaN.r ? NAN : result.r;\n  result.g = isNaN.g ? NAN : result.g;\n  result.b = isNaN.b ? NAN : result.b;\n  result.a = isNaN.a ? NAN : result.a;\n\n  return result;\n",
        cpuKernelImpl: jT
    })
      , IR = {
        kernelName: pn,
        backendName: "webgl",
        kernelFunc: kR
    };
    class SR {
        constructor(e, t, n) {
            this.variableNames = ["x"],
            this.outputShape = t.map(((t,n)=>t[0] + e[n] + t[1]));
            const s = e.length
              , r = hN(s)
              , a = t.map((e=>e[0])).join(",")
              , i = t.map(((t,n)=>t[0] + e[n])).join(",")
              , o = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, s)
              , l = "reflect" === n ? 0 : 1;
            this.userCode = 1 !== s ? `\n      ${r} start = ${r}(${a});\n      ${r} end = ${r}(${i});\n\n      void main() {\n        ${r} outC = getOutputCoords();\n        for (int i = 0; i < ${s}; i++) {\n          if (outC[i] < start[i]) {\n            outC[i] = start[i] * 2 - outC[i] - ${l};\n          } else if(outC[i] >= end[i]) {\n            outC[i] = (end[i] - 1) * 2 - outC[i] + ${l};\n          }\n        }\n        ${r} coords = outC - start;\n        setOutput(getX(${o}));\n      }\n    ` : `\n        int start = ${a};\n        int end = ${i};\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start) {\n            outC = start * 2 - outC - ${l};\n          } else if(outC >= end) {\n            outC = (end - 1) * 2 - outC + ${l};\n          }\n          setOutput(getX(outC - start));\n        }\n      `
        }
    }
    class NR {
        constructor(e, t, n) {
            this.variableNames = ["x"],
            this.packedInputs = !0,
            this.packedOutput = !0,
            this.outputShape = t.map(((t,n)=>t[0] + e[n] + t[1]));
            const s = e.length
              , r = hN(s)
              , a = t.map((e=>e[0])).join(",")
              , i = t.map(((t,n)=>t[0] + e[n])).join(",")
              , o = nT("rc", s)
              , l = nT("source", s)
              , u = `${o[s - 1]} < ${this.outputShape[s - 1]}`
              , c = 1 === s ? "source" : `vec2(${l.slice(-2).join()})`
              , h = "reflect" === n ? 0 : 1;
            let p = "";
            if (1 === s) {
                const e = `\n        ${r} source = rc;\n        if (source < start) {\n          source = start * 2 - source - ${h};\n        } else if (source >= end) {\n          source = (end - 1) * 2 - source + ${h};\n        }\n        source -= start;\n      `;
                p = `\n        ${r} rc = outputLoc;\n        ${e}\n        result[0] = getChannel(getX(${l.join()}), ${c});\n        ${o[s - 1]} += 1;\n        if(${u}) {\n          ${e}\n          result[1] = getChannel(getX(${l.join()}), ${c});\n        }\n      `
            } else {
                const e = `\n        ${r} source = rc;\n        ${r} lt = ${r}(lessThan(source, start));\n        ${r} gte = ${r}(greaterThanEqual(source, end));\n        ${r} orig = 1 - (lt + gte);\n        source = orig * source +\n                lt * (start * 2 - source - ${h}) +\n                gte * ((end - 1) * 2 - source + ${h});\n        source -= start;\n      `;
                p = `\n        ${r} rc = outputLoc;\n        ${e}\n        result[0] = getChannel(getX(${l.join()}), ${c});\n        ${o[s - 1]} += 1;\n        if(${u}) {\n          ${e}\n          result[1] = getChannel(getX(${l.join()}), ${c});\n        }\n        rc = outputLoc;\n        ${o[s - 2]} += 1;\n        if(${o[s - 2]} < ${this.outputShape[s - 2]}) {\n          ${e}\n          result[2] = getChannel(getX(${l.join()}), ${c});\n          ${o[s - 1]} += 1;\n          if(${u}) {\n            ${e}\n            result[3] = getChannel(getX(${l.join()}), ${c});\n          }\n        }\n      `
            }
            this.userCode = `\n      const ${r} start = ${r}(${a});\n      const ${r} end = ${r}(${i});\n\n      void main() {\n        ${r} outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ${p}\n        setOutput(result);\n      }\n    `
        }
    }
    const TR = {
        kernelName: dn,
        backendName: "webgl",
        kernelFunc: ({inputs: e, backend: t, attrs: n})=>{
            const {x: s} = e
              , {paddings: r, mode: a} = n
              , i = ie().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new NR(s.shape,r,a) : new SR(s.shape,r,a);
            return t.runWebGLProgram(i, [s], s.dtype)
        }
    }
      , CR = xT({
        opSnippet: "if (b == 0.0) return NAN;\n  return mod(a, b);",
        packedOpSnippet: "\n  vec4 result = mod(a, b);\n  bvec4 isNaN = equal(b, vec4(0.0));\n  \n  result.r = isNaN.r ? NAN : result.r;\n  result.g = isNaN.g ? NAN : result.g;\n  result.b = isNaN.b ? NAN : result.b;\n  result.a = isNaN.a ? NAN : result.a;\n\n  return result;\n"
    })
      , $R = {
        kernelName: fn,
        backendName: "webgl",
        kernelFunc: CR
    };
    class ER {
        constructor(e, t, n) {
            this.variableNames = ["probs"],
            this.customUniforms = [{
                name: "seed",
                type: "float"
            }],
            this.outputShape = [e, n],
            this.userCode = `\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n\n        float r = random(seed);\n        float cdf = 0.0;\n\n        for (int i = 0; i < ${t - 1}; i++) {\n          cdf += getProbs(batch, i);\n\n          if (r < cdf) {\n            setOutput(float(i));\n            return;\n          }\n        }\n\n        // If no other event happened, last event happened.\n        setOutput(float(${t - 1}));\n      }\n    `
        }
    }
    const AR = xT({
        opSnippet: "\nif (a == b) {\n  return 1.0;\n};\nreturn a / b;",
        packedOpSnippet: "\n  // vec4 one = vec4(equal(a, b));\n  // return one + (vec4(1.0) - one) * a / b;\n  vec4 result = a / b;\n  if(a.x == b.x) {\n    result.x = 1.;\n  }\n  if(a.y == b.y) {\n    result.y = 1.;\n  }\n  if(a.z == b.z) {\n    result.z = 1.;\n  }\n  if(a.w == b.w) {\n    result.w = 1.;\n  }\n\n  return result;\n",
        checkOutOfBounds: !0
    })
      , RR = {
        kernelName: wt,
        backendName: "webgl",
        kernelFunc: AR
    }
      , FR = "return a - b;"
      , DR = xT({
        opSnippet: FR,
        packedOpSnippet: FR,
        supportsComplex: !0,
        cpuKernelImpl: fC
    })
      , _R = {
        kernelName: ys,
        backendName: "webgl",
        kernelFunc: DR
    };
    function OR(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {logits: r} = t
          , {dim: a} = s
          , i = Hs.parseAxisParam([a], r.shape)
          , o = uR({
            inputs: {
                x: r
            },
            backend: n,
            attrs: {
                reductionIndices: i,
                keepDims: !1
            }
        })
          , l = dm.expandShapeToKeepDim(o.shape, i)
          , u = IC({
            inputs: {
                x: o
            },
            backend: n,
            attrs: {
                shape: l
            }
        })
          , c = DR({
            inputs: {
                a: r,
                b: u
            },
            backend: n
        })
          , h = eA({
            inputs: {
                x: c
            },
            backend: n
        })
          , p = RC({
            inputs: {
                x: h
            },
            backend: n,
            attrs: {
                axis: i,
                keepDims: !1
            }
        })
          , d = IC({
            inputs: {
                x: p
            },
            backend: n,
            attrs: {
                shape: l
            }
        })
          , f = AR({
            inputs: {
                a: h,
                b: d
            },
            backend: n
        });
        return n.disposeIntermediateTensorInfo(o),
        n.disposeIntermediateTensorInfo(u),
        n.disposeIntermediateTensorInfo(c),
        n.disposeIntermediateTensorInfo(h),
        n.disposeIntermediateTensorInfo(p),
        n.disposeIntermediateTensorInfo(d),
        f
    }
    const MR = {
        kernelName: as,
        backendName: "webgl",
        kernelFunc: OR
    };
    const LR = {
        kernelName: mn,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {logits: r} = t
              , {numSamples: a, seed: i, normalized: o} = s
              , l = o ? r : OR({
                inputs: {
                    logits: r
                },
                backend: n,
                attrs: {
                    dim: r.shape.length - 1
                }
            })
              , u = l.shape[0]
              , c = l.shape[1]
              , h = new ER(u,c,a)
              , p = [[i]]
              , d = n.runWebGLProgram(h, [l], "int32", p);
            return o || n.disposeIntermediateTensorInfo(l),
            d
        }
    };
    const zR = {
        kernelName: yn,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {x: s} = t;
            if (n.shouldExecuteOnCPU([s])) {
                const e = n.texData.get(s.dataId)
                  , [t,r] = KT(e.values, s.shape, s.dtype);
                return n.makeTensorInfo(r, s.dtype, t)
            }
            let r;
            return r = ie().getBool("WEBGL_PACK_UNARY_OPERATIONS") ? new yT(s.shape,"\n  vec4 result = -x;\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n") : new fT(s.shape,"if (isnan(x)) return x;\n  return -x;\n"),
            n.runWebGLProgram(r, [s], s.dtype)
        }
    }
      , BR = Dg.nonMaxSuppressionV3Impl;
    const PR = {
        kernelName: xn,
        backendName: "webgl",
        kernelFunc: function(e) {
            dm.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
            const {inputs: t, backend: n, attrs: s} = e
              , {boxes: r, scores: a} = t
              , {maxOutputSize: i, iouThreshold: o, scoreThreshold: l} = s
              , u = n.readSync(r.dataId)
              , c = n.readSync(a.dataId)
              , {selectedIndices: h} = BR(u, c, i, o, l);
            return n.makeTensorInfo([h.length], "int32", new Int32Array(h))
        }
    }
      , WR = Dg.nonMaxSuppressionV4Impl;
    const UR = {
        kernelName: wn,
        backendName: "webgl",
        kernelFunc: function(e) {
            dm.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
            const {inputs: t, backend: n, attrs: s} = e
              , {boxes: r, scores: a} = t
              , {maxOutputSize: i, iouThreshold: o, scoreThreshold: l, padToMaxOutputSize: u} = s
              , c = n.readSync(r.dataId)
              , h = n.readSync(a.dataId)
              , {selectedIndices: p, validOutputs: d} = WR(c, h, i, o, l, u);
            return [n.makeTensorInfo([p.length], "int32", new Int32Array(p)), n.makeTensorInfo([], "int32", new Int32Array([d]))]
        }
    }
      , VR = Dg.nonMaxSuppressionV5Impl;
    const GR = {
        kernelName: vn,
        backendName: "webgl",
        kernelFunc: function(e) {
            dm.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
            const {inputs: t, backend: n, attrs: s} = e
              , {boxes: r, scores: a} = t
              , {maxOutputSize: i, iouThreshold: o, scoreThreshold: l, softNmsSigma: u} = s
              , c = n.readSync(r.dataId)
              , h = n.readSync(a.dataId)
              , p = i
              , d = o
              , f = l
              , m = u
              , {selectedIndices: g, selectedScores: y} = VR(c, h, p, d, f, m);
            return [n.makeTensorInfo([g.length], "int32", new Int32Array(g)), n.makeTensorInfo([y.length], "float32", new Float32Array(y))]
        }
    };
    class HR {
        constructor(e, t, n, s) {
            this.variableNames = ["indices"],
            this.outputShape = [e, t],
            this.userCode = `\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int index = round(getIndices(coords.x));\n        setOutput(mix(float(${s}), float(${n}),\n                      float(index == coords.y)));\n      }\n    `
        }
    }
    const jR = {
        kernelName: In,
        backendName: "webgl",
        kernelFunc: e=>{
            const {inputs: t, backend: n, attrs: s} = e
              , {indices: r} = t
              , {dtype: a, depth: i, onValue: o, offValue: l} = s
              , u = Hs.sizeFromShape(r.shape)
              , c = new HR(u,i,o,l)
              , h = IC({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    shape: [u]
                }
            })
              , p = n.runWebGLProgram(c, [h], a);
            n.disposeIntermediateTensorInfo(h);
            const d = IC({
                inputs: {
                    x: p
                },
                backend: n,
                attrs: {
                    shape: [...r.shape, i]
                }
            });
            return n.disposeIntermediateTensorInfo(p),
            d
        }
    };
    function qR(e) {
        const {inputs: t, backend: n} = e
          , {x: s} = t;
        if ("complex64" === s.dtype) {
            const e = M$({
                inputs: {
                    input: s
                },
                backend: n
            })
              , t = qR({
                inputs: {
                    x: e
                },
                backend: n
            })
              , r = Z$({
                inputs: {
                    input: s
                },
                backend: n
            })
              , a = qR({
                inputs: {
                    x: r
                },
                backend: n
            })
              , i = iT({
                inputs: {
                    real: t,
                    imag: a
                },
                backend: n
            });
            return n.disposeIntermediateTensorInfo(e),
            n.disposeIntermediateTensorInfo(t),
            n.disposeIntermediateTensorInfo(r),
            n.disposeIntermediateTensorInfo(a),
            i
        }
        return hA({
            attrs: {
                shape: s.shape,
                dtype: s.dtype,
                value: "string" === s.dtype ? "" : 0
            },
            backend: n
        })
    }
    const KR = {
        kernelName: Cs,
        backendName: "webgl",
        kernelFunc: qR
    };
    const XR = {
        kernelName: kn,
        backendName: "webgl",
        kernelFunc: function e(t) {
            const {inputs: n, backend: s} = t
              , {x: r} = n;
            if ("string" === r.dtype)
                throw new Error("onesLike is not supported under string dtype");
            if ("complex64" === r.dtype) {
                const t = M$({
                    inputs: {
                        input: r
                    },
                    backend: s
                })
                  , n = e({
                    inputs: {
                        x: t
                    },
                    backend: s
                })
                  , a = Z$({
                    inputs: {
                        input: r
                    },
                    backend: s
                })
                  , i = qR({
                    inputs: {
                        x: a
                    },
                    backend: s
                })
                  , o = iT({
                    inputs: {
                        real: n,
                        imag: i
                    },
                    backend: s
                });
                return s.disposeIntermediateTensorInfo(t),
                s.disposeIntermediateTensorInfo(n),
                s.disposeIntermediateTensorInfo(a),
                s.disposeIntermediateTensorInfo(i),
                o
            }
            return hA({
                attrs: {
                    shape: r.shape,
                    dtype: r.dtype,
                    value: 1
                },
                backend: s
            })
        }
    };
    const YR = {
        kernelName: Sn,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {axis: r} = s;
            if (1 === t.length)
                return nA({
                    inputs: {
                        input: t[0]
                    },
                    backend: n,
                    attrs: {
                        dim: r
                    }
                });
            const a = t[0].shape
              , i = t[0].dtype;
            t.forEach((e=>{
                Hs.assertShapesMatch(a, e.shape, "All tensors passed to stack must have matching shapes"),
                Hs.assert(i === e.dtype, (()=>"All tensors passed to stack must have matching dtypes"))
            }
            ));
            const o = []
              , l = eE({
                inputs: t.map((e=>{
                    const t = nA({
                        inputs: {
                            input: e
                        },
                        backend: n,
                        attrs: {
                            dim: r
                        }
                    });
                    return o.push(t),
                    t
                }
                )),
                backend: n,
                attrs: {
                    axis: r
                }
            });
            return o.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            l
        }
    };
    class ZR {
        constructor(e, t, n) {
            this.variableNames = ["x"],
            this.customUniforms = [{
                name: "value",
                type: "float"
            }],
            this.outputShape = t.map(((t,n)=>t[0] + e[n] + t[1]));
            const s = e.length
              , r = hN(s)
              , a = t.map((e=>e[0])).join(",")
              , i = t.map(((t,n)=>t[0] + e[n])).join(",")
              , o = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, s);
            this.userCode = 1 !== s ? `\n      ${r} start = ${r}(${a});\n      ${r} end = ${r}(${i});\n\n      void main() {\n        ${r} outC = getOutputCoords();\n        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {\n          setOutput(value);\n        } else {\n          ${r} coords = outC - start;\n          setOutput(getX(${o}));\n        }\n      }\n    ` : `\n        int start = ${a};\n        int end = ${i};\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start || outC >= end) {\n            setOutput(value);\n          } else {\n            setOutput(getX(outC - start));\n          }\n        }\n      `
        }
    }
    class JR {
        constructor(e, t, n) {
            this.variableNames = ["x"],
            this.packedInputs = !0,
            this.packedOutput = !0,
            this.customUniforms = [{
                name: "value",
                type: "float"
            }],
            this.outputShape = t.map(((t,n)=>t[0] + e[n] + t[1]));
            const s = e.length
              , r = hN(s)
              , a = t.map((e=>e[0])).join(",")
              , i = t.map(((t,n)=>t[0] + e[n])).join(",")
              , o = nT("rc", s)
              , l = nT("source", s)
              , u = `${o[s - 1]} < ${this.outputShape[s - 1]}`
              , c = 1 === s ? "source" : `vec2(${l.slice(-2).join()})`
              , h = [`${r} rc = outputLoc;`, `${o[s - 1]} += 1;\n       if(${u}) {\n      `, 1 === s ? "" : `}\n       rc = outputLoc;\n       ${o[s - 2]} += 1;\n       if(${o[s - 2]} < ${this.outputShape[s - 2]}) {`, 1 === s ? "" : `  ${o[s - 1]} += 1;\n         if(${u}) {`]
              , p = 1 === s ? "rc < start || rc >= end" : "any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))";
            let d = "";
            for (let e = 0, t = 1 === s ? 2 : 4; e < t; e++)
                d += `\n        ${h[e]}\n        if (${p}) {\n          result[${e}] = float(value);\n        } else {\n          ${r} source = rc - start;\n          result[${e}] = getChannel(getX(${l.join()}), ${c});\n        }\n      `;
            d += 1 === s ? "} " : "}}",
            this.userCode = `\n      const ${r} start = ${r}(${a});\n      const ${r} end = ${r}(${i});\n\n      void main() {\n        ${r} outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ${d}\n        setOutput(result);\n      }\n    `
        }
    }
    const QR = e=>{
        const {inputs: t, backend: n, attrs: s} = e
          , {x: r} = t
          , {paddings: a, constantValue: i} = s;
        if (0 === Hs.sizeFromShape(r.shape)) {
            return hA({
                backend: n,
                attrs: {
                    shape: a.map(((e,t)=>e[0] + r.shape[t] + e[1])),
                    value: i,
                    dtype: r.dtype
                }
            })
        }
        const o = ie().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new JR(r.shape,a,i) : new ZR(r.shape,a,i)
          , l = [[i]];
        return n.runWebGLProgram(o, [r], r.dtype, l)
    }
      , eF = {
        kernelName: Nn,
        backendName: "webgl",
        kernelFunc: QR
    }
      , tF = xT({
        opSnippet: "\n  if(a < 0.0 && floor(b) < b){\n    return NAN;\n  }\n  if (b == 0.0) {\n    return 1.0;\n  }\n  return (round(mod(b, 2.0)) != 1) ?\n      pow(abs(a), b) : sign(a) * pow(abs(a), b);\n",
        packedOpSnippet: "\n  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.\n  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));\n  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);\n  vec4 result = multiplier * pow(abs(a), b);\n\n  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS\n  bvec4 isExpZero = equal(b, vec4(0.0));\n  result.r = isExpZero.r ? 1.0 : result.r;\n  result.g = isExpZero.g ? 1.0 : result.g;\n  result.b = isExpZero.b ? 1.0 : result.b;\n  result.a = isExpZero.a ? 1.0 : result.a;\n\n  bvec4 isNaN1 = lessThan(a, vec4(0.0));\n  bvec4 isNaN2 = lessThan(floor(b), b);\n  bvec4 isNaN = bvec4(isNaN1.x && isNaN2.x, isNaN1.y && isNaN2.y, isNaN1.z && isNaN2.z, isNaN1.w && isNaN2.w);\n  \n  result.r = isNaN.r ? NAN : result.r;\n  result.g = isNaN.g ? NAN : result.g;\n  result.b = isNaN.b ? NAN : result.b;\n  result.a = isNaN.a ? NAN : result.a;\n\n  return result;\n"
    })
      , nF = {
        kernelName: Tn,
        backendName: "webgl",
        kernelFunc: tF
    };
    const sF = {
        kernelName: $n,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {axis: a, keepDims: i} = s
              , o = r.shape.length
              , l = []
              , u = Hs.parseAxisParam(a, r.shape);
            let c = u;
            const h = dm.getAxesPermutation(c, o);
            let p, d = r;
            if (null != h && (d = DC({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    perm: h
                }
            }),
            c = dm.getInnerMostAxes(c.length, o),
            l.push(d)),
            dm.assertAxesAreInnerMostDims("prod", c, o),
            n.shouldExecuteOnCPU([d])) {
                const e = n.texData.get(d.dataId).values
                  , {outVals: t, outShape: s, outDtype: r} = YT(d.shape, d.dtype, e, c);
                p = n.makeTensorInfo(s, r, t)
            } else {
                const [e,t] = dm.computeOutAndReduceShapes(d.shape, c)
                  , s = Hs.sizeFromShape(t)
                  , a = IC({
                    inputs: {
                        x: d
                    },
                    backend: n,
                    attrs: {
                        shape: [-1, s]
                    }
                })
                  , i = CC(a, pa(r.dtype), "prod", n);
                p = IC({
                    inputs: {
                        x: i
                    },
                    backend: n,
                    attrs: {
                        shape: e
                    }
                }),
                l.push(a),
                l.push(i)
            }
            if (i) {
                l.push(p);
                const e = dm.expandShapeToKeepDim(p.shape, u);
                p = IC({
                    inputs: {
                        x: p
                    },
                    backend: n,
                    attrs: {
                        shape: e
                    }
                })
            }
            return l.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            p
        }
    };
    const rF = {
        kernelName: En,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {paramsNestedSplits: r, paramsDenseValues: a, indices: i} = t
              , {outputRaggedRank: o} = s
              , l = r.map((e=>n.readSync(e.dataId)))
              , u = r.map((e=>e.shape))
              , c = n.readSync(a.dataId)
              , h = n.readSync(i.dataId)
              , [p,d,f] = ZT(l, u, c, a.shape, a.dtype, h, i.shape, o)
              , m = p.map((e=>n.makeTensorInfo([e.length], "int32", e)))
              , g = n.makeTensorInfo(f, a.dtype, d);
            return m.concat([g])
        }
    };
    const aF = {
        kernelName: An,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {starts: s, limits: r, deltas: a} = t
              , i = n.readSync(s.dataId)
              , o = n.readSync(r.dataId)
              , l = n.readSync(a.dataId)
              , [u,c] = JT(i, s.shape, s.dtype, o, r.shape, l, a.shape);
            return [n.makeTensorInfo([u.length], "int32", u), n.makeTensorInfo([c.length], s.dtype, c)]
        }
    };
    const iF = {
        kernelName: Rn,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {shape: r, values: a, defaultValue: i, rowPartitionTensors: o} = t
              , {rowPartitionTypes: l} = s
              , u = n.readSync(r.dataId)
              , c = n.readSync(a.dataId)
              , h = n.readSync(i.dataId)
              , p = o.map((e=>n.readSync(e.dataId)))
              , d = o.map((e=>e.shape))
              , [f,m] = QT(u, r.shape, c, a.shape, a.dtype, h, i.shape, p, d, l);
            return n.makeTensorInfo(f, a.dtype, m)
        }
    }
      , oF = e=>{
        const {backend: t, attrs: n} = e
          , {start: s, stop: r, step: a, dtype: i} = n
          , o = eC(s, r, a, i);
        return t.makeTensorInfo([o.length], i, o)
    }
      , lF = {
        kernelName: Fn,
        backendName: "webgl",
        kernelFunc: oF
    }
      , uF = bT({
        opSnippet: "return 1.0 / x;"
    })
      , cF = {
        kernelName: _n,
        backendName: "webgl",
        kernelFunc: uF
    }
      , hF = bT({
        opSnippet: "if (isnan(x)) return x;\n  return (x < 0.0) ? 0.0 : x;\n",
        packedOpSnippet: "\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n"
    })
      , pF = {
        kernelName: On,
        backendName: "webgl",
        kernelFunc: hF
    }
      , dF = bT({
        opSnippet: "if (isnan(x)) return x;\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n",
        packedOpSnippet: "\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n"
    })
      , fF = {
        kernelName: Wn,
        backendName: "webgl",
        kernelFunc: dF
    };
    class mF {
        constructor(e, t, n, s, r) {
            this.variableNames = ["A"],
            this.outputShape = [];
            const [a,i,o,l] = e;
            this.outputShape = [a, t, n, l];
            const u = [s && t > 1 ? i - 1 : i, s && n > 1 ? o - 1 : o]
              , c = [s && t > 1 ? t - 1 : t, s && n > 1 ? n - 1 : n];
            let h;
            h = r ? "(vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC - vec2(0.5)" : "vec2(yRC) * effectiveInputOverOutputRatioRC",
            this.userCode = `\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ${u[0] / c[0]},\n          ${u[1] / c[1]});\n      const vec2 inputShapeRC = vec2(${i}.0, ${o}.0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = ${h};\n\n        // Compute the four integer indices.\n        ivec2 sourceFloorRC = ivec2(max(sourceFracIndexRC, vec2(0.0)));\n        ivec2 sourceCeilRC = ivec2(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);\n        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);\n        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);\n        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);\n\n        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);\n\n        float top = topLeft + (topRight - topLeft) * fracRC.y;\n        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;\n        float newValue = top + (bottom - top) * fracRC.x;\n\n        setOutput(newValue);\n      }\n    `
        }
    }
    class gF {
        constructor(e, t, n, s, r) {
            this.variableNames = ["A"],
            this.packedInputs = !0,
            this.packedOutput = !0,
            this.outputShape = [];
            const [a,i,o,l] = e;
            this.outputShape = [a, t, n, l];
            const u = [s && t > 1 ? i - 1 : i, s && n > 1 ? o - 1 : o]
              , c = [s && t > 1 ? t - 1 : t, s && n > 1 ? n - 1 : n];
            let h;
            h = r ? "(vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC - vec3(0.5)" : "vec3(yRC) * effectiveInputOverOutputRatioRC",
            this.userCode = `\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ${u[0] / c[0]},\n          ${u[1] / c[1]},\n          ${u[1] / c[1]});\n      const vec3 inputShapeRC = vec3(${i}.0, ${o}.0,\n                                     ${o}.0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = ${h};\n\n        // Compute the four integer indices.\n        ivec3 sourceFloorRC = ivec3(max(sourceFracIndexRC, vec3(0.0)));\n        ivec3 sourceCeilRC = ivec3(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ${l - 1};\n        bool hasNextRow = coords.z < ${n - 1};\n\n        // In parallel, construct four corners for all four components in\n        // packed 2x2 cell.\n        vec4 topLeft = vec4(\n          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 bottomLeft = vec4(\n          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 topRight = vec4(\n          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec4 bottomRight = vec4(\n          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);\n\n        vec4 top = mix(topLeft, topRight, fracRC.yyzz);\n        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);\n        vec4 newValue = mix(top, bottom, fracRC.x);\n\n        setOutput(newValue);\n      }\n    `
        }
    }
    const yF = {
        kernelName: Bn,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {images: r} = t
              , {alignCorners: a, halfPixelCenters: i, size: o} = s
              , [l,u] = o
              , c = ie().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new gF(r.shape,l,u,a,i) : new mF(r.shape,l,u,a,i);
            return n.runWebGLProgram(c, [r], "float32")
        }
    };
    class bF {
        constructor(e, t, n) {
            this.variableNames = ["dy"],
            this.outputShape = [],
            this.outputShape = t;
            const [,s,r] = t
              , [,a,i] = e
              , o = [n && a > 1 ? s - 1 : s, n && i > 1 ? r - 1 : r]
              , l = [n && a > 1 ? a - 1 : a, n && i > 1 ? i - 1 : i]
              , u = o[0] / l[0]
              , c = o[1] / l[1]
              , h = 1 / u
              , p = 1 / c
              , d = 2 * Math.ceil(h) + 2
              , f = 2 * Math.ceil(p) + 2;
            this.userCode = `\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(${u});\n        const float widthScale = float(${c});\n\n        const float invHeightScale = float(${h});\n        const float invWidthScale = float(${p});\n\n        const int winHeight = int(${d});\n        const int winWidth = int(${f});\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(startRLerp - float(winHeight / 2));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(startCLerp - float(winWidth / 2));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ${a}) {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ${i}) {\n              continue;\n            }\n\n            float dxR = float(dyR) * heightScale;\n            int topDxRIndex = int(floor(dxR));\n            int bottomDxRIndex = int(min(ceil(dxR), ${s - 1}.0));\n            float dxRLerp = dxR - float(topDxRIndex);\n            float inverseDxRLerp = 1.0 - dxRLerp;\n\n            float dxC = float(dyC) * widthScale;\n            int leftDxCIndex = int(floor(dxC));\n            int rightDxCIndex = int(min(ceil(dxC), ${r - 1}.0));\n            float dxCLerp = dxC - float(leftDxCIndex);\n            float inverseDxCLerp = 1.0 - dxCLerp;\n\n            if (r == topDxRIndex && c == leftDxCIndex) {\n              // topLeft\n              accumulator +=\n                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;\n            }\n\n            if (r == topDxRIndex && c == rightDxCIndex) {\n              // topRight\n              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == leftDxCIndex) {\n              // bottomLeft\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == rightDxCIndex) {\n              // bottomRight\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    `
        }
    }
    const xF = {
        kernelName: Pn,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {images: r, dy: a} = t
              , {alignCorners: i} = s
              , o = new bF(a.shape,r.shape,i);
            return n.runWebGLProgram(o, [a], a.dtype)
        }
    };
    class wF {
        constructor(e, t, n, s, r) {
            this.variableNames = ["A"],
            this.outputShape = [];
            const [a,i,o,l] = e;
            this.outputShape = [a, t, n, l];
            const u = [s && t > 1 ? i - 1 : i, s && n > 1 ? o - 1 : o]
              , c = [s && t > 1 ? t - 1 : t, s && n > 1 ? n - 1 : n]
              , h = s ? "0.5" : "0.0";
            let p;
            p = r ? "max((vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC, vec2(0.0))" : "vec2(yRC) * effectiveInputOverOutputRatioRC",
            this.userCode = `\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ${u[0] / c[0]},\n          ${u[1] / c[1]});\n      const vec2 inputShapeRC = vec2(${i}.0, ${o}.0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = ${p};\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec2 sourceNearestRC = ivec2(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${h})));\n        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);\n\n        setOutput(newValue);\n      }\n    `
        }
    }
    class vF {
        constructor(e, t, n, s, r) {
            this.variableNames = ["A"],
            this.packedInputs = !0,
            this.packedOutput = !0,
            this.outputShape = [];
            const [a,i,o,l] = e;
            this.outputShape = [a, t, n, l];
            const u = [s && t > 1 ? i - 1 : i, s && n > 1 ? o - 1 : o]
              , c = [s && t > 1 ? t - 1 : t, s && n > 1 ? n - 1 : n]
              , h = s ? "0.5" : "0.0";
            let p;
            p = r ? "max((vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC, vec3(0.0))" : "vec3(yRC) * effectiveInputOverOutputRatioRC",
            this.userCode = `\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ${u[0] / c[0]},\n          ${u[1] / c[1]},\n          ${u[1] / c[1]});\n      const vec3 inputShapeRC = vec3(${i}.0, ${o}.0,\n                                     ${o}.0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = ${p};\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec3 sourceNearestRC = ivec3(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${h})));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ${l - 1};\n        bool hasNextRow = coords.z < ${n - 1};\n\n        vec4 newValue = vec4(\n          getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d),\n          hasNextCol ? getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d + 1) : 0.0);\n\n        setOutput(newValue);\n      }\n    `
        }
    }
    const kF = {
        kernelName: Ln,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {images: r} = t
              , {alignCorners: a, halfPixelCenters: i, size: o} = s
              , [l,u] = o
              , c = ie().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new vF(r.shape,l,u,a,i) : new wF(r.shape,l,u,a,i);
            return n.runWebGLProgram(c, [r], r.dtype)
        }
    };
    class IF {
        constructor(e, t, n) {
            this.variableNames = ["dy"],
            this.outputShape = [],
            this.outputShape = t;
            const [,s,r] = t
              , [,a,i] = e
              , o = [n && a > 1 ? s - 1 : s, n && i > 1 ? r - 1 : r]
              , l = [n && a > 1 ? a - 1 : a, n && i > 1 ? i - 1 : i]
              , u = o[0] / l[0]
              , c = o[1] / l[1]
              , h = 1 / u
              , p = 1 / c
              , d = 2 * Math.ceil(h) + 2
              , f = 2 * Math.ceil(p) + 2;
            this.userCode = `\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(${u});\n        const float widthScale = float(${c});\n\n        const float invHeightScale = float(${h});\n        const float invWidthScale = float(${p});\n\n        const int winHeight = int(${d});\n        const int winWidth = int(${f});\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(floor(startRLerp - float(winHeight / 2)));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(floor(startCLerp - float(winWidth / 2)));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ${a}) {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ${i}) {\n              continue;\n            }\n\n            float sourceFracRow =\n              float(${o[0]}) *\n                (float(dyR) / float(${l[0]}));\n\n            float sourceFracCol =\n                float(${o[1]}) *\n                  (float(dyC) / float(${l[1]}));\n\n            int sourceNearestRow = int(min(\n                float(int(${s}) - 1),\n                ${n} ? float(round(sourceFracRow)) :\n                                  float(floor(sourceFracRow))));\n\n            int sourceNearestCol = int(min(\n                float(int(${r}) - 1),\n                ${n} ? float(round(sourceFracCol)) :\n                                  float(floor(sourceFracCol))));\n\n            if (r == sourceNearestRow && c == sourceNearestCol) {\n              accumulator += getDy(b, dyR, dyC, d);\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    `
        }
    }
    const SF = {
        kernelName: zn,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {images: r, dy: a} = t
              , {alignCorners: i} = s
              , o = new IF(a.shape,r.shape,i);
            return n.runWebGLProgram(o, [a], a.dtype)
        }
    };
    class NF {
        constructor(e, t) {
            this.variableNames = ["x"];
            const n = e.length;
            if (n > 4)
                throw new Error(`WebGL backend: Reverse of rank-${n} tensor is not yet supported`);
            if (this.outputShape = e,
            1 === n)
                return void (this.userCode = `\n        void main() {\n          int coord = getOutputCoords();\n          setOutput(getX(${e[0]} - coord - 1));\n        }\n      `);
            const s = e.map(((n,s)=>(n=>-1 !== t.indexOf(n) && 1 !== e[n] ? `${e[n]} - coords[${n}] - 1` : `coords[${n}]`)(s))).join(",")
              , r = hN(n);
            this.userCode = `\n      void main() {\n        ${r} coords = getOutputCoords();\n        setOutput(getX(${s}));\n      }\n    `
        }
    }
    class TF {
        constructor(e, t) {
            this.variableNames = ["x"],
            this.packedInputs = !0,
            this.packedOutput = !0;
            const n = e.length;
            if (n > 4)
                throw new Error(`WebGL backend: Reverse of rank-${n} tensor is not yet supported`);
            this.outputShape = e;
            const s = nT("rc", n)
              , r = `${s[n - 1]} + 1 < ${this.outputShape[n - 1]}`
              , a = `${s[n - 2]} + 1 < ${this.outputShape[n - 2]}`
              , i = hN(n);
            var o;
            function l(n) {
                const s = e.map(((s,r)=>function(n, s) {
                    return -1 !== t.indexOf(n) && 1 !== e[n] ? `${e[n]} - ${s[n]} - 1` : `${s[n]}`
                }(r, n)));
                return `getChannel(getX(${s.join(",")}), vec2(${s.slice(-2).join(",")}))`
            }
            this.userCode = 1 === n ? `\n        void main(){\n          int rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = getChannel(getX(${e[0]} - rc - 1),\n            ${e[0]} - rc - 1);\n          if(${r}){\n              result.g = getChannel(getX(${e[0]} - (rc  + 1) - 1),\n                ${e[0]} - (rc  + 1) - 1);\n          }\n          setOutput(result);\n        }\n      ` : `\n        void main() {\n          ${i} rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = ${o = s.slice(),
            l(o)};\n          if(${r}){\n            result.g = ${function(e) {
                return e[n - 1] = "(" + e[n - 1] + " + 1)",
                l(e)
            }(s.slice())};\n          }\n          if(${a}) {\n            result.b = ${function(e) {
                return e[n - 2] = "(" + e[n - 2] + " + 1)",
                l(e)
            }(s.slice())};\n            if(${r}) {\n              result.a = ${function(e) {
                return e[n - 1] = "(" + e[n - 1] + " + 1)",
                e[n - 2] = "(" + e[n - 2] + " + 1)",
                l(e)
            }(s.slice())};\n            }\n          }\n          setOutput(result);\n        }\n    `
        }
    }
    const CF = {
        kernelName: Un,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {dims: a} = s
              , i = r.shape.length
              , o = Hs.parseAxisParam(a, r.shape);
            if (0 === i)
                return rT({
                    inputs: {
                        x: r
                    },
                    backend: n
                });
            const l = ie().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new TF(r.shape,o) : new NF(r.shape,o);
            return n.runWebGLProgram(l, [r], r.dtype)
        }
    };
    class $F {
        constructor(e, t) {
            this.variableNames = ["Image"],
            this.outputShape = [],
            this.customUniforms = [{
                name: "params",
                type: "vec4"
            }];
            const n = e[1]
              , s = e[2];
            this.outputShape = e;
            let r = "";
            r = "number" == typeof t ? `float outputValue = ${t.toFixed(2)};` : `\n        vec3 fill = vec3(${t.join(",")});\n        float outputValue = fill[coords[3]];`,
            this.userCode = `\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n          int y = coords[1];\n          float coordXFloat = (float(x) - params[0]) * params[3] -\n            (float(y) - params[1]) * params[2];\n          float coordYFloat = (float(x) - params[0]) * params[2] +\n            (float(y) - params[1]) * params[3];\n          int coordX = int(round(coordXFloat + params[0]));\n          int coordY = int(round(coordYFloat + params[1]));\n          ${r}\n          if(coordX >= 0 && coordX < ${s} && coordY >= 0 && coordY < ${n}) {\n            outputValue = getImage(coords[0], coordY, coordX, coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    `
        }
    }
    const EF = {
        kernelName: As,
        backendName: "webgl",
        kernelFunc: ({inputs: e, attrs: t, backend: n})=>{
            const {image: s} = e
              , {radians: r, fillValue: a, center: i} = t
              , o = n
              , l = new $F(s.shape,a)
              , [u,c] = dm.getImageCenter(i, s.shape[1], s.shape[2])
              , h = [[u, c, Math.sin(r), Math.cos(r)]];
            return o.runWebGLProgram(l, [s], s.dtype, h)
        }
    }
      , AF = bT({
        opSnippet: "\n  // OpenGL ES does not support round function.\n  // The algorithm is based on banker's rounding.\n  float base = floor(x);\n  if ((x - base) < 0.5) {\n    return floor(x);\n  } else if ((x - base) > 0.5) {\n    return ceil(x);\n  } else {\n    if (mod(base, 2.0) == 0.0) {\n      return base;\n    } else {\n      return base + 1.0;\n    }\n  }\n"
    })
      , RF = {
        kernelName: Vn,
        backendName: "webgl",
        kernelFunc: AF
    }
      , FF = bT({
        opSnippet: "return inversesqrt(x);",
        cpuKernelImpl: tC
    })
      , DF = {
        kernelName: Gn,
        backendName: "webgl",
        kernelFunc: FF
    };
    class _F {
        constructor(e, t, n, s, r, a, i=!0) {
            this.variableNames = ["updates", "indices", "defaultValue"],
            this.outputShape = a;
            const o = hN(r.length)
              , l = hN(a.length);
            let u = "";
            1 === n ? u = "i" : 2 === n && (u = "i, j");
            const c = `getIndices(${u})`;
            let h = "";
            1 === s ? h = "i" : 2 === s && (h = "i, coords[1]");
            const p = `getUpdates(${h})`
              , d = t > 1 ? "strides[j]" : "strides";
            this.userCode = `\n        ${o} strides = ${o}(${r});\n\n        void main() {\n          ${l} coords = getOutputCoords();\n          float sum = 0.0;\n          bool found = false;\n          for (int i = 0; i < ${e}; i++) {\n            int flattenedIndex = 0;\n            for (int j = 0; j < ${t}; j++) {\n              int index = round(${c});\n              flattenedIndex += index * ${d};\n            }\n            if (flattenedIndex == coords[0]) {\n              sum += ${p};\n              found = true;\n            }\n          }\n          setOutput(mix(getDefaultValue(), sum, float(found)));\n        }\n      `
        }
    }
    const OF = {
        kernelName: Hn,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {indices: r, updates: a} = t
              , {shape: i} = s
              , {sliceRank: o, numUpdates: l, sliceSize: u, strides: c, outputSize: h} = dm.calculateShapes(a, r, i)
              , p = [h / u, u];
            if (0 === h)
                return n.makeTensorInfo(i, r.dtype);
            const d = IC({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    shape: [l, o]
                }
            })
              , f = IC({
                inputs: {
                    x: a
                },
                backend: n,
                attrs: {
                    shape: [l, u]
                }
            })
              , m = n.makeTensorInfo([], "float32", new Float32Array([0]))
              , g = new _F(l,o,d.shape.length,f.shape.length,c,p)
              , y = n.runWebGLProgram(g, [f, d, m], f.dtype)
              , b = IC({
                inputs: {
                    x: y
                },
                backend: n,
                attrs: {
                    shape: i
                }
            });
            return n.disposeIntermediateTensorInfo(d),
            n.disposeIntermediateTensorInfo(f),
            n.disposeIntermediateTensorInfo(y),
            n.disposeIntermediateTensorInfo(m),
            b
        }
    };
    class MF {
        constructor(e, t, n, s) {
            this.variableNames = ["sortedSequence", "values"],
            this.customUniforms = [{
                name: "numInputs",
                type: "int"
            }],
            this.outputShape = [e, n];
            const r = `for (int i = 0; i < ${Math.ceil(Math.log2(t + 1))}; ++i) { if (left >= right) break;`
              , a = 2 === ie().getNumber("WEBGL_VERSION") ? "while (left < right) {" : r
              , i = "left" === s ? "<" : "<=";
            this.userCode = `\n       int findBound(int batch, float value) {\n         int left = 0;\n         int right = numInputs;\n         int mid;\n         ${a}\n           mid = (left + right) / 2;\n           if (getSortedSequence(batch, mid) ${i} value) {\n             left = mid + 1;\n           } else {\n             right = mid;\n           }\n         }\n         return right;\n       }\n\n       void main() {\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int valueIndex = coords[1];\n\n         float value = getValues(batch, valueIndex);\n\n         setOutput(float(findBound(batch, value)));\n       }\n     `
        }
    }
    const LF = {
        kernelName: jn,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {sortedSequence: r, values: a} = t
              , {side: i} = s
              , o = new MF(r.shape[0],r.shape[1],a.shape[1],i)
              , l = [[r.shape[1]]];
            return n.runWebGLProgram(o, [r, a], "int32", l)
        }
    };
    class zF {
        constructor(e, t, n) {
            let s, r;
            if (this.variableNames = ["c", "a", "b"],
            this.outputShape = t,
            n > 4)
                throw Error(`Where for rank ${n} is not yet supported`);
            if (1 === n)
                r = "resRC",
                s = "resRC";
            else {
                const n = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"]
                  , a = []
                  , i = [];
                for (let s = 0; s < t.length; s++)
                    i.push(`${n[s]}`),
                    s < e && a.push(`${n[s]}`);
                s = a.join(),
                r = i.join()
            }
            const a = hN(n);
            this.userCode = `\n      void main() {\n        ${a} resRC = getOutputCoords();\n        float cVal = getC(${s});\n        if (cVal >= 1.0) {\n          setOutput(getA(${r}));\n        } else {\n          setOutput(getB(${r}));\n        }\n      }\n    `
        }
    }
    const BF = {
        kernelName: qn,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {condition: s, t: r, e: a} = t
              , i = new zF(s.shape.length,r.shape,r.shape.length);
            return n.runWebGLProgram(i, [s, r, a], ha(r.dtype, a.dtype))
        }
    }
      , PF = bT({
        opSnippet: `\n  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\n  // see: https://arxiv.org/abs/1706.02515\n  float scaleAlpha = ${dm.SELU_SCALEALPHA};\n  float scale = ${dm.SELU_SCALE};\n  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);\n`
    })
      , WF = {
        kernelName: Kn,
        backendName: "webgl",
        kernelFunc: PF
    }
      , UF = bT({
        opSnippet: "if (isnan(x)) return x;\n  return 1.0 / (1.0 + exp(-1.0 * x));\n",
        packedOpSnippet: "\n  vec4 result = 1.0 / (1.0 + exp(-1.0 * x));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",
        cpuKernelImpl: sC
    })
      , VF = {
        kernelName: Qn,
        backendName: "webgl",
        kernelFunc: UF
    }
      , GF = bT({
        opSnippet: "\n  if (isnan(x)) { return 0.0; }\n  return sign(x);\n"
    })
      , HF = {
        kernelName: Jn,
        backendName: "webgl",
        kernelFunc: GF
    }
      , jF = bT({
        opSnippet: "if (isnan(x)) return x;\n  return sin(x);\n"
    })
      , qF = {
        kernelName: Yn,
        backendName: "webgl",
        kernelFunc: jF
    }
      , KF = bT({
        opSnippet: "\n  float e2x = exp(x);\n  return (e2x - 1.0 / e2x) / 2.0;\n"
    })
      , XF = {
        kernelName: Zn,
        backendName: "webgl",
        kernelFunc: KF
    }
      , YF = bT({
        opSnippet: "\n  float epsilon = 1.1920928955078125e-7;\n  float threshold = log(epsilon) + 2.0;\n\n  bool too_large = x > -threshold;\n  bool too_small = x < threshold;\n\n  float result;\n  float exp_x = exp(x);\n\n  if (too_large){\n    result = x;\n  }\n  else if (too_small){\n    result = exp_x;\n  }\n  else{\n    result = log(exp_x + 1.0);\n  }\n  return result;\n"
    })
      , ZF = {
        kernelName: es,
        backendName: "webgl",
        kernelFunc: YF
    }
      , JF = {
        kernelName: ss,
        backendName: "webgl",
        kernelFunc: e=>{
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {blockShape: a, paddings: i} = s;
            Hs.assert(r.shape.length <= 4, (()=>"spaceToBatchND for rank > 4 with a WebGL backend not implemented yet"));
            const o = a.reduce(((e,t)=>e * t))
              , l = [[0, 0]];
            l.push(...i);
            for (let e = 1 + a.length; e < r.shape.length; ++e)
                l.push([0, 0]);
            const u = []
              , c = QR({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    paddings: l,
                    constantValue: 0
                }
            })
              , h = dm.getReshaped(c.shape, a, o, !1)
              , p = dm.getPermuted(h.length, a.length, !1)
              , d = dm.getReshapedPermuted(c.shape, a, o, !1)
              , f = IC({
                inputs: {
                    x: c
                },
                backend: n,
                attrs: {
                    shape: h
                }
            })
              , m = DC({
                inputs: {
                    x: f
                },
                backend: n,
                attrs: {
                    perm: p
                }
            })
              , g = IC({
                inputs: {
                    x: m
                },
                backend: n,
                attrs: {
                    shape: d
                }
            });
            return u.push(c),
            u.push(f),
            u.push(m),
            u.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            g
        }
    };
    const QF = {
        kernelName: is,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {indices: s, values: r, denseShape: a, defaultValue: i} = t;
            if (1 !== a.shape.length)
                throw new Error(`Dense shape must be a vector, saw:\n         ${a.shape}`);
            if (2 !== s.shape.length)
                throw new Error(`Indices must be a matrix, saw:\n         ${s.shape}`);
            if (1 !== r.shape.length)
                throw new Error(`Values must be a vector, saw:\n         ${r.shape}`);
            if (0 !== i.shape.length)
                throw new Error(`Default value must be a scalar, saw:\n        ${i.shape}`);
            const o = n.readSync(s.dataId)
              , l = n.readSync(r.dataId)
              , u = n.readSync(a.dataId)
              , c = n.readSync(i.dataId)[0]
              , [h,p,d,f,m] = iC(o, s.shape, s.dtype, l, r.dtype, u, c);
            return [n.makeTensorInfo(p, s.dtype, h), n.makeTensorInfo([p[0]], r.dtype, d), n.makeTensorInfo([f.length], "bool", new Uint8Array(f.map((e=>Number(e))))), n.makeTensorInfo([m.length], s.dtype, new Int32Array(m))]
        }
    };
    const eD = {
        kernelName: os,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {inputIndices: s, inputShape: r, newShape: a} = t;
            if (2 !== s.shape.length)
                throw new Error(`Input indices should be a matrix but received shape ${s.shape}`);
            if (1 !== r.shape.length)
                throw new Error(`Input shape should be a vector but received shape ${r.shape}`);
            if (1 !== a.shape.length)
                throw new Error(`Target shape should be a vector but received shape ${a.shape}`);
            const i = Array.from(n.readSync(r.dataId))
              , o = n.readSync(s.dataId)
              , l = Array.from(n.readSync(a.dataId))
              , [u,c,h] = oC(o, s.shape, s.dtype, i, l);
            return [n.makeTensorInfo(c, s.dtype, u), n.makeTensorInfo([h.length], a.dtype, new Int32Array(h))]
        }
    };
    const tD = {
        kernelName: ls,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {data: s, indices: r, segmentIds: a} = t;
            if (s.shape.length < 1)
                throw new Error("Data should be at least 1 dimensional but received scalar");
            if (1 !== r.shape.length)
                throw new Error(`Indices should be a vector but received shape\n              ${r.shape}`);
            if (1 !== a.shape.length)
                throw new Error(`Segment ids should be a vector but received shape\n              ${a.shape}`);
            const i = n.readSync(s.dataId)
              , o = n.readSync(r.dataId)
              , l = n.readSync(a.dataId)
              , [u,c] = lC(i, s.shape, s.dtype, o, l, !0);
            return n.makeTensorInfo(c, s.dtype, u)
        }
    };
    const nD = {
        kernelName: us,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n} = e
              , {data: s, indices: r, segmentIds: a} = t;
            if (s.shape.length < 1)
                throw new Error("Data should be at least 1 dimensional but received scalar");
            if (1 !== r.shape.length)
                throw new Error(`Indices should be a vector but received shape\n             ${r.shape}`);
            if (1 !== a.shape.length)
                throw new Error(`Segment ids should be a vector but received shape\n             ${a.shape}`);
            const i = n.readSync(s.dataId)
              , o = n.readSync(r.dataId)
              , l = n.readSync(a.dataId)
              , [u,c] = lC(i, s.shape, s.dtype, o, l);
            return n.makeTensorInfo(c, s.dtype, u)
        }
    };
    const sD = {
        kernelName: cs,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {sparseIndices: r, sparseValues: a, defaultValue: i} = t
              , {outputShape: o} = s
              , {sliceRank: l, numUpdates: u, sliceSize: c, strides: h, outputSize: p} = dm.calculateShapes(a, r, o);
            if ("string" === a.dtype) {
                const e = n.bufferSync(r)
                  , t = n.bufferSync(a)
                  , s = Hs.decodeString(n.readSync(i.dataId)[0])
                  , d = nC(e, t, o, p, c, u, l, h, s, false);
                return n.makeTensorInfo(o, d.dtype, d.values)
            }
            const d = new _F(u,l,r.shape.length,a.shape.length,h,[p, 1],false)
              , f = n.runWebGLProgram(d, [a, r, i], a.dtype)
              , m = IC({
                inputs: {
                    x: f
                },
                backend: n,
                attrs: {
                    shape: o
                }
            });
            return n.disposeIntermediateTensorInfo(f),
            m
        }
    };
    const rD = {
        kernelName: rs,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {numOrSizeSplits: a, axis: i} = s
              , o = Hs.parseAxisParam(i, r.shape)[0]
              , l = dm.prepareSplitSize(r, a, o)
              , u = r.shape.length
              , c = new Array(u).fill(0)
              , h = r.shape.slice();
            return l.map((e=>{
                const t = [...h];
                t[o] = e;
                const s = E$({
                    inputs: {
                        x: r
                    },
                    backend: n,
                    attrs: {
                        begin: c,
                        size: t
                    }
                });
                return c[o] += e,
                s
            }
            ))
        }
    }
      , aD = "return sqrt(x);"
      , iD = bT({
        opSnippet: aD,
        packedOpSnippet: aD,
        cpuKernelImpl: uC
    })
      , oD = {
        kernelName: ts,
        backendName: "webgl",
        kernelFunc: iD
    }
      , lD = {
        kernelName: ps,
        backendName: "webgl",
        kernelFunc: bT({
            opSnippet: "return x * x;"
        })
    }
      , uD = "return (a - b) * (a - b);"
      , cD = xT({
        opSnippet: uD,
        packedOpSnippet: uD
    })
      , hD = {
        kernelName: hs,
        backendName: "webgl",
        kernelFunc: cD
    };
    const pD = {
        kernelName: $s,
        backendName: "webgl",
        kernelFunc: function({inputs: e, attrs: t, backend: n}) {
            const {x: s} = e
              , r = `if (isnan(x)) return x;\n    return x > 0.0 ? 1.0 : float(${t.alpha});\n  `
              , a = new fT(s.shape,r);
            return n.runWebGLProgram(a, [s], s.dtype)
        }
    };
    class dD {
        constructor(e, t, n) {
            this.variableNames = ["x"],
            this.outputShape = n;
            const s = n.length
              , r = hN(n.length)
              , a = hN(n.length);
            let i = "";
            if (1 === s)
                i = "coords * strides + begin";
            else {
                let e = 0;
                i = n.map(((t,s)=>(e++,
                1 === n.length ? `coords * strides[${s}] + begin[${s}]` : `coords[${e - 1}] * strides[${s}] + begin[${s}]`))).join(",")
            }
            this.userCode = `\n      ${r} begin = ${r}(${e});\n      ${r} strides = ${r}(${t});\n\n      void main() {\n        ${a} coords = getOutputCoords();\n        setOutput(getX(${i}));\n      }\n    `
        }
    }
    const fD = {
        kernelName: ds,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {begin: a, end: i, strides: o, beginMask: l, endMask: u, ellipsisMask: c, newAxisMask: h, shrinkAxisMask: p} = s
              , {finalShapeSparse: d, finalShape: f, isIdentity: m, sliceDim0: g, isSimpleSlice: y, begin: b, end: x, strides: w} = Xf.sliceInfo(r.shape, a, i, o, l, u, c, h, p);
            let v;
            if (m)
                v = IC({
                    inputs: {
                        x: r
                    },
                    backend: n,
                    attrs: {
                        shape: f
                    }
                });
            else if (g || y) {
                Hs.assert(r.shape.length >= 1, (()=>`Input must have rank at least 1, got: ${r.shape.length}`));
                const e = Xf.computeOutShape(b, x, w)
                  , t = E$({
                    inputs: {
                        x: r
                    },
                    backend: n,
                    attrs: {
                        begin: b,
                        size: e
                    }
                });
                v = IC({
                    inputs: {
                        x: t
                    },
                    backend: n,
                    attrs: {
                        shape: f
                    }
                }),
                n.disposeIntermediateTensorInfo(t)
            } else {
                if (n.shouldExecuteOnCPU([r])) {
                    const e = n.readSync(r.dataId)
                      , t = qo(r.shape, r.dtype, e)
                      , s = cC(d, t, w, b);
                    v = n.makeTensorInfo(f, r.dtype, s.values)
                } else {
                    const e = new dD(b,w,d);
                    v = n.runWebGLProgram(e, [r], r.dtype)
                }
            }
            const k = IC({
                inputs: {
                    x: v
                },
                backend: n,
                attrs: {
                    shape: f
                }
            });
            return n.disposeIntermediateTensorInfo(v),
            k
        }
    };
    const mD = {
        kernelName: fs,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {separator: r, nGramWidths: a, leftPad: i, rightPad: o, padWidth: l, preserveShortSequences: u} = s
              , {data: c, dataSplits: h} = t
              , p = n.readSync(c.dataId)
              , d = n.readSync(h.dataId)
              , [f,m] = hC(p, d, r, a, i, o, l, u);
            return [n.makeTensorInfo([f.length], "string", f), n.makeTensorInfo(h.shape, "int32", m)]
        }
    };
    const gD = {
        kernelName: ms,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {skipEmpty: r} = s
              , {input: a, delimiter: i} = t;
            if ("string" !== a.dtype)
                throw new Error("Input must be of datatype string");
            if (1 !== a.shape.length)
                throw new Error(`Input must be a vector, got shape: ${a.shape}`);
            if (0 !== i.shape.length)
                throw new Error(`Delimiter must be a scalar, got shape: ${i.shape}`);
            const o = n.readSync(a.dataId)
              , l = n.readSync(i.dataId)[0]
              , [u,c,h] = pC(o, l, r)
              , p = c.length;
            return [n.makeTensorInfo([p, 2], "int32", u), n.makeTensorInfo([p], "string", c), n.makeTensorInfo([2], "int32", new Int32Array(h))]
        }
    };
    const yD = {
        kernelName: gs,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {numBuckets: r} = s
              , {input: a} = t;
            if ("string" !== a.dtype)
                throw new Error("Input must be of datatype string");
            if (r <= 0)
                throw new Error("Number of buckets must be at least 1");
            const i = n.readSync(a.dataId)
              , o = dC(i, r);
            return n.makeTensorInfo(a.shape, "int32", o)
        }
    }
      , bD = bT({
        opSnippet: "return tan(x);"
    })
      , xD = {
        kernelName: bs,
        backendName: "webgl",
        kernelFunc: bD
    }
      , wD = bT({
        opSnippet: "\n  float e2x = exp(-2.0 * abs(x));\n  return sign(x) * (1.0 - e2x) / (1.0 + e2x);\n"
    })
      , vD = {
        kernelName: xs,
        backendName: "webgl",
        kernelFunc: wD
    };
    class kD {
        constructor(e, t) {
            this.variableNames = ["A"];
            const n = new Array(e.length);
            for (let s = 0; s < n.length; s++)
                n[s] = e[s] * t[s];
            this.outputShape = n,
            this.rank = n.length;
            const s = hN(this.rank)
              , r = function(e) {
                const t = e.length;
                if (t > 5)
                    throw Error(`Tile for rank ${t} is not yet supported`);
                if (1 === t)
                    return `imod(resRC, ${e[0]})`;
                const n = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u"]
                  , s = [];
                for (let t = 0; t < e.length; t++)
                    s.push(`imod(${n[t]}, ${e[t]})`);
                return s.join()
            }(e);
            this.userCode = `\n      void main() {\n        ${s} resRC = getOutputCoords();\n        setOutput(getA(${r}));\n      }\n    `
        }
    }
    function ID(e) {
        const {inputs: t, backend: n, attrs: s} = e
          , {x: r} = t
          , {reps: a} = s;
        if ("string" === r.dtype || r.shape.length > 5) {
            const e = n.readSync(r.dataId)
              , t = "string" === r.dtype ? e.map((e=>Hs.decodeString(e))) : e
              , s = qo(r.shape, r.dtype, t)
              , i = mC(s, a);
            return n.makeTensorInfo(i.shape, i.dtype, i.values)
        }
        const i = new kD(r.shape,a);
        return n.runWebGLProgram(i, [r], r.dtype)
    }
    const SD = {
        kernelName: ws,
        backendName: "webgl",
        kernelFunc: ID
    };
    class ND {
        constructor(e) {
            this.variableNames = ["x", "indices"],
            this.customUniforms = [{
                name: "n",
                type: "int"
            }, {
                name: "firstPass",
                type: "int"
            }, {
                name: "negativeInf",
                type: "float"
            }, {
                name: "dir",
                type: "int"
            }, {
                name: "inc",
                type: "int"
            }],
            this.outputShape = e,
            this.userCode = "\n       void main() {\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int elemIdx = coords[1];\n\n         // We compare elements pair-wise within a group of size 2 * inc.\n         // The comparing rule for each group alternates between ascending\n         // and descending. Within each group, we compare each pair at\n         // positions i and i+inc. To decide whether an element at position i\n         // is x0 or x1, we mod it by 2 * inc, if the result is smaller than\n         // inc, it is in the first half of the group, we denote it as x0,\n         // otherwise we denote it as x1.\n         // For example, as shown in the Bitonic top K paper referenced above,\n         // Figure5(a) shows that element[1] is in the\n         // second half of the group when group size is 2, but it is in the\n         // first half of the group when group size is 4.\n\n         bool isFirstInPair = imod(elemIdx, 2 * inc) < inc;\n         int i = isFirstInPair ? elemIdx : elemIdx - inc;\n\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\n         int i1 = firstPass == 1 ? i + inc : int(getIndices(batch, i + inc));\n         float x0 = i0 < n ? getX(batch, i0) : negativeInf;\n         float x1 = i1 < n ? getX(batch, i1) : negativeInf;\n\n         // Denotes which direction indices are in (ascending or descending).\n         bool reverse = imod(elemIdx, 2 * dir) >= dir;\n         bool isGreater = x0 > x1 || (x0 == x1 && i1 > i0);\n         if (reverse == isGreater) { // Elements in opposite order of direction\n           int iTemp = i0;\n           i0 = i1;\n           i1 = iTemp;\n         }\n         if (isFirstInPair) {\n            setOutput(float(i0));\n         } else {\n            setOutput(float(i1));\n         }\n       }\n     "
        }
    }
    class TD {
        constructor(e) {
            this.variableNames = ["x", "indices"],
            this.customUniforms = [{
                name: "n",
                type: "int"
            }, {
                name: "firstPass",
                type: "int"
            }, {
                name: "k",
                type: "int"
            }],
            this.outputShape = e,
            this.userCode = "\n    void main() {\n         // Takes max of indices (0, k), (1, k + 1), (2, k + 2) ...\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int elemIdx = coords[1];\n\n         // The output size is half of the previous size.\n         // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _ (k=4),\n         // we only need to output the indices at positions |, the indices at\n         // positions _ can be thrown away, see Figure5(b) After Phase 2\n         // (Merge phase) in the Bitonic Top K paper referenced above.\n         // For example, the paper shows we only need to output the orange bars.\n         // The output sequence should look like this | | | | | | | |.\n         // Because the sequence is halved, to map the output index back\n         // to the previous sequence to find the corresponding value,\n         // we need to double the index. When we double the index,\n         // we basically interpolate a position, so 2i looks like\n         // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k position\n         // of each 2k positions by - elemIdx % k. E.g. for output at\n         // index 4,5,6,7, we want to get the corresponding element at\n         // original index 8,9,10,11, for output at index 8,9,10,11,\n         // we want to get the corresponding element at original index\n         // 16,17,18,19, so on and so forth.\n\n         int i = elemIdx < k ? elemIdx : (elemIdx * 2 - imod(elemIdx, k));\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\n         int i1 = firstPass == 1 ? i + k : int(getIndices(batch, i + k));\n\n         float x0 = getX(batch, i0);\n         float x1 = i1 < n ? getX(batch, i1) : x0;\n\n         setOutput(x0 >= x1 ? float(i0) : float(i1));\n       }\n     "
        }
    }
    function CD(e, t) {
        null !== t && e.disposeIntermediateTensorInfo(t)
    }
    function $D(e) {
        let t = 1;
        for (; t < e; )
            t *= 2;
        return t
    }
    const ED = {
        kernelName: vs,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r} = t
              , {k: a, sorted: i} = s
              , o = ie().getNumber("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD")
              , l = ie().getNumber("TOPK_K_CPU_HANDOFF_THRESHOLD")
              , u = r.shape
              , c = u[u.length - 1];
            if (n.shouldExecuteOnCPU([r]) || c < o || a > l) {
                const e = n.readSync(r.dataId)
                  , [t,s] = gC(e, u, r.dtype, a, i);
                return [n.makeTensorInfo(t.shape, t.dtype, t.values), n.makeTensorInfo(s.shape, s.dtype, s.values)]
            }
            if (0 === a)
                return u[u.length - 1] = 0,
                [n.makeTensorInfo(u, r.dtype, []), n.makeTensorInfo(u, "int32", [])];
            if (1 === c)
                return [r, hA({
                    attrs: {
                        shape: u,
                        dtype: "int32",
                        value: 0
                    },
                    backend: n
                })];
            const h = n.texData.get(r.dataId)
              , p = null !== h && h.isPacked
              , d = p ? n.unpackTensor(r) : r
              , f = Hs.sizeFromShape(u) / c
              , m = IC({
                inputs: {
                    x: d
                },
                attrs: {
                    shape: [f, c]
                },
                backend: n
            });
            p && CD(n, d);
            const g = $D(a)
              , y = $D(c);
            let b = null;
            const x = ()=>null === b ? [m, m] : [m, b]
              , w = (e,t,s)=>{
                const r = x()
                  , a = new ND(s)
                  , i = [[c], [null === b ? 1 : 0], [Number.NEGATIVE_INFINITY], [e], [t]]
                  , o = b;
                b = n.runWebGLProgram(a, r, "int32", i),
                CD(n, o)
            }
            ;
            for (let e = 1; e < g; e *= 2) {
                const t = 2 * e;
                for (let n = e; n >= 1; n /= 2)
                    w(t, n, [f, y])
            }
            for (let e = y; e > g; e /= 2) {
                const t = x()
                  , s = new TD([f, e / 2])
                  , r = [[c], [null === b ? 1 : 0], [g]]
                  , a = b;
                b = n.runWebGLProgram(s, t, "int32", r),
                CD(n, a);
                const i = g / 2
                  , o = 2 * i;
                for (let e = i; e >= 1; e /= 2)
                    w(o, e, b.shape)
            }
            let v = b;
            b = E$({
                inputs: {
                    x: b
                },
                backend: n,
                attrs: {
                    begin: 0,
                    size: [f, a]
                }
            }),
            CD(n, v);
            let k = AA({
                inputs: {
                    x: m,
                    indices: b
                },
                backend: n,
                attrs: {
                    axis: 1,
                    batchDims: 1
                }
            });
            CD(n, m);
            const I = u.slice(0, -1);
            I.push(a),
            v = b,
            b = IC({
                inputs: {
                    x: b
                },
                attrs: {
                    shape: I
                },
                backend: n
            }),
            CD(n, v);
            const S = k;
            return k = IC({
                inputs: {
                    x: k
                },
                attrs: {
                    shape: I
                },
                backend: n
            }),
            CD(n, S),
            [k, b]
        }
    };
    class AD {
        constructor(e, t, n, s, r, a) {
            this.variableNames = ["Image", "Transforms"],
            this.outputShape = a;
            const i = "nearest" === n ? 1 : 2;
            let o;
            switch (s) {
            case "constant":
            default:
                o = 1;
                break;
            case "reflect":
                o = 2;
                break;
            case "wrap":
                o = 3;
                break;
            case "nearest":
                o = 4
            }
            this.userCode = `\n            float mapCoord(float outCoord, float len) {\n              float inCoord = outCoord;\n              if(${o} == 2) {\n                if (inCoord < 0.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz2 = 2.0 * len;\n                    if (inCoord < sz2) {\n                      inCoord = sz2 * float(int(float(-inCoord / sz2))) +\n                      inCoord;\n                    }\n                    inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1.0;\n                  }\n                } else if (inCoord > len - 1.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz2 = 2.0 * len;\n                    inCoord -= sz2 * float(int(float(inCoord / sz2)));\n                    if (inCoord >= len) {\n                      inCoord = sz2 - inCoord - 1.0;\n                    }\n                  }\n                }\n                return clamp(inCoord, 0.0, len - 1.0);\n              } else if (${o} == 3) {\n                if (inCoord < 0.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz = len - 1.0;\n                    inCoord += len * (float(int(float(-inCoord / sz))) + 1.0);\n                  }\n                } else if (inCoord > len - 1.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz = len - 1.0;\n                    inCoord -= len * float(int(float(inCoord / sz)));\n                  }\n                }\n                return clamp(inCoord, 0.0, len - 1.0);\n              } else if (${o} == 4) {\n                return clamp(outCoord, 0.0, len - 1.0);\n              } else {\n                return outCoord;\n              }\n            }\n\n            float readWithFillValue(int batch, int coordY, int coordX,\n              int channel) {\n              float outputValue;\n              if (0 <= coordY && coordY < ${e} && 0 <= coordX && coordX < ${t}) {\n                  outputValue = getImage(batch, coordY, coordX, channel);\n              } else {\n                outputValue = float(${r});\n              }\n              return outputValue;\n            }\n\n            void main() {\n              ivec4 coords = getOutputCoords();\n              float outputValue;\n              int batch = coords[0];\n              int x = coords[2];\n              int y = coords[1];\n              int channel = coords[3];\n              float xf = float(x);\n              float yf = float(y);\n              float a1 = getTransforms(batch, 0);\n              float a2 = getTransforms(batch, 1);\n              float a3 = getTransforms(batch, 2);\n              float b1 = getTransforms(batch, 3);\n              float b2 = getTransforms(batch, 4);\n              float b3 = getTransforms(batch, 5);\n              float c1 = getTransforms(batch, 6);\n              float c2 = getTransforms(batch, 7);\n              float projection = c1 * xf + c2 * yf + 1.0;\n              if (projection == 0.0) {\n                outputValue = float(${r});\n              } else {\n                float inX = (a1 * xf + a2 * yf + a3) / projection;\n                float inY = (b1 * xf + b2 * yf + b3) / projection;\n                float mapX = mapCoord(inX, float(${t}));\n                float mapY = mapCoord(inY, float(${e}));\n\n                if (${i} == 1) {\n                  int coordY = int(round(mapY));\n                  int coordX = int(round(mapX));\n                  outputValue = readWithFillValue(batch, coordY, coordX,\n                    channel);\n                } else {\n                  float yFloor = floor(mapY);\n                  float xFloor = floor(mapX);\n                  float yCeil = yFloor + 1.0;\n                  float xCeil = xFloor + 1.0;\n                  float valueYFloor = (xCeil - mapX) *\n                  readWithFillValue(batch, int(yFloor), int(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, int(yFloor), int(xCeil), channel);\n                  float valueYCeil = (xCeil - mapX) *\n                  readWithFillValue(batch, int(yCeil), int(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, int(yCeil), int(xCeil), channel);\n                  outputValue = (yCeil - mapY) * valueYFloor +\n                  (mapY - yFloor) * valueYCeil;\n                }\n              }\n              setOutput(outputValue);\n            }\n        `
        }
    }
    const RD = {
        kernelName: ks,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {image: r, transforms: a} = t
              , {interpolation: i, fillMode: o, fillValue: l, outputShape: u} = s
              , [c,h,p,d] = r.shape
              , [f,m] = null != u ? u : [h, p]
              , g = new AD(h,p,i,o,l,[c, f, m, d]);
            return n.runWebGLProgram(g, [r, a], "float32")
        }
    };
    const FD = {
        kernelName: Ss,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, attrs: n, backend: s} = e
              , {axis: r} = n
              , {x: a} = t;
            XN(a, "unique"),
            console.warn("WARNING: ", "UI might be locked temporarily as data is being downloaded");
            const i = s.readSync(a.dataId)
              , {outputValues: o, outputShape: l, indices: u} = bC(i, r, a.shape, a.dtype);
            return [s.makeTensorInfo(l, a.dtype, o), s.makeTensorInfo([u.length], "int32", u)]
        }
    };
    const DD = {
        kernelName: Ns,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {value: r} = t;
            let {axis: a} = s;
            a < 0 && (a += r.shape.length);
            const i = r
              , o = i.shape.length
              , l = r.shape[a]
              , u = new Array(o - 1);
            let c = 0;
            for (let e = 0; e < o; e++)
                e !== a && (u[c++] = i.shape[e]);
            const h = []
              , p = new Array(o).fill(0)
              , d = i.shape.slice();
            d[a] = 1;
            const f = new Array(l);
            for (let e = 0; e < f.length; e++) {
                p[a] = e;
                const t = E$({
                    inputs: {
                        x: i
                    },
                    backend: n,
                    attrs: {
                        begin: p,
                        size: d
                    }
                })
                  , s = IC({
                    inputs: {
                        x: t
                    },
                    backend: n,
                    attrs: {
                        shape: u
                    }
                });
                f[e] = s,
                h.push(t)
            }
            return h.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            f
        }
    };
    class _D {
        constructor(e, t) {
            this.variableNames = ["x", "segmentIds"];
            const n = e.windowSize
              , s = e.batchSize
              , r = e.inSize
              , a = e.numSegments
              , i = a * Math.ceil(r / n);
            this.outputShape = [s, i];
            const o = 4 * Math.floor(n / 4)
              , l = n % 4
              , u = "\n        sumValue += dot(values, segFilter);\n    ";
            let c = "";
            r % n > 0 && (c = `\n        if (inIdx < 0 || inIdx >= ${r}) {\n          return initializationValue;\n        }\n      `);
            let h = "";
            r % n > 0 && (h = `\n        if (inIdx < 0 || inIdx >= ${r}) {\n          return -1.0;\n        }\n      `),
            this.userCode = `\n      const float initializationValue = 0.0;\n\n      float getValue(int batch, int inIdx) {\n        ${c}\n        return getX(batch, inIdx);\n      }\n\n      float getSegmentIdAtIndex(int inIdx) {\n        ${h}\n        return getSegmentIds(inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = int(floor(float(outIdx) / float(\n          ${a})) * float(${n}));\n        int currentSeg = int(mod(float(outIdx), float(${a})));\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ${o}; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0\n          );\n\n          ${u}\n        }\n\n        int inIdx = inOffset + ${o};\n        if (${1 === l}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            0,\n            0,\n            0\n          );\n\n          ${u}\n        } else if (${2 === l}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n              0,\n              0\n          );\n\n          ${u}\n        } else if (${3 === l}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            0\n          );\n\n          ${u}\n        }\n        setOutput(sumValue);\n      }\n    `
        }
    }
    const OD = [MC, zC, PC, UC, HC, KC, XC, YC, n$, s$, a$, o$, u$, h$, d$, g$, y$, w$, v$, k$, N$, R$, F$, D$, z$, W$, G$, oT, q$, tE, uE, fE, mE, gE, yE, bE, wE, kE, SE, AE, RE, FE, _E, LE, PE, WE, VE, HE, jE, KE, XE, ZE, QE, tA, sA, iA, uA, pA, fA, yA, xA, kA, NA, TA, $A, RA, DA, OA, aT, MA, J$, zA, PA, UA, cT, GA, jA, qA, XA, ZA, QA, tR, sR, iR, lR, cR, pR, dR, fR, yR, bR, xR, wR, vR, IR, TR, $R, LR, vC, zR, PR, UR, GR, O$, jR, XR, YR, eF, nF, dT, sF, rF, aF, iF, lF, L$, RR, cF, pF, fF, SC, yF, xF, kF, SF, CF, EF, RF, DF, OF, LF, BF, WF, VF, HF, qF, XF, A$, MR, ZF, JF, QF, eD, tD, nD, sD, rD, oD, lD, hD, pD, fD, mD, gD, yD, _R, FC, xD, vD, SD, ED, RD, _C, FD, DD, {
        kernelName: Ts,
        backendName: "webgl",
        kernelFunc: function(e) {
            const {inputs: t, backend: n, attrs: s} = e
              , {x: r, segmentIds: a} = t
              , {numSegments: i} = s
              , o = r.shape.length
              , l = [];
            let u = 0;
            const c = dm.getAxesPermutation([u], o);
            let h = r;
            null != c && (h = DC({
                inputs: {
                    x: r
                },
                backend: n,
                attrs: {
                    perm: c
                }
            }),
            l.push(h),
            u = dm.getInnerMostAxes(1, o)[0]);
            const p = dm.segment_util.computeOutShape(h.shape, u, i)
              , d = Hs.sizeFromShape([h.shape[u]])
              , f = IC({
                inputs: {
                    x: h
                },
                backend: n,
                attrs: {
                    shape: [-1, d]
                }
            });
            l.push(f);
            const m = pa(r.dtype)
              , g = (e,t,s,r,a)=>{
                const i = e.shape[0]
                  , o = e.shape[1]
                  , u = dm.segment_util.segOpComputeOptimalWindowSize(o, a)
                  , c = new _D({
                    windowSize: u,
                    inSize: o,
                    batchSize: i,
                    numSegments: a
                },t)
                  , h = n.compileAndRun(c, [e, s], r);
                if (l.push(h),
                h.shape[1] === a)
                    return h;
                const p = oF({
                    backend: n,
                    attrs: {
                        start: 0,
                        stop: a,
                        step: 1,
                        dtype: "float32"
                    }
                })
                  , d = ID({
                    inputs: {
                        x: p
                    },
                    backend: n,
                    attrs: {
                        reps: [o / u]
                    }
                });
                l.push(p),
                l.push(d);
                return g(h, t, d, r, a)
            }
              , y = IC({
                inputs: {
                    x: g(f, "unsortedSegmentSum", a, m, i)
                },
                backend: n,
                attrs: {
                    shape: p
                }
            });
            let b = y;
            if (null != c) {
                l.push(y);
                const e = dm.getUndoAxesPermutation(c);
                b = DC({
                    inputs: {
                        x: b
                    },
                    backend: n,
                    attrs: {
                        perm: e
                    }
                })
            }
            return l.forEach((e=>n.disposeIntermediateTensorInfo(e))),
            b
        }
    }, KR];
    for (const e of OD)
        Us(e);
    const MD = ie();
    MD.registerFlag("HAS_WEBGL", (()=>MD.getNumber("WEBGL_VERSION") > 0)),
    MD.registerFlag("WEBGL_VERSION", (()=>jN(2) ? 2 : jN(1) ? 1 : 0)),
    MD.registerFlag("WEBGL_CHECK_NUMERICAL_PROBLEMS", (()=>!1)),
    MD.registerFlag("WEBGL_BUFFER_SUPPORTED", (()=>2 === MD.get("WEBGL_VERSION"))),
    MD.registerFlag("WEBGL_CPU_FORWARD", (()=>!0)),
    MD.registerFlag("WEBGL_FORCE_F16_TEXTURES", (()=>!1)),
    MD.registerFlag("WEBGL_PACK", (()=>MD.getBool("HAS_WEBGL"))),
    MD.registerFlag("WEBGL_PACK_NORMALIZATION", (()=>MD.getBool("WEBGL_PACK"))),
    MD.registerFlag("WEBGL_PACK_CLIP", (()=>MD.getBool("WEBGL_PACK"))),
    MD.registerFlag("WEBGL_PACK_DEPTHWISECONV", (()=>MD.getBool("WEBGL_PACK"))),
    MD.registerFlag("WEBGL_PACK_BINARY_OPERATIONS", (()=>MD.getBool("WEBGL_PACK"))),
    MD.registerFlag("WEBGL_PACK_UNARY_OPERATIONS", (()=>MD.getBool("WEBGL_PACK"))),
    MD.registerFlag("WEBGL_PACK_ARRAY_OPERATIONS", (()=>MD.getBool("WEBGL_PACK"))),
    MD.registerFlag("WEBGL_PACK_IMAGE_OPERATIONS", (()=>MD.getBool("WEBGL_PACK"))),
    MD.registerFlag("WEBGL_PACK_REDUCE", (()=>MD.getBool("WEBGL_PACK"))),
    MD.registerFlag("WEBGL_LAZILY_UNPACK", (()=>MD.getBool("WEBGL_PACK"))),
    MD.registerFlag("WEBGL_CONV_IM2COL", (()=>MD.getBool("WEBGL_PACK"))),
    MD.registerFlag("WEBGL_MAX_TEXTURE_SIZE", (()=>function(e) {
        if (null == VN) {
            const t = yN(e);
            VN = t.getParameter(t.MAX_TEXTURE_SIZE)
        }
        return VN
    }(MD.getNumber("WEBGL_VERSION")))),
    MD.registerFlag("WEBGL_MAX_TEXTURES_IN_SHADER", (()=>function(e) {
        if (null == GN) {
            const t = yN(e);
            GN = t.getParameter(t.MAX_TEXTURE_IMAGE_UNITS)
        }
        return Math.min(16, GN)
    }(MD.getNumber("WEBGL_VERSION")))),
    MD.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION", (()=>{
        const e = MD.getNumber("WEBGL_VERSION");
        return 0 === e ? 0 : function(e) {
            if (0 === e)
                return 0;
            let t;
            const n = yN(e);
            return t = HN(n, "EXT_disjoint_timer_query_webgl2") && 2 === e ? 2 : HN(n, "EXT_disjoint_timer_query") ? 1 : 0,
            t
        }(e)
    }
    )),
    MD.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE", (()=>MD.getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0 && !Sa.isMobile())),
    MD.registerFlag("WEBGL_RENDER_FLOAT32_CAPABLE", (()=>function(e) {
        if (0 === e)
            return !1;
        const t = yN(e);
        if (1 === e) {
            if (!HN(t, "OES_texture_float"))
                return !1
        } else if (!HN(t, "EXT_color_buffer_float"))
            return !1;
        return KN(t)
    }(MD.getNumber("WEBGL_VERSION")))),
    MD.registerFlag("WEBGL_RENDER_FLOAT32_ENABLED", (()=>!MD.getBool("WEBGL_FORCE_F16_TEXTURES") && MD.getBool("WEBGL_RENDER_FLOAT32_CAPABLE"))),
    MD.registerFlag("WEBGL_DOWNLOAD_FLOAT_ENABLED", (()=>qN(MD.getNumber("WEBGL_VERSION")))),
    MD.registerFlag("WEBGL_FENCE_API_ENABLED", (()=>{
        return 2 === (e = MD.getNumber("WEBGL_VERSION")) && null != yN(e).fenceSync;
        var e
    }
    )),
    MD.registerFlag("WEBGL_SIZE_UPLOAD_UNIFORM", (()=>MD.getBool("WEBGL_RENDER_FLOAT32_ENABLED") ? 4 : 0)),
    MD.registerFlag("WEBGL_DELETE_TEXTURE_THRESHOLD", (()=>-1), (e=>{
        if (e < 0 && -1 !== e)
            throw new Error(`WEBGL_DELETE_TEXTURE_THRESHOLD must be -1 (indicating never delete) or at least 0, but got ${e}.`)
    }
    )),
    MD.registerFlag("WEBGL_FLUSH_THRESHOLD", (()=>Sa.isMobile() ? 1 : -1), (e=>{
        if (e < 0 && -1 !== e)
            throw new Error(`WEBGL_FLUSH_THRESHOLD must be -1 (indicating never manual flush) or at least 0, but got ${e}.`)
    }
    )),
    MD.registerFlag("CPU_HANDOFF_SIZE_THRESHOLD", (()=>128)),
    MD.registerFlag("WEBGL_USE_SHAPES_UNIFORMS", (()=>!1)),
    MD.registerFlag("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD", (()=>1e5)),
    MD.registerFlag("TOPK_K_CPU_HANDOFF_THRESHOLD", (()=>128)),
    MD.registerFlag("WEBGL_EXP_CONV", (()=>!1)),
    MD.registerFlag("SOFTWARE_WEBGL_ENABLED", (()=>MD.getBool("IS_TEST"))),
    MD.registerFlag("WEBGL_MAX_SIZE_FOR_NARROW_TEXTURE", (()=>1 / 0)),
    MD.registerFlag("WEBGL_AUTO_SQUARIFY_NARROW_TEXTURE_SHAPE", (()=>!1)),
    MD.registerFlag("WEBGL2_ISNAN_CUSTOM", (()=>!1)),
    MD.registerFlag("ENGINE_COMPILE_ONLY", (()=>!1));
    class LD {
        constructor(e) {
            this.variableNames = ["A"],
            this.packedInputs = !1,
            this.packedOutput = !0,
            this.outPackingScheme = bN.DENSE,
            this.customUniforms = [{
                name: "texShape",
                type: "ivec2"
            }];
            const t = KS();
            this.outputShape = e,
            this.enableShapeUniforms = QN(this.outputShape.length),
            this.userCode = `\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ${this.enableShapeUniforms ? YS(["r", "c", "d"], e) : XS(["r", "c", "d"], e)}\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));\n        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getA(rc.x, rc.y, rc.z);\n        }\n\n        ${t.output} = result;\n      }\n    `
        }
    }
    class zD {
        constructor(e) {
            this.variableNames = ["A"],
            this.packedInputs = !0,
            this.packedOutput = !0,
            this.outPackingScheme = bN.DENSE,
            this.customUniforms = [{
                name: "texShape",
                type: "ivec2"
            }];
            const t = KS();
            this.outputShape = e,
            this.enableShapeUniforms = QN(this.outputShape.length),
            this.userCode = `\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ${this.enableShapeUniforms ? YS(["r", "c", "d"], e) : XS(["r", "c", "d"], e)}\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));\n        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));\n        }\n\n        ${t.output} = result;\n      }\n    `
        }
    }
    class BD {
        constructor(e) {
            this.variableNames = ["A"],
            this.outTexUsage = xN.DOWNLOAD;
            const t = KS();
            this.outputShape = e,
            this.userCode = `\n      ${QS}\n\n      void main() {\n        float x = getAAtOutCoords();\n        ${t.output} = encode_float(x);\n      }\n    `
        }
    }
    class PD {
        constructor(e) {
            this.variableNames = ["A"],
            this.packedInputs = !0,
            this.packedOutput = !1,
            this.outTexUsage = xN.DOWNLOAD;
            const t = KS();
            this.outputShape = e,
            this.userCode = `\n      ${QS}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));\n        ${t.output} = encode_float(x);\n      }\n    `
        }
    }
    const WD = {
        R: 0,
        G: 1,
        B: 2,
        A: 3
    };
    class UD {
        constructor(e, t=!1, n="RGBA") {
            this.variableNames = ["A"],
            this.customUniforms = [{
                name: "texShape",
                type: "ivec2"
            }];
            const s = KS();
            this.outputShape = e,
            this.enableShapeUniforms = QN(this.outputShape.length);
            let r = "result";
            t && (r = "floor(result * 255. + 0.5)");
            let a = "";
            for (let e = 0; e < n.length; e++) {
                const t = n[e];
                a += `\n          if(offset == ${e}) {\n            result = values[${WD[t]}];\n          }`
            }
            this.userCode = `\n      ${this.enableShapeUniforms ? "\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * outShapeStrides[0] + coords.y * outShapeStrides[1] + coords.z;\n  }\n" : JS(e)}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int flatIndex = getFlatIndex(coords);\n        float result = 0.;\n        int offset = imod(flatIndex, ${n.length});\n\n        flatIndex = idiv(flatIndex, ${n.length}, 1.);\n\n        int r = flatIndex / texShape[1];\n        if (r < texShape[0]) {\n          int c = imod(flatIndex, texShape[1]);\n          vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);\n          vec4 values = ${s.texture2D}(A, uv);\n          ${a}\n        }\n        ${s.output} = vec4(${r}, 0., 0., 0.);\n      }\n    `
        }
    }
    class VD {
        constructor(e, t=!1) {
            this.variableNames = ["A"],
            this.packedInputs = !1,
            this.packedOutput = !0,
            this.customUniforms = [{
                name: "texShape",
                type: "ivec2"
            }];
            const n = KS();
            this.outputShape = e,
            this.enableShapeUniforms = QN(this.outputShape.length);
            let s = ""
              , r = "result";
            t && (r = "floor(result * 255. + 0.5)");
            for (let t = 0; t <= 1; t++)
                for (let r = 0; r <= 1; r++) {
                    const a = 2 * t + r;
                    s += `\n          localCoords = coords;\n          if(localCoords[2] + ${r} < ${this.enableShapeUniforms ? "outShape[2]" : `${e[2]}`}) {\n          localCoords[2] += ${r};\n          if (localCoords[1] + ${t} < ${this.enableShapeUniforms ? "outShape[1]" : `${e[1]}`}) {\n            localCoords[1] += ${t};\n\n            flatIndex = getFlatIndex(localCoords);\n            offset = imod(flatIndex, 4);\n\n            flatIndex = idiv(flatIndex, 4, 1.);\n\n            int r = flatIndex / texShape[1];\n            int c = imod(flatIndex, texShape[1]);\n            vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);\n            values = ${n.texture2D}(A, uv);\n\n            if (offset == 0) {\n              result[${a}] = values[0];\n            } else if (offset == 1) {\n              result[${a}] = values[1];\n            } else if (offset == 2) {\n              result[${a}] = values[2];\n            } else {\n              result[${a}] = values[3];\n            }\n          }\n        }\n        `
                }
            this.userCode = `\n        ${this.enableShapeUniforms ? "\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * outShapeStrides[0] + coords.y * outShapeStrides[1] + coords.z;\n  }\n" : JS(e)}\n\n        void main() {\n          ivec3 coords = getOutputCoords();\n\n          vec4 result = vec4(0.);\n          int flatIndex, r, c, offset;\n          ivec3 localCoords;\n          vec2 uv;\n          vec4 values;\n\n          ${s}\n\n          ${n.output} = ${r};\n        }\n    `
        }
    }
    function GD(e) {
        const t = KS();
        return function(e, t) {
            const n = MN(e, (()=>e.createShader(e.VERTEX_SHADER)), "Unable to create vertex WebGLShader.");
            if (NN(e, (()=>e.shaderSource(n, t))),
            NN(e, (()=>e.compileShader(n))),
            !1 === e.getShaderParameter(n, e.COMPILE_STATUS))
                throw console.log(e.getShaderInfoLog(n)),
                new Error("Failed to compile vertex shader.");
            return n
        }(e, `${t.version}\n    precision highp float;\n    ${t.attribute} vec3 clipSpacePos;\n    ${t.attribute} vec2 uv;\n    ${t.varyingVs} vec2 resultUV;\n\n    void main() {\n      gl_Position = vec4(clipSpacePos, 1);\n      resultUV = uv;\n    }`)
    }
    function HD(e) {
        return function(e, t) {
            const n = MN(e, (()=>e.createBuffer()), "Unable to create WebGLBuffer");
            return NN(e, (()=>e.bindBuffer(e.ARRAY_BUFFER, n))),
            NN(e, (()=>e.bufferData(e.ARRAY_BUFFER, t, e.STATIC_DRAW))),
            n
        }(e, new Float32Array([-1, 1, 0, 0, 1, -1, -1, 0, 0, 0, 1, 1, 0, 1, 1, 1, -1, 0, 1, 0]))
    }
    function jD(e) {
        return function(e, t) {
            const n = MN(e, (()=>e.createBuffer()), "Unable to create WebGLBuffer");
            return NN(e, (()=>e.bindBuffer(e.ELEMENT_ARRAY_BUFFER, n))),
            NN(e, (()=>e.bufferData(e.ELEMENT_ARRAY_BUFFER, t, e.STATIC_DRAW))),
            n
        }(e, new Uint16Array([0, 1, 2, 2, 1, 3]))
    }
    function qD(e, t, n, s, r, a) {
        !function(e, t) {
            const n = ie().getNumber("WEBGL_MAX_TEXTURE_SIZE");
            if (e <= 0 || t <= 0)
                throw new Error(`Requested texture size [${e}x${t}] is invalid.`);
            if (e > n || t > n)
                throw new Error(`Requested texture size [${e}x${t}] greater than WebGL maximum on this browser / GPU [${n}x${n}].`)
        }(t, n);
        const i = function(e) {
            return MN(e, (()=>e.createTexture()), "Unable to create WebGLTexture.")
        }(e)
          , o = e.TEXTURE_2D;
        return NN(e, (()=>e.bindTexture(o, i))),
        NN(e, (()=>e.texParameteri(o, e.TEXTURE_WRAP_S, e.CLAMP_TO_EDGE))),
        NN(e, (()=>e.texParameteri(o, e.TEXTURE_WRAP_T, e.CLAMP_TO_EDGE))),
        NN(e, (()=>e.texParameteri(o, e.TEXTURE_MIN_FILTER, e.NEAREST))),
        NN(e, (()=>e.texParameteri(o, e.TEXTURE_MAG_FILTER, e.NEAREST))),
        1 === ie().getNumber("WEBGL_VERSION") ? NN(e, (()=>e.texImage2D(o, 0, s, t, n, 0, r, a, null))) : NN(e, (()=>e.texStorage2D(o, 1, s, t, n))),
        NN(e, (()=>e.bindTexture(e.TEXTURE_2D, null))),
        {
            texture: i,
            texShape: [n, t]
        }
    }
    function KD(e) {
        return e.internalFormatFloat
    }
    function XD(e) {
        return e.internalFormatHalfFloat
    }
    function YD(e) {
        return e.downloadTextureFormat
    }
    function ZD(e) {
        return e.internalFormatPackedFloat
    }
    function JD(e) {
        return e.internalFormatPackedHalfFloat
    }
    function QD(e, t, n, s, r, a, i, o) {
        const l = e
          , u = new Float32Array(function(e, t) {
            const [n,s] = IN(e, t);
            return n * s * 4
        }(a, i));
        return l.bindBuffer(l.PIXEL_PACK_BUFFER, t),
        l.getBufferSubData(l.PIXEL_PACK_BUFFER, 0, u),
        l.bindBuffer(l.PIXEL_PACK_BUFFER, null),
        u
    }
    class e_ {
        constructor(e) {
            this.outputTexture = null,
            this.program = null,
            this.disposed = !1,
            this.itemsToPoll = [];
            const t = ie().getNumber("WEBGL_VERSION");
            if (null != e ? (this.gl = e,
            function(e, t) {
                mN[e] = t
            }(t, e)) : this.gl = yN(t),
            e = this.gl,
            2 === ie().getNumber("WEBGL_VERSION")) {
                const t = e;
                this.createVertexArray = ()=>NN(t, (()=>t.createVertexArray())),
                this.bindVertexArray = e=>NN(t, (()=>t.bindVertexArray(e))),
                this.deleteVertexArray = e=>NN(t, (()=>t.deleteVertexArray(e))),
                this.getVertexArray = ()=>NN(t, (()=>t.getParameter(t.VERTEX_ARRAY_BINDING)))
            } else if (null != e) {
                const t = e.getExtension("OES_vertex_array_object");
                if (null == t)
                    throw new Error("All WebGL1 implementations are expected to offer OES_vertex_array_object.");
                this.createVertexArray = ()=>NN(e, (()=>t.createVertexArrayOES())),
                this.bindVertexArray = n=>NN(e, (()=>t.bindVertexArrayOES(n))),
                this.deleteVertexArray = n=>NN(e, (()=>t.deleteVertexArrayOES(n))),
                this.getVertexArray = ()=>NN(e, (()=>e.getParameter(t.VERTEX_ARRAY_BINDING_OES)))
            }
            let n = "WEBGL_color_buffer_float";
            const s = "EXT_color_buffer_half_float";
            if (this.parallelCompilationExtension = this.gl.getExtension("KHR_parallel_shader_compile"),
            1 === ie().getNumber("WEBGL_VERSION")) {
                const e = "OES_texture_float"
                  , t = "OES_texture_half_float";
                if (this.textureFloatExtension = CN(this.gl, e),
                HN(this.gl, t))
                    this.textureHalfFloatExtension = CN(this.gl, t);
                else if (ie().get("WEBGL_FORCE_F16_TEXTURES"))
                    throw new Error("GL context does not support half float textures, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");
                if (this.colorBufferFloatExtension = this.gl.getExtension(n),
                HN(this.gl, s))
                    this.colorBufferHalfFloatExtension = CN(this.gl, s);
                else if (ie().get("WEBGL_FORCE_F16_TEXTURES"))
                    throw new Error("GL context does not support color renderable half floats, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.")
            } else if (n = "EXT_color_buffer_float",
            HN(this.gl, n))
                this.colorBufferFloatExtension = this.gl.getExtension(n);
            else {
                if (!HN(this.gl, s))
                    throw new Error("GL context does not support color renderable floats");
                this.colorBufferHalfFloatExtension = this.gl.getExtension(s)
            }
            this.vertexBuffer = HD(this.gl),
            this.indexBuffer = jD(this.gl),
            this.framebuffer = function(e) {
                return MN(e, (()=>e.createFramebuffer()), "Unable to create WebGLFramebuffer.")
            }(this.gl),
            this.textureConfig = SN(this.gl, this.textureHalfFloatExtension)
        }
        get debug() {
            return ie().getBool("DEBUG")
        }
        dispose() {
            if (this.disposed)
                return;
            null != this.program && console.warn("Disposing a GPGPUContext that still has a bound WebGLProgram. This is probably a resource leak, delete the program with GPGPUContext.deleteProgram before disposing."),
            null != this.outputTexture && console.warn("Disposing a GPGPUContext that still has a bound output matrix texture.  This is probably a resource leak, delete the output matrix texture with GPGPUContext.deleteMatrixTexture before disposing.");
            const e = this.gl;
            NN(e, (()=>e.finish())),
            NN(e, (()=>e.bindFramebuffer(e.FRAMEBUFFER, null))),
            NN(e, (()=>e.deleteFramebuffer(this.framebuffer))),
            NN(e, (()=>e.bindBuffer(e.ARRAY_BUFFER, null))),
            NN(e, (()=>e.bindBuffer(e.ELEMENT_ARRAY_BUFFER, null))),
            NN(e, (()=>e.deleteBuffer(this.indexBuffer))),
            this.disposed = !0
        }
        createFloat32MatrixTexture(e, t) {
            return this.throwIfDisposed(),
            function(e, t, n, s) {
                const [r,a] = vN(t, n);
                return qD(e, r, a, KD(s), s.textureFormatFloat, e.FLOAT)
            }(this.gl, e, t, this.textureConfig)
        }
        createFloat16MatrixTexture(e, t) {
            return this.throwIfDisposed(),
            function(e, t, n, s) {
                const [r,a] = vN(t, n);
                return qD(e, r, a, XD(s), s.textureFormatFloat, s.textureTypeHalfFloat)
            }(this.gl, e, t, this.textureConfig)
        }
        createUnsignedBytesMatrixTexture(e, t) {
            return this.throwIfDisposed(),
            function(e, t, n, s) {
                const [r,a] = vN(t, n);
                return qD(e, r, a, YD(s), e.RGBA, e.UNSIGNED_BYTE)
            }(this.gl, e, t, this.textureConfig)
        }
        uploadPixelDataToTexture(e, t) {
            this.throwIfDisposed(),
            function(e, t, n) {
                NN(e, (()=>e.bindTexture(e.TEXTURE_2D, t))),
                n.data instanceof Uint8Array ? 2 === ie().getNumber("WEBGL_VERSION") ? NN(e, (()=>e.texSubImage2D(e.TEXTURE_2D, 0, 0, 0, n.width, n.height, e.RGBA, e.UNSIGNED_BYTE, n.data))) : NN(e, (()=>e.texImage2D(e.TEXTURE_2D, 0, e.RGBA, n.width, n.height, 0, e.RGBA, e.UNSIGNED_BYTE, n.data))) : 2 === ie().getNumber("WEBGL_VERSION") ? NN(e, (()=>e.texSubImage2D(e.TEXTURE_2D, 0, 0, 0, e.RGBA, e.UNSIGNED_BYTE, n))) : NN(e, (()=>e.texImage2D(e.TEXTURE_2D, 0, e.RGBA, e.RGBA, e.UNSIGNED_BYTE, n))),
                NN(e, (()=>e.bindTexture(e.TEXTURE_2D, null)))
            }(this.gl, e, t)
        }
        uploadDenseMatrixToTexture(e, t, n, s) {
            this.throwIfDisposed(),
            function(e, t, n, s, r, a) {
                let i, o, l;
                NN(e, (()=>e.bindTexture(e.TEXTURE_2D, t))),
                r instanceof Uint8Array ? (i = new Uint8Array(n * s * 4),
                o = e.UNSIGNED_BYTE,
                l = e.RGBA) : (i = new Float32Array(n * s * 4),
                o = e.FLOAT,
                l = a.internalFormatPackedFloat),
                i.set(r),
                2 === ie().getNumber("WEBGL_VERSION") ? NN(e, (()=>e.texSubImage2D(e.TEXTURE_2D, 0, 0, 0, n, s, e.RGBA, o, i))) : NN(e, (()=>e.texImage2D(e.TEXTURE_2D, 0, l, n, s, 0, e.RGBA, o, i))),
                NN(e, (()=>e.bindTexture(e.TEXTURE_2D, null)))
            }(this.gl, e, t, n, s, this.textureConfig)
        }
        createFloat16PackedMatrixTexture(e, t) {
            return this.throwIfDisposed(),
            function(e, t, n, s) {
                const [r,a] = IN(t, n);
                return qD(e, r, a, JD(s), e.RGBA, s.textureTypeHalfFloat)
            }(this.gl, e, t, this.textureConfig)
        }
        createPackedMatrixTexture(e, t) {
            return this.throwIfDisposed(),
            function(e, t, n, s) {
                const [r,a] = IN(t, n);
                return qD(e, r, a, ZD(s), e.RGBA, e.FLOAT)
            }(this.gl, e, t, this.textureConfig)
        }
        deleteMatrixTexture(e) {
            this.throwIfDisposed(),
            this.outputTexture === e && (_N(this.gl, this.framebuffer),
            this.outputTexture = null),
            NN(this.gl, (()=>this.gl.deleteTexture(e)))
        }
        downloadByteEncodedFloatMatrixFromOutputTexture(e, t, n) {
            return this.downloadMatrixDriver(e, (()=>function(e, t, n, s) {
                const [r,a] = vN(t, n)
                  , i = new Uint8Array(t * n * 4);
                return NN(e, (()=>e.readPixels(0, 0, r, a, s.downloadTextureFormat, e.UNSIGNED_BYTE, i))),
                new Float32Array(i.buffer)
            }(this.gl, t, n, this.textureConfig)))
        }
        downloadPackedMatrixFromBuffer(e, t, n, s, r, a) {
            return QD(this.gl, e, 0, 0, 0, r, a, this.textureConfig)
        }
        downloadFloat32MatrixFromBuffer(e, t) {
            return function(e, t, n) {
                const s = e
                  , r = new Float32Array(n);
                return s.bindBuffer(s.PIXEL_PACK_BUFFER, t),
                s.getBufferSubData(s.PIXEL_PACK_BUFFER, 0, r),
                s.bindBuffer(s.PIXEL_PACK_BUFFER, null),
                r
            }(this.gl, e, t)
        }
        createBufferFromTexture(e, t, n) {
            this.bindTextureToFrameBuffer(e);
            const s = function(e, t, n, s) {
                const r = e.createBuffer();
                NN(e, (()=>e.bindBuffer(e.PIXEL_PACK_BUFFER, r)));
                const a = 16 * t * n;
                return NN(e, (()=>e.bufferData(e.PIXEL_PACK_BUFFER, a, e.STREAM_READ))),
                NN(e, (()=>e.readPixels(0, 0, n, t, e.RGBA, e.FLOAT, 0))),
                NN(e, (()=>e.bindBuffer(e.PIXEL_PACK_BUFFER, null))),
                r
            }(this.gl, t, n, this.textureConfig);
            return this.unbindTextureToFrameBuffer(),
            s
        }
        createAndWaitForFence() {
            const e = this.createFence(this.gl);
            return this.pollFence(e)
        }
        createFence(e) {
            let t, n;
            if (ie().getBool("WEBGL_FENCE_API_ENABLED")) {
                const s = e
                  , r = s.fenceSync(s.SYNC_GPU_COMMANDS_COMPLETE, 0);
                e.flush(),
                n = ()=>{
                    const e = s.clientWaitSync(r, 0, 0);
                    return e === s.ALREADY_SIGNALED || e === s.CONDITION_SATISFIED
                }
                ,
                t = r
            } else
                ie().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0 ? (t = this.beginQuery(),
                this.endQuery(),
                n = ()=>this.isQueryAvailable(t, ie().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))) : n = ()=>!0;
            return {
                query: t,
                isFencePassed: n
            }
        }
        downloadMatrixFromPackedTexture(e, t, n) {
            return this.downloadMatrixDriver(e, (()=>function(e, t, n) {
                const s = new Float32Array(t * n * 4);
                return NN(e, (()=>e.readPixels(0, 0, n, t, e.RGBA, e.FLOAT, s))),
                s
            }(this.gl, t, n)))
        }
        createProgram(e) {
            this.throwIfDisposed();
            const t = this.gl;
            null == this.vertexShader && (this.vertexShader = GD(t));
            const n = function(e) {
                return MN(e, (()=>e.createProgram()), "Unable to create WebGLProgram.")
            }(t);
            let s;
            return NN(t, (()=>t.attachShader(n, this.vertexShader))),
            NN(t, (()=>t.attachShader(n, e))),
            function(e, t) {
                if (NN(e, (()=>e.linkProgram(t))),
                !ie().get("ENGINE_COMPILE_ONLY") && !1 === e.getProgramParameter(t, e.LINK_STATUS))
                    throw console.log(e.getProgramInfoLog(t)),
                    new Error("Failed to link vertex and fragment shaders.")
            }(t, n),
            s = Object.assign(n, {
                vao: this.createVertexArray()
            }),
            this.bindVertexArray(s.vao),
            NN(t, (()=>t.bindBuffer(t.ELEMENT_ARRAY_BUFFER, this.indexBuffer))),
            console.assert(function(e, t, n) {
                return NN(e, (()=>e.bindBuffer(e.ARRAY_BUFFER, n))),
                RN(e, t, "clipSpacePos", n, 3, 20, 0) && RN(e, t, "uv", n, 2, 20, 12)
            }(t, s, this.vertexBuffer), "gpgpu_util.bindVertexProgramAttributeStreams not fully successful."),
            this.debug && AN(t, s),
            this.setProgram(s),
            s
        }
        deleteProgram(e) {
            this.throwIfDisposed(),
            e === this.program && (this.program = null),
            null != e && (NN(this.gl, (()=>this.gl.deleteProgram(e))),
            this.deleteVertexArray(e.vao))
        }
        setProgram(e) {
            this.throwIfDisposed(),
            this.program = e,
            null != this.program && (this.bindVertexArray(this.program.vao),
            this.debug && AN(this.gl, this.program)),
            NN(this.gl, (()=>this.gl.useProgram(e)))
        }
        getUniformLocation(e, t, n=!0) {
            return this.throwIfDisposed(),
            n ? function(e, t, n) {
                return MN(e, (()=>e.getUniformLocation(t, n)), 'uniform "' + n + '" not present in program.')
            }(this.gl, e, t) : function(e, t, n) {
                return e.getUniformLocation(t, n)
            }(this.gl, e, t)
        }
        getAttributeLocation(e, t) {
            return this.throwIfDisposed(),
            NN(this.gl, (()=>this.gl.getAttribLocation(e, t)))
        }
        getUniformLocationNoThrow(e, t) {
            return this.throwIfDisposed(),
            this.gl.getUniformLocation(e, t)
        }
        setInputMatrixTexture(e, t, n) {
            this.throwIfDisposed(),
            this.throwIfNoProgram(),
            FN(this.gl, e, t, n)
        }
        setOutputMatrixTexture(e, t, n) {
            this.setOutputMatrixTextureDriver(e, n, t)
        }
        setOutputPackedMatrixTexture(e, t, n) {
            this.throwIfDisposed();
            const [s,r] = IN(t, n);
            this.setOutputMatrixTextureDriver(e, s, r)
        }
        setOutputMatrixWriteRegion(e, t, n, s) {
            this.setOutputMatrixWriteRegionDriver(n, e, s, t)
        }
        setOutputPackedMatrixWriteRegion(e, t, n, s) {
            throw new Error("setOutputPackedMatrixWriteRegion not implemented.")
        }
        debugValidate() {
            null != this.program && AN(this.gl, this.program),
            ON(this.gl)
        }
        executeProgram() {
            this.throwIfDisposed(),
            this.throwIfNoProgram();
            const e = this.gl;
            if (this.debug) {
                const e = this.getVertexArray();
                console.assert(e === this.program.vao, "VAO changed between setProgram and executeProgram!"),
                this.debugValidate()
            }
            NN(e, (()=>e.drawElements(e.TRIANGLES, 6, e.UNSIGNED_SHORT, 0)))
        }
        blockUntilAllProgramsCompleted() {
            this.throwIfDisposed(),
            NN(this.gl, (()=>this.gl.finish()))
        }
        getQueryTimerExtension() {
            return null == this.disjointQueryTimerExtension && (this.disjointQueryTimerExtension = CN(this.gl, 2 === ie().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") ? "EXT_disjoint_timer_query_webgl2" : "EXT_disjoint_timer_query")),
            this.disjointQueryTimerExtension
        }
        getQueryTimerExtensionWebGL2() {
            return this.getQueryTimerExtension()
        }
        getQueryTimerExtensionWebGL1() {
            return this.getQueryTimerExtension()
        }
        beginQuery() {
            if (2 === ie().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")) {
                const e = this.gl
                  , t = this.getQueryTimerExtensionWebGL2()
                  , n = e.createQuery();
                return e.beginQuery(t.TIME_ELAPSED_EXT, n),
                n
            }
            const e = this.getQueryTimerExtensionWebGL1()
              , t = e.createQueryEXT();
            return e.beginQueryEXT(e.TIME_ELAPSED_EXT, t),
            t
        }
        endQuery() {
            if (2 === ie().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")) {
                const e = this.gl
                  , t = this.getQueryTimerExtensionWebGL2();
                return void e.endQuery(t.TIME_ELAPSED_EXT)
            }
            const e = this.getQueryTimerExtensionWebGL1();
            e.endQueryEXT(e.TIME_ELAPSED_EXT)
        }
        async waitForQueryAndGetTime(e) {
            return await Hs.repeatedTry((()=>this.disposed || this.isQueryAvailable(e, ie().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")))),
            this.getQueryTime(e, ie().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))
        }
        getQueryTime(e, t) {
            if (0 === t)
                return null;
            if (2 === t) {
                const t = this.gl;
                return t.getQueryParameter(e, t.QUERY_RESULT) / 1e6
            }
            {
                const t = this.getQueryTimerExtensionWebGL1();
                return t.getQueryObjectEXT(e, t.QUERY_RESULT_EXT) / 1e6
            }
        }
        isQueryAvailable(e, t) {
            if (0 === t)
                return !0;
            if (2 === t) {
                const t = this.gl
                  , n = this.getQueryTimerExtensionWebGL2()
                  , s = t.getQueryParameter(e, t.QUERY_RESULT_AVAILABLE);
                return null == this.disjoint && (this.disjoint = this.gl.getParameter(n.GPU_DISJOINT_EXT)),
                s && !this.disjoint
            }
            {
                const t = this.getQueryTimerExtensionWebGL1()
                  , n = t.getQueryObjectEXT(e, t.QUERY_RESULT_AVAILABLE_EXT);
                return null == this.disjoint && (this.disjoint = this.gl.getParameter(t.GPU_DISJOINT_EXT)),
                n && !this.disjoint
            }
        }
        pollFence(e) {
            return new Promise((t=>{
                this.addItemToPoll((()=>e.isFencePassed()), (()=>t()))
            }
            ))
        }
        pollItems() {
            const e = function(e) {
                let t = 0;
                for (; t < e.length; ++t) {
                    if (!e[t]())
                        break
                }
                return t - 1
            }(this.itemsToPoll.map((e=>e.isDoneFn)));
            for (let t = 0; t <= e; ++t) {
                const {resolveFn: e} = this.itemsToPoll[t];
                e()
            }
            this.itemsToPoll = this.itemsToPoll.slice(e + 1)
        }
        addItemToPoll(e, t) {
            if (this.itemsToPoll.push({
                isDoneFn: e,
                resolveFn: t
            }),
            this.itemsToPoll.length > 1)
                return;
            let n;
            "setTimeoutCustom"in ie().platform && (n = ie().platform.setTimeoutCustom.bind(ie().platform)),
            Hs.repeatedTry((()=>(this.pollItems(),
            0 === this.itemsToPoll.length)), (()=>0), null, n)
        }
        bindTextureToFrameBuffer(e) {
            this.throwIfDisposed(),
            DN(this.gl, e, this.framebuffer),
            this.debug && ON(this.gl)
        }
        unbindTextureToFrameBuffer() {
            null != this.outputTexture ? (DN(this.gl, this.outputTexture, this.framebuffer),
            this.debug && ON(this.gl)) : _N(this.gl, this.framebuffer)
        }
        downloadMatrixDriver(e, t) {
            this.bindTextureToFrameBuffer(e);
            const n = t();
            return this.unbindTextureToFrameBuffer(),
            n
        }
        setOutputMatrixTextureDriver(e, t, n) {
            this.throwIfDisposed();
            const s = this.gl;
            DN(s, e, this.framebuffer),
            this.debug && ON(s),
            this.outputTexture = e,
            NN(s, (()=>s.viewport(0, 0, t, n))),
            NN(s, (()=>s.scissor(0, 0, t, n)))
        }
        setOutputMatrixWriteRegionDriver(e, t, n, s) {
            this.throwIfDisposed(),
            NN(this.gl, (()=>this.gl.scissor(e, t, n, s)))
        }
        throwIfDisposed() {
            if (this.disposed)
                throw new Error("Attempted to use disposed GPGPUContext.")
        }
        throwIfNoProgram() {
            if (null == this.program)
                throw new Error("No GPU program is currently set.")
        }
    }
    class t_ {
        constructor(e) {
            if (this.variableNames = ["A"],
            this.packedInputs = !1,
            this.packedOutput = !0,
            this.outputShape = e,
            this.rank = e.length,
            this.enableShapeUniforms = QN(this.outputShape.length),
            0 === this.rank)
                this.userCode = "\n        void main() {\n          setOutput(vec4(getA(), 0., 0., 0.));\n        }\n      ";
            else {
                const e = nT("rc", this.rank)
                  , t = hN(this.rank)
                  , n = this.getOutOfBoundsCondition(e)
                  , s = this.getSetup(e)
                  , r = this.getOutput(e);
                this.userCode = `\n        void main() {\n          ${t} rc = getOutputCoords();\n\n          if(${n}) {\n            setOutput(vec4(0));\n          } else {\n            ${s}\n\n            setOutput(vec4(${r}));\n          }\n        }\n      `
            }
        }
        getSourceCoordsArr(e) {
            const t = [];
            for (let n = 0; n <= 1; n++)
                for (let s = 0; s <= 1; s++) {
                    let r = `${0 === n ? "r" : "rp1"}, ${0 === s ? "c" : "cp1"}`;
                    for (let t = 2; t < this.rank; t++)
                        r = `${e[e.length - 1 - t]},` + r;
                    t.push(r)
                }
            return t
        }
        getOutOfBoundsCondition(e) {
            if (1 === this.rank)
                return `rc > ${this.enableShapeUniforms ? "outShape" : this.outputShape[0]}`;
            let t = "";
            for (let n = this.rank - 2; n < this.rank; n++)
                t += `${e[n]} >= ${this.enableShapeUniforms ? `outShape[${n}]` : this.outputShape[n]}`,
                n < this.rank - 1 && (t += "||");
            return t
        }
        getSetup(e) {
            if (1 === this.rank)
                return "";
            const t = e.slice(-2)
              , n = this.enableShapeUniforms ? `outShape[${this.rank} - 1]` : this.outputShape[this.rank - 1]
              , s = this.enableShapeUniforms ? `outShape[${this.rank} - 2]` : this.outputShape[this.rank - 2];
            return `\n      int r = ${t[0]};\n      int c = ${t[1]};\n      int rp1 = r + 1;\n      int cp1 = c + 1;\n\n      bool cEdge = cp1 >= ${n};\n      bool rEdge = rp1 >= ${s};\n    `
        }
        getOutput(e) {
            const t = this.getSourceCoordsArr(e);
            if (1 === this.rank) {
                return `getA(rc), (rc + 1 >= ${this.enableShapeUniforms ? "outShape" : this.outputShape[0]} ? 0. : getA(rc + 1)), 0, 0`
            }
            return `getA(${t[0]}),\n            cEdge ? 0. : getA(${t[1]}),\n            rEdge ? 0. : getA(${t[2]}),\n            rEdge || cEdge ? 0. : getA(${t[3]})`
        }
    }
    class n_ {
        constructor(e) {
            this.gpgpu = e,
            this.numUsedTextures = 0,
            this.numFreeTextures = 0,
            this._numBytesAllocated = 0,
            this._numBytesFree = 0,
            this.freeTextures = {},
            this.logEnabled = !1,
            this.usedTextures = {}
        }
        acquireTexture(e, t, n) {
            const s = r_(t, n)
              , r = a_(e, s, n);
            r in this.freeTextures || (this.freeTextures[r] = []),
            r in this.usedTextures || (this.usedTextures[r] = []);
            const a = s_(e, s, this.gpgpu.gl, this.gpgpu.textureConfig, n);
            if (this.freeTextures[r].length > 0) {
                this.numFreeTextures--,
                this.numUsedTextures++,
                this._numBytesFree -= a,
                this.log();
                const e = this.freeTextures[r].shift();
                return this.usedTextures[r].push(e),
                e
            }
            let i;
            return s === wN.PACKED_2X2_FLOAT32 ? i = this.gpgpu.createPackedMatrixTexture(e[0], e[1]) : s === wN.PACKED_2X2_FLOAT16 ? i = this.gpgpu.createFloat16PackedMatrixTexture(e[0], e[1]) : s === wN.UNPACKED_FLOAT32 ? i = this.gpgpu.createFloat32MatrixTexture(e[0], e[1]) : s === wN.UNPACKED_FLOAT16 ? i = this.gpgpu.createFloat16MatrixTexture(e[0], e[1]) : s === wN.PACKED_4X1_UNSIGNED_BYTE && (i = this.gpgpu.createUnsignedBytesMatrixTexture(e[0], e[1])),
            this.usedTextures[r].push(i),
            this.numUsedTextures++,
            this._numBytesAllocated += a,
            this.log(),
            i
        }
        releaseTexture(e, t, n, s) {
            if (null == this.freeTextures)
                return;
            const r = r_(n, s)
              , a = a_(t, r, s);
            a in this.freeTextures || (this.freeTextures[a] = []);
            const i = s_(t, r, this.gpgpu.gl, this.gpgpu.textureConfig, s)
              , o = ie().get("WEBGL_DELETE_TEXTURE_THRESHOLD");
            -1 !== o && this._numBytesAllocated > o ? (this.gpgpu.deleteMatrixTexture(e.texture),
            this._numBytesAllocated -= i) : (this.freeTextures[a].push(e),
            this.numFreeTextures++,
            this._numBytesFree += i),
            this.numUsedTextures--;
            const l = this.usedTextures[a]
              , u = l.indexOf(e);
            if (u < 0)
                throw new Error("Cannot release a texture that was never provided by this texture manager");
            l.splice(u, 1),
            this.log()
        }
        log() {
            if (!this.logEnabled)
                return;
            const e = this.numFreeTextures + this.numUsedTextures;
            console.log("Free/Used", `${this.numFreeTextures} / ${this.numUsedTextures}`, `(${e})`);
            const t = this._numBytesFree / this._numBytesAllocated;
            console.log(`Bytes allocated: ${this._numBytesAllocated}`),
            console.log(`Bytes unused: ${this._numBytesFree} (${Math.round(100 * t)}%)`)
        }
        get numBytesAllocated() {
            return this._numBytesAllocated
        }
        get numBytesFree() {
            return this._numBytesFree
        }
        getNumUsedTextures() {
            return this.numUsedTextures
        }
        getNumFreeTextures() {
            return this.numFreeTextures
        }
        dispose() {
            if (null != this.freeTextures) {
                for (const e in this.freeTextures)
                    this.freeTextures[e].forEach((e=>{
                        this.gpgpu.deleteMatrixTexture(e.texture)
                    }
                    ));
                for (const e in this.usedTextures)
                    this.usedTextures[e].forEach((e=>{
                        this.gpgpu.deleteMatrixTexture(e.texture)
                    }
                    ));
                this.freeTextures = null,
                this.usedTextures = null,
                this.numUsedTextures = 0,
                this.numFreeTextures = 0,
                this._numBytesAllocated = 0,
                this._numBytesFree = 0
            }
        }
    }
    function s_(e, t, n, s, r) {
        const a = function(e, t) {
            switch (e) {
            case wN.PACKED_2X2_FLOAT32:
                return ZD(t);
            case wN.PACKED_2X2_FLOAT16:
                return JD(t);
            case wN.UNPACKED_FLOAT32:
                return KD(t);
            case wN.UNPACKED_FLOAT16:
                return XD(t);
            case wN.PACKED_4X1_UNSIGNED_BYTE:
                return YD(t);
            default:
                throw new Error(`Unknown physical texture type ${e}`)
            }
        }(t, s);
        let i;
        if (r) {
            const [t,n] = IN(e[0], e[1]);
            i = t * n
        } else {
            const [t,n] = vN(e[0], e[1]);
            i = t * n
        }
        const o = function(e, t) {
            const n = e;
            if (t === n.R32F)
                return 4;
            if (t === n.R16F)
                return 2;
            if (t === n.RGBA32F)
                return 16;
            if (t === e.RGBA)
                return 16;
            if (t === n.RGBA16F)
                return 8;
            if (t === n.RGBA8)
                return 4;
            throw new Error(`Unknown internal format ${t}`)
        }(n, a);
        return i * o
    }
    function r_(e, t) {
        if (e === xN.UPLOAD)
            return wN.PACKED_2X2_FLOAT32;
        if (e === xN.RENDER || null == e)
            return function(e) {
                return ie().getBool("WEBGL_RENDER_FLOAT32_ENABLED") ? e ? wN.PACKED_2X2_FLOAT32 : wN.UNPACKED_FLOAT32 : e ? wN.PACKED_2X2_FLOAT16 : wN.UNPACKED_FLOAT16
            }(t);
        if (e === xN.DOWNLOAD || e === xN.PIXELS)
            return wN.PACKED_4X1_UNSIGNED_BYTE;
        throw new Error(`Unknown logical texture type ${e}`)
    }
    function a_(e, t, n) {
        return `${e[0]}_${e[1]}_${t}_${n}`
    }
    class i_ {
        constructor(e) {
            this.variableNames = ["A"],
            this.packedInputs = !0,
            this.packedOutput = !1,
            this.outputShape = e,
            this.enableShapeUniforms = QN(this.outputShape.length);
            const t = e.length
              , n = nT("rc", t)
              , s = hN(t)
              , r = function(e, t) {
                if (1 === e)
                    return "rc";
                let n = "";
                for (let s = 0; s < e; s++)
                    n += t[s],
                    s < e - 1 && (n += ",");
                return n
            }(t, n)
              , a = n.slice(-2)
              , i = t <= 1 ? "rc" : `vec2(${a.join(",")})`;
            this.userCode = `\n      void main() {\n        ${s} rc = getOutputCoords();\n        vec4 packedInput = getA(${r});\n\n        setOutput(getChannel(packedInput, ${i}));\n      }\n    `
        }
    }
    const o_ = Dg.whereImpl
      , l_ = {};
    const u_ = ie().getNumber("CPU_HANDOFF_SIZE_THRESHOLD");
    class c_ extends o {
        constructor(e) {
            if (super(),
            this.pendingRead = new WeakMap,
            this.pendingDisposal = new WeakSet,
            this.dataRefCount = new WeakMap,
            this.numBytesInGPU = 0,
            this.uploadWaitMs = 0,
            this.downloadWaitMs = 0,
            this.lastGlFlushTime = 0,
            this.warnedAboutMemory = !1,
            this.pendingDeletes = 0,
            this.disposed = !1,
            !ie().getBool("HAS_WEBGL"))
                throw new Error("WebGL is not supported on this device");
            let t;
            if (null != e) {
                if (e instanceof e_)
                    t = e;
                else {
                    const n = yN(ie().getNumber("WEBGL_VERSION"), e);
                    t = new e_(n)
                }
                this.binaryCache = {},
                this.gpgpuCreatedLocally = !1
            } else {
                const e = yN(ie().getNumber("WEBGL_VERSION"));
                t = new e_(e),
                this.binaryCache = ((n = ie().getNumber("WEBGL_VERSION"))in l_ || (l_[n] = {}),
                l_[n]),
                this.gpgpuCreatedLocally = !0
            }
            var n;
            this.gpgpu = t,
            this.canvas = this.gpgpu.gl.canvas,
            this.textureManager = new n_(this.gpgpu),
            this.numMBBeforeWarning = null == ie().global.screen ? 1024 : ie().global.screen.height * ie().global.screen.width * window.devicePixelRatio * 600 / 1024 / 1024,
            this.texData = new i(this,Zo())
        }
        nextDataId() {
            return c_.nextDataId++
        }
        numDataIds() {
            return this.texData.numDataIds() - this.pendingDeletes
        }
        writeTexture(e, t, n, s, r, a) {
            const i = this.makeTensorInfo(t, n)
              , o = this.texData.get(i.dataId);
            o.isPacked = !1,
            o.texture = {
                texture: e,
                texShape: [s, r]
            },
            o.texShape = [s, r];
            const l = PN(t)
              , u = new UD(l,!1,a)
              , c = this.runWebGLProgram(u, [i], n, [[s, r]]);
            return c.shape = t,
            o.texture = null,
            this.disposeIntermediateTensorInfo(i),
            c.dataId
        }
        write(e, t, n) {
            if ((ie().getBool("WEBGL_CHECK_NUMERICAL_PROBLEMS") || ie().getBool("DEBUG")) && this.checkNumericalProblems(e),
            "complex64" === n && null != e)
                throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");
            const s = {
                id: this.nextDataId()
            };
            return this.texData.set(s, {
                shape: t,
                dtype: n,
                values: e,
                usage: xN.UPLOAD,
                refCount: 1
            }),
            s
        }
        refCount(e) {
            if (this.texData.has(e)) {
                return this.texData.get(e).refCount
            }
            return 0
        }
        incRef(e) {
            this.texData.get(e).refCount++
        }
        decRef(e) {
            if (this.texData.has(e)) {
                this.texData.get(e).refCount--
            }
        }
        move(e, t, n, s, r) {
            if (ie().getBool("DEBUG") && this.checkNumericalProblems(t),
            "complex64" === s)
                throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");
            this.texData.set(e, {
                shape: n,
                dtype: s,
                values: t,
                usage: xN.UPLOAD,
                refCount: r
            })
        }
        disposeIntermediateTensorInfo(e) {
            this.disposeData(e.dataId)
        }
        readSync(e) {
            const t = this.texData.get(e)
              , {values: n, dtype: s, complexTensorInfos: r, slice: a, shape: i, isPacked: o} = t;
            if (null != a) {
                let t;
                t = o ? new yT(i,gT) : new fT(i,gT);
                const n = this.runWebGLProgram(t, [{
                    dataId: e,
                    shape: i,
                    dtype: s
                }], s)
                  , r = this.readSync(n.dataId);
                return this.disposeIntermediateTensorInfo(n),
                r
            }
            if (null != n)
                return this.convertAndCacheOnCPU(e);
            if ("string" === s)
                return n;
            const l = null != this.activeTimers;
            let u, c;
            if (l && (u = Hs.now()),
            "complex64" === s) {
                const e = this.readSync(r.real.dataId)
                  , t = this.readSync(r.imag.dataId);
                c = dm.mergeRealAndImagArrays(e, t)
            } else
                c = this.getValuesFromTexture(e);
            return l && (this.downloadWaitMs += Hs.now() - u),
            this.convertAndCacheOnCPU(e, c)
        }
        async read(e) {
            if (this.pendingRead.has(e)) {
                const t = this.pendingRead.get(e);
                return new Promise((e=>t.push(e)))
            }
            const t = this.texData.get(e)
              , {values: n, shape: s, slice: r, dtype: a, complexTensorInfos: i, isPacked: o} = t;
            if (null != r) {
                let t;
                t = o ? new yT(s,gT) : new fT(s,gT);
                const n = this.runWebGLProgram(t, [{
                    dataId: e,
                    shape: s,
                    dtype: a
                }], a)
                  , r = this.read(n.dataId);
                return this.disposeIntermediateTensorInfo(n),
                r
            }
            if (null != n)
                return this.convertAndCacheOnCPU(e);
            if (ie().getBool("DEBUG") && !ie().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED") && 2 === ie().getNumber("WEBGL_VERSION"))
                throw new Error("tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and WEBGL_VERSION=2 not yet supported.");
            let l, u, c = null;
            if ("complex64" !== a && ie().get("WEBGL_BUFFER_SUPPORTED")) {
                l = this.decode(e);
                const t = this.texData.get(l.dataId);
                c = this.gpgpu.createBufferFromTexture(t.texture.texture, ...kN(s))
            }
            if (this.pendingRead.set(e, []),
            "complex64" !== a && await this.gpgpu.createAndWaitForFence(),
            "complex64" === a) {
                const e = await Promise.all([this.read(i.real.dataId), this.read(i.imag.dataId)])
                  , t = e[0]
                  , n = e[1];
                u = dm.mergeRealAndImagArrays(t, n)
            } else if (null == c)
                u = this.getValuesFromTexture(e);
            else {
                const e = Hs.sizeFromShape(s);
                u = this.gpgpu.downloadFloat32MatrixFromBuffer(c, e)
            }
            if (null != l && this.disposeIntermediateTensorInfo(l),
            null != c) {
                const e = this.gpgpu.gl;
                NN(e, (()=>e.deleteBuffer(c)))
            }
            const h = this.convertAndCacheOnCPU(e, u)
              , p = this.pendingRead.get(e);
            return this.pendingRead.delete(e),
            p.forEach((e=>e(h))),
            this.pendingDisposal.has(e) && (this.pendingDisposal.delete(e),
            this.disposeData(e) && Zo().removeDataId(e, this),
            this.pendingDeletes--),
            h
        }
        readToGPU(e, t={}) {
            const n = this.texData.get(e)
              , {values: s, shape: r, slice: a, dtype: i, isPacked: o, texture: l} = n;
            if ("complex64" === i)
                throw new Error("Does not support reading texture for complex64 dtype.");
            if (null != a) {
                let n;
                n = o ? new yT(r,gT) : new fT(r,gT);
                const s = this.runWebGLProgram(n, [{
                    dataId: e,
                    shape: r,
                    dtype: i
                }], i)
                  , a = this.readToGPU(s, t);
                return this.disposeIntermediateTensorInfo(s),
                a
            }
            if (null == l)
                throw null != s ? new Error("Data is not on GPU but on CPU.") : new Error("There is no data on GPU or CPU.");
            const u = this.decode(e, t.customTexShape)
              , c = Zo().makeTensorFromTensorInfo(u)
              , h = this.texData.get(u.dataId);
            return Object.assign({
                tensorRef: c
            }, h.texture)
        }
        bufferSync(e) {
            const t = this.readSync(e.dataId);
            if ("string" === e.dtype)
                try {
                    const n = t.map((e=>Hs.decodeString(e)));
                    return qo(e.shape, e.dtype, n)
                } catch (e) {
                    throw new Error("Failed to decode encoded string bytes into utf-8")
                }
            return qo(e.shape, e.dtype, t)
        }
        checkNumericalProblems(e) {
            if (null != e)
                for (let t = 0; t < e.length; t++) {
                    const n = e[t];
                    if (!TN(n)) {
                        if (ie().getBool("WEBGL_RENDER_FLOAT32_CAPABLE"))
                            throw Error(`The value ${n} cannot be represented with your current settings. Consider enabling float32 rendering: 'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'`);
                        throw Error(`The value ${n} cannot be represented on this device.`)
                    }
                }
        }
        getValuesFromTexture(e) {
            const {shape: t, dtype: n, isPacked: s} = this.texData.get(e)
              , r = Hs.sizeFromShape(t);
            if (ie().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")) {
                const n = this.decode(e)
                  , s = this.texData.get(n.dataId)
                  , a = this.gpgpu.downloadMatrixFromPackedTexture(s.texture.texture, ...kN(t)).subarray(0, r);
                return this.disposeIntermediateTensorInfo(n),
                a
            }
            const a = ie().getBool("WEBGL_PACK") && !0 === s
              , i = a ? PN(t) : t
              , o = a ? new PD(i) : new BD(i)
              , l = this.runWebGLProgram(o, [{
                shape: i,
                dtype: n,
                dataId: e
            }], "float32")
              , u = this.texData.get(l.dataId)
              , c = this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(u.texture.texture, u.texShape[0], u.texShape[1]).subarray(0, r);
            return this.disposeIntermediateTensorInfo(l),
            c
        }
        timerAvailable() {
            return ie().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0
        }
        time(e) {
            const t = this.activeTimers
              , n = [];
            let s = !1;
            null == this.programTimersStack ? (this.programTimersStack = n,
            s = !0) : this.activeTimers.push(n),
            this.activeTimers = n,
            e();
            const r = Hs.flatten(this.activeTimers.map((e=>e.query))).filter((e=>null != e))
              , a = Hs.flatten(this.activeTimers.map((e=>e.name))).filter((e=>null != e));
            this.activeTimers = t,
            s && (this.programTimersStack = null);
            const i = {
                uploadWaitMs: this.uploadWaitMs,
                downloadWaitMs: this.downloadWaitMs,
                kernelMs: null,
                wallMs: null
            };
            return (async()=>{
                if (ie().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
                    const e = await Promise.all(r);
                    i.kernelMs = Hs.sum(e),
                    i.getExtraProfileInfo = ()=>e.map(((e,t)=>({
                        name: a[t],
                        ms: e
                    }))).map((e=>`${e.name}: ${e.ms}`)).join(", ")
                } else
                    i.kernelMs = {
                        error: "WebGL query timers are not supported in this environment."
                    };
                return this.uploadWaitMs = 0,
                this.downloadWaitMs = 0,
                i
            }
            )()
        }
        memory() {
            return {
                unreliable: !1,
                numBytesInGPU: this.numBytesInGPU,
                numBytesInGPUAllocated: this.textureManager.numBytesAllocated,
                numBytesInGPUFree: this.textureManager.numBytesFree
            }
        }
        startTimer() {
            return ie().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0 ? this.gpgpu.beginQuery() : {
                startMs: Hs.now(),
                endMs: null
            }
        }
        endTimer(e) {
            return ie().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0 ? (this.gpgpu.endQuery(),
            e) : (e.endMs = Hs.now(),
            e)
        }
        async getQueryTime(e) {
            if (ie().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0)
                return this.gpgpu.waitForQueryAndGetTime(e);
            const t = e;
            return t.endMs - t.startMs
        }
        disposeData(e, t=!1) {
            if (this.pendingDisposal.has(e))
                return !1;
            if (!this.texData.has(e))
                return !0;
            if (t ? this.texData.get(e).refCount = 0 : this.texData.get(e).refCount--,
            !t && this.texData.get(e).refCount > 0)
                return !1;
            if (this.pendingRead.has(e))
                return this.pendingDisposal.add(e),
                this.pendingDeletes++,
                !1;
            this.releaseGPUData(e);
            const {complexTensorInfos: n} = this.texData.get(e);
            return null != n && (this.disposeData(n.real.dataId, t),
            this.disposeData(n.imag.dataId, t)),
            this.texData.delete(e),
            !0
        }
        releaseGPUData(e) {
            const {texture: t, dtype: n, texShape: s, usage: r, isPacked: a, slice: i} = this.texData.get(e)
              , o = i && i.origDataId || e
              , l = this.dataRefCount.get(o);
            l > 1 ? this.dataRefCount.set(o, l - 1) : (this.dataRefCount.delete(o),
            null != t && (this.numBytesInGPU -= this.computeBytes(s, n),
            this.textureManager.releaseTexture(t, s, r, a)));
            const u = this.texData.get(e);
            u.texture = null,
            u.texShape = null,
            u.isPacked = !1,
            u.slice = null
        }
        getTexture(e) {
            return this.uploadToGPU(e),
            this.texData.get(e).texture.texture
        }
        getDataInfo(e) {
            return this.texData.get(e)
        }
        shouldExecuteOnCPU(e, t=u_) {
            return ie().getBool("WEBGL_CPU_FORWARD") && e.every((e=>null == this.texData.get(e.dataId).texture && Hs.sizeFromShape(e.shape) < t))
        }
        getGPGPUContext() {
            return this.gpgpu
        }
        where(e) {
            dm.warn("tf.where() in webgl locks the UI thread. Call tf.whereAsync() instead");
            const t = e.dataSync();
            return o_(e.shape, t)
        }
        packedUnaryOp(e, t, n) {
            const s = new yT(e.shape,t)
              , r = this.compileAndRun(s, [e], n);
            return Zo().makeTensorFromTensorInfo(r)
        }
        abs(e) {
            if (this.shouldExecuteOnCPU([e]) && "complex64" !== e.dtype) {
                const t = rC(this.texData.get(e.dataId).values);
                return this.makeOutput(e.shape, e.dtype, t)
            }
            if (ie().getBool("WEBGL_PACK_UNARY_OPERATIONS"))
                return this.packedUnaryOp(e, mT, e.dtype);
            const t = new fT(e.shape,mT)
              , n = this.compileAndRun(t, [e]);
            return Zo().makeTensorFromTensorInfo(n)
        }
        makeTensorInfo(e, t, n) {
            let s;
            if ("string" === t && null != n && n.length > 0 && Hs.isString(n[0])) {
                const r = n.map((e=>Hs.encodeString(e)));
                s = this.write(r, e, t)
            } else
                s = this.write(n, e, t);
            return this.texData.get(s).usage = null,
            {
                dataId: s,
                shape: e,
                dtype: t
            }
        }
        makeOutput(e, t, n) {
            return Zo().makeTensorFromTensorInfo(this.makeTensorInfo(e, t, n), this)
        }
        unpackTensor(e) {
            const t = new i_(e.shape);
            return this.runWebGLProgram(t, [e], e.dtype)
        }
        packTensor(e) {
            const t = new t_(e.shape);
            return this.runWebGLProgram(t, [e], e.dtype, null, !0)
        }
        packedReshape(e, t) {
            const n = [zN(e.shape), ...BN(e.shape)]
              , s = {
                dtype: e.dtype,
                shape: n,
                dataId: e.dataId
            }
              , r = [zN(t), ...BN(t)]
              , a = new kC(r,n)
              , i = [n]
              , o = this.runWebGLProgram(a, [s], e.dtype, i, !0);
            return {
                dataId: o.dataId,
                shape: t,
                dtype: o.dtype
            }
        }
        decode(e, t) {
            const n = this.texData.get(e)
              , {isPacked: s, shape: r, dtype: a} = n;
            if (null != t) {
                const e = Hs.sizeFromShape(r)
                  , n = t[0] * t[1] * 4;
                Hs.assert(e <= n, (()=>"customTexShape is too small. Row * Column * 4 should be equal or larger than the size of the tensor data."))
            }
            const i = PN(r);
            let o;
            o = s ? new zD(i) : new LD(i);
            const l = [null != t ? t : kN(i)];
            return {
                dtype: a,
                shape: r,
                dataId: this.runWebGLProgram(o, [{
                    shape: i,
                    dtype: a,
                    dataId: e
                }], a, l, !0, t).dataId
            }
        }
        runWebGLProgram(e, t, n, s, r=!1, a) {
            const i = this.makeTensorInfo(e.outputShape, n)
              , o = this.texData.get(i.dataId);
            if (e.packedOutput && (o.isPacked = !0),
            e.outPackingScheme === bN.DENSE) {
                const t = null != a ? a : kN(e.outputShape);
                o.texShape = t.map((e=>2 * e))
            }
            if (null != e.outTexUsage && (o.usage = e.outTexUsage),
            0 === Hs.sizeFromShape(i.shape))
                return o.values = Hs.getTypedArrayFromDType(i.dtype, 0),
                i;
            const l = []
              , u = t.map((t=>{
                if ("complex64" === t.dtype)
                    throw new Error("GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.");
                let n = this.texData.get(t.dataId);
                if (null == n.texture) {
                    if (!e.packedInputs && Hs.sizeFromShape(t.shape) <= ie().getNumber("WEBGL_SIZE_UPLOAD_UNIFORM"))
                        return {
                            shape: t.shape,
                            texData: null,
                            isUniform: !0,
                            uniformValues: n.values
                        };
                    e.packedInputs && (n.isPacked = !0,
                    n.shape = t.shape)
                }
                if (this.uploadToGPU(t.dataId),
                !!n.isPacked != !!e.packedInputs)
                    t = n.isPacked ? this.unpackTensor(t) : this.packTensor(t),
                    l.push(t),
                    n = this.texData.get(t.dataId);
                else if (n.isPacked && !UN(n.shape, t.shape)) {
                    const e = t
                      , s = t.shape;
                    t.shape = n.shape,
                    t = this.packedReshape(t, s),
                    l.push(t),
                    n = this.texData.get(t.dataId),
                    e.shape = s
                }
                return {
                    shape: t.shape,
                    texData: n,
                    isUniform: !1
                }
            }
            ));
            this.uploadToGPU(i.dataId);
            const c = {
                shape: i.shape,
                texData: o,
                isUniform: !1
            }
              , h = function(e, t, n) {
                let s = "";
                t.concat(n).forEach((t=>{
                    const r = null != t.texData && null != t.texData.slice && t.texData.slice.flatOffset > 0;
                    if (e.enableShapeUniforms && !t.isUniform) {
                        const a = t.texData.texShape
                          , {useSqueezeShape: i, uniformShape: o, keptDims: l} = pN(e.packedInputs, t.shape, a);
                        let u = ""
                          , c = ""
                          , h = "";
                        if (1 === o.length && e.packedInputs) {
                            const e = [Math.ceil(a[0] / 2), Math.ceil(a[1] / 2)];
                            u = `${e[0] > 1}_${e[1] > 1}`
                        } else if (2 !== o.length || e.packedInputs) {
                            if (o.length > 2 && !e.packedInputs) {
                                const e = Hs.computeStrides(o);
                                h = `${e[0] === a[1]}_${e[e.length - 1] === a[1]}`
                            }
                        } else
                            c = `${o[0] > 1}_${o[1] > 1}`;
                        const p = t.shape.length
                          , d = 2 === o.length && Hs.arraysEqual(t.shape, a)
                          , f = 1 === Hs.sizeFromShape(t.shape)
                          , m = dm.getBroadcastDims(t.shape, n.shape)
                          , g = !e.packedInputs && p === n.shape.length && Hs.arraysEqual(a, n.texData.texShape)
                          , y = e.packedInputs || o.length > 2 ? "" : `${a[0] > 1}_${a[1] > 1}`;
                        s += `${p}_${g}_${i ? l : ""}_${o.length}_${f}_${m}_${d}_${u}_${c}_${h}_${y}_${r}`
                    } else {
                        const e = t.isUniform ? "uniform" : t.texData.texShape;
                        s += `${t.shape}_${e}_${r}`
                    }
                }
                ));
                const r = e.userCode;
                let a = e.constructor.name;
                return a += "_" + s + "_" + r + `${ie().getNumber("WEBGL_VERSION")}`,
                a
            }(e, u, c)
              , p = this.getAndSaveBinary(h, (()=>YN(this.gpgpu, e, u, c)))
              , d = null != this.activeTimers;
            let f;
            d && (f = this.startTimer()),
            ie().get("ENGINE_COMPILE_ONLY") || function(e, t, n, s, r) {
                t.program.enableShapeUniforms || (JN(t.inShapeInfos, n),
                JN([t.outShapeInfo], [s]));
                const a = s.texData.texture
                  , i = s.texData.texShape;
                s.texData.isPacked ? e.setOutputPackedMatrixTexture(a.texture, i[0], i[1]) : e.setOutputMatrixTexture(a.texture, i[0], i[1]),
                e.setProgram(t.webGLProgram),
                1 === ie().getNumber("WEBGL_VERSION") && null !== t.infLoc && e.gl.uniform1f(t.infLoc, 1 / 0),
                null !== t.nanLoc && e.gl.uniform1f(t.nanLoc, NaN),
                n.forEach(((n,s)=>{
                    const r = t.program.variableNames[s]
                      , a = t.uniformLocations[r]
                      , i = t.uniformLocations[`offset${r}`]
                      , o = t.inShapesLocations[`${r}Shape`]
                      , l = t.inTexShapesLocations[`${r}TexShape`];
                    if (o) {
                        const {uniformShape: s} = pN(t.program.packedInputs, n.shape, n.texData.texShape);
                        switch (s.length) {
                        case 1:
                            e.gl.uniform1iv(o, new Int32Array(s));
                            break;
                        case 2:
                            e.gl.uniform2iv(o, new Int32Array(s));
                            break;
                        case 3:
                            e.gl.uniform3iv(o, new Int32Array(s));
                            break;
                        case 4:
                            e.gl.uniform4iv(o, new Int32Array(s))
                        }
                    }
                    if (l && e.gl.uniform2i(l, n.texData.texShape[0], n.texData.texShape[1]),
                    null != a)
                        if (n.isUniform)
                            if (Hs.sizeFromShape(n.shape) < 2)
                                e.gl.uniform1f(a, n.uniformValues[0]);
                            else {
                                let t = n.uniformValues;
                                t instanceof Float32Array || (t = new Float32Array(t)),
                                e.gl.uniform1fv(a, t)
                            }
                        else
                            null != n.texData.slice && null != i && e.gl.uniform1i(i, n.texData.slice.flatOffset),
                            e.setInputMatrixTexture(n.texData.texture.texture, a, s)
                }
                ));
                const o = t.outShapeLocation;
                if (o)
                    switch (s.shape.length) {
                    case 1:
                        e.gl.uniform1iv(o, new Int32Array(s.shape));
                        break;
                    case 2:
                        e.gl.uniform2iv(o, new Int32Array(s.shape));
                        break;
                    case 3:
                        e.gl.uniform3iv(o, new Int32Array(s.shape));
                        break;
                    case 4:
                        e.gl.uniform4iv(o, new Int32Array(s.shape))
                    }
                if (t.outShapeStridesLocation) {
                    const n = Hs.computeStrides(s.shape);
                    switch (s.shape.length) {
                    case 2:
                        e.gl.uniform1iv(t.outShapeStridesLocation, new Int32Array(n));
                        break;
                    case 3:
                        e.gl.uniform2iv(t.outShapeStridesLocation, new Int32Array(n));
                        break;
                    case 4:
                        e.gl.uniform3iv(t.outShapeStridesLocation, new Int32Array(n))
                    }
                }
                t.outTexShapeLocation && e.gl.uniform2i(t.outTexShapeLocation, s.texData.texShape[0], s.texData.texShape[1]),
                t.program.customUniforms && r && t.program.customUniforms.forEach(((n,s)=>{
                    const a = t.customUniformLocations[s]
                      , i = r[s];
                    if ("float" === n.type)
                        e.gl.uniform1fv(a, i);
                    else if ("vec2" === n.type)
                        e.gl.uniform2fv(a, i);
                    else if ("vec3" === n.type)
                        e.gl.uniform3fv(a, i);
                    else if ("vec4" === n.type)
                        e.gl.uniform4fv(a, i);
                    else if ("int" === n.type)
                        e.gl.uniform1iv(a, i);
                    else if ("ivec2" === n.type)
                        e.gl.uniform2iv(a, i);
                    else if ("ivec3" === n.type)
                        e.gl.uniform3iv(a, i);
                    else {
                        if ("ivec4" !== n.type)
                            throw Error(`uniform type ${n.type} is not supported yet.`);
                        e.gl.uniform4iv(a, i)
                    }
                }
                )),
                e.executeProgram()
            }(this.gpgpu, p, u, c, s),
            l.forEach((e=>this.disposeIntermediateTensorInfo(e))),
            d && (f = this.endTimer(f),
            this.activeTimers.push({
                name: e.constructor.name,
                query: this.getQueryTime(f)
            }));
            const m = ie().get("WEBGL_FLUSH_THRESHOLD");
            if (m > 0) {
                const e = Hs.now();
                e - this.lastGlFlushTime > m && (this.gpgpu.gl.flush(),
                this.lastGlFlushTime = e)
            }
            if (!ie().getBool("WEBGL_LAZILY_UNPACK") && o.isPacked && !1 === r) {
                const e = this.unpackTensor(i);
                return this.disposeIntermediateTensorInfo(i),
                e
            }
            return i
        }
        compileAndRun(e, t, n, s, r=!1) {
            n = n || t[0].dtype;
            return this.runWebGLProgram(e, t, n, s, r)
        }
        getAndSaveBinary(e, t) {
            return e in this.binaryCache || (this.binaryCache[e] = t()),
            this.binaryCache[e]
        }
        getTextureManager() {
            return this.textureManager
        }
        dispose() {
            if (!this.disposed) {
                if (!ie().getBool("IS_TEST")) {
                    Object.keys(this.binaryCache).forEach((e=>{
                        this.gpgpu.deleteProgram(this.binaryCache[e].webGLProgram),
                        delete this.binaryCache[e]
                    }
                    ))
                }
                this.textureManager.dispose(),
                null != this.canvas && "undefined" != typeof HTMLCanvasElement && this.canvas instanceof HTMLCanvasElement ? this.canvas.remove() : this.canvas = null,
                this.gpgpuCreatedLocally && (this.gpgpu.program = null,
                this.gpgpu.dispose()),
                this.disposed = !0
            }
        }
        floatPrecision() {
            return null == this.floatPrecisionValue && (this.floatPrecisionValue = Qo((()=>{
                if (!ie().get("WEBGL_RENDER_FLOAT32_ENABLED")) {
                    const e = ie().getBool("DEBUG");
                    ie().set("DEBUG", !1);
                    const t = this.abs(wl(1e-8)).dataSync()[0];
                    if (ie().set("DEBUG", e),
                    t > 0)
                        return 32
                }
                return 16
            }
            ))),
            this.floatPrecisionValue
        }
        epsilon() {
            return 32 === this.floatPrecision() ? 1e-7 : 1e-4
        }
        uploadToGPU(e) {
            const t = this.texData.get(e)
              , {shape: n, dtype: s, values: r, texture: a, usage: i, isPacked: o} = t;
            if (null != a)
                return;
            const l = null != this.activeTimers;
            let u;
            l && (u = Hs.now());
            let c = t.texShape;
            if (null == c && (c = function(e, t=!1) {
                let n = ie().getNumber("WEBGL_MAX_TEXTURE_SIZE")
                  , s = ie().getNumber("WEBGL_MAX_SIZE_FOR_NARROW_TEXTURE");
                if (s === 1 / 0 && ie().getBool("WEBGL_AUTO_SQUARIFY_NARROW_TEXTURE_SHAPE") && (s = n / 2),
                t && (n *= 2,
                s *= 2,
                1 === (e = e.map(((t,n)=>n >= e.length - 2 ? Hs.nearestLargerEven(e[n]) : e[n]))).length && (e = [2, e[0]])),
                2 !== e.length) {
                    const t = Hs.squeezeShape(e);
                    e = t.newShape
                }
                let r = Hs.sizeFromShape(e)
                  , a = null;
                e.length <= 1 && r <= n ? a = [1, r] : 2 === e.length && e[0] <= n && e[1] <= n ? a = e : 3 === e.length && e[0] * e[1] <= n && e[2] <= n ? a = [e[0] * e[1], e[2]] : 3 === e.length && e[0] <= n && e[1] * e[2] <= n ? a = [e[0], e[1] * e[2]] : 4 === e.length && e[0] * e[1] * e[2] <= n && e[3] <= n ? a = [e[0] * e[1] * e[2], e[3]] : 4 === e.length && e[0] <= n && e[1] * e[2] * e[3] <= n && (a = [e[0], e[1] * e[2] * e[3]]);
                const i = null != a && Math.max(...a) > s && Math.min(...a) <= (t ? 2 : 1) && Math.min(...a) > 0;
                if (null == a || i)
                    if (t) {
                        const t = zN(e);
                        let n = 2
                          , s = 2;
                        e.length && ([n,s] = BN(e)),
                        r = t * (n / 2) * (s / 2),
                        a = Hs.sizeToSquarishShape(r).map((e=>2 * e))
                    } else
                        a = Hs.sizeToSquarishShape(r);
                return a
            }(n, o),
            t.texShape = c),
            null != r) {
                const e = PN(n);
                let a, i = c[1], h = c[0];
                const p = r instanceof Uint8Array || r instanceof Uint8ClampedArray;
                !o && p || ([i,h] = IN(c[0], c[1])),
                a = o ? new VD(e,p) : new UD(e,p);
                const d = p ? [h, i] : c
                  , f = this.makeTensorInfo(d, s)
                  , m = this.texData.get(f.dataId);
                m.usage = p ? xN.PIXELS : xN.UPLOAD,
                m.texShape = d,
                this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(f.dataId), i, h, r);
                const g = [[h, i]]
                  , y = !0
                  , b = this.runWebGLProgram(a, [f], s, g, y)
                  , x = this.texData.get(b.dataId);
                t.texShape = x.texShape,
                t.isPacked = x.isPacked,
                t.usage = x.usage,
                ie().get("ENGINE_COMPILE_ONLY") ? this.disposeData(b.dataId) : (t.texture = x.texture,
                t.values = null,
                this.texData.delete(b.dataId)),
                this.disposeIntermediateTensorInfo(f),
                l && (this.uploadWaitMs += Hs.now() - u)
            } else {
                const e = this.acquireTexture(c, i, s, o);
                t.texture = e
            }
        }
        convertAndCacheOnCPU(e, t) {
            const n = this.texData.get(e)
              , {dtype: s} = n;
            return null != t && (n.values = function(e, t) {
                if ("float32" === t || "complex64" === t)
                    return e;
                if ("int32" === t || "bool" === t) {
                    const n = "int32" === t ? new Int32Array(e.length) : new Uint8Array(e.length);
                    for (let t = 0; t < n.length; ++t)
                        n[t] = Math.round(e[t]);
                    return n
                }
                throw new Error(`Unknown dtype ${t}`)
            }(t, s)),
            n.values
        }
        acquireTexture(e, t, n, s) {
            if (this.numBytesInGPU += this.computeBytes(e, n),
            !this.warnedAboutMemory && this.numBytesInGPU > 1048576 * this.numMBBeforeWarning) {
                const e = (this.numBytesInGPU / 1024 / 1024).toFixed(2);
                this.warnedAboutMemory = !0,
                console.warn(`High memory usage in GPU: ${e} MB, most likely due to a memory leak`)
            }
            return this.textureManager.acquireTexture(e, t, s)
        }
        computeBytes(e, t) {
            return e[0] * e[1] * Hs.bytesPerElement(t)
        }
        checkCompileCompletion() {
            for (const [,e] of Object.entries(this.binaryCache))
                this.checkCompletion_(e)
        }
        async checkCompileCompletionAsync() {
            const e = [];
            if (this.gpgpu.parallelCompilationExtension) {
                for (const [,t] of Object.entries(this.binaryCache))
                    e.push(this.checkCompletionAsync_(t));
                return Promise.all(e)
            }
            for (const [,t] of Object.entries(this.binaryCache)) {
                const n = new Promise((e=>{
                    try {
                        this.checkCompletion_(t),
                        e(!0)
                    } catch (e) {
                        throw e
                    }
                }
                ));
                e.push(n)
            }
            return Promise.all(e)
        }
        async checkCompletionAsync_(e) {
            return this.gpgpu.gl.getProgramParameter(e.webGLProgram, this.gpgpu.parallelCompilationExtension.COMPLETION_STATUS_KHR) ? this.checkCompletion_(e) : (await Mg(),
            this.checkCompletionAsync_(e))
        }
        checkCompletion_(e) {
            if (!1 === this.gpgpu.gl.getProgramParameter(e.webGLProgram, this.gpgpu.gl.LINK_STATUS)) {
                if (console.log(this.gpgpu.gl.getProgramInfoLog(e.webGLProgram)),
                !1 === this.gpgpu.gl.getShaderParameter(e.fragmentShader, this.gpgpu.gl.COMPILE_STATUS))
                    throw EN(e.source, this.gpgpu.gl.getShaderInfoLog(e.fragmentShader)),
                    new Error("Failed to compile fragment shader.");
                throw new Error("Failed to link vertex and fragment shaders.")
            }
            return !0
        }
        getUniformLocations() {
            for (const [,e] of Object.entries(this.binaryCache)) {
                const {uniformLocations: t, customUniformLocations: n, infLoc: s, nanLoc: r, inShapesLocations: a, inTexShapesLocations: i, outShapeLocation: o, outShapeStridesLocation: l, outTexShapeLocation: u} = ZN(this.gpgpu, e.program, e.webGLProgram);
                e.uniformLocations = t,
                e.customUniformLocations = n,
                e.infLoc = s,
                e.nanLoc = r,
                e.inShapesLocations = a,
                e.inTexShapesLocations = i,
                e.outShapeLocation = o,
                e.outShapeStridesLocation = l,
                e.outTexShapeLocation = u
            }
        }
        createTensorFromGPUData(e, t, n) {
            e.channels = e.channels || "RGBA";
            const {texture: s, height: r, width: a, channels: i} = e
              , o = Zo().backend;
            if (!o.gpgpu.gl.isTexture(s))
                throw new Error("The texture is invalid. Also, please make sure the texture and the TFJS WebGL backend are using the same canvas. If you want to use your own custom canvas, you have to create and use the custom TFJS WebGL backend created from the canvas through 'new tf.MathBackendWebGL(customCanvas)'.");
            const l = o.writeTexture(s, t, n, r, a, i);
            return Zo().makeTensorFromDataId(l, t, n, o)
        }
    }
    c_.nextDataId = 0;
    Sa.isBrowser() && nl("webgl", (()=>new c_), 2);
    class h_ extends Error {
        constructor(e) {
            super(e),
            Object.setPrototypeOf(this, h_.prototype)
        }
    }
    class p_ extends Error {
        constructor(e) {
            super(e),
            Object.setPrototypeOf(this, p_.prototype)
        }
    }
    class d_ extends Error {
        constructor(e) {
            super(e),
            Object.setPrototypeOf(this, d_.prototype)
        }
    }
    class f_ extends Error {
        constructor(e) {
            super(e),
            Object.setPrototypeOf(this, f_.prototype)
        }
    }
    class m_ extends Error {
        constructor(e) {
            super(e),
            Object.setPrototypeOf(this, m_.prototype)
        }
    }
    Error;
    class g_ {
        constructor(e) {
            this.maxEntries = e || 100,
            this.cache = new Map
        }
        get(e) {
            let t;
            return this.cache.has(e) && (t = this.cache.get(e),
            this.cache.delete(e),
            this.cache.set(e, t)),
            t
        }
        put(e, t) {
            if (this.cache.has(e))
                this.cache.delete(e);
            else if (this.cache.size >= this.maxEntries) {
                const e = this.cache.keys().next().value;
                this.cache.delete(e)
            }
            this.cache.set(e, t)
        }
        getMaxEntries() {
            return this.maxEntries
        }
        setMaxEntries(e) {
            if (e < 0)
                throw new Error(`The maxEntries of LRU caches must be at least 0, but got ${e}.`);
            if (this.maxEntries > e)
                for (let t = 0; t < this.maxEntries - e; t++) {
                    const e = this.cache.keys().next().value;
                    this.cache.delete(e)
                }
            this.maxEntries = e
        }
    }
    function y_(e, t) {
        if (Array.isArray(e)) {
            let n = [];
            for (let s = 0; s < t; s++)
                n = n.concat(e);
            return n
        }
        {
            const n = new Array(t);
            return n.fill(e),
            n
        }
    }
    function b_(e, t) {
        if (!e)
            throw new m_(t)
    }
    function x_(e, t) {
        let n = 0;
        for (const s of e)
            s === t && n++;
        return n
    }
    function w_(e) {
        return 1 === e.length ? e[0] : e
    }
    function v_(e) {
        return Array.isArray(e) ? e : [e]
    }
    function k_(e) {
        const t = e.replace(/(.)([A-Z][a-z0-9]+)/g, "$1_$2").replace(/([a-z])([A-Z])/g, "$1_$2").toLowerCase();
        return "_" !== t[0] ? t : "private" + t
    }
    function I_(e) {
        return e.length <= 1 || -1 === e.indexOf("_") ? e : e.replace(/[_]+(\w|$)/g, ((e,t)=>t.toUpperCase()))
    }
    let S_ = {};
    function N_(e) {
        if (null == e)
            return null;
        const t = {};
        return t.className = e.getClassName(),
        t.config = e.getConfig(),
        t
    }
    function T_(e) {
        if (null != e && "object" == typeof e)
            if (Array.isArray(e))
                e.forEach((e=>T_(e)));
            else {
                const t = Object.keys(e);
                for (const n of t) {
                    const t = e[n];
                    null != t && "object" == typeof t && (Array.isArray(t) || "ndarray" !== t.type || "number" != typeof t.value ? T_(t) : e[n] = t.value)
                }
            }
    }
    function C_(e, t={}, n={}, s="object", r=!1) {
        if ("string" == typeof e) {
            const r = e;
            let a;
            if (r in n)
                a = n[r];
            else if (r in S_)
                a = S_[r];
            else if (a = t[r],
            null == a)
                throw new d_(`Unknown ${s}: ${e}. This may be due to one of the following reasons:\n1. The ${s} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ${s} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);
            return a
        }
        {
            const a = e;
            if (null == a.className || null == a.config)
                throw new d_(`${s}: Improper config format: ${JSON.stringify(a)}.\n'className' and 'config' must set.`);
            const i = a.className;
            let o, l;
            if (i in n ? [o,l] = n[i] : i in S_ ? [o,l] = S_.className : i in t && ([o,l] = t[i]),
            null == o)
                throw new d_(`Unknown ${s}: ${i}. This may be due to one of the following reasons:\n1. The ${s} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ${s} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);
            if (null != l) {
                const e = {};
                for (const t of Object.keys(S_))
                    e[t] = S_[t];
                for (const t of Object.keys(n))
                    e[t] = n[t];
                a.config.customObjects = e;
                const t = Object.assign({}, S_);
                for (const e of Object.keys(n))
                    S_[e] = n[e];
                T_(a.config);
                const s = l(o, a.config, n, r);
                return S_ = Object.assign({}, t),
                s
            }
            {
                const e = Object.assign({}, S_);
                for (const e of Object.keys(n))
                    S_[e] = n[e];
                const t = new o(a.config);
                return S_ = Object.assign({}, e),
                t
            }
        }
    }
    function $_(e, t) {
        return -1 * function(e, t) {
            return e < t ? -1 : e > t ? 1 : 0
        }(e, t)
    }
    function E_(e) {
        if (null == e)
            return e;
        const t = [];
        for (const n of e)
            -1 === t.indexOf(n) && t.push(n);
        return t
    }
    function A_(e) {
        if (null == e)
            throw new d_(`Invalid value in obj: ${JSON.stringify(e)}`);
        for (const t in e)
            if (e.hasOwnProperty(t))
                return !1;
        return !0
    }
    function R_(e, t, n) {
        if (null != n && e.indexOf(n) < 0)
            throw new d_(`${n} is not a valid ${t}.  Valid values are ${e} or null/undefined.`)
    }
    function F_(e, t, n=0, s=1 / 0) {
        return b_(n >= 0),
        b_(s >= n),
        Array.isArray(e) && e.length >= n && e.length <= s && e.every((e=>typeof e === t))
    }
    function D_(e, t) {
        Array.isArray(e) ? (Hs.assert(e.length > 0, (()=>`${t} is unexpectedly an empty array.`)),
        e.forEach(((e,n)=>D_(e, `element ${n + 1} of ${t}`)))) : Hs.assert(Number.isInteger(e) && e > 0, (()=>`Expected ${t} to be a positive integer, but got ${__(e)}.`))
    }
    function __(e) {
        return null === e ? "null" : Array.isArray(e) ? "[" + e.map((e=>__(e))).join(",") + "]" : "string" == typeof e ? `"${e}"` : `${e}`
    }
    function O_(e) {
        return "relu" === e ? "relu" : "linear" === e ? "linear" : "elu" === e ? "elu" : null
    }
    /**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */
    let M_ = 0;
    function L_() {
        return M_++
    }
    const z_ = {};
    function B_(e="") {
        return e in z_ || (z_[e] = 0),
        z_[e] += 1,
        e + z_[e].toString()
    }
    const P_ = ["channelsFirst", "channelsLast"]
      , W_ = ["nearest", "bilinear"]
      , U_ = ["valid", "same", "causal"]
      , V_ = ["max", "avg"]
      , G_ = ["sum", "mul", "concat", "ave"]
      , H_ = new Map;
    function j_(e) {
        R_(P_, "DataFormat", e)
    }
    function q_(e) {
        R_(U_, "PaddingMode", e)
    }
    function K_(e) {
        R_(V_, "PoolMode", e)
    }
    const X_ = [];
    function Y_(e, t) {
        X_.push(e);
        try {
            const e = t();
            return X_.pop(),
            e
        } catch (e) {
            throw X_.pop(),
            e
        }
    }
    function Z_(e) {
        if (!eO(e))
            throw new Error("Not a valid tensor name: '" + e + "'");
        return (0 === X_.length ? "" : X_.join("/") + "/") + e
    }
    function J_(e) {
        if (!eO(e))
            throw new Error("Not a valid tensor name: '" + e + "'");
        H_.has(e) || H_.set(e, 0);
        const t = H_.get(e);
        if (H_.set(e, H_.get(e) + 1),
        t > 0) {
            const n = `${e}_${t}`;
            return H_.set(n, 1),
            n
        }
        return e
    }
    const Q_ = new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\._\/]*$/);
    function eO(e) {
        return !!e.match(Q_)
    }
    function tO(e, t, n) {
        null == t && (t = 0),
        null == n && (n = e.length);
        let s = 1;
        for (let r = t; r < n; ++r)
            s *= e[r];
        return s
    }
    function nO(e) {
        if (0 === e.length)
            return Number.NaN;
        let t = Number.POSITIVE_INFINITY;
        for (let n = 0; n < e.length; n++) {
            const s = e[n];
            s < t && (t = s)
        }
        return t
    }
    function sO(e) {
        if (0 === e.length)
            return Number.NaN;
        let t = Number.NEGATIVE_INFINITY;
        for (let n = 0; n < e.length; n++) {
            const s = e[n];
            s > t && (t = s)
        }
        return t
    }
    function rO(e, t) {
        if (t < e)
            throw new d_(`end (${t}) < begin (${e}) is forbidden.`);
        const n = [];
        for (let s = e; s < t; ++s)
            n.push(s);
        return n
    }
    let aO;
    function iO() {
        return null == aO && (aO = ka.backend.epsilon()),
        aO
    }
    function oO(e, t) {
        return Ko(e, t)
    }
    function lO(e, t=-1) {
        const n = e.shape.slice();
        return t < 0 && (t = n.length + t + 1),
        n.splice(t, 0, 1),
        hl(e, n)
    }
    function uO(e, t, n) {
        return Qo((()=>{
            switch (e.rank) {
            case 1:
                return yd(e, t, n);
            case 2:
                return bd(e, [t, 0], [n, e.shape[1]]);
            case 3:
                return xd(e, [t, 0, 0], [n, e.shape[1], e.shape[2]]);
            case 4:
                return wd(e, [t, 0, 0, 0], [n, e.shape[1], e.shape[2], e.shape[3]]);
            case 5:
                return pl(e, [t, 0, 0, 0, 0], [n, e.shape[1], e.shape[2], e.shape[3], e.shape[4]]);
            case 6:
                return pl(e, [t, 0, 0, 0, 0, 0], [n, e.shape[1], e.shape[2], e.shape[3], e.shape[4], e.shape[5]]);
            default:
                throw new d_(`sliceAlongFirstAxis() received an unsupported tensor rank: ${e.rank}`)
            }
        }
        ))
    }
    function cO(e, t, n) {
        return Qo((()=>{
            switch (e.rank) {
            case 1:
                return yd(e, t, n);
            case 2:
                return bd(e, [0, t], [e.shape[0], n]);
            case 3:
                return xd(e, [0, 0, t], [e.shape[0], e.shape[1], n]);
            case 4:
                return wd(e, [0, 0, 0, t], [e.shape[0], e.shape[1], e.shape[2], n]);
            default:
                throw new d_(`sliceAlongLastAxis() received an unsupported tensor rank: ${e.rank}`)
            }
        }
        ))
    }
    function hO(e, t, n, s) {
        return Qo((()=>{
            switch (e.rank) {
            case 1:
                return yd(e, t, n);
            case 2:
                switch (s) {
                case 1:
                    return uO(e, t, n);
                case 2:
                    return cO(e, t, n);
                default:
                    throw new d_(`The axis is not within the rank of the tensor ${s}`)
                }
            case 3:
                switch (s) {
                case 1:
                    return uO(e, t, n);
                case 2:
                    return xd(e, [0, t, 0], [e.shape[0], n, e.shape[2]]);
                case 3:
                    return cO(e, t, n);
                default:
                    throw new d_(`The axis is not within the rank of the tensor ${s}`)
                }
            case 4:
                switch (s) {
                case 1:
                    return uO(e, t, n);
                case 2:
                    return wd(e, [0, t, 0, 0], [e.shape[0], n, e.shape[2], e.shape[3]]);
                case 3:
                    return wd(e, [0, 0, t, 0], [e.shape[0], e.shape[1], n, e.shape[3]]);
                case 4:
                    return cO(e, t, n);
                default:
                    throw new d_(`The axis is not within the rank of the tensor ${s}`)
                }
            default:
                throw new d_(`sliceAlongLastAxis() received an unsupported tensor rank: ${e.rank}`)
            }
        }
        ))
    }
    function pO(e, t=-1) {
        let n;
        return t < 0 && (n = e[0].rank,
        t = 0 !== n ? n : 0),
        t === e[0].rank && (t = -1),
        ll(e, t)
    }
    function dO(e, t) {
        switch (e.rank) {
        case 1:
            return Rh([e, t]);
        case 2:
            return Fh([e, t], 0);
        case 3:
            return Dh([e, t], 0);
        case 4:
            return _h([e, t], 0);
        default:
            throw new d_(`concatAlongFirstAxis() received an unsupported tensor rank: ${e.rank}`)
        }
    }
    function fO(e, t) {
        if (Array.isArray(t) || (t = [t]),
        e.rank !== t.length)
            throw new d_(`The length of input n (${t.length}) does not match the number of dimensions in input x (${e.rank})`);
        return Tu(e, t)
    }
    function mO(e, t=0, n=1, s, r) {
        return nd(e, t, n, s, r)
    }
    function gO(e, t, n, s) {
        if (e.rank < 2 || t.rank < 2)
            throw new f_(`dot requires both inputs to be rank >= 2 but got x shape = ${e.shape} and y shape = ${t.shape}`);
        if (t.rank >= 3) {
            if (e.shape.slice(-1)[0] !== t.shape.slice(-2)[0])
                throw new f_(`If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = ${e.shape} and  y shape = ${t.shape}`)
        }
        if (2 === e.rank && 2 === t.rank) {
            const r = !1
              , a = !1;
            return kl.matMul({
                a: e,
                b: t,
                transposeA: r,
                transposeB: a,
                bias: s ? xO(e.rank, s, "channelsLast") : null,
                activation: n
            })
        }
        {
            const r = e.shape.slice()
              , a = r.pop();
            e = hl(e, [-1, a]);
            const i = t.shape.slice()
              , o = i.pop()
              , l = i.pop()
              , u = [...i, o]
              , c = Array.from({
                length: t.rank
            }, ((e,n)=>0 === n ? t.rank - 2 : n <= t.rank - 2 ? n - 1 : n));
            t = hl(Fc(t, c), [l, -1]);
            const h = [...r, ...u]
              , p = !1
              , d = !1;
            return hl(kl.matMul({
                a: e,
                b: t,
                transposeA: p,
                transposeB: d,
                bias: s ? xO(e.rank, s, "channelsLast") : null,
                activation: n
            }), h)
        }
    }
    function yO(e, t, n) {
        return Qo((()=>(t = Array.isArray(t) ? mu(t, "int32") : Ko(t, "int32"),
        np(e, t, n))))
    }
    function bO(e) {
        return il(e, e)
    }
    function xO(e, t, n) {
        const s = t.shape;
        if (1 !== t.rank && t.rank !== e)
            throw new d_(`Unexpected bias dimensions: ${t.rank}; expected it to be 1 or ${e}`);
        if (5 === e) {
            if ("channelsFirst" === n)
                return 1 === s.length ? hl(t, [1, s[0], 1, 1, 1]) : hl(t, [1, s[3], s[0], s[1], s[2]]);
            if ("channelsLast" === n)
                return 1 === s.length ? hl(t, [1, 1, 1, 1, s[0]]) : hl(t, [1].concat(s))
        } else if (4 === e) {
            if ("channelsFirst" === n)
                return 1 === s.length ? hl(t, [1, s[0], 1, 1]) : hl(t, [1, s[2], s[0], s[1]]);
            if ("channelsLast" === n)
                return 1 === s.length ? hl(t, [1, 1, 1, s[0]]) : hl(t, [1].concat(s))
        } else if (3 === e) {
            if ("channelsFirst" === n)
                return 1 === s.length ? hl(t, [1, s[0], 1]) : hl(t, [1, s[1], s[0]]);
            if ("channelsLast" === n)
                return 1 === s.length ? hl(t, [1, 1, s[0]]) : hl(t, [1].concat(s))
        } else if (e < 3)
            return t;
        throw new d_(`Unsupported input rank by biasAdd: ${t.rank}`)
    }
    function wO(e, t, n) {
        return Qo((()=>(null == n && (n = "channelsLast"),
        j_(n),
        sl(e, xO(e.rank, t, n)))))
    }
    function vO(e, t, n, s) {
        return Qo((()=>Zd(e, t, n, s)))
    }
    function kO(e, t, n=!1) {
        return n ? e() : t()
    }
    const IO = ["fanIn", "fanOut", "fanAvg"]
      , SO = ["normal", "uniform", "truncatedNormal"];
    class NO extends lf.Serializable {
        fromConfigUsesCustomObjects() {
            return !1
        }
        getConfig() {
            return {}
        }
    }
    class TO extends NO {
        apply(e, t) {
            return fl(e, t)
        }
    }
    TO.className = "Zeros",
    lf.registerClass(TO);
    class CO extends NO {
        apply(e, t) {
            return zc(e, t)
        }
    }
    CO.className = "Ones",
    lf.registerClass(CO);
    class $O extends NO {
        constructor(e) {
            if (super(),
            "object" != typeof e)
                throw new d_(`Expected argument of type ConstantConfig but got ${e}`);
            if (void 0 === e.value)
                throw new d_(`config must have value set but got ${e}`);
            this.value = e.value
        }
        apply(e, t) {
            return Qo((()=>il(wl(this.value), zc(e, t))))
        }
        getConfig() {
            return {
                value: this.value
            }
        }
    }
    $O.className = "Constant",
    lf.registerClass($O);
    class EO extends NO {
        constructor(e) {
            super(),
            this.DEFAULT_MINVAL = -.05,
            this.DEFAULT_MAXVAL = .05,
            this.minval = e.minval || this.DEFAULT_MINVAL,
            this.maxval = e.maxval || this.DEFAULT_MAXVAL,
            this.seed = e.seed
        }
        apply(e, t) {
            return rd(e, this.minval, this.maxval, t, this.seed)
        }
        getConfig() {
            return {
                minval: this.minval,
                maxval: this.maxval,
                seed: this.seed
            }
        }
    }
    EO.className = "RandomUniform",
    lf.registerClass(EO);
    class AO extends NO {
        constructor(e) {
            super(),
            this.DEFAULT_MEAN = 0,
            this.DEFAULT_STDDEV = .05,
            this.mean = e.mean || this.DEFAULT_MEAN,
            this.stddev = e.stddev || this.DEFAULT_STDDEV,
            this.seed = e.seed
        }
        apply(e, t) {
            if ("float32" !== (t = t || "float32") && "int32" !== t)
                throw new f_(`randomNormal does not support dType ${t}.`);
            return mO(e, this.mean, this.stddev, t, this.seed)
        }
        getConfig() {
            return {
                mean: this.mean,
                stddev: this.stddev,
                seed: this.seed
            }
        }
    }
    AO.className = "RandomNormal",
    lf.registerClass(AO);
    class RO extends NO {
        constructor(e) {
            super(),
            this.DEFAULT_MEAN = 0,
            this.DEFAULT_STDDEV = .05,
            this.mean = e.mean || this.DEFAULT_MEAN,
            this.stddev = e.stddev || this.DEFAULT_STDDEV,
            this.seed = e.seed
        }
        apply(e, t) {
            if ("float32" !== (t = t || "float32") && "int32" !== t)
                throw new f_(`truncatedNormal does not support dType ${t}.`);
            return Ed(e, this.mean, this.stddev, t, this.seed)
        }
        getConfig() {
            return {
                mean: this.mean,
                stddev: this.stddev,
                seed: this.seed
            }
        }
    }
    RO.className = "TruncatedNormal",
    lf.registerClass(RO);
    class FO extends NO {
        constructor(e) {
            super(),
            this.gain = null != e.gain ? e.gain : 1
        }
        apply(e, t) {
            return Qo((()=>{
                if (2 !== e.length || e[0] !== e[1])
                    throw new d_("Identity matrix initializer can only be used for 2D square matrices.");
                return il(this.gain, Ec(e[0]))
            }
            ))
        }
        getConfig() {
            return {
                gain: this.gain
            }
        }
    }
    FO.className = "Identity",
    lf.registerClass(FO);
    class DO extends NO {
        constructor(e) {
            if (super(),
            e.scale < 0)
                throw new d_(`scale must be a positive float. Got: ${e.scale}`);
            var t;
            this.scale = null == e.scale ? 1 : e.scale,
            this.mode = null == e.mode ? "fanIn" : e.mode,
            t = this.mode,
            R_(IO, "FanMode", t),
            this.distribution = null == e.distribution ? "normal" : e.distribution,
            function(e) {
                R_(SO, "Distribution", e)
            }(this.distribution),
            this.seed = e.seed
        }
        apply(e, t) {
            const n = function(e, t="channelsLast") {
                let n, s;
                if (j_(t),
                2 === e.length)
                    n = e[0],
                    s = e[1];
                else if (-1 !== [3, 4, 5].indexOf(e.length)) {
                    if ("channelsFirst" === t) {
                        const t = tO(e, 2);
                        n = e[1] * t,
                        s = e[0] * t
                    } else if ("channelsLast" === t) {
                        const t = tO(e, 0, e.length - 2);
                        n = e[e.length - 2] * t,
                        s = e[e.length - 1] * t
                    }
                } else {
                    const t = tO(e);
                    n = Math.sqrt(t),
                    s = Math.sqrt(t)
                }
                return [n, s]
            }(e)
              , s = n[0]
              , r = n[1];
            let a = this.scale;
            if ("fanIn" === this.mode ? a /= Math.max(1, s) : "fanOut" === this.mode ? a /= Math.max(1, r) : a /= Math.max(1, (s + r) / 2),
            "normal" === this.distribution) {
                const n = Math.sqrt(a);
                if ("float32" !== (t = t || "float32") && "int32" !== t)
                    throw new f_(`${this.getClassName()} does not support dType ${t}.`);
                return Ed(e, 0, n, t, this.seed)
            }
            {
                const n = Math.sqrt(3 * a);
                return rd(e, -n, n, t, this.seed)
            }
        }
        getConfig() {
            return {
                scale: this.scale,
                mode: this.mode,
                distribution: this.distribution,
                seed: this.seed
            }
        }
    }
    DO.className = "VarianceScaling",
    lf.registerClass(DO);
    class _O extends DO {
        constructor(e) {
            super({
                scale: 1,
                mode: "fanAvg",
                distribution: "uniform",
                seed: null == e ? null : e.seed
            })
        }
        getClassName() {
            return DO.className
        }
    }
    _O.className = "GlorotUniform",
    lf.registerClass(_O);
    class OO extends DO {
        constructor(e) {
            super({
                scale: 1,
                mode: "fanAvg",
                distribution: "normal",
                seed: null == e ? null : e.seed
            })
        }
        getClassName() {
            return DO.className
        }
    }
    OO.className = "GlorotNormal",
    lf.registerClass(OO);
    class MO extends DO {
        constructor(e) {
            super({
                scale: 2,
                mode: "fanIn",
                distribution: "normal",
                seed: null == e ? null : e.seed
            })
        }
        getClassName() {
            return DO.className
        }
    }
    MO.className = "HeNormal",
    lf.registerClass(MO);
    class LO extends DO {
        constructor(e) {
            super({
                scale: 2,
                mode: "fanIn",
                distribution: "uniform",
                seed: null == e ? null : e.seed
            })
        }
        getClassName() {
            return DO.className
        }
    }
    LO.className = "HeUniform",
    lf.registerClass(LO);
    class zO extends DO {
        constructor(e) {
            super({
                scale: 1,
                mode: "fanIn",
                distribution: "normal",
                seed: null == e ? null : e.seed
            })
        }
        getClassName() {
            return DO.className
        }
    }
    zO.className = "LeCunNormal",
    lf.registerClass(zO);
    class BO extends DO {
        constructor(e) {
            super({
                scale: 1,
                mode: "fanIn",
                distribution: "uniform",
                seed: null == e ? null : e.seed
            })
        }
        getClassName() {
            return DO.className
        }
    }
    BO.className = "LeCunUniform",
    lf.registerClass(BO);
    class PO extends NO {
        constructor(e) {
            if (super(),
            this.DEFAULT_GAIN = 1,
            this.gain = null == e.gain ? this.DEFAULT_GAIN : e.gain,
            this.seed = e.seed,
            null != this.seed)
                throw new f_("Random seed is not implemented for Orthogonal Initializer yet.")
        }
        apply(e, t) {
            return Qo((()=>{
                if (e.length < 2)
                    throw new f_("Shape must be at least 2D.");
                e[0] * e[1] > 2e3 && console.warn(`Orthogonal initializer is being called on a matrix with more than 2000 (${e[0] * e[1]}) elements: Slowness may result.`);
                const t = mO(e[0] > e[1] ? [e[1], e[0]] : e, 0, 1, "float32");
                let n = sf.gramSchmidt(t);
                return e[0] > e[1] && (n = Fc(n)),
                il(this.gain, n)
            }
            ))
        }
        getConfig() {
            return {
                gain: this.gain,
                seed: this.seed
            }
        }
    }
    PO.className = "Orthogonal",
    lf.registerClass(PO);
    const WO = {
        constant: "Constant",
        glorotNormal: "GlorotNormal",
        glorotUniform: "GlorotUniform",
        heNormal: "HeNormal",
        heUniform: "HeUniform",
        identity: "Identity",
        leCunNormal: "LeCunNormal",
        leCunUniform: "LeCunUniform",
        ones: "Ones",
        orthogonal: "Orthogonal",
        randomNormal: "RandomNormal",
        randomUniform: "RandomUniform",
        truncatedNormal: "TruncatedNormal",
        varianceScaling: "VarianceScaling",
        zeros: "Zeros"
    };
    function UO(e, t={}) {
        return C_(e, lf.SerializationMap.getMap().classNameMap, t, "initializer")
    }
    function VO(e) {
        return N_(e)
    }
    function GO(e) {
        if ("string" == typeof e) {
            const t = e in WO ? WO[e] : e;
            if ("GlorotNormal" === t)
                return new OO;
            if ("GlorotUniform" === t)
                return new _O;
            if ("HeNormal" === t)
                return new MO;
            if ("HeUniform" === t)
                return new LO;
            if ("LeCunNormal" === t)
                return new zO;
            if ("LeCunUniform" === t)
                return new BO;
            {
                const e = {};
                return e.className = t,
                e.config = {},
                UO(e)
            }
        }
        return e instanceof NO ? e : UO(e)
    }
    function HO(e) {
        return Array.isArray(e) && Array.isArray(e[0])
    }
    function jO(e) {
        return 0 === e.length ? [] : Array.isArray(e[0]) ? e : [e]
    }
    function qO(e) {
        let t;
        if (Array.isArray(e)) {
            if (1 !== e.length)
                throw new d_(`Expected Tensor length to be 1; got ${e.length}`);
            t = e[0]
        } else
            t = e;
        return t
    }
    function KO(e) {
        if (Array.isArray(e) && Array.isArray(e[0])) {
            if (1 === e.length)
                return e[0];
            throw new d_(`Expected exactly 1 Shape; got ${e.length}`)
        }
        return e
    }
    function XO(e) {
        let t = 0;
        for (const n of e)
            0 === n.shape.length ? t += 1 : t += n.shape.reduce(((e,t)=>e * t));
        return t
    }
    const YO = "Variable";
    class ZO {
        constructor(e, t="float32", n="Variable", s=!0, r=null) {
            this.dtype = null == t ? "float32" : t,
            this.shape = e.shape,
            this.id = L_(),
            n = null == n ? YO : n,
            this.originalName = Z_(n),
            this.name = J_(this.originalName),
            this.trainable_ = s,
            this.constraint = r,
            this.val = Dd(e, this.trainable_, this.name, this.dtype)
        }
        read() {
            return this.assertNotDisposed(),
            this.val
        }
        write(e) {
            return this.assertNotDisposed(),
            function(e, t) {
                if (e.shape.toString() !== t.shape.toString())
                    throw new Error("Shape mismatch: " + JSON.stringify(e.shape) + " vs. " + JSON.stringify(t.shape))
            }(this.val, e),
            this.val.id !== e.id && (this.val.assign(e),
            null != this.constraint && this.val.assign(this.constraint.apply(this.val))),
            this
        }
        dispose() {
            this.assertNotDisposed(),
            this.val.dispose()
        }
        assertNotDisposed() {
            if (this.val.isDisposed)
                throw new Error(`LayersVariable ${this.name} is already disposed.`)
        }
        get trainable() {
            return this.trainable_
        }
        set trainable(e) {
            this.trainable_ = e,
            this.val.trainable = e
        }
    }
    function JO(e) {
        return e.map((e=>e.read()))
    }
    function QO(e) {
        e.forEach((e=>{
            e[0].write(e[1])
        }
        ))
    }
    class eM {
        constructor(e) {
            this.dtype = e.dtype,
            this.shape = e.shape,
            null != e.shape ? this.ndim = e.shape.length : this.ndim = e.ndim,
            this.maxNDim = e.maxNDim,
            this.minNDim = e.minNDim,
            this.axes = e.axes || {}
        }
    }
    class tM {
        constructor(e, t, n, s, r, a, i) {
            this.dtype = e,
            this.shape = t,
            this.sourceLayer = n,
            this.inputs = s,
            this.callArgs = r,
            this.outputTensorIndex = i,
            this.id = L_(),
            null != a && (this.originalName = Z_(a),
            this.name = J_(this.originalName)),
            this.rank = t.length
        }
    }
    let nM = 0;
    class sM {
        constructor(e, t) {
            this.callArgs = t,
            this.id = nM++,
            this.outboundLayer = e.outboundLayer,
            this.inboundLayers = e.inboundLayers,
            this.nodeIndices = e.nodeIndices,
            this.tensorIndices = e.tensorIndices,
            this.inputTensors = e.inputTensors,
            this.outputTensors = e.outputTensors,
            this.inputMasks = e.inputMasks,
            this.outputMasks = e.outputMasks,
            this.inputShapes = e.inputShapes,
            this.outputShapes = e.outputShapes;
            for (const t of e.inboundLayers)
                null != t && t.outboundNodes.push(this);
            e.outboundLayer.inboundNodes.push(this)
        }
        getConfig() {
            const e = [];
            for (const t of this.inboundLayers)
                null != t ? e.push(t.name) : e.push(null);
            return {
                outboundLayer: this.outboundLayer ? this.outboundLayer.name : null,
                inboundLayers: e,
                nodeIndices: this.nodeIndices,
                tensorIndices: this.tensorIndices
            }
        }
    }
    let rM = 0;
    class aM extends lf.Serializable {
        constructor(e={}) {
            super(),
            this._callHook = null,
            this._addedWeightNames = [],
            this._stateful = !1,
            this.id = rM++,
            this.activityRegularizer = null,
            this.inputSpec = null,
            this.supportsMasking = !1,
            this._trainableWeights = [],
            this._nonTrainableWeights = [],
            this._losses = [],
            this._updates = [],
            this._built = !1,
            this.inboundNodes = [],
            this.outboundNodes = [];
            let t = e.name;
            if (!t) {
                const e = this.getClassName();
                t = k_(e) + "_" + B_(e)
            }
            if (this.name = t,
            this.trainable_ = null == e.trainable || e.trainable,
            null != e.inputShape || null != e.batchInputShape) {
                let t;
                if (null != e.batchInputShape)
                    t = e.batchInputShape;
                else if (null != e.inputShape) {
                    let n = null;
                    null != e.batchSize && (n = e.batchSize),
                    t = [n].concat(e.inputShape)
                }
                this.batchInputShape = t;
                let n = e.dtype;
                null == n && (n = e.inputDType),
                null == n && (n = "float32"),
                this.dtype = n
            }
            null != e.weights ? this.initialWeights = e.weights : this.initialWeights = null,
            this._refCount = null,
            this.fastWeightInitDuringBuild = !1
        }
        static nodeKey(e, t) {
            return e.name + "_ib-" + t.toString()
        }
        getNodeAtIndex(e, t) {
            if (0 === this.inboundNodes.length)
                throw new p_(`The layer has never been called and thus has no defined ${t}.`);
            if (this.inboundNodes.length <= e)
                throw new d_(`Asked to get ${t} at node ${e}, but the layer has only ${this.inboundNodes.length} inbound nodes.`);
            return this.inboundNodes[e]
        }
        getInputAt(e) {
            return w_(this.getNodeAtIndex(e, "input").inputTensors)
        }
        getOutputAt(e) {
            return w_(this.getNodeAtIndex(e, "output").outputTensors)
        }
        get input() {
            if (this.inboundNodes.length > 1)
                throw new h_(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer input" is ill-defined. Use \`getInputAt(nodeIndex)\` instead.`);
            if (0 === this.inboundNodes.length)
                throw new h_(`Layer ${this.name} is not connected, no input to return.`);
            return w_(this.getNodeAtIndex(0, "input").inputTensors)
        }
        get output() {
            if (0 === this.inboundNodes.length)
                throw new h_(`Layer ${this.name} has no inbound nodes.`);
            if (this.inboundNodes.length > 1)
                throw new h_(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer output" is ill-defined. Use \`getOutputAt(nodeIndex)\` instead.`);
            return w_(this.getNodeAtIndex(0, "output").outputTensors)
        }
        get losses() {
            return this._losses
        }
        calculateLosses() {
            return this.losses.map((e=>e()))
        }
        get updates() {
            return this._updates
        }
        get built() {
            return this._built
        }
        set built(e) {
            this._built = e
        }
        get trainable() {
            return this.trainable_
        }
        set trainable(e) {
            this._trainableWeights.forEach((t=>t.trainable = e)),
            this.trainable_ = e
        }
        get trainableWeights() {
            return this.trainable_ ? this._trainableWeights.filter((e=>e.trainable)) : []
        }
        set trainableWeights(e) {
            this._trainableWeights = e
        }
        get nonTrainableWeights() {
            return this.trainable ? this._trainableWeights.filter((e=>!e.trainable)).concat(this._nonTrainableWeights) : this._trainableWeights.concat(this._nonTrainableWeights)
        }
        set nonTrainableWeights(e) {
            this._nonTrainableWeights = e
        }
        get weights() {
            return this.trainableWeights.concat(this.nonTrainableWeights)
        }
        get stateful() {
            return this._stateful
        }
        resetStates() {
            if (!this.stateful)
                throw new Error("Cannot call the resetStates() method of a non-stateful Layer object.")
        }
        assertInputCompatibility(e) {
            if (e = v_(e),
            null == this.inputSpec || 0 === this.inputSpec.length)
                return;
            const t = v_(this.inputSpec);
            if (e.length !== t.length)
                throw new d_(`Layer ${this.name} expects ${t.length} inputs, but it received ${e.length} input tensors. Input received: ${e}`);
            for (let n = 0; n < e.length; n++) {
                const s = e[n]
                  , r = t[n];
                if (null == r)
                    continue;
                const a = s.rank;
                if (null != r.ndim && a !== r.ndim)
                    throw new d_(`Input ${n} is incompatible with layer ${this.name}: expected ndim=${r.ndim}, found ndim=${a}`);
                if (null != r.maxNDim && a > r.maxNDim)
                    throw new d_(`Input ${n} is incompatible with layer ${this.name}: expected max_ndim=${r.maxNDim}, found ndim=${a}`);
                if (null != r.minNDim && a < r.minNDim)
                    throw new d_(`Input ${n} is incompatible with layer ${this.name}: expected min_ndim=${r.minNDim}, found ndim=${a}.`);
                if (null != r.dtype && s.dtype !== r.dtype)
                    throw new d_(`Input ${n} is incompatible with layer ${this.name} : expected dtype=${r.dtype}, found dtype=${s.dtype}.`);
                if (r.axes) {
                    const e = s.shape;
                    for (const t in r.axes) {
                        const s = Number(t)
                          , a = r.axes[t]
                          , i = s >= 0 ? e[s] : e[e.length + s];
                        if (null != a && -1 === [a, null].indexOf(i))
                            throw new d_(`Input ${n} is incompatible with layer ${this.name}: expected axis ${s} of input shape to have value ${a} but got shape ${e}.`)
                    }
                }
                if (null != r.shape)
                    for (let e = 0; e < r.shape.length; ++e) {
                        const t = r.shape[e]
                          , a = s.shape[e];
                        if (null != t && null != a && t !== a)
                            throw new d_(`Input ${n} is incompatible with layer ${this.name}: expected shape=${r.shape}, found shape=${s.shape}.`)
                    }
            }
        }
        call(e, t) {
            return e
        }
        invokeCallHook(e, t) {
            null != this._callHook && this._callHook(e, t)
        }
        setCallHook(e) {
            this._callHook = e
        }
        clearCallHook() {
            this._callHook = null
        }
        apply(e, t) {
            t = t || {},
            this.assertNotDisposed();
            const n = v_(e);
            let s = !0;
            for (const e of n)
                if (!(e instanceof tM)) {
                    s = !1;
                    break
                }
            let r = !0;
            for (const e of n)
                if (e instanceof tM) {
                    r = !1;
                    break
                }
            if (s === r)
                throw new d_("Arguments to apply() must be all SymbolicTensors or all Tensors");
            return Y_(this.name, (()=>{
                if (!this.built) {
                    this.assertInputCompatibility(e);
                    const t = [];
                    for (const n of v_(e))
                        t.push(n.shape);
                    this.build(w_(t)),
                    this.built = !0,
                    this.initialWeights && this.setWeights(this.initialWeights),
                    null === this._refCount && r && (this._refCount = 1)
                }
                if (this.assertInputCompatibility(e),
                r) {
                    let s = this.call(e, t);
                    const r = v_(s)
                      , a = [];
                    for (let e of r)
                        -1 !== n.indexOf(e) && (e = e.clone()),
                        a.push(e);
                    if (s = w_(a),
                    null != this.activityRegularizer)
                        throw new f_("Layer invocation in the presence of activity regularizer(s) is not supported yet.");
                    return s
                }
                {
                    const n = function(e) {
                        e = v_(e);
                        const t = [];
                        for (const n of e)
                            t.push(n.shape);
                        return w_(t)
                    }(e)
                      , s = this.computeOutputShape(n);
                    let r;
                    const a = "float32";
                    if (this.warnOnIncompatibleInputShape(Array.isArray(e) ? n[0] : n),
                    r = null != s && s.length > 0 && Array.isArray(s[0]) ? s.map(((n,s)=>new tM(a,n,this,v_(e),t,this.name,s))) : new tM(a,s,this,v_(e),t,this.name),
                    this.addInboundNode(e, r, null, null, n, s, t),
                    this._refCount++,
                    null != this.activityRegularizer)
                        throw new f_("Layer invocation in the presence of activity regularizer(s) is not supported yet.");
                    return r
                }
            }
            ))
        }
        warnOnIncompatibleInputShape(e) {
            if (null != this.batchInputShape)
                if (e.length !== this.batchInputShape.length)
                    console.warn(`The rank of the input tensor provided (shape: ${JSON.stringify(e)}) does not match that of the batchInputShape (${JSON.stringify(this.batchInputShape)}) of the layer ${this.name}`);
                else {
                    let t = !1;
                    this.batchInputShape.forEach(((n,s)=>{
                        null != n && null != e[s] && e[s] !== n && (t = !0)
                    }
                    )),
                    t && console.warn(`The shape of the input tensor (${JSON.stringify(e)}) does not match the expectation of layer ${this.name}: ${JSON.stringify(this.batchInputShape)}`)
                }
        }
        get outputShape() {
            if (null == this.inboundNodes || 0 === this.inboundNodes.length)
                throw new h_(`The layer ${this.name} has never been called and thus has no defined output shape.`);
            const e = [];
            for (const t of this.inboundNodes) {
                const n = JSON.stringify(t.outputShapes);
                -1 === e.indexOf(n) && e.push(n)
            }
            if (1 === e.length) {
                const e = this.inboundNodes[0].outputShapes;
                return Array.isArray(e) && Array.isArray(e[0]) && 1 === e.length ? e[0] : e
            }
            throw new h_(`The layer ${this.name} has multiple inbound nodes with different output shapes. Hence the notion of "output shape" is ill-defined for the layer.`)
        }
        countParams() {
            if (!this.built)
                throw new p_(`You tried to call countParams() on ${this.name}, but the layer is not built yet. Build it first by calling build(batchInputShape).`);
            return XO(this.weights)
        }
        build(e) {
            this.built = !0
        }
        getWeights(e=!1) {
            return JO(e ? this.trainableWeights : this.weights)
        }
        setWeights(e) {
            Qo((()=>{
                const t = this.weights;
                if (t.length !== e.length)
                    throw new d_(`You called setWeights(weights) on layer "${this.name}" with a weight list of length ${e.length}, but the layer was expecting ${t.length} weights. Provided weights: ${e}...`);
                if (0 === t.length)
                    return;
                const n = []
                  , s = JO(t);
                for (let r = 0; r < s.length; ++r) {
                    const a = s[r]
                      , i = t[r]
                      , o = e[r];
                    if (!Hs.arraysEqual(a.shape, o.shape))
                        throw new d_(`Layer weight shape ${a.shape} not compatible with provided weight shape ${o.shape}`);
                    n.push([i, o])
                }
                QO(n)
            }
            ))
        }
        addWeight(e, t, n, s, r, a, i, o) {
            if (-1 !== this._addedWeightNames.indexOf(e))
                throw new d_(`Duplicate weight name ${e} for layer ${this.name}`);
            this._addedWeightNames.push(e),
            null == n && (n = "float32"),
            this.fastWeightInitDuringBuild && (s = null != o ? o() : GO("zeros"));
            const l = s.apply(t, n)
              , u = new ZO(l,n,e,a,i);
            return l.dispose(),
            null != r && this.addLoss((()=>r.apply(u.read()))),
            null == a && (a = !0),
            a ? this._trainableWeights.push(u) : this._nonTrainableWeights.push(u),
            u
        }
        setFastWeightInitDuringBuild(e) {
            this.fastWeightInitDuringBuild = e
        }
        addLoss(e) {
            null == e || Array.isArray(e) && 0 === e.length || (e = v_(e),
            void 0 !== this._losses && null !== this._losses && this.losses.push(...e))
        }
        computeOutputShape(e) {
            return e
        }
        computeMask(e, t) {
            if (!this.supportsMasking) {
                if (null != t) {
                    if (!Array.isArray(t))
                        throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);
                    t.forEach((e=>{
                        if (null != e)
                            throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`)
                    }
                    ))
                }
                return null
            }
            return t
        }
        addInboundNode(e, t, n, s, r, a, i=null) {
            const o = v_(e);
            t = v_(t),
            n = v_(n),
            s = v_(s),
            r = jO(r),
            a = jO(a);
            const l = []
              , u = []
              , c = [];
            for (const e of o)
                l.push(e.sourceLayer),
                u.push(e.nodeIndex),
                c.push(e.tensorIndex);
            new sM({
                outboundLayer: this,
                inboundLayers: l,
                nodeIndices: u,
                tensorIndices: c,
                inputTensors: o,
                outputTensors: t,
                inputMasks: n,
                outputMasks: s,
                inputShapes: r,
                outputShapes: a
            },i);
            for (let e = 0; e < t.length; e++)
                t[e].sourceLayer = this,
                t[e].nodeIndex = this.inboundNodes.length - 1,
                t[e].tensorIndex = e
        }
        getConfig() {
            const e = {
                name: this.name,
                trainable: this.trainable
            };
            return null != this.batchInputShape && (e.batchInputShape = this.batchInputShape),
            null != this.dtype && (e.dtype = this.dtype),
            e
        }
        disposeWeights() {
            return this.weights.forEach((e=>e.dispose())),
            this.weights.length
        }
        assertNotDisposed() {
            if (0 === this._refCount)
                throw new Error(`Layer '${this.name}' is already disposed.`)
        }
        dispose() {
            if (!this.built)
                throw new Error(`Cannot dispose Layer ${this.name} because it has not been built yet.`);
            if (null === this._refCount)
                throw new Error(`Cannot dispose Layer ${this.name} because it has not been used yet.`);
            this.assertNotDisposed();
            let e = 0;
            return 0 == --this._refCount && (e = this.disposeWeights()),
            {
                refCountAfterDispose: this._refCount,
                numDisposedVariables: e
            }
        }
    }
    function iM(e, t, n) {
        if ((null == t || null != n && n > 0) && (t = e.sourceLayer,
        n = e.nodeIndex),
        0 === t.inboundNodes.length)
            return [e];
        {
            const e = t.inboundNodes[n];
            if (0 === e.inboundLayers.length)
                return e.inputTensors;
            {
                const t = [];
                for (let n = 0; n < e.inboundLayers.length; n++) {
                    const s = iM(e.inputTensors[n], e.inboundLayers[n], e.nodeIndices[n]);
                    for (const e of s)
                        -1 === t.indexOf(e) && t.push(e)
                }
                return t
            }
        }
    }
    class oM extends aM {
        constructor(e) {
            if (super({
                dtype: e.dtype,
                name: null != e.name ? e.name : B_("input").toString()
            }),
            null == e.batchSize && (e.batchSize = null),
            null == e.sparse && (e.sparse = !1),
            this.trainable = !1,
            this.built = !0,
            this.sparse = e.sparse,
            null != e.inputShape && null != e.batchInputShape)
                throw new d_("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");
            let t = e.batchInputShape;
            if (null == t) {
                if (null == e.inputShape)
                    throw new d_("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");
                t = [e.batchSize].concat(e.inputShape)
            } else if (null != e.batchSize)
                throw new d_("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");
            const n = e.dtype || "float32";
            this.batchInputShape = t,
            this.dtype = n,
            this.inputSpec = [{
                shape: t
            }];
            const s = new tM(this.dtype,this.batchInputShape,this,[],{},this.name);
            s.nodeIndex = 0,
            s.tensorIndex = 0,
            new sM({
                outboundLayer: this,
                inboundLayers: [],
                nodeIndices: [],
                tensorIndices: [],
                inputTensors: [s],
                outputTensors: [s],
                inputMasks: [null],
                outputMasks: [null],
                inputShapes: [t],
                outputShapes: [t]
            })
        }
        apply(e, t) {
            throw new d_(`Cannot pass any input to an InputLayer's apply() method. InputLayer name: ${this.name}`)
        }
        dispose() {
            return {
                refCountAfterDispose: this._refCount,
                numDisposedVariables: 0
            }
        }
        getConfig() {
            return {
                batchInputShape: this.batchInputShape,
                dtype: this.dtype,
                sparse: this.sparse,
                name: this.name
            }
        }
    }
    function lM(e) {
        if (null == e.batchShape && null == e.shape)
            throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");
        if (null != e.batchShape && null != e.shape)
            throw new d_("Please provide either a `shape` or `batchShape` argument to Input, but not both.");
        let t = e.batchShape;
        null != e.shape && null == t && (t = [null].concat(e.shape));
        let n = e.dtype;
        null == n && (n = "float32");
        return new oM({
            batchInputShape: t,
            name: e.name,
            dtype: n,
            sparse: e.sparse
        }).inboundNodes[0].outputTensors[0]
    }
    oM.className = "InputLayer",
    lf.registerClass(oM);
    class uM {
        constructor(e) {
            if (this.id2Value = {},
            this.id2Mask = {},
            this.name2Id = {},
            e instanceof uM)
                for (const t in e.id2Value)
                    this.id2Value[t] = e.id2Value[t],
                    t in e.id2Mask && (this.id2Mask[t] = e.id2Mask[t]);
            else {
                if (null == e)
                    return;
                for (const t of e)
                    this.add(t.key, t.value)
            }
        }
        add(e, t, n) {
            if (null != this.id2Value[e.id])
                throw new d_(`Duplicate key: name=${e.name}, id=${e.id}`);
            return this.id2Value[e.id] = function(e, t) {
                if (null == e.dtype || e.dtype === t.dtype)
                    return t;
                try {
                    return Ko(t, e.dtype)
                } catch (n) {
                    throw new d_(`The dtype of the feed (${t.dtype}) can not be cast to the dtype of the key '${e.name}' (${e.dtype}).`)
                }
            }(e, t),
            this.name2Id[e.name] = e.id,
            null != n && (this.id2Mask[e.id] = n),
            this
        }
        addFeed(e) {
            this.add(e.key, e.value)
        }
        hasKey(e) {
            return null != this.id2Value[e.id]
        }
        names() {
            return Object.keys(this.name2Id)
        }
        getValue(e) {
            if (e instanceof tM) {
                if (null == this.id2Value[e.id])
                    throw new d_(`Nonexistent key: ${e.name}`);
                return this.id2Value[e.id]
            }
            {
                const t = this.name2Id[e];
                if (null == t)
                    throw new d_(`Feed dict has no SymbolicTensor name: ${e}`);
                return this.id2Value[t]
            }
        }
        getMask(e) {
            if (e instanceof tM) {
                if (null == this.id2Value[e.id])
                    throw new d_(`Nonexistent key: ${e.name}`);
                return this.id2Mask[e.id]
            }
            {
                const t = this.name2Id[e];
                if (null == t)
                    throw new d_(`Feed dict has no SymbolicTensor name: ${e}`);
                return this.id2Mask[t]
            }
        }
        disposeMasks() {
            null != this.id2Mask && el(this.id2Mask)
        }
    }
    const cM = new g_
      , hM = new g_;
    function pM(e, t, n, s) {
        const r = null != n && n.training
          , a = Array.isArray(e)
          , i = a ? e : [e]
          , o = i.map((e=>e.name))
          , l = []
          , u = t.names();
        for (const e of o)
            -1 !== u.indexOf(e) ? l.push(t.getValue(e)) : l.push(null);
        null != s && (s.maxNumTensors = -1 / 0,
        s.minNumTensors = 1 / 0);
        const c = o.join(",") + "|" + t.names().sort().join(",");
        let h, p = cM.get(c);
        if (null == p) {
            const e = function(e, t) {
                Hs.assert(null != e && e.length > 0, (()=>"Expected at least one fetch, got none"));
                let n = []
                  , s = {};
                if (1 === e.length) {
                    const r = fM(e[0], t);
                    n = r.sorted,
                    s = r.recipientMap
                } else {
                    const r = new Set;
                    for (const a of e) {
                        const {sorted: e, recipientMap: i} = fM(a, t);
                        for (const t of e)
                            r.has(t.name) || (n.push(t),
                            r.add(t.name));
                        for (const e in i)
                            null == s[e] && (s[e] = new Set),
                            i[e].forEach((t=>s[e].add(t)))
                    }
                }
                return {
                    sorted: n,
                    recipientCounts: dM(s)
                }
            }(i, t);
            p = e.sorted,
            h = e.recipientCounts,
            cM.put(c, p),
            hM.put(c, h)
        }
        h = {},
        r || Object.assign(h, hM.get(c));
        const d = new uM(t);
        for (let e = 0; e < p.length; ++e) {
            if (null != s) {
                const e = Jo().numTensors;
                e > s.maxNumTensors && (s.maxNumTensors = e),
                e < s.minNumTensors && (s.minNumTensors = e)
            }
            const a = p[e]
              , i = a.sourceLayer;
            if (i instanceof oM)
                continue;
            const u = []
              , c = []
              , f = [];
            let m = !1;
            for (const e of a.inputs) {
                const n = d.getValue(e)
                  , s = d.getMask(e);
                u.push(n),
                c.push(s),
                null != s && (m = !0),
                r || (h[e.name]--,
                0 !== h[e.name] || t.hasKey(e) || -1 !== o.indexOf(e.name) || n.isDisposed || !0 === e.sourceLayer.stateful || f.push(n))
            }
            m && ((n = n || {}).mask = c[0]);
            const g = v_(i.apply(u, n));
            let y = null;
            i.supportsMasking && (y = i.computeMask(u, c));
            const b = mM(a)
              , x = Array.isArray(b) ? b : [b];
            for (let e = 0; e < x.length; ++e) {
                d.hasKey(x[e]) || d.add(x[e], g[e], Array.isArray(y) ? y[0] : y);
                const t = o.indexOf(x[e].name);
                -1 !== t && (l[t] = g[e])
            }
            r || el(f)
        }
        return d.disposeMasks(),
        a ? l : l[0]
    }
    function dM(e) {
        const t = {};
        for (const n in e)
            t[n] = e[n].size;
        return t
    }
    function fM(e, t) {
        const n = new Set
          , s = []
          , r = {};
        for (const e of t.names())
            n.add(e);
        const a = []
          , i = [];
        for (a.push(e); a.length > 0; ) {
            const e = a[a.length - 1];
            if (n.has(e.name)) {
                a.pop();
                continue
            }
            const t = i[i.length - 1] === a.length - 1;
            if (0 === e.inputs.length || t)
                a.pop(),
                s.push(e),
                n.add(e.name),
                t && i.pop();
            else {
                i.push(a.length - 1);
                for (const t of e.inputs)
                    null == r[t.name] && (r[t.name] = new Set),
                    r[t.name].add(e.name),
                    n.has(t.name) || a.push(t)
            }
        }
        return {
            sorted: s,
            recipientMap: r
        }
    }
    function mM(e) {
        let t;
        if (1 === e.sourceLayer.inboundNodes.length)
            t = e.sourceLayer.output;
        else {
            let n = null;
            for (let t = 0; t < e.sourceLayer.inboundNodes.length; ++t)
                for (const s of e.sourceLayer.inboundNodes[t].outputTensors)
                    if (s.id === e.id) {
                        n = t;
                        break
                    }
            t = e.sourceLayer.getOutputAt(n)
        }
        return t
    }
    function gM(e, t) {
        return Qo((()=>kc(nu(il(e, e), t, !0))))
    }
    ie().registerFlag("TOPOLOGICAL_SORT_CACHE_MAX_ENTRIES", (()=>100), (function(e) {
        null != cM && cM.setMaxEntries(e),
        null != hM && hM.setMaxEntries(e)
    }
    ));
    class yM extends lf.Serializable {
        getConfig() {
            return {}
        }
    }
    class bM extends yM {
        constructor(e) {
            super(),
            this.defaultMaxValue = 2,
            this.defaultAxis = 0,
            this.maxValue = null != e.maxValue ? e.maxValue : this.defaultMaxValue,
            this.axis = null != e.axis ? e.axis : this.defaultAxis
        }
        apply(e) {
            return Qo((()=>{
                const t = gM(e, this.axis)
                  , n = Ah(t, 0, this.maxValue);
                return il(e, al(n, sl(iO(), t)))
            }
            ))
        }
        getConfig() {
            return {
                maxValue: this.maxValue,
                axis: this.axis
            }
        }
    }
    bM.className = "MaxNorm",
    lf.registerClass(bM);
    class xM extends yM {
        constructor(e) {
            super(),
            this.defaultAxis = 0,
            this.axis = null != e.axis ? e.axis : this.defaultAxis
        }
        apply(e) {
            return Qo((()=>al(e, sl(iO(), gM(e, this.axis)))))
        }
        getConfig() {
            return {
                axis: this.axis
            }
        }
    }
    xM.className = "UnitNorm",
    lf.registerClass(xM);
    class wM extends yM {
        apply(e) {
            return Jl(e)
        }
    }
    wM.className = "NonNeg",
    lf.registerClass(wM);
    class vM extends yM {
        constructor(e) {
            super(),
            this.defaultMinValue = 0,
            this.defaultMaxValue = 1,
            this.defaultRate = 1,
            this.defaultAxis = 0,
            this.minValue = null != e.minValue ? e.minValue : this.defaultMinValue,
            this.maxValue = null != e.maxValue ? e.maxValue : this.defaultMaxValue,
            this.rate = null != e.rate ? e.rate : this.defaultRate,
            this.axis = null != e.axis ? e.axis : this.defaultAxis
        }
        apply(e) {
            return Qo((()=>{
                const t = gM(e, this.axis)
                  , n = sl(il(this.rate, Ah(t, this.minValue, this.maxValue)), il(1 - this.rate, t));
                return il(e, al(n, sl(iO(), t)))
            }
            ))
        }
        getConfig() {
            return {
                minValue: this.minValue,
                maxValue: this.maxValue,
                rate: this.rate,
                axis: this.axis
            }
        }
    }
    vM.className = "MinMaxNorm",
    lf.registerClass(vM);
    const kM = {
        maxNorm: "MaxNorm",
        minMaxNorm: "MinMaxNorm",
        nonNeg: "NonNeg",
        unitNorm: "UnitNorm"
    };
    function IM(e) {
        return N_(e)
    }
    function SM(e, t={}) {
        return C_(e, lf.SerializationMap.getMap().classNameMap, t, "constraint")
    }
    function NM(e) {
        if (null == e)
            return null;
        if ("string" == typeof e) {
            return SM({
                className: e in kM ? kM[e] : e,
                config: {}
            })
        }
        return e instanceof yM ? e : SM(e)
    }
    async function TM(e) {
        if (null == e)
            return;
        const t = []
          , n = []
          , s = [];
        for (const r in e) {
            const a = e[r];
            if ("number" != typeof a) {
                const e = a;
                t.push(e.data()),
                n.push(r),
                s.push(e)
            }
        }
        if (t.length > 0) {
            const r = await Promise.all(t);
            for (let t = 0; t < r.length; ++t)
                e[n[t]] = r[t][0];
            el(s)
        }
    }
    function CM(e) {
        if (null != e)
            for (const t in e) {
                const n = e[t];
                "number" != typeof n && n.dispose()
            }
    }
    var $M;
    !function(e) {
        e[e.SILENT = 0] = "SILENT",
        e[e.VERBOSE = 1] = "VERBOSE"
    }($M || ($M = {}));
    class EM {
        constructor() {
            this.validationData = null
        }
        setParams(e) {
            this.params = e
        }
        async onEpochBegin(e, t) {}
        async onEpochEnd(e, t) {}
        async onBatchBegin(e, t) {}
        async onBatchEnd(e, t) {}
        async onTrainBegin(e) {}
        async onTrainEnd(e) {}
        setModel(e) {}
    }
    class AM {
        constructor(e, t=10) {
            null == e && (e = []),
            this.callbacks = e,
            this.queueLength = t
        }
        append(e) {
            this.callbacks.push(e)
        }
        setParams(e) {
            for (const t of this.callbacks)
                t.setParams(e)
        }
        setModel(e) {
            for (const t of this.callbacks)
                t.setModel(e)
        }
        async onEpochBegin(e, t) {
            null == t && (t = {});
            for (const n of this.callbacks)
                await n.onEpochBegin(e, t)
        }
        async onEpochEnd(e, t) {
            null == t && (t = {});
            for (const n of this.callbacks)
                await n.onEpochEnd(e, t)
        }
        async onBatchBegin(e, t) {
            null == t && (t = {});
            for (const n of this.callbacks)
                await n.onBatchBegin(e, t)
        }
        async onBatchEnd(e, t) {
            null == t && (t = {});
            for (const n of this.callbacks)
                await n.onBatchEnd(e, t)
        }
        async onTrainBegin(e) {
            null == e && (e = {});
            for (const t of this.callbacks)
                await t.onTrainBegin(e)
        }
        async onTrainEnd(e) {
            null == e && (e = {});
            for (const t of this.callbacks)
                await t.onTrainEnd(e)
        }
    }
    class RM extends EM {
        constructor() {
            super()
        }
        async onEpochBegin(e) {
            this.seen = 0,
            this.totals = {}
        }
        async onBatchEnd(e, t) {
            null == t && (t = {});
            const n = null == t.size ? 0 : t.size;
            this.seen += n;
            for (const e in t) {
                const s = t[e];
                if ("number" == typeof s)
                    this.totals.hasOwnProperty(e) || (this.totals[e] = 0),
                    this.totals[e] = this.totals[e] + s * n;
                else {
                    let t;
                    e in this.totals ? t = this.totals[e] : this.totals[e] = 0;
                    const r = Qo((()=>sl(this.totals[e], il(s, n))));
                    this.totals[e] = r,
                    null != t && t.dispose()
                }
            }
        }
        async onEpochEnd(e, t) {
            if (null != t)
                for (const e of this.params.metrics)
                    null != this.totals[e] && ("number" == typeof this.totals[e] ? t[e] = this.totals[e] / this.seen : Qo((()=>{
                        const n = il(al(1, this.seen), this.totals[e]);
                        t[e] = n,
                        this.totals[e].dispose(),
                        tl(t[e])
                    }
                    )))
        }
    }
    class FM extends EM {
        async onTrainBegin(e) {
            this.epoch = [],
            this.history = {}
        }
        async onEpochEnd(e, t) {
            null == t && (t = {}),
            this.epoch.push(e);
            for (const e in t)
                null == this.history[e] && (this.history[e] = []),
                this.history[e].push(t[e])
        }
        async syncData() {
            const e = []
              , t = []
              , n = [];
            for (const s in this.history) {
                const r = this.history[s];
                for (let a = 0; a < r.length; ++a)
                    if ("number" != typeof r[a]) {
                        const i = r[a];
                        e.push(i.data()),
                        t.push(s),
                        n.push(a)
                    }
            }
            const s = await Promise.all(e);
            for (let e = 0; e < s.length; ++e) {
                this.history[t[e]][n[e]].dispose(),
                this.history[t[e]][n[e]] = s[e][0]
            }
        }
    }
    class DM extends EM {
        constructor(e, t) {
            if (super(),
            this.currentEpoch = 0,
            this.nowFunc = e.nowFunc,
            this.nextFrameFunc = e.nextFrameFunc || Mg,
            this.yieldEvery = t || "auto",
            "auto" === this.yieldEvery && (this.yieldEvery = 125),
            "never" === this.yieldEvery && null != e.onYield)
                throw new Error("yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback");
            Hs.isNumber(this.yieldEvery) && (this.maybeWait = function(e, t, n) {
                let s, r = null != n ? n() : Hs.now();
                return (...a)=>{
                    const i = null != n ? n() : Hs.now();
                    return i - r < t || (r = i,
                    s = e(...a)),
                    s
                }
            }(this.maybeWait.bind(this), this.yieldEvery, this.nowFunc)),
            this.trainBegin = e.onTrainBegin,
            this.trainEnd = e.onTrainEnd,
            this.epochBegin = e.onEpochBegin,
            this.epochEnd = e.onEpochEnd,
            this.batchBegin = e.onBatchBegin,
            this.batchEnd = e.onBatchEnd,
            this.yield = e.onYield
        }
        async maybeWait(e, t, n) {
            const s = [];
            null != this.yield && (await TM(n),
            s.push(this.yield(e, t, n))),
            s.push(this.nextFrameFunc()),
            await Promise.all(s)
        }
        async onEpochBegin(e, t) {
            this.currentEpoch = e,
            null != this.epochBegin && (await TM(t),
            await this.epochBegin(e, t))
        }
        async onEpochEnd(e, t) {
            const n = [];
            null != this.epochEnd && (await TM(t),
            n.push(this.epochEnd(e, t))),
            "epoch" === this.yieldEvery && n.push(this.nextFrameFunc()),
            await Promise.all(n)
        }
        async onBatchBegin(e, t) {
            null != this.batchBegin && (await TM(t),
            await this.batchBegin(e, t))
        }
        async onBatchEnd(e, t) {
            const n = [];
            null != this.batchEnd && (await TM(t),
            n.push(this.batchEnd(e, t))),
            "batch" === this.yieldEvery ? n.push(this.nextFrameFunc()) : Hs.isNumber(this.yieldEvery) && n.push(this.maybeWait(this.currentEpoch, e, t)),
            await Promise.all(n)
        }
        async onTrainBegin(e) {
            null != this.trainBegin && (await TM(e),
            await this.trainBegin(e))
        }
        async onTrainEnd(e) {
            null != this.trainEnd && (await TM(e),
            await this.trainEnd(e))
        }
    }
    function _M(e, t) {
        if (null == e && (e = {}),
        e instanceof EM)
            return [e];
        if (Array.isArray(e) && e[0]instanceof EM)
            return e;
        return v_(e).map((e=>new DM(e,t)))
    }
    class OM {
        constructor() {}
        static registerCallbackConstructor(e, t) {
            Hs.assert(e >= 0 && Number.isInteger(e), (()=>`Verbosity level is expected to be an integer >= 0, but got ${e}`)),
            OM.checkForDuplicate(t),
            null == OM.constructors[e] && (OM.constructors[e] = []),
            OM.constructors[e].push(t)
        }
        static checkForDuplicate(e) {
            for (const t in OM.constructors) {
                OM.constructors[+t].forEach((t=>{
                    if (t === e)
                        throw new d_("Duplicate callback constructor.")
                }
                ))
            }
        }
        static clear() {
            OM.constructors = {}
        }
        static createCallbacks(e) {
            const t = [];
            for (const n in OM.constructors) {
                const s = +n;
                e >= s && t.push(...OM.constructors[s])
            }
            return t.map((e=>new e))
        }
    }
    function MM(e, t, n, s, r, a, i, o, l) {
        const u = new FM
          , c = [new RM, ...OM.createCallbacks(t)];
        null != e && c.push(...e),
        c.push(u);
        const h = new AM(c);
        return h.setParams({
            epochs: n,
            initialEpoch: s,
            samples: r,
            steps: a,
            batchSize: i,
            verbose: t,
            doValidation: o,
            metrics: l
        }),
        {
            callbackList: h,
            history: u
        }
    }
    function LM(e, t={}, n=!1) {
        return C_(e, lf.SerializationMap.getMap().classNameMap, t, "layer", n)
    }
    function zM(e, t) {
        return Qo((()=>{
            "float32" !== e.dtype && (e = Ko(e, "float32"));
            const n = nu(bO(e), t, !0)
              , s = wu(n.shape, iO())
              , r = kc(kp(n, s));
            return al(e, r)
        }
        ))
    }
    function BM(e, t) {
        return Qo((()=>Mc(bO(Yu(t, e)), -1)))
    }
    function PM(e, t) {
        return Qo((()=>Mc(uc(Yu(t, e)), -1)))
    }
    function WM(e, t) {
        return Qo((()=>{
            const n = Yu(e, t)
              , s = Ah(uc(e), iO(), Number.MAX_VALUE)
              , r = uc(al(n, s));
            return il(100, Mc(r, -1))
        }
        ))
    }
    function UM(e, t) {
        return Qo((()=>{
            const n = Ah(t, iO(), Number.MAX_VALUE)
              , s = Hc(sl(1, n))
              , r = Ah(e, iO(), Number.MAX_VALUE)
              , a = Hc(sl(1, r));
            return Mc(bO(Yu(s, a)), -1)
        }
        ))
    }
    function VM(e, t, n=!1) {
        return Qo((()=>{
            if (n)
                t = vd(t);
            else {
                const e = nu(t, t.shape.length - 1, !0);
                t = al(t, e)
            }
            return t = Ah(t, iO(), 1 - iO()),
            Ac(nu(il(Ko(e, "float32"), Hc(t)), t.shape.length - 1))
        }
        ))
    }
    function GM(e, t, n=!1) {
        return Qo((()=>{
            const s = Ko(tp(function(e) {
                const t = [tO(e.shape)];
                return hl(e, t)
            }(e)), "int32")
              , r = (t = Ah(t, iO(), 1 - iO())).shape;
            return VM(hl(Ep(s, r[r.length - 1]), r), t, n)
        }
        ))
    }
    function HM(e, t) {
        return Qo((()=>{
            let n;
            return n = Ah(t, iO(), 1 - iO()),
            n = Hc(al(n, Yu(1, n))),
            Mc(function(e, t) {
                if (!Hs.arraysEqual(e.shape, t.shape))
                    throw new d_(`logits and labels must have the same shape, but got shapes ${JSON.stringify(e.shape)} and ${JSON.stringify(t.shape)}`);
                return Qo((()=>{
                    const n = Jl(t)
                      , s = Ac(uc(t));
                    return sl(Yu(n, il(t, e)), Yc(Xc(s)))
                }
                ))
            }(e, n), -1)
        }
        ))
    }
    function jM(e, t) {
        return Qo((()=>{
            const n = Ah(e, iO(), 1)
              , s = Ah(t, iO(), 1);
            return nu(il(e, Hc(al(n, s))), -1)
        }
        ))
    }
    function qM(e, t) {
        return Qo((()=>{
            const n = zM(e, -1)
              , s = zM(t, -1)
              , r = il(n, s);
            return Ac(nu(r, -1))
        }
        ))
    }
    OM.constructors = {};
    const KM = {
        meanSquaredError: BM,
        meanAbsoluteError: PM,
        meanAbsolutePercentageError: WM,
        meanSquaredLogarithmicError: UM,
        squaredHinge: function(e, t) {
            return Qo((()=>{
                const n = kp(0, Yu(1, il(e, t)));
                return Mc(bO(n), -1)
            }
            ))
        },
        hinge: function(e, t) {
            return Qo((()=>{
                const n = kp(0, Yu(1, il(e, t)));
                return Mc(n, -1)
            }
            ))
        },
        categoricalHinge: function(e, t) {
            return Qo((()=>{
                const n = nu(il(e, t), -1)
                  , s = xc(il(Yu(1, e), t), -1);
                return kp(0, sl(1, Yu(s, n)))
            }
            ))
        },
        logcosh: function(e, t) {
            return Qo((()=>{
                const n = Math.log(2)
                  , s = Yu(t, e)
                  , r = Yu(sl(s, up(il(-2, s))), n);
                return Mc(r, -1)
            }
            ))
        },
        categoricalCrossentropy: VM,
        sparseCategoricalCrossentropy: GM,
        binaryCrossentropy: HM,
        kullbackLeiblerDivergence: jM,
        poisson: function(e, t) {
            return Qo((()=>{
                const n = Hc(sl(iO(), t));
                return Mc(Yu(t, il(e, n)), -1)
            }
            ))
        },
        cosineProximity: qM
    };
    function XM(e) {
        if ("string" == typeof e) {
            if (e in KM)
                return KM[e];
            let t = `Unknown loss ${e}`;
            throw e.toLowerCase().includes("softmaxcrossentropy") && (t = `Unknown loss ${e}. Use "categoricalCrossentropy" as the string name for tf.losses.softmaxCrossEntropy`),
            new d_(t)
        }
        return e
    }
    function YM(e, t) {
        return Qo((()=>{
            const n = il(.5, Ap(t))
              , s = oO(Xu(t, n), e.dtype);
            return Mc(Kh(e, s), -1)
        }
        ))
    }
    function ZM(e, t) {
        return Qo((()=>oO(Kh(ph(e, -1), ph(t, -1)), "float32")))
    }
    function JM(e, t) {
        return Qo((()=>Ko(nu(rc(Kh(e, 1), Kh(t, 1))), "float32")))
    }
    function QM(e, t) {
        return Qo((()=>{
            const n = JM(e, t)
              , s = function(e, t) {
                return Qo((()=>Ko(nu(rc(Kh(e, 0), Kh(t, 1))), "float32")))
            }(e, t)
              , r = sl(n, s);
            return Ko(Qu(Xu(r, 0), al(n, r), 0), "float32")
        }
        ))
    }
    function eL(e, t) {
        return HM(e, t)
    }
    function tL(e, t) {
        return e.rank === t.rank && (e = Tc(e, [e.rank - 1])),
        (t = ph(t, -1)).dtype !== e.dtype && (t = Ko(t, e.dtype)),
        Ko(Kh(e, t), "float32")
    }
    const nL = VM
      , sL = GM
      , rL = {
        binaryAccuracy: YM,
        categoricalAccuracy: ZM,
        precision: QM,
        categoricalCrossentropy: nL,
        sparseCategoricalCrossentropy: sL,
        mse: BM,
        MSE: BM,
        mae: PM,
        MAE: PM,
        mape: WM,
        MAPE: WM,
        cosine: qM
    };
    function aL(e) {
        if ("string" == typeof e && e in rL)
            return rL[e];
        if ("string" != typeof e && null != e)
            return e;
        throw new d_(`Unknown metric ${e}`)
    }
    function iL(e) {
        if (b_(null !== e, `Unknown LossOrMetricFn ${e}`),
        "string" == typeof e)
            return e;
        {
            let t;
            for (const n of Object.keys(KM))
                if (KM[n] === e) {
                    t = n;
                    break
                }
            if (void 0 !== t)
                return t;
            for (const n of Object.keys(rL))
                if (rL[n] === e) {
                    t = n;
                    break
                }
            return void 0 !== t ? t : e.name
        }
    }
    const oL = 1048576;
    function lL(e, t, n=!1) {
        if (null == e || "object" != typeof e || Object.getPrototypeOf(e) !== Object.prototype || !uL(e))
            throw new Error("User-defined metadata is expected to be a JSON object, but is not.");
        if (n) {
            const n = JSON.stringify(e);
            n.length > oL && console.warn(`User-defined metadata of model "${t}" is too large in size (length=${n.length} when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= 1048576.`)
        }
    }
    function uL(e) {
        if (null === e)
            return !0;
        if ("object" == typeof e) {
            if (Object.getPrototypeOf(e) === Object.prototype) {
                const t = Object.keys(e);
                for (const n of t) {
                    if ("string" != typeof n)
                        return !1;
                    if (!uL(e[n]))
                        return !1
                }
                return !0
            }
            if (Array.isArray(e)) {
                for (const t of e)
                    if (!uL(t))
                        return !1;
                return !0
            }
            return !1
        }
        {
            const t = typeof e;
            return "string" === t || "number" === t || "boolean" === t
        }
    }
    function cL(e, t, n, s=console.log) {
        const r = function(e) {
            let t = !0;
            const n = []
              , s = [];
            for (const t in e.nodesByDepth)
                n.push(e.nodesByDepth[t]);
            for (const e of n) {
                if (e.length > 1 || 1 === e.length && e[0].inboundLayers.length > 1) {
                    t = !1;
                    break
                }
                s.push(...e)
            }
            if (t)
                for (const n of e.layers) {
                    let e = !1;
                    for (const r of n.inboundNodes)
                        if (-1 !== s.indexOf(r)) {
                            if (e) {
                                t = !1;
                                break
                            }
                            e = !0
                        }
                    if (!t)
                        break
                }
            return t
        }(e)
          , a = ["Layer (type)", "Input Shape", "Output shape", "Param #"];
        let i;
        if (r ? (t = t || 90,
        n = n || [.32, .61, .89, 1]) : (t = t || 115,
        n = n || [.24, .48, .7, .8, 1]),
        n[n.length - 1] <= 1 && (n = n.map((e=>Math.floor(t * e)))),
        !r) {
            a.push("Receives inputs"),
            i = [];
            for (const t in e.nodesByDepth)
                i.push(...e.nodesByDepth[t])
        }
        s("_".repeat(t)),
        hL(a, n, s),
        s("=".repeat(t));
        const o = e.layers;
        for (let e = 0; e < o.length; ++e)
            r ? pL(o[e], n, s) : dL(o[e], n, i, s),
            s((e === o.length - 1 ? "=" : "_").repeat(t));
        e.checkTrainableWeightsConsistency();
        const l = function(e) {
            let t;
            t = null != e.collectedTrainableWeights ? XO(e.collectedTrainableWeights) : XO(e.trainableWeights);
            return t
        }(e)
          , u = XO(e.nonTrainableWeights);
        s(`Total params: ${l + u}`),
        s(`Trainable params: ${l}`),
        s(`Non-trainable params: ${u}`),
        s("_".repeat(t))
    }
    function hL(e, t, n=console.log) {
        let s = "";
        for (let n = 0; n < e.length; ++n)
            n > 0 && (s = s.slice(0, s.length - 1) + " "),
            s += e[n],
            s = s.slice(0, t[n]),
            s += " ".repeat(t[n] - s.length);
        n(s)
    }
    function pL(e, t, n) {
        let s, r;
        try {
            r = e.inboundNodes.map((e=>JSON.stringify(e.inputShapes))).join(",")
        } catch (e) {
            r = "multiple"
        }
        try {
            s = JSON.stringify(e.outputShape)
        } catch (e) {
            s = "multiple"
        }
        hL([`${e.name} (${e.getClassName()})`, r, s, e.countParams().toString()], t, n)
    }
    function dL(e, t, n, s) {
        let r, a;
        try {
            a = e.inboundNodes.map((e=>JSON.stringify(e.inputShapes))).join(",")
        } catch (e) {
            a = "multiple"
        }
        try {
            r = JSON.stringify(e.outputShape)
        } catch (e) {
            r = "multiple"
        }
        const i = [];
        for (const t of e.inboundNodes)
            if (!(null != n && n.length > 0 && -1 === n.indexOf(t)))
                for (let e = 0; e < t.inboundLayers.length; ++e) {
                    const n = t.inboundLayers[e].name
                      , s = t.nodeIndices[e]
                      , r = t.tensorIndices[e];
                    i.push(`${n}[${s}][${r}]`)
                }
        const o = e.name
          , l = e.getClassName()
          , u = 0 === i.length ? "" : i[0];
        hL([`${o} (${l})`, a, r, e.countParams().toString(), u], t, s);
        for (let e = 1; e < i.length; ++e)
            hL(["", "", "", "", i[e]], t, s)
    }
    function fL(e, t, n) {
        return ("inboundNodes" === e || "outputLayers" === e || "inputLayers" === e) && 0 === t && "string" == typeof n
    }
    function mL(e, t) {
        if (null === e)
            return null;
        if ("string" == typeof e)
            return I_(e);
        if ("number" == typeof e || "boolean" == typeof e)
            return e;
        if (e instanceof Array) {
            const n = []
              , s = e.length;
            for (let r = 0; r < s; ++r) {
                const s = e[r];
                fL(t, r, s) ? n.push(s) : n.push(mL(s, t))
            }
            return n
        }
        {
            const t = {};
            for (const n of Object.keys(e)) {
                const s = e[n];
                if ("name" === n && "string" == typeof s)
                    t[n] = s;
                else {
                    const e = I_(n);
                    t[e] = mL(s, e)
                }
            }
            return t
        }
    }
    function gL(e, t) {
        if (null == e)
            return null;
        if ("string" == typeof e)
            return k_(e);
        if ("number" == typeof e || "boolean" == typeof e)
            return e;
        if (e instanceof Array) {
            const n = []
              , s = e.length;
            for (let r = 0; r < s; ++r) {
                const s = e[r];
                fL(t, r, s) ? n.push(s) : n.push(gL(s, t))
            }
            return n
        }
        {
            const t = {};
            for (const n of Object.keys(e)) {
                const s = e[n]
                  , r = k_(n);
                t[r] = "name" !== n && "className" !== n || "string" != typeof s ? gL(s, n) : s
            }
            return t
        }
    }
    /** @license See the LICENSE file. */
    class yL extends aM {
        constructor(e) {
            if (super({}),
            this.containerNodes = new Set,
            this.name = e.name,
            null == this.name) {
                const e = this.getClassName().toLowerCase();
                this.name = B_(e)
            }
            if (this.supportsMasking = !1,
            this.trainable_ = !0,
            Array.isArray(e.inputs) ? this.inputs = e.inputs.slice() : this.inputs = [e.inputs],
            Array.isArray(e.outputs) ? this.outputs = e.outputs.slice() : this.outputs = [e.outputs],
            E_(this.inputs).length !== this.inputs.length)
                throw new d_(`The list of inputs passed to the model is redundant. All inputs should only appear once. Found: ${this.inputs.map((e=>e.name))}`);
            E_(this.outputs).length !== this.outputs.length && console.warn(`The list of outputs passed to the model is redundant. All outputs should only appear once. Found: ${this.outputs.map((e=>e.name))}`),
            this.inputLayers = [],
            this.inputLayersNodeIndices = [],
            this.inputLayersTensorIndices = [],
            this.outputLayers = [],
            this.outputLayersNodeIndices = [],
            this.outputLayersTensorIndices = [],
            this.layers = [],
            this.internalContainerRefs = [];
            for (const e of this.outputs) {
                const t = e.sourceLayer
                  , n = e.nodeIndex
                  , s = e.tensorIndex;
                this.outputLayers.push(t),
                this.outputLayersNodeIndices.push(n),
                this.outputLayersTensorIndices.push(s)
            }
            for (const e of this.inputs) {
                const t = e.sourceLayer
                  , n = e.nodeIndex
                  , s = e.tensorIndex;
                b_(0 === n, "input layer has >1 nodes"),
                b_(0 === s, "input layer has >1 tensors"),
                this.inputLayers.push(t),
                this.inputLayersNodeIndices.push(n),
                this.inputLayersTensorIndices.push(s)
            }
            this.inputNames = [],
            this.outputNames = [],
            this.feedInputShapes = [],
            this.feedInputNames = [],
            this.feedOutputNames = [];
            for (let t = 0; t < this.inputLayers.length; t++) {
                const n = this.inputLayers[t];
                if (!(n instanceof oM))
                    throw new TypeError(`Input layers to a LayersModel must be InputLayer objects. Received inputs: ${e.inputs}. Input ${t} (0-based) originates from layer type ${n.getClassName()}.`);
                this.inputNames.push(n.name),
                this.feedInputShapes.push(n.batchInputShape),
                this.feedInputNames.push(n.name)
            }
            for (const e of this.outputLayers)
                this.outputNames.push(e.name);
            this.internalInputShapes = this.inputs.map((e=>e.shape)),
            this.internalOutputShapes = this.outputs.map((e=>e.shape));
            const t = {}
              , n = {}
              , s = {}
              , r = {}
              , a = {}
              , i = []
              , o = (e,t,n,s,r,l)=>{
                null != s && null != r && null != l || (s = e.sourceLayer,
                r = e.nodeIndex,
                l = e.tensorIndex);
                const u = s.inboundNodes[r];
                if (-1 !== n.indexOf(u))
                    throw new p_(`The tensor ${e.name} at layer "${s.name}" is part of a cycle.`);
                if (-1 !== t.indexOf(u))
                    return;
                this.containerNodes.add(yL.nodeKey(s, r)),
                s.id in a || (a[s.id] = Object.keys(a).length),
                -1 === n.indexOf(u) && n.push(u);
                const c = u.inboundLayers.length;
                for (let e = 0; e < c; e++) {
                    const s = u.inputTensors[e]
                      , r = u.inboundLayers[e]
                      , a = u.nodeIndices[e]
                      , i = u.tensorIndices[e];
                    o(s, t, n, r, a, i)
                }
                for (t.push(u); n.indexOf(u) >= 0; )
                    n.splice(n.indexOf(u), 1);
                i.push(u)
            }
              , l = []
              , u = [];
            for (const e of this.outputs)
                o(e, l, u);
            const c = i.slice().reverse();
            for (const e of c) {
                n[e.id] = e,
                e.id in t || (t[e.id] = 0);
                let a = t[e.id];
                const i = null == s[e.outboundLayer.id] ? 0 : s[e.outboundLayer.id];
                a = Math.max(a, i),
                s[e.outboundLayer.id] = a,
                r[e.outboundLayer.id] = e.outboundLayer,
                t[e.id] = a;
                for (let s = 0; s < e.inboundLayers.length; s++) {
                    const r = e.inboundLayers[s]
                      , i = e.nodeIndices[s]
                      , o = r.inboundNodes[i]
                      , l = null == t[o.id] ? 0 : t[o.id];
                    t[o.id] = Math.max(a + 1, l),
                    n[o.id] = o
                }
            }
            const h = {};
            for (const e in t) {
                const s = t[e];
                s in h || (h[s] = []),
                h[s].push(n[e])
            }
            const p = {};
            for (const e in s) {
                const t = s[e];
                t in p || (p[t] = []),
                p[t].push(r[e])
            }
            let d = Object.keys(p).map((e=>parseInt(e, 10))).sort($_);
            this.layers = [];
            for (const e of d) {
                const t = p[e];
                t.sort(((e,t)=>{
                    const n = a[e.id]
                      , s = a[t.id];
                    return n < s ? -1 : n > s ? 1 : 0
                }
                ));
                for (const e of t)
                    e instanceof yL && this.internalContainerRefs.push(e),
                    this.layers.push(e)
            }
            this.layersByDepth = p,
            d = Object.keys(h).map((e=>parseInt(e, 10))).sort($_);
            const f = this.inputs.slice()
              , m = [];
            for (const e of d)
                for (const t of h[e]) {
                    const e = t.outboundLayer;
                    if (null != e) {
                        for (const n of t.inputTensors)
                            if (-1 === f.indexOf(n))
                                throw new p_(`Graph disconnected: cannot obtain value for tensor ${n} at layer "${e.name}". The following previous layers were accessed without issue: ${m}`);
                        for (const e of t.outputTensors)
                            f.push(e);
                        m.push(e.name)
                    }
                }
            this.nodesByDepth = h;
            const g = this.layers.map((e=>e.name));
            for (const e of g) {
                const t = g.filter((t=>t === e)).length;
                if (1 !== t)
                    throw new p_(`The name "${e}" is used ${t} times in the model. All layer names should be unique. Layer names: ` + JSON.stringify(g))
            }
            this.outboundNodes = [],
            this.inboundNodes = [],
            new sM({
                outboundLayer: this,
                inboundLayers: [],
                nodeIndices: [],
                tensorIndices: [],
                inputTensors: this.inputs,
                outputTensors: this.outputs,
                inputMasks: this.inputs.map((e=>null)),
                outputMasks: this.outputs.map((e=>null)),
                inputShapes: this.inputs.map((e=>e.shape)),
                outputShapes: this.outputs.map((e=>e.shape))
            }),
            this.built = !0,
            this._refCount = 1
        }
        assertNotDisposed() {
            if (0 === this._refCount)
                throw new Error(`Container '${this.name}' is already disposed.`)
        }
        dispose() {
            this.assertNotDisposed();
            const e = {
                refCountAfterDispose: null,
                numDisposedVariables: 0
            };
            if (0 == --this._refCount) {
                for (const t of this.layers)
                    e.numDisposedVariables += t.dispose().numDisposedVariables;
                for (const t of this.internalContainerRefs)
                    e.numDisposedVariables += t.dispose().numDisposedVariables
            }
            return e.refCountAfterDispose = this._refCount,
            e
        }
        get trainable() {
            return this.trainable_
        }
        set trainable(e) {
            this.layers.forEach((t=>{
                t._trainableWeights.forEach((t=>t.trainable = e))
            }
            )),
            this.trainable_ = e
        }
        get trainableWeights() {
            if (this._trainableWeights.length > 0)
                throw new d_("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");
            if (!this.trainable)
                return [];
            let e = [];
            for (const t of this.layers)
                e = e.concat(t.trainableWeights);
            return e
        }
        get nonTrainableWeights() {
            const e = [];
            for (const t of this.layers)
                e.push(...t.nonTrainableWeights);
            if (!this.trainable) {
                const t = [];
                for (const e of this.layers)
                    t.push(...e.trainableWeights);
                return t.concat(e)
            }
            return e
        }
        get weights() {
            return this.trainableWeights.concat(this.nonTrainableWeights)
        }
        loadWeights(e, t=!0) {
            const n = {};
            let s = 0;
            for (const e of this.layers)
                for (const t of e.weights) {
                    if (null != n[t.originalName])
                        throw new d_(`Duplicate weight name: ${t.originalName}`);
                    n[t.originalName] = t,
                    s++
                }
            const r = [];
            for (const s in e) {
                let a = s;
                if (null == n[s]) {
                    const e = s.split("/");
                    a = e.slice(0, -2).concat([e[e.length - 1]]).join("/")
                }
                if (null != n[a])
                    r.push([n[a], e[s]]);
                else if (t)
                    throw new d_(`Provided weight data has no target variable: ${s}`);
                delete n[a]
            }
            if (t) {
                const e = [];
                for (const t in n)
                    e.push(t);
                if (e.length > 0)
                    throw new d_(`${e.length} of ${s} weights are not set: ${e}`)
            }
            QO(r)
        }
        updatedConfig() {
            const e = this.getConfig()
              , t = {};
            return t.className = this.getClassName(),
            t.config = e,
            t.kerasVersion = "tfjs-layers 4.2.0",
            t.backend = "TensorFlow.js",
            t
        }
        toJSON(e, t=!0) {
            const n = gL(this.updatedConfig());
            return t ? JSON.stringify(n) : n
        }
        call(e, t) {
            return Qo((()=>{
                e = v_(e);
                const n = new uM;
                for (let t = 0; t < this.inputs.length; ++t)
                    n.add(this.inputs[t], e[t]);
                return pM(this.outputs, n, t)
            }
            ))
        }
        computeMask(e, t) {
            return Qo((()=>{
                let n;
                return e = v_(e),
                n = null == t ? y_(null, e.length) : v_(t),
                this.runInternalGraph(e, n)[1]
            }
            ))
        }
        computeOutputShape(e) {
            const t = jO(e);
            if (t.length !== this.inputLayers.length)
                throw new d_(`Invalid inputShape argument ${e}: model has ${this.inputLayers.length} tensor inputs.`);
            const n = {};
            for (let e = 0; e < t.length; e++) {
                const s = this.inputLayers[e]
                  , r = t[e];
                n[s.name + "_0_0"] = r
            }
            const s = Object.keys(this.nodesByDepth).map((e=>parseInt(e, 10))).sort($_);
            if (s.length > 1)
                for (const e of s) {
                    const t = this.nodesByDepth[e];
                    for (const e of t) {
                        const t = e.outboundLayer;
                        if (-1 !== this.inputLayers.map((e=>e.id)).indexOf(t.id))
                            continue;
                        const s = [];
                        for (let t = 0; t < e.inboundLayers.length; t++) {
                            const r = e.inboundLayers[t]
                              , a = e.nodeIndices[t]
                              , i = e.tensorIndices[t]
                              , o = n[`${r.name}_${a}_${i}`];
                            s.push(o)
                        }
                        const r = jO(t.computeOutputShape(w_(s)))
                          , a = t.inboundNodes.indexOf(e);
                        for (let e = 0; e < r.length; e++) {
                            n[`${t.name}_${a}_${e}`] = r[e]
                        }
                    }
                }
            const r = []
              , a = [];
            for (let e = 0; e < this.outputLayers.length; e++) {
                const t = this.outputLayers[e]
                  , n = this.outputLayersNodeIndices[e]
                  , s = this.outputLayersTensorIndices[e]
                  , r = `${t.name}_${n}_${s}`;
                a.push(r)
            }
            for (let e = 0; e < a.length; e++) {
                const t = a[e];
                b_(t in n),
                r.push(n[t])
            }
            return w_(r)
        }
        runInternalGraph(e, t) {
            null == t && (t = y_(null, e.length));
            const n = {};
            for (let s = 0; s < this.inputs.length; ++s) {
                const r = this.inputs[s]
                  , a = e[s]
                  , i = t[s];
                n[r.id] = [a, i]
            }
            const s = Object.keys(this.nodesByDepth).map((e=>parseInt(e, 10))).sort($_);
            for (const e of s) {
                const t = this.nodesByDepth[e];
                for (const e of t) {
                    const t = e.outboundLayer
                      , s = e.inputTensors
                      , r = e.outputTensors
                      , a = new Array;
                    for (const e of s)
                        e.id in n && a.push(n[e.id]);
                    if (a.length === s.length) {
                        let s, i, o, l, u = {};
                        if (null != e.callArgs && (u = e.callArgs),
                        1 === a.length) {
                            const [e,n] = a[0];
                            null == u.mask && (u.mask = n),
                            o = v_(t.call(e, u)),
                            l = v_(t.computeMask(e, n)),
                            s = [e],
                            i = [n]
                        } else
                            s = a.map((e=>e[0])),
                            i = a.map((e=>e[1])),
                            null == u.mask && (u.mask = i),
                            o = v_(t.call(s, u)),
                            l = v_(t.computeMask(s, i));
                        if (t.activityRegularizer)
                            throw new f_("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");
                        for (let e = 0; e < r.length; ++e) {
                            const t = r[e]
                              , s = o[e]
                              , a = l[e];
                            n[t.id] = [s, a]
                        }
                    }
                }
            }
            const r = []
              , a = []
              , i = [];
            for (const e of this.outputs) {
                b_(e.id in n, `Could not compute output ${e.name} : ${e.id}`);
                const [t,s] = n[e.id];
                i.push(t.shape),
                r.push(t),
                a.push(s)
            }
            return [r, a, i]
        }
        buildNodeConversionMap(e) {
            const t = {};
            let n;
            for (const e of this.layers) {
                n = e instanceof yL ? 1 : 0;
                for (let s = 0; s < e.inboundNodes.length; s++) {
                    const r = yL.nodeKey(e, s);
                    this.containerNodes.has(r) && (t[r] = n,
                    n += 1)
                }
            }
            return t
        }
        getLayer(e, t) {
            if (null != t) {
                if (this.layers.length <= t)
                    throw new d_(`Was asked to retrieve layer at index ${t}, but model only has ${this.layers.length} layer(s).`);
                return this.layers[t]
            }
            if (null == e)
                throw new d_("Provide either a layer name or layer index");
            for (const t of this.layers)
                if (t.name === e)
                    return t;
            throw new d_(`No such layer: ${e}`)
        }
        calculateLosses() {
            return Qo((()=>{
                const e = [];
                for (const t of this.layers)
                    for (let n = 0; n < t.inboundNodes.length; ++n) {
                        const s = yL.nodeKey(t, n);
                        this.containerNodes.has(s) && e.push(...t.calculateLosses())
                    }
                return e
            }
            ))
        }
        getConfig() {
            const e = {
                name: this.name
            }
              , t = this.buildNodeConversionMap(this.layers)
              , n = [];
            for (const e of this.layers) {
                const s = e.getClassName()
                  , r = e.getConfig()
                  , a = [];
                for (let n = 0; n < e.inboundNodes.length; n++) {
                    const s = e.inboundNodes[n]
                      , r = yL.nodeKey(e, n);
                    let i = {};
                    if (this.containerNodes.has(r)) {
                        if (s.callArgs)
                            try {
                                JSON.stringify(s.callArgs),
                                i = s.callArgs
                            } catch (t) {
                                console.warn(`Layer ${e.name} was passed non-serializable keyword arguments: ${s.callArgs}. They will not be included in the serialized model (and thus will be missing at deserialization time).`),
                                i = {}
                            }
                        if (s.inboundLayers.length > 0) {
                            const e = [];
                            for (let n = 0; n < s.inboundLayers.length; n++) {
                                const r = s.inboundLayers[n]
                                  , a = s.nodeIndices[n]
                                  , o = s.tensorIndices[n];
                                let l = t[yL.nodeKey(r, a)];
                                null == l && (l = 0),
                                e.push([r.name, l, o, i])
                            }
                            a.push(e)
                        }
                    }
                }
                const i = {};
                i.name = e.name,
                i.className = s,
                i.config = r,
                i.inboundNodes = a,
                n.push(i)
            }
            e.layers = n;
            const s = [];
            for (let e = 0; e < this.inputLayers.length; e++) {
                const n = this.inputLayers[e]
                  , r = this.inputLayersNodeIndices[e]
                  , a = yL.nodeKey(n, r);
                if (!this.containerNodes.has(a))
                    continue;
                let i = t[a];
                null == i && (i = 0);
                const o = this.inputLayersTensorIndices[e];
                s.push([n.name, i, o])
            }
            e.inputLayers = s;
            const r = [];
            for (let e = 0; e < this.outputLayers.length; e++) {
                const n = this.outputLayers[e]
                  , s = this.outputLayersNodeIndices[e]
                  , a = yL.nodeKey(n, s);
                if (!this.containerNodes.has(a))
                    continue;
                let i = t[a];
                null == i && (i = 0);
                const o = this.outputLayersTensorIndices[e];
                r.push([n.name, i, o])
            }
            return e.outputLayers = r,
            e
        }
        static fromConfig(e, t, n={}, s=!1) {
            const r = {}
              , a = {};
            function i(e, t) {
                e.name in a ? a[e.name].push(t) : a[e.name] = [t]
            }
            function o(e, t) {
                const n = [];
                let s;
                for (const a of t) {
                    const o = a[0]
                      , l = a[1]
                      , u = a[2];
                    if (s = null == a[3] ? {} : a[3],
                    !(o in r))
                        return void i(e, t);
                    const c = r[o];
                    if (c.inboundNodes.length <= l)
                        return void i(e, t);
                    const h = c.inboundNodes[l];
                    n.push(h.outputTensors[u])
                }
                n.length > 0 && e.apply(w_(n), s)
            }
            function l(e) {
                const n = e.name
                  , a = LM(e, null != t.customObjects ? t.customObjects : {});
                a.setFastWeightInitDuringBuild(s),
                r[n] = a;
                e.inboundNodes.forEach((e=>{
                    if (!(e instanceof Array))
                        throw new d_(`Corrupted configuration, expected array for nodeData: ${e}`);
                    i(a, e)
                }
                ))
            }
            const u = t.name
              , c = t.layers;
            for (const e of c)
                l(e);
            for (; !A_(a); )
                for (const e of c) {
                    const t = r[e.name];
                    if (t.name in a) {
                        const e = a[t.name];
                        delete a[t.name];
                        for (const n of e)
                            o(t, n)
                    }
                }
            const h = []
              , p = []
              , d = t.inputLayers;
            for (const e of d) {
                const t = e[0]
                  , n = e[1]
                  , s = e[2];
                b_(t in r);
                const a = r[t].inboundNodes[n].outputTensors;
                h.push(a[s])
            }
            const f = t.outputLayers;
            for (const e of f) {
                const t = e[0]
                  , n = e[1]
                  , s = e[2];
                b_(t in r);
                const a = r[t].inboundNodes[n].outputTensors;
                p.push(a[s])
            }
            return new e({
                inputs: h,
                outputs: p,
                name: u
            })
        }
        get stateful() {
            if (this._stateful)
                throw new d_("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");
            for (const e of this.layers)
                if (e.stateful)
                    return !0;
            return !1
        }
        resetStates() {
            Qo((()=>{
                this.layers.forEach((e=>{
                    e.stateful && e.resetStates()
                }
                ))
            }
            ))
        }
    }
    function bL(e, t, n) {
        const s = t.length;
        if (null == e || Array.isArray(e) && 0 === e.length)
            return t.map((e=>null));
        if (1 === s)
            return Array.isArray(e) && 1 === e.length ? e : "object" == typeof e && t[0]in e ? [e[t[0]]] : [e];
        if (Array.isArray(e)) {
            if (e.length !== s)
                throw new Error(`Provided ${n} is an array of ${e.length} element(s), but the model has ${s} outputs. Make sure a set of weights is provided for each model output.`);
            return e
        }
        if ("object" == typeof e && Object.keys(e).length > 0 && "object" == typeof e[Object.keys(e)[0]]) {
            const n = [];
            return t.forEach((t=>{
                t in e ? n.push(e[t]) : n.push(null)
            }
            )),
            n
        }
        throw new Error(`The model has multiple (${s}) outputs, so ${n} must be either an array with ${s} elements or an object with ${t} keys. Provided ${n} not understood: ${JSON.stringify(e)}`)
    }
    function xL(e, t) {
        return bL(e, t, "classWeight")
    }
    async function wL(e, t, n, s) {
        if (null != t || null != s)
            throw new Error("Support sampleWeight is not implemented yet");
        if (null != n) {
            const t = Qo((()=>{
                if (1 === e.shape.length)
                    return Xo(e);
                if (2 === e.shape.length) {
                    if (e.shape[1] > 1) {
                        return ph(e, 1)
                    }
                    if (1 === e.shape[1])
                        return hl(e, [e.shape[0]]);
                    throw new Error(`Encountered unexpected last-dimension size (${e.shape[1]}) during handling of class weights. The size is expected to be >= 1.`)
                }
                throw new Error(`Unexpected rank of target (y) tensor (${e.rank}) during handling of class weights. The rank is expected to be 1 or 2.`)
            }
            ))
              , s = Array.from(await t.data());
            el(t);
            const r = [];
            return s.forEach((e=>{
                if (null == n[e])
                    throw new Error(`classWeight must contain all classes in the training data. The class ${e} exists in the data but not in classWeight`);
                r.push(n[e])
            }
            )),
            mu(r, "float32")
        }
        return null
    }
    function vL(e, t) {
        return il(e, t)
    }
    function kL(e, t) {
        let n, s;
        const r = t;
        n = r.xs,
        s = r.ys,
        Hs.assert(null != n && null != s, (()=>`A Dataset iterator for fitDataset() is expected to generate objects of the form \`{xs: xVal, ys: yVal}\`, where the two values may be \`tf.Tensor\`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates ${t}`));
        const a = IL("input", e.inputNames, n)
          , i = IL("output", e.outputNames, s)
          , o = a[0].shape[0];
        Hs.assert(a.length === e.inputs.length, (()=>`LayersModel has ${e.inputs.length} inputs, but the dataset provides ${a.length} inputs.  (Expected input keys: ${JSON.stringify(e.inputNames)})`)),
        Hs.assert(i.length === e.outputs.length, (()=>`LayersModel has ${e.outputs.length} outputs, but the dataset provides ${i.length} outputs.  (Expected output keys: ${JSON.stringify(e.outputNames)})`));
        for (let t = 0; t < a.length; t++)
            Hs.assert(a[t].shape[0] === o, (()=>`Batch size mismatch: input ${e.inputNames[t]} has ${a[t].shape[0]}; expected  ${o} based on input ${e.inputNames[0]}.`));
        for (let t = 0; t < i.length; t++)
            Hs.assert(i[t].shape[0] === o, (()=>`Batch size mismatch: output ${e.outputNames[t]} has ${i[t].shape[0]}; expected  ${o} based on input ${e.inputNames[0]}.`));
        return {
            xs: a,
            ys: i
        }
    }
    function IL(e, t, n) {
        if (n instanceof Zr)
            return [n];
        if (Array.isArray(n))
            return Hs.assert(n.length === t.length, (()=>`Received an array of ${n.length} Tensors, but expected ${t.length} to match the ${e} keys ${t}.`)),
            n;
        {
            const s = [];
            for (const r of t) {
                if (null == n[r])
                    throw new d_(`The feature data generated by the dataset lacks the required ${e} key '${r}'.`);
                s.push(n[r])
            }
            return s
        }
    }
    async function SL(e, t, n) {
        const s = null != n.batchesPerEpoch;
        if (Hs.assert(null != e.optimizer, (()=>"You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig).")),
        Hs.assert(null != n, (()=>"For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call.")),
        Hs.assert(null != n.epochs && n.epochs > 0 && Number.isInteger(n.epochs), (()=>`For fitDataset(), config.epochs is expected to be a positive integer, but got ${n.epochs}`)),
        Hs.assert(!s || n.batchesPerEpoch > 0 && Number.isInteger(n.batchesPerEpoch), (()=>`For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got ${n.batchesPerEpoch}`)),
        Hs.assert(null == n.validationSplit, (()=>"`validationSplit` is not supported by `fitDataset()`. Use validationData instead.")),
        e.isTraining)
            throw new Error("Cannot start training because another fit() call is ongoing.");
        e.isTraining = !0;
        try {
            const r = null != n.validationData;
            let a, i;
            if (r)
                if (NL(n.validationData))
                    Hs.assert(null == n.validationBatches || n.validationBatches > 0 && Number.isInteger(n.validationBatches), (()=>`For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got ${n.validationBatches}`));
                else {
                    const e = function(e) {
                        if (3 === e.length)
                            throw new f_("Validation with sample weights is not implemented yet.");
                        return {
                            xs: e[0],
                            ys: e[1]
                        }
                    }(n.validationData);
                    a = e.xs,
                    i = e.ys
                }
            const o = e.makeTrainFunction()
              , l = e.getDedupedMetricsNames();
            let u;
            u = r ? l.slice().concat(l.map((e=>"val_" + e))) : l.slice();
            const c = _M(n.callbacks, n.yieldEvery)
              , h = null == n.verbose ? 1 : n.verbose
              , {callbackList: p, history: d} = MM(c, h, n.epochs, null, null, function(e, t) {
                let n = null;
                null != t.batchesPerEpoch ? n = t.batchesPerEpoch : Number.isFinite(e.size) && (n = e.size);
                return n
            }(t, n), null, r, u);
            p.setModel(e),
            e.history = d,
            await p.onTrainBegin(),
            e.stopTraining_ = !1;
            let f = null == n.initialEpoch ? 0 : n.initialEpoch
              , m = await t.iterator();
            for (; f < n.epochs; ) {
                const u = {};
                await p.onEpochBegin(f);
                let c = 0
                  , h = 0;
                for (s || (m = await t.iterator()); !s || c < n.batchesPerEpoch; ) {
                    const t = await m.next();
                    if (s && t.done) {
                        console.warn(`You provided \`batchesPerEpoch\` as ${n.batchesPerEpoch}, but your dataset iterator ran out of data after ${c} batches; interrupting training. Make sure that your dataset can generate at least \`batchesPerEpoch * epochs\` batches (in this case, ` + n.batchesPerEpoch * n.epochs + " batches). You may need to use the repeat() function when building your dataset.");
                        break
                    }
                    if (null != t.value) {
                        const {xs: s, ys: r} = kL(e, t.value)
                          , a = {};
                        a.batch = h,
                        a.size = s[0].shape[0],
                        await p.onBatchBegin(h, a);
                        const i = [];
                        if (null != n.classWeight) {
                            const t = xL(n.classWeight, e.outputNames);
                            for (let e = 0; e < t.length; ++e)
                                i.push(await wL(r[e], null, t[e]))
                        }
                        const u = s.concat(r).concat(i)
                          , d = o(u);
                        el(u);
                        for (let e = 0; e < l.length; ++e) {
                            const t = l[e]
                              , n = d[e];
                            a[t] = n,
                            tl(n)
                        }
                        await p.onBatchEnd(h, a),
                        CM(a),
                        h++,
                        c++
                    }
                    if (s ? c >= n.batchesPerEpoch : t.done) {
                        if (r) {
                            let t;
                            t = NL(n.validationData) ? v_(await e.evaluateDataset(n.validationData, {
                                batches: n.validationBatches
                            })) : v_(e.evaluate(a, i, {
                                batchSize: null == n.validationBatchSize ? 32 : n.validationBatchSize,
                                verbose: 0
                            }));
                            for (let n = 0; n < e.metricsNames.length; ++n)
                                u[`val_${e.metricsNames[n]}`] = t[n]
                        }
                        break
                    }
                    if (e.stopTraining_)
                        break
                }
                if (await p.onEpochEnd(f, u),
                f++,
                e.stopTraining_)
                    break
            }
            return await p.onTrainEnd(),
            await e.history.syncData(),
            e.history
        } finally {
            e.isTraining = !1
        }
    }
    function NL(e) {
        return "function" == typeof e.iterator
    }
    function TL(e) {
        Hs.assert(e > 0 && Number.isInteger(e), (()=>`batchSize is required to be a positive integer, but got ${e}`))
    }
    function CL(e, t, n) {
        return null == e ? [null] : Array.isArray(e) ? e.map((e=>uO(e, t, n - t))) : uO(e, t, n - t)
    }
    function $L(e, t) {
        return Qo((()=>null == e ? null : Array.isArray(e) ? e.map((e=>$L(e, t))) : yO(e, "int32" === t.dtype ? t : Ko(t, "int32"))))
    }
    function EL(e, t) {
        const n = [];
        let s = 0
          , r = null;
        for (; s < e; )
            r = s + t,
            r >= e && (r = e),
            n.push([s, r]),
            s = r;
        return n
    }
    function AL(e) {
        const t = [];
        e instanceof Zr && (e = [e]);
        for (let n = 0; n < e.length; ++n) {
            const s = e[n];
            if (1 === s.rank)
                t.push(lO(s, 1));
            else {
                if (0 === s.rank)
                    throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");
                t.push(s)
            }
        }
        return t
    }
    function RL(e, t) {
        if (null == e)
            return;
        const n = [];
        if (t instanceof Zr)
            n.push(t.id);
        else if (Array.isArray(t))
            t.forEach((e=>n.push(e.id)));
        else if (null != t)
            for (const e in t) {
                const s = t[e];
                n.push(s.id)
            }
        const s = [];
        if (e instanceof Zr)
            -1 === n.indexOf(e.id) && s.push(e);
        else if (Array.isArray(e))
            e.forEach((e=>{
                -1 === n.indexOf(e.id) && s.push(e)
            }
            ));
        else if (null != e)
            for (const t in e) {
                const r = e[t];
                -1 === n.indexOf(r.id) && s.push(r)
            }
        s.forEach((e=>{
            e.isDisposed || e.dispose()
        }
        ))
    }
    function FL(e) {
        return Array.isArray(e)
    }
    function DL(e) {
        return !function(e) {
            return e instanceof Zr
        }(e) && !FL(e)
    }
    function _L(e, t, n, s=!0, r="") {
        if (null == t || 0 === t.length) {
            if (null != e) {
                let t = !1;
                if (FL(e) && e.length > 0)
                    t = !0;
                else if (DL(e)) {
                    for (const n in e)
                        if (e.hasOwnProperty(n)) {
                            t = !0;
                            break
                        }
                } else
                    t = !0;
                if (t)
                    throw new d_(`Error when checking model ${r} expected no data, but got ${e}`)
            }
            return []
        }
        if (null == e)
            return t.map((e=>null));
        let a;
        if (DL(e)) {
            a = [];
            for (const n of t) {
                if (null == e[n])
                    throw new d_(`No data provided for "${n}". Need data for each key in: ${t}`);
                a.push(e[n])
            }
        } else if (FL(e)) {
            if (e.length !== t.length)
                throw new d_(`Error when checking model ${r}: the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see ${t.length} Tensor(s), but instead got the following list of Tensor(s): ${e}`);
            a = e
        } else {
            if (t.length > 1)
                throw new d_(`The model ${r} expects ${t.length} Tensor(s), but only received one Tensor. Found: Tensor with shape ${e.shape}`);
            a = [e]
        }
        if (a = AL(a),
        null != n)
            for (let e = 0; e < t.length; ++e) {
                if (null == n[e])
                    continue;
                const i = a[e];
                if (i.shape.length !== n[e].length)
                    throw new d_(`Error when checking ${r}: expected ${t[e]} to have ${n[e].length} dimension(s). but got array with shape ${i.shape}`);
                for (let t = 0; t < n[e].length; ++t) {
                    if (0 === t && !s)
                        continue;
                    const a = i.shape[t]
                      , o = n[e][t];
                    if (null != o && o >= 0 && a !== o)
                        throw new d_(`${r} expected a batch of elements where each example has shape [${n[e].slice(1, n[e].length)}] (i.e.,tensor shape [*,${n[e].slice(1, n[e].length)}]) but the ${r} received an input with ${i.shape[0]} examples, each with shape [${i.shape.slice(1, i.shape.length)}] (tensor shape [${i.shape}])`)
                }
            }
        return a
    }
    function OL(e, t, n, s=!0, r="") {
        let a;
        if (Array.isArray(e)) {
            if (e.length !== t.length)
                throw new d_(`Error when checking model ${r}: the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see ${t.length} Tensor(s), but instead got ${e.length} Tensors(s).`);
            a = e
        } else {
            if (t.length > 1)
                throw new d_(`The model expects ${t.length} ${r} Tensors, but only received one Tensor. Found: array with shape ${JSON.stringify(e.shape)}.`);
            a = [e]
        }
        if (null != n)
            for (let e = 0; e < t.length; ++e) {
                if (null == n[e])
                    continue;
                const i = a[e];
                if (i.shape.length !== n[e].length)
                    throw new d_(`Error when checking ${r}: expected ${t[e]} to have ${n[e].length} dimension(s), but got array with shape ${JSON.stringify(i.shape)}`);
                for (let a = 0; a < n[e].length; ++a) {
                    if (0 === a && !s)
                        continue;
                    const o = i.shape[a]
                      , l = n[e][a];
                    if (null != l && l !== o)
                        throw new d_(`Error when checking ${r}: expected ${t[e]} to have shape ${JSON.stringify(n[e])} but got array with shape ${JSON.stringify(i.shape)}.`)
                }
            }
    }
    class ML extends yL {
        constructor(e) {
            super(e),
            this.isTraining = !1
        }
        summary(e, t, n=console.log) {
            if (!this.built)
                throw new d_("This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).");
            cL(this, e, t, n)
        }
        compile(e) {
            if (null == e.loss && (e.loss = []),
            this.loss = e.loss,
            "string" == typeof e.optimizer)
                this.optimizer_ = function(e) {
                    const t = {
                        Adagrad: ()=>_g.adagrad(.01),
                        Adadelta: ()=>_g.adadelta(1, .95, iO()),
                        Adam: ()=>_g.adam(.001, .9, .999, iO()),
                        Adamax: ()=>_g.adamax(.002, .9, .999, iO(), 0),
                        RMSProp: ()=>_g.rmsprop(.001, .9, 0, iO()),
                        SGD: ()=>_g.sgd(.01)
                    };
                    if (t.adagrad = t.Adagrad,
                    t.adadelta = t.Adadelta,
                    t.adam = t.Adam,
                    t.adamax = t.Adamax,
                    t.rmsprop = t.RMSProp,
                    t.sgd = t.SGD,
                    e in t)
                        return t[e]();
                    throw new d_(`Unknown Optimizer ${e}`)
                }(e.optimizer),
                this.isOptimizerOwned = !0;
            else {
                if (!(e.optimizer instanceof pf))
                    throw new d_("User-defined optimizer must be an instance of tf.Optimizer.");
                this.optimizer_ = e.optimizer,
                this.isOptimizerOwned = !1
            }
            let t = [];
            if (Array.isArray(e.loss) || "string" == typeof e.loss || "function" == typeof e.loss)
                if (Array.isArray(e.loss)) {
                    if (e.loss.length !== this.outputs.length)
                        throw new d_(`When passing an Array as loss, it should have one entry per model output. The model has ${this.outputs.length} output(s), but you passed loss=${e.loss}.`);
                    const n = e.loss;
                    t = n.map((e=>XM(e)))
                } else {
                    const n = XM(e.loss);
                    this.outputs.forEach((e=>{
                        t.push(n)
                    }
                    ))
                }
            else {
                e.loss = e.loss;
                for (const t in e.loss)
                    if (-1 === this.outputNames.indexOf(t))
                        throw new d_(`Unknown entry in loss dictionary: "${t}". Only expected the following keys: ${this.outputNames}`);
                for (const n of this.outputNames)
                    null == e.loss[n] && console.warn(`Output "${n}" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to ${n} during training`),
                    t.push(XM(e.loss[n]))
            }
            this.lossFunctions = t,
            this.feedOutputNames = [],
            this.feedOutputShapes = [],
            this.feedLossFns = [];
            for (let e = 0; e < this.outputs.length; ++e) {
                const t = this.internalOutputShapes[e]
                  , n = this.outputNames[e];
                this.feedOutputNames.push(n),
                this.feedOutputShapes.push(t),
                this.feedLossFns.push(this.lossFunctions[e])
            }
            const n = [];
            this.metrics = e.metrics,
            this.metricsNames = ["loss"],
            this.metricsTensors = [],
            Y_("loss", (()=>{
                for (let e = 0; e < this.outputs.length; ++e) {
                    if (-1 !== n.indexOf(e))
                        continue;
                    const t = this.lossFunctions[e];
                    this.outputs.length > 1 && (this.metricsTensors.push([t, e]),
                    this.metricsNames.push(this.outputNames[e] + "_loss"))
                }
            }
            ));
            const s = function(e, t) {
                if (null == e || Array.isArray(e) && 0 === e.length)
                    return t.map((e=>[]));
                let n;
                if ("string" == typeof e || "function" == typeof e)
                    n = [e];
                else {
                    if (!Array.isArray(e) && "object" != typeof e)
                        throw new TypeError(`Type of metrics argument not understood. Expected an string,function, Array, or Object, found: ${e}`);
                    n = e
                }
                if (Array.isArray(n))
                    return t.map((e=>n));
                {
                    const e = [];
                    for (const s of t) {
                        let t = n.hasOwnProperty(s) ? n[s] : [];
                        Array.isArray(t) || (t = [t]),
                        e.push(t)
                    }
                    return e
                }
            }(e.metrics, this.outputNames)
              , r = (e,t,n)=>{
                this.outputNames.length > 1 && (t = this.outputNames[e] + "_" + t),
                this.metricsNames.push(t),
                this.metricsTensors.push([n, e])
            }
            ;
            Y_("metric", (()=>{
                for (let e = 0; e < this.outputs.length; ++e) {
                    if (-1 !== n.indexOf(e))
                        continue;
                    (t=>{
                        let n, s, a;
                        for (const i of t) {
                            if ("string" == typeof i && -1 !== ["accuracy", "acc", "crossentropy", "ce"].indexOf(i)) {
                                const t = this.internalOutputShapes[e];
                                let r;
                                1 === t[t.length - 1] || this.lossFunctions[e] === HM ? -1 !== ["accuracy", "acc"].indexOf(i) ? s = YM : -1 !== ["crossentropy", "ce"].indexOf(i) && (s = eL) : this.lossFunctions[e] === GM ? -1 !== ["accuracy", "acc"].indexOf(i) ? s = tL : -1 !== ["crossentropy", "ce"].indexOf(i) && (s = sL) : -1 !== ["accuracy", "acc"].indexOf(i) ? s = ZM : -1 !== ["crossentropy", "ce"].indexOf(i) && (s = nL),
                                -1 !== ["accuracy", "acc"].indexOf(i) ? r = "acc" : -1 !== ["crossentropy", "ce"].indexOf(i) && (r = "ce"),
                                a = s,
                                n = "" + r
                            } else {
                                const e = aL(i);
                                a = e,
                                n = "" + iL(i)
                            }
                            let t;
                            Y_(n, (()=>{
                                t = a
                            }
                            )),
                            r(e, n, t)
                        }
                    }
                    )(s[e])
                }
            }
            )),
            this.collectedTrainableWeights = this.trainableWeights
        }
        checkTrainableWeightsConsistency() {
            null != this.collectedTrainableWeights && this.trainableWeights.length !== this.collectedTrainableWeights.length && console.warn("Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?")
        }
        evaluate(e, t, n={}) {
            const s = null == n.batchSize ? 32 : n.batchSize;
            TL(s);
            const r = this.standardizeUserDataXY(e, t, !0, s);
            try {
                const a = r[0].concat(r[1]);
                this.makeTestFunction();
                const i = this.testFunction;
                return w_(this.testLoop(i, a, s, n.verbose, n.steps))
            } finally {
                RL(r[0], e),
                RL(r[1], t)
            }
        }
        async evaluateDataset(e, t) {
            return this.makeTestFunction(),
            async function(e, t, n) {
                const s = null != (n = n || {}).batches
                  , r = e.testFunction;
                let a = [];
                if (n.verbose > 0)
                    throw new f_("Verbose mode is not implemented yet.");
                Hs.assert(!s || n.batches > 0 && Number.isInteger(n.batches), (()=>`Test loop expects \`batches\` to be a positive integer, but received ${JSON.stringify(n.batches)}`));
                const i = "function" == typeof t.next ? t : await t.iterator();
                let o = 0
                  , l = 0;
                for (; !s || l < n.batches; ) {
                    const t = await i.next();
                    if (a = Qo((()=>{
                        if (t.value) {
                            const {xs: n, ys: s} = kL(e, t.value)
                              , i = n.concat(s)
                              , u = Qo((()=>r(i)));
                            if (el(i),
                            0 === l)
                                for (let e = 0; e < u.length; ++e)
                                    a.push(wl(0));
                            const c = i[0].shape[0];
                            for (let e = 0; e < u.length; ++e) {
                                const t = u[e]
                                  , n = a[e];
                                a[e] = Qo((()=>sl(a[e], il(c, t)))),
                                l > 0 && el(n)
                            }
                            el(u),
                            o += c,
                            ++l
                        }
                        return a
                    }
                    )),
                    t.done) {
                        s && console.warn(`Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least \`batches\` batches (in this case, ${n.batches} batches). You may need to use the repeat() function when building your dataset.`);
                        break
                    }
                }
                for (let e = 0; e < a.length; ++e) {
                    const t = a[e];
                    a[e] = al(a[e], o),
                    el(t)
                }
                return w_(a)
            }(this, e, t)
        }
        checkNumSamples(e, t, n, s="steps") {
            let r;
            if (null != n) {
                if (r = null,
                null != t)
                    throw new d_(`If ${s} is set, batchSize must be null or undefined.Got batchSize = ${t}`)
            } else {
                if (null == e)
                    throw new d_(`Either the input data should have a defined shape, or ${s} shoud be specified.`);
                r = Array.isArray(e) ? e[0].shape[0] : e.shape[0]
            }
            return r
        }
        execute(e, t) {
            if (Array.isArray(t) && 0 === t.length)
                throw new d_("`outputs` is an empty Array, which is not allowed.");
            const n = Array.isArray(t)
              , s = n ? t : [t]
              , r = this.retrieveSymbolicTensors(s)
              , a = new uM;
            if (e instanceof Zr && (e = [e]),
            Array.isArray(e)) {
                if (e.length !== this.inputs.length)
                    throw new d_(`The number of inputs provided (${e.length}) does not match the number of inputs of this model (${this.inputs.length}).`);
                for (let t = 0; t < this.inputs.length; ++t)
                    a.add(this.inputs[t], e[t])
            } else
                for (const t of this.inputs) {
                    const n = e[t.name];
                    if (null == n)
                        throw new d_(`No value is provided for the model's input ${t.name}`);
                    a.add(t, n)
                }
            const i = pM(r, a);
            return n ? i : i[0]
        }
        retrieveSymbolicTensors(e) {
            const t = y_(null, e.length);
            let n = e.length;
            for (const s of this.layers) {
                const r = Array.isArray(s.output) ? s.output : [s.output]
                  , a = r.map((e=>e.name));
                for (let s = 0; s < e.length; ++s) {
                    const i = a.indexOf(e[s]);
                    if (-1 !== i && (t[s] = r[i],
                    n--),
                    0 === n)
                        break
                }
                if (0 === n)
                    break
            }
            if (n > 0) {
                const n = [];
                throw t.forEach(((t,s)=>{
                    null == t && n.push(e[s])
                }
                )),
                new d_(`Cannot find SymbolicTensors for output name(s): ${JSON.stringify(n)}`)
            }
            return t
        }
        predictLoop(e, t=32, n=!1) {
            return Qo((()=>{
                const s = this.checkNumSamples(e);
                if (n)
                    throw new f_("Verbose predictLoop() is not implemented yet.");
                const r = EL(s, t)
                  , a = this.outputs.map((e=>[]));
                for (let t = 0; t < r.length; ++t) {
                    Qo((()=>{
                        const n = r[t][0]
                          , s = r[t][1]
                          , a = CL(e, n, s)
                          , i = [];
                        if (Array.isArray(a))
                            for (let e = 0; e < a.length; ++e)
                                i.push({
                                    key: this.inputs[e],
                                    value: a[e]
                                });
                        else
                            i.push({
                                key: this.inputs[0],
                                value: a
                            });
                        const o = new uM(i);
                        return pM(this.outputs, o)
                    }
                    )).forEach(((e,t)=>a[t].push(e)))
                }
                return w_(a.map((e=>ll(e, 0))))
            }
            ))
        }
        predict(e, t={}) {
            const n = AL(e);
            OL(n, this.inputNames, this.feedInputShapes, !1);
            try {
                const s = null == t.batchSize ? 32 : t.batchSize;
                return TL(s),
                this.predictLoop(n, s)
            } finally {
                RL(n, e)
            }
        }
        predictOnBatch(e) {
            OL(e, this.inputNames, this.feedInputShapes, !0);
            const t = (Array.isArray(e) ? e[0] : e).shape[0];
            return this.predictLoop(e, t)
        }
        standardizeUserDataXY(e, t, n=!0, s) {
            if (null == this.optimizer_)
                throw new p_("You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).");
            const r = [];
            for (let e = 0; e < this.feedOutputShapes.length; ++e) {
                const t = this.feedOutputShapes[e];
                this.feedLossFns[e] === GM ? r.push(t.slice(0, t.length - 1).concat([1])) : r.push(t)
            }
            if (function(e, t, n) {
                const s = E_(e.map((e=>e.shape[0])));
                s.sort();
                const r = E_(t.map((e=>e.shape[0])));
                if (r.sort(),
                s.length > 1)
                    throw new d_(`All input Tensors (x) should have the same number of samples. Got array shapes: ${JSON.stringify(e.map((e=>e.shape)))}`);
                if (r.length > 1)
                    throw new d_(`All target Tensors (y) should have the same number of samples. Got array shapes: ${JSON.stringify(t.map((e=>e.shape)))}`);
                if (s.length > 0 && r.length > 0 && !Hs.arraysEqual(s, r))
                    throw new d_(`Input Tensors should have the same number of samples as target Tensors. Found ${s[0]} input sample(s) and ${r[0]} target sample(s).`)
            }(e = _L(e, this.feedInputNames, this.feedInputShapes, !1, "input"), t = _L(t, this.feedOutputNames, r, !1, "target")),
            function(e, t, n) {
                const s = [BM, HM, VM];
                for (let r = 0; r < e.length; ++r) {
                    const a = e[r]
                      , i = t[r]
                      , o = n[r];
                    if (null != i) {
                        if (i === VM && 1 === a.shape[a.shape.length - 1])
                            throw new d_(`You are passing a target array of shape ${a.shape} while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes].`);
                        if (-1 !== s.indexOf(i)) {
                            const e = a.shape.slice(1)
                              , t = o.slice(1);
                            for (let n = 0; n < e.length; ++n) {
                                const s = e[n]
                                  , r = t[n];
                                if (null != r && s !== r)
                                    throw new d_(`A target Tensor with shape ${a.shape} was passed for an output of shape ${o}, while using a loss function that expects targets to have the same shape as the output.`)
                            }
                        }
                    }
                }
            }(t, this.feedLossFns, this.feedOutputShapes),
            this.stateful && null != s && s > 0 && e[0].shape[0] % s != 0)
                throw new d_(`In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size ${s}. Found: ${e[0].shape[0]} sample(s).`);
            return [e, t]
        }
        async standardizeUserData(e, t, n, s, r=!0, a) {
            const [i,o] = this.standardizeUserDataXY(e, t, r, a);
            if (null != n)
                throw new Error("sample weight is not supported yet.");
            let l = null;
            if (null != s) {
                const e = xL(s, this.outputNames);
                l = [];
                for (let t = 0; t < e.length; ++t)
                    l.push(await wL(o[t], null, e[t]))
            }
            return [i, o, l]
        }
        testLoop(e, t, n, s=0, r) {
            return Qo((()=>{
                const a = this.checkNumSamples(t, n, r, "steps")
                  , i = [];
                if (s > 0)
                    throw new f_("Verbose mode is not implemented yet.");
                if (null != r)
                    throw new f_("steps mode in testLoop() is not implemented yet");
                {
                    const s = EL(a, n)
                      , r = mu(rO(0, a));
                    for (let n = 0; n < s.length; ++n) {
                        const a = s[n][0]
                          , o = s[n][1]
                          , l = uO(r, a, o - a)
                          , u = $L(t, l)
                          , c = e(u);
                        if (0 === n)
                            for (let e = 0; e < c.length; ++e)
                                i.push(wl(0));
                        for (let e = 0; e < c.length; ++e) {
                            const t = c[e];
                            i[e] = sl(i[e], il(o - a, t))
                        }
                    }
                    for (let e = 0; e < i.length; ++e)
                        i[e] = al(i[e], a)
                }
                return i
            }
            ))
        }
        getDedupedMetricsNames() {
            const e = this.metricsNames
              , t = [];
            for (let n = 0; n < e.length; ++n) {
                const s = e[n];
                let r = s;
                if (x_(e, s) > 1) {
                    r += `_${x_(e.slice(0, n), s)}`
                }
                t.push(r)
            }
            return t
        }
        makeTrainFunction() {
            return e=>{
                const t = []
                  , n = e.slice(0, this.inputs.length)
                  , s = e.slice(this.inputs.length, this.inputs.length + this.outputs.length)
                  , r = e.slice(this.inputs.length + this.outputs.length, this.inputs.length + 2 * this.outputs.length)
                  , a = []
                  , i = this.collectedTrainableWeights.map((e=>e.read()));
                return [this.optimizer_.minimize((()=>{
                    const e = [];
                    for (let t = 0; t < this.inputs.length; ++t)
                        e.push({
                            key: this.inputs[t],
                            value: n[t]
                        });
                    const i = new uM(e)
                      , o = pM(this.outputs, i, {
                        training: !0
                    });
                    let l;
                    for (let e = 0; e < this.lossFunctions.length; ++e) {
                        let n = (0,
                        this.lossFunctions[e])(s[e], o[e]);
                        null != r[e] && (n = vL(n, r[e]));
                        const a = Mc(n);
                        t.push(a),
                        l = 0 === e ? n : sl(l, n)
                    }
                    for (let e = 0; e < this.metricsTensors.length; ++e) {
                        let n;
                        if (this.outputs.length > 1 && e < this.outputs.length)
                            n = t[e];
                        else {
                            const t = this.metricsTensors[e][0]
                              , r = this.metricsTensors[e][1];
                            n = Mc(t(s[r], o[r]))
                        }
                        tl(n),
                        a.push(n)
                    }
                    return l = Mc(l),
                    this.calculateLosses().forEach((e=>{
                        l = sl(l, e)
                    }
                    )),
                    l
                }
                ), !0, i)].concat(a)
            }
        }
        makeTestFunction() {
            this.testFunction = e=>Qo((()=>{
                const t = [];
                let n;
                const s = e.slice(0, this.inputs.length)
                  , r = e.slice(this.inputs.length, this.inputs.length + this.outputs.length)
                  , a = [];
                for (let e = 0; e < this.inputs.length; ++e)
                    a.push({
                        key: this.inputs[e],
                        value: s[e]
                    });
                const i = new uM(a)
                  , o = pM(this.outputs, i);
                for (let e = 0; e < this.lossFunctions.length; ++e) {
                    const s = this.lossFunctions[e]
                      , a = Mc(s(r[e], o[e]));
                    n = 0 === e ? a : sl(n, a),
                    t.push(n)
                }
                for (let e = 0; e < this.metricsTensors.length; ++e) {
                    const n = this.metricsTensors[e][0]
                      , s = this.metricsTensors[e][1]
                      , a = Mc(n(r[s], o[s]));
                    t.push(a)
                }
                return t
            }
            ))
        }
        async fit(e, t, n={}) {
            if (this.isTraining)
                throw new Error("Cannot start training because another fit() call is ongoing.");
            let s, r, a, i, o, l, u, c, h;
            this.isTraining = !0;
            try {
                const p = null == n.batchSize ? 32 : n.batchSize;
                TL(p);
                const d = !1
                  , f = await this.standardizeUserData(e, t, n.sampleWeight, n.classWeight, d, p);
                s = f[0],
                r = f[1],
                h = f[2];
                let m, g = !1;
                if (null != n.validationData && n.validationData.length > 0) {
                    if (g = !0,
                    2 !== n.validationData.length)
                        throw 3 === n.validationData.length ? new f_("validationData including sample weights is not supported yet.") : new d_(`When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; ${n.validationData} is invalid.`);
                    o = n.validationData[0],
                    l = n.validationData[1];
                    const e = !0
                      , t = await this.standardizeUserData(o, l, null, null, e, p);
                    u = t[0],
                    c = t[1],
                    m = u.concat(c)
                } else if (null != n.validationSplit && n.validationSplit > 0 && n.validationSplit < 1) {
                    g = !0;
                    const e = Math.floor(s[0].shape[0] * (1 - n.validationSplit))
                      , t = s[0].shape[0];
                    u = CL(s, e, t),
                    a = s,
                    s = CL(s, 0, e),
                    c = CL(r, e, t),
                    i = r,
                    r = CL(r, 0, e),
                    m = u.concat(c)
                } else
                    null != n.validationSteps && (g = !0);
                const y = s.concat(r).concat(h);
                this.checkTrainableWeightsConsistency();
                const b = this.makeTrainFunction()
                  , x = this.getDedupedMetricsNames();
                let w, v;
                g ? (this.makeTestFunction(),
                w = this.testFunction,
                v = x.slice().concat(x.map((e=>"val_" + e)))) : (w = null,
                m = [],
                v = x.slice());
                const k = _M(n.callbacks, n.yieldEvery);
                return await this.fitLoop(b, y, x, p, n.epochs, n.verbose, k, w, m, n.shuffle, v, n.initialEpoch, null, null)
            } finally {
                this.isTraining = !1,
                RL(s, e),
                RL(r, t),
                RL(a, e),
                RL(i, t),
                RL(u, o),
                RL(c, l),
                null != h && el(h)
            }
        }
        async fitLoop(e, t, n, s, r, a, i, o, l, u, c, h, p, d) {
            null == s && (s = 32),
            null == r && (r = 1),
            null == u && (u = !0),
            null == h && (h = 0);
            let f = !1;
            if (null != o && null != l && (f = !0),
            null != d && (f = !0,
            null == p))
                throw new d_("Can only use `validationSteps` when doing step-wise training, i.e., `stepsPerEpoch` must be set.");
            const m = this.checkNumSamples(t, s, p, "steps_per_epoch");
            let g;
            null != m && (g = rO(0, m)),
            null == a && (a = 1);
            const {callbackList: y, history: b} = MM(i, a, r, h, m, p, s, f, c);
            y.setModel(this),
            this.history = b,
            await y.onTrainBegin(),
            this.stopTraining_ = !1;
            for (let a = h; a < r; ++a) {
                await y.onEpochBegin(a);
                const r = {};
                if (null != p)
                    throw new f_("stepsPerEpoch mode is not implemented yet.");
                {
                    if ("batch" === u)
                        throw new f_("batch shuffling is not implemneted yet");
                    u && Hs.shuffle(g);
                    const a = mu(g)
                      , i = EL(m, s);
                    for (let u = 0; u < i.length; ++u) {
                        const c = {};
                        if (await y.onBatchBegin(u, c),
                        Qo((()=>{
                            const h = i[u][0]
                              , p = i[u][1]
                              , d = uO(a, h, p - h);
                            c.batch = u,
                            c.size = p - h;
                            const m = $L(t, d)
                              , g = e(m);
                            for (let e = 0; e < n.length; ++e) {
                                const t = n[e]
                                  , s = g[e];
                                c[t] = s,
                                tl(s)
                            }
                            if (u === i.length - 1 && f) {
                                const e = this.testLoop(o, l, s);
                                for (let t = 0; t < n.length; ++t) {
                                    const s = n[t]
                                      , a = e[t];
                                    tl(a),
                                    r["val_" + s] = a
                                }
                            }
                        }
                        )),
                        await y.onBatchEnd(u, c),
                        CM(c),
                        this.stopTraining_)
                            break
                    }
                    a.dispose()
                }
                if (await y.onEpochEnd(a, r),
                this.stopTraining_)
                    break
            }
            return await y.onTrainEnd(),
            await this.history.syncData(),
            this.history
        }
        async fitDataset(e, t) {
            return SL(this, e, t)
        }
        async trainOnBatch(e, t) {
            const n = await this.standardizeUserData(e, t)
              , s = n[0]
              , r = n[1]
              , a = this.makeTrainFunction()(s.concat(r))
              , i = [];
            for (const e of a) {
                const t = await e.data();
                i.push(t[0])
            }
            return el(a),
            RL(n[0], e),
            RL(n[1], t),
            w_(i)
        }
        getNamedWeights(e) {
            const t = []
              , n = null != e && e.trainableOnly
              , s = n ? this.trainableWeights : this.weights
              , r = this.getWeights(n);
            for (let e = 0; e < s.length; ++e)
                n && !s[e].trainable || t.push({
                    name: s[e].originalName,
                    tensor: r[e]
                });
            return t
        }
        set stopTraining(e) {
            this.stopTraining_ = e
        }
        get stopTraining() {
            return this.stopTraining_
        }
        get optimizer() {
            return this.optimizer_
        }
        set optimizer(e) {
            this.optimizer_ !== e && (this.optimizer_ = e,
            this.isOptimizerOwned = !1)
        }
        dispose() {
            const e = super.dispose();
            if (0 === e.refCountAfterDispose && null != this.optimizer && this.isOptimizerOwned) {
                const t = Jo().numTensors;
                this.optimizer_.dispose(),
                e.numDisposedVariables += t - Jo().numTensors
            }
            return e
        }
        getLossIdentifiers() {
            let e;
            if ("string" == typeof this.loss)
                e = k_(this.loss);
            else if (Array.isArray(this.loss)) {
                for (const e of this.loss)
                    if ("string" != typeof e)
                        throw new Error("Serialization of non-string loss is not supported.");
                e = this.loss.map((e=>k_(e)))
            } else {
                const t = Object.keys(this.loss);
                e = {};
                const n = this.loss;
                for (const s of t) {
                    if ("string" != typeof n[s])
                        throw new Error("Serialization of non-string loss is not supported.");
                    e[s] = k_(n[s])
                }
            }
            return e
        }
        getMetricIdentifiers() {
            if ("string" == typeof this.metrics || "function" == typeof this.metrics)
                return [k_(iL(this.metrics))];
            if (Array.isArray(this.metrics))
                return this.metrics.map((e=>k_(iL(e))));
            {
                const e = {};
                for (const t in this.metrics)
                    e[t] = k_(iL(this.metrics[t]));
                return e
            }
        }
        getTrainingConfig() {
            return {
                loss: this.getLossIdentifiers(),
                metrics: this.getMetricIdentifiers(),
                optimizer_config: {
                    class_name: this.optimizer.getClassName(),
                    config: this.optimizer.getConfig()
                }
            }
        }
        loadTrainingConfig(e) {
            if (null != e.weighted_metrics)
                throw new Error("Loading weight_metrics is not supported yet.");
            if (null != e.loss_weights)
                throw new Error("Loading loss_weights is not supported yet.");
            if (null != e.sample_weight_mode)
                throw new Error("Loading sample_weight_mode is not supported yet.");
            const t = LM(mL(e.optimizer_config));
            let n, s;
            if ("string" == typeof e.loss)
                n = I_(e.loss);
            else if (Array.isArray(e.loss))
                n = e.loss.map((e=>I_(e)));
            else if (null != e.loss) {
                n = {};
                for (const t in e.loss)
                    n[t] = I_(e.loss[t])
            }
            if (Array.isArray(e.metrics))
                s = e.metrics.map((e=>I_(e)));
            else if (null != e.metrics) {
                s = {};
                for (const t in e.metrics)
                    s[t] = I_(e.metrics[t])
            }
            this.compile({
                loss: n,
                metrics: s,
                optimizer: t
            })
        }
        async save(e, t) {
            if ("string" == typeof e) {
                const t = vf.getSaveHandlers(e);
                if (0 === t.length)
                    throw new d_(`Cannot find any save handlers for URL '${e}'`);
                if (t.length > 1)
                    throw new d_(`Found more than one (${t.length}) save handlers for URL '${e}'`);
                e = t[0]
            }
            if (null == e.save)
                throw new d_("LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");
            const n = await vf.encodeWeights(this.getNamedWeights(t))
              , s = {
                modelTopology: this.toJSON(null, !1),
                format: "layers-model",
                generatedBy: "TensorFlow.js tfjs-layers v4.2.0",
                convertedBy: null
            };
            if (null != t && t.includeOptimizer && null != this.optimizer) {
                s.trainingConfig = this.getTrainingConfig();
                const e = "optimizer"
                  , {data: t, specs: r} = await vf.encodeWeights(await this.optimizer.getWeights(), e);
                n.specs.push(...r),
                n.data = vf.concatenateArrayBuffers([n.data, t])
            }
            if (null != this.userDefinedMetadata) {
                const e = !0;
                lL(this.userDefinedMetadata, this.name, e),
                s.userDefinedMetadata = this.userDefinedMetadata
            }
            return s.weightData = n.data,
            s.weightSpecs = n.specs,
            e.save(s)
        }
        setUserDefinedMetadata(e) {
            lL(e, this.name),
            this.userDefinedMetadata = e
        }
        getUserDefinedMetadata() {
            return this.userDefinedMetadata
        }
    }
    ML.className = "Model",
    lf.registerClass(ML);
    class LL extends ML {
    }
    async function zL(e, t) {
        if (null == t && (t = {}),
        "string" == typeof e) {
            const n = vf.getLoadHandlers(e, t);
            if (0 === n.length)
                n.push(vf.browserHTTPRequest(e, t));
            else if (n.length > 1)
                throw new d_(`Found more than one (${n.length}) load handlers for URL '${e}'`);
            e = n[0]
        }
        return async function(e, t, n) {
            null == n && (n = {});
            if (null == e.load)
                throw new d_("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");
            const s = await e.load();
            let r = s.modelTopology;
            null != r.model_config && (r = r.model_config);
            const a = null == n.strict || n.strict
              , i = null != s.weightData && null != s.weightSpecs && a
              , o = LM(mL(r), t, i)
              , l = s.trainingConfig;
            null != l && o.loadTrainingConfig(l);
            null != s.userDefinedMetadata && o.setUserDefinedMetadata(s.userDefinedMetadata);
            if (null != s.weightData) {
                if (null == s.weightSpecs)
                    throw new d_("LayersModel artifacts contains weight data, but not weight specs. Therefore loading of weights cannot proceed.");
                const {modelWeights: e, optimizerWeights: t} = function(e, t) {
                    const n = vf.decodeWeights(e, t)
                      , s = {}
                      , r = [];
                    return t.forEach((e=>{
                        "optimizer" === e.group ? r.push({
                            name: e.name,
                            tensor: n[e.name]
                        }) : s[e.name] = n[e.name]
                    }
                    )),
                    {
                        modelWeights: s,
                        optimizerWeights: r
                    }
                }(s.weightData, s.weightSpecs);
                o.loadWeights(e, a),
                null != o.optimizer && t.length > 0 && await o.optimizer.setWeights(t),
                el(e),
                el(t.map((e=>e.tensor)))
            }
            return o
        }(e, void 0, t)
    }
    LL.className = "Functional",
    lf.registerClass(LL);
    class BL extends ML {
        constructor(e) {
            if (super({
                inputs: [],
                outputs: []
            }),
            e = e || {},
            this.trainable = !0,
            this.built = !1,
            this.name = null != e.name ? e.name : B_("sequential_"),
            null != e.layers)
                for (const t of e.layers)
                    this.add(t)
        }
        checkShape(e) {
            if (e.inboundNodes[0].outputTensors[0].shape.some((e=>e < 0)))
                throw new d_(`Negative dimension size caused by adding layer ${e.name} with input shape [${e.inboundNodes[0].inputTensors[0].shape}]`)
        }
        add(e) {
            const t = e instanceof BL || e instanceof ML;
            let n;
            if (t) {
                if (n = e,
                1 !== n.outputs.length)
                    throw new d_("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
                if (1 !== n.inputs.length)
                    throw new d_("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.")
            }
            if (0 === this.outputs.length) {
                if (0 === e.inboundNodes.length) {
                    if (null == e.batchInputShape)
                        throw new d_("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");
                    const t = lM({
                        batchShape: e.batchInputShape,
                        dtype: e.dtype,
                        name: e.name + "_input"
                    });
                    e.apply(t)
                }
                if (t)
                    this.outputs = n.outputs,
                    this.inputs = n.inputs;
                else {
                    if (1 !== e.inboundNodes.length)
                        throw new d_(`A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ${e.name} which has ${e.inboundNodes.length} pre-existing inbound connections.`);
                    if (1 !== e.inboundNodes[0].outputTensors.length)
                        throw new d_("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
                    this.checkShape(e),
                    this.outputs = [e.inboundNodes[0].outputTensors[0]],
                    this.inputs = iM(this.outputs[0])
                }
                this.inboundNodes = [],
                new sM({
                    outboundLayer: this,
                    inboundLayers: [],
                    nodeIndices: [],
                    tensorIndices: [],
                    inputTensors: this.inputs,
                    outputTensors: this.outputs,
                    inputMasks: y_(null, this.inputs.length),
                    outputMasks: [null],
                    inputShapes: this.inputs.map((e=>e.shape)),
                    outputShapes: this.outputs[0].shape
                })
            } else {
                const t = e.apply(this.outputs[0]);
                if (Array.isArray(t))
                    throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
                this.checkShape(e),
                this.outputs = [t],
                this.inboundNodes[0].outputTensors = this.outputs,
                this.inboundNodes[0].outputShapes = [this.outputs[0].shape]
            }
            this.layers.push(e),
            this.built = !1
        }
        pop() {
            if (0 === this.layers.length)
                throw new TypeError("There are no layers in the model.");
            if (this.layers.pop(),
            0 === this.layers.length)
                this.outputs = [],
                this.inboundNodes = [],
                this.outboundNodes = [];
            else {
                const e = this.layers.length - 1;
                this.layers[e].outboundNodes = [],
                this.outputs = [this.layers[e].output],
                this.inboundNodes[0].outputTensors = this.outputs,
                this.inboundNodes[0].outputShapes = [this.outputs[0].shape]
            }
        }
        call(e, t) {
            return null == this.model && this.build(),
            this.model.call(e, t)
        }
        build(e) {
            if (KO(e),
            0 === this.inputs.length || 0 === this.outputs.length)
                throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");
            this.model = new ML({
                inputs: this.inputs,
                outputs: this.outputs[0],
                name: this.name + "_model"
            }),
            this.model.trainable = this.trainable,
            this.supportsMasking = this.model.supportsMasking,
            this.inputLayers = this.model.inputLayers,
            this.inputLayersNodeIndices = this.model.inputLayersNodeIndices,
            this.inputLayersTensorIndices = this.model.inputLayersTensorIndices,
            this.outputLayers = this.model.outputLayers,
            this.outputLayersNodeIndices = this.model.outputLayersNodeIndices,
            this.outputLayersTensorIndices = this.model.outputLayersTensorIndices,
            this.nodesByDepth = this.model.nodesByDepth,
            this.containerNodes = this.model.containerNodes,
            this.outputNames = this.model.outputNames,
            this.inputNames = this.model.inputNames,
            this.built = !0
        }
        countParams() {
            return this.built || this.build(),
            super.countParams()
        }
        summary(e, t, n=console.log) {
            this.built || this.build(),
            super.summary(e, t, n)
        }
        setWeights(e) {
            null == this.model && this.build(),
            this.model.setWeights(e)
        }
        evaluate(e, t, n={}) {
            if (!this.built)
                throw new p_("The model needs to be compiled before being used.");
            return this.model.evaluate(e, t, n)
        }
        async evaluateDataset(e, t) {
            if (!this.built)
                throw new p_("The model needs to be compiled before being used.");
            return this.model.evaluateDataset(e, t)
        }
        predict(e, t={}) {
            return null == this.model && this.build(),
            this.model.predict(e, t)
        }
        predictOnBatch(e) {
            return null == this.model && this.build(),
            this.model.predictOnBatch(e)
        }
        compile(e) {
            this.build(),
            this.model.compile(e),
            this.optimizer_ = this.model.optimizer,
            this.isOptimizerOwned = this.model.isOptimizerOwned,
            this.loss = this.model.loss,
            this.metrics = this.model.metrics,
            this.metricsTensors = this.model.metricsTensors,
            this.metricsNames = this.model.metricsNames
        }
        get optimizer() {
            return null == this.model ? void 0 : this.model.optimizer
        }
        set optimizer(e) {
            this.model.optimizer = e
        }
        async fit(e, t, n={}) {
            if (!this.built)
                throw new p_("The model needs to be compiled before being used.");
            return this.model.fit(e, t, n)
        }
        async fitDataset(e, t) {
            if (!this.built)
                throw new p_("The model needs to be compiled before being used.");
            return this.model.fitDataset(e, t)
        }
        async trainOnBatch(e, t) {
            return this.model.trainOnBatch(e, t)
        }
        static fromConfig(e, t, n={}, s=!1) {
            let r, a = {};
            if (t instanceof Array) {
                if (null == t[0].className || "Merge" === t[0].className)
                    throw new d_("Legacy serialization format not supported yet.");
                r = t
            } else
                Hs.assert(null != t.layers, (()=>"When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field.")),
                r = t.layers,
                delete t.layers,
                a = t;
            const i = new e(a);
            if (!(i instanceof BL))
                throw new f_(`Sequential.fromConfig called on non-Sequential input: ${i}`);
            for (const e of r) {
                const t = LM(e, void 0, s);
                s && t.setFastWeightInitDuringBuild(!0),
                i.add(t)
            }
            return i
        }
        set stopTraining(e) {
            if (null == this.model)
                throw new d_("Cannot set the stopTraining property of a sequential model before it is compiled.");
            this.model.stopTraining = e
        }
        get stopTraining() {
            if (null == this.model)
                throw new d_("Cannot get the stopTraining property of a sequential model before it is compiled.");
            return this.model.stopTraining
        }
        getConfig() {
            const e = [];
            for (const t of this.layers) {
                const n = {};
                n.className = t.getClassName(),
                n.config = t.getConfig(),
                e.push(n)
            }
            return {
                name: this.name,
                layers: e
            }
        }
    }
    BL.className = "Sequential",
    lf.registerClass(BL);
    class PL extends lf.Serializable {
        getConfig() {
            return {}
        }
    }
    class WL extends PL {
        apply(e, t=1) {
            return function(e, t=1) {
                if (1 !== t)
                    throw new f_(`Support for alpha values other than 1 (${t}) is not implemented yet.`);
                return Xl(e)
            }(e, t)
        }
    }
    WL.className = "elu",
    lf.registerClass(WL);
    class UL extends PL {
        apply(e) {
            return hd(e)
        }
    }
    UL.className = "selu",
    lf.registerClass(UL);
    class VL extends PL {
        apply(e) {
            return Jl(e)
        }
    }
    VL.className = "relu",
    lf.registerClass(VL);
    class GL extends PL {
        apply(e) {
            return Qo((()=>Vc(6, Jl(e))))
        }
    }
    GL.className = "relu6",
    lf.registerClass(GL);
    class HL extends PL {
        apply(e) {
            return e
        }
    }
    HL.className = "linear",
    lf.registerClass(HL);
    class jL extends PL {
        apply(e) {
            return eu(e)
        }
    }
    jL.className = "sigmoid",
    lf.registerClass(jL);
    class qL extends PL {
        apply(e) {
            return function(e) {
                return Qo((()=>{
                    const t = sl(.5, il(.2, e));
                    return Ah(t, 0, 1)
                }
                ))
            }(e)
        }
    }
    qL.className = "hardSigmoid",
    lf.registerClass(qL);
    class KL extends PL {
        apply(e) {
            return up(e)
        }
    }
    KL.className = "softplus",
    lf.registerClass(KL);
    class XL extends PL {
        apply(e) {
            return function(e) {
                return Qo((()=>al(e, sl(uc(e), 1))))
            }(e)
        }
    }
    XL.className = "softsign",
    lf.registerClass(XL);
    class YL extends PL {
        apply(e) {
            return vh(e)
        }
    }
    YL.className = "tanh",
    lf.registerClass(YL);
    class ZL extends PL {
        apply(e, t=-1) {
            return vd(e, t)
        }
    }
    ZL.className = "softmax",
    lf.registerClass(ZL);
    class JL extends PL {
        apply(e, t=-1) {
            return hp(e, t)
        }
    }
    JL.className = "logSoftmax",
    lf.registerClass(JL);
    class QL extends PL {
        apply(e, t=1) {
            return Qo((()=>il(eu(il(e, t)), e)))
        }
    }
    QL.className = "swish",
    lf.registerClass(QL);
    class ez extends PL {
        apply(e) {
            return Qo((()=>il(e, vh(up(e)))))
        }
    }
    function tz(e) {
        return e.getClassName()
    }
    function nz(e, t={}) {
        return C_(e, lf.SerializationMap.getMap().classNameMap, t, "activation")
    }
    function sz(e) {
        if (null == e) {
            const e = {
                className: "linear",
                config: {}
            };
            return nz(e)
        }
        if ("string" == typeof e) {
            const t = {};
            return t.className = e,
            t.config = {},
            nz(t)
        }
        return e instanceof PL ? e : nz(e)
    }
    function rz(e) {
        if (null != e && "object" != typeof e)
            throw new Error(`Argument to L1L2 regularizer's constructor is expected to be an object, but received: ${e}`)
    }
    ez.className = "mish",
    lf.registerClass(ez);
    class az extends lf.Serializable {
    }
    class iz extends az {
        constructor(e) {
            super(),
            rz(e),
            this.l1 = null == e || null == e.l1 ? .01 : e.l1,
            this.l2 = null == e || null == e.l2 ? .01 : e.l2,
            this.hasL1 = 0 !== this.l1,
            this.hasL2 = 0 !== this.l2
        }
        apply(e) {
            return Qo((()=>{
                let t = fl([1]);
                return this.hasL1 && (t = sl(t, nu(il(this.l1, uc(e))))),
                this.hasL2 && (t = sl(t, nu(il(this.l2, bO(e))))),
                hl(t, [])
            }
            ))
        }
        getConfig() {
            return {
                l1: this.l1,
                l2: this.l2
            }
        }
        static fromConfig(e, t) {
            return new e({
                l1: t.l1,
                l2: t.l2
            })
        }
    }
    iz.className = "L1L2",
    lf.registerClass(iz);
    const oz = {
        l1l2: "L1L2"
    };
    function lz(e) {
        return N_(e)
    }
    function uz(e, t={}) {
        return C_(e, lf.SerializationMap.getMap().classNameMap, t, "regularizer")
    }
    function cz(e) {
        if (null == e)
            return null;
        if ("string" == typeof e) {
            return uz({
                className: e in oz ? oz[e] : e,
                config: {}
            })
        }
        return e instanceof az ? e : uz(e)
    }
    class hz extends aM {
        constructor(e) {
            super(null == e ? {} : e),
            this.supportsMasking = !0,
            null != e && (this.maxValue = e.maxValue)
        }
        call(e, t) {
            e = qO(e);
            let n = Jl(e);
            return null != this.maxValue && (n = Ah(n, 0, this.maxValue)),
            n
        }
        computeOutputShape(e) {
            return e
        }
        getConfig() {
            const e = {
                maxValue: this.maxValue
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    hz.className = "ReLU",
    lf.registerClass(hz);
    class pz extends aM {
        constructor(e) {
            super(null == e ? {} : e),
            this.DEFAULT_ALPHA = .3,
            null == e && (e = {}),
            this.alpha = null == e.alpha ? this.DEFAULT_ALPHA : e.alpha
        }
        call(e, t) {
            const n = qO(e);
            return Yl(n, this.alpha)
        }
        computeOutputShape(e) {
            return e
        }
        getConfig() {
            const e = {
                alpha: this.alpha
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    pz.className = "LeakyReLU",
    lf.registerClass(pz);
    class dz extends aM {
        constructor(e) {
            if (super(null == e ? {} : e),
            this.DEFAULT_ALPHA_INITIALIZER = "zeros",
            null == e && (e = {}),
            this.supportsMasking = !0,
            this.alphaInitializer = GO(e.alphaInitializer || this.DEFAULT_ALPHA_INITIALIZER),
            this.alphaRegularizer = cz(e.alphaRegularizer),
            this.alphaConstraint = NM(e.alphaConstraint),
            null == e.sharedAxes)
                this.sharedAxes = null;
            else if (Array.isArray(e.sharedAxes))
                this.sharedAxes = e.sharedAxes;
            else {
                if ("number" != typeof e.sharedAxes)
                    throw new d_(`Expected sharedAxes to be a number or an array of numbers, but got ${e.sharedAxes}`);
                this.sharedAxes = [e.sharedAxes]
            }
        }
        build(e) {
            const t = (e = KO(e)).slice(1);
            if (null != this.sharedAxes)
                for (const e of this.sharedAxes)
                    t[e - 1] = 1;
            this.alpha = this.addWeight("alpha", t, "float32", this.alphaInitializer, this.alphaRegularizer, !0, this.alphaConstraint);
            const n = {};
            if (null != this.sharedAxes)
                for (let t = 1; t < e.length; ++t)
                    n[t] = e[t];
            this.inputSpec = [new eM({
                ndim: e.length,
                axes: n
            })],
            this.built = !0
        }
        call(e, t) {
            return e = qO(e),
            Zl(e, this.alpha.read())
        }
        getConfig() {
            const e = {
                alphaInitializer: VO(this.alphaInitializer),
                alphaRegularizer: lz(this.alphaRegularizer),
                alphaConstraint: IM(this.alphaConstraint),
                sharedAxes: this.sharedAxes
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    dz.className = "PReLU",
    lf.registerClass(dz);
    class fz extends aM {
        constructor(e) {
            if (super(null == e ? {} : e),
            this.DEFAULT_ALPHA = 1,
            null == e && (e = {}),
            null != e.alpha && e.alpha !== this.DEFAULT_ALPHA)
                throw new f_(`Non-default alpha value (${e.alpha}) is not supported by the ELU layer yet.`);
            this.alpha = null == e.alpha ? this.DEFAULT_ALPHA : e.alpha
        }
        call(e, t) {
            const n = qO(e);
            return Xl(n)
        }
        computeOutputShape(e) {
            return e
        }
        getConfig() {
            const e = {
                alpha: this.alpha
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    fz.className = "ELU",
    lf.registerClass(fz);
    class mz extends aM {
        constructor(e) {
            super(null == e ? {} : e),
            this.DEFAULT_THETA = 1,
            null == e && (e = {}),
            this.theta = null == e.theta ? this.DEFAULT_THETA : e.theta
        }
        call(e, t) {
            const n = qO(e);
            return il(n, Ko(Xu(n, this.theta), "float32"))
        }
        computeOutputShape(e) {
            return e
        }
        getConfig() {
            const e = {
                theta: this.theta
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    mz.className = "ThresholdedReLU",
    lf.registerClass(mz);
    class gz extends aM {
        constructor(e) {
            super(null == e ? {} : e),
            this.DEFAULT_AXIS = 1,
            null == e && (e = {}),
            this.softmax = (new ZL).apply,
            this.axis = null == e.axis ? this.DEFAULT_AXIS : e.axis
        }
        call(e, t) {
            const n = qO(e);
            return this.softmax(n, this.axis)
        }
        computeOutputShape(e) {
            return e
        }
        getConfig() {
            const e = {
                axis: this.axis
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    function yz(e, t, n) {
        if ("number" == typeof e)
            return y_(e, t);
        if (e.length !== t)
            throw new d_(`The ${n} argument must be an integer or tuple of ${t} integers. Received: ${e.length} elements.`);
        for (let r = 0; r < t; ++r) {
            const a = e[r];
            if ((s = a) !== parseInt(s.toString(), 10))
                throw new d_(`The ${n} argument must be an integer or tuple of ${t} integers. Received: ${JSON.stringify(e)} including a non-integer number ${a}`)
        }
        return e;
        var s
    }
    function bz(e, t, n, s, r=1) {
        if (null == e)
            return e;
        let a;
        return a = "same" === n ? e : e - (t + (t - 1) * (r - 1)) + 1,
        Math.floor((a + s - 1) / s)
    }
    function xz(e, t, n, s) {
        if (null == e)
            return null;
        if ("valid" === s)
            e = e * t + sO([n - t, 0]);
        else {
            if ("same" !== s)
                throw new d_(`Unsupport padding mode: ${s}.`);
            e *= t
        }
        return e
    }
    function wz(e, t) {
        return Qo((()=>(j_(t),
        "channelsFirst" === t ? Fc(e, [0, 2, 3, 1]) : e)))
    }
    function vz(e, t) {
        return Qo((()=>(j_(t),
        "channelsFirst" === t ? Fc(e, [0, 2, 3, 4, 1]) : e)))
    }
    function kz(e, t, n, s=1, r="valid", a, i=1) {
        return Qo((()=>{
            if (null == a && (a = "channelsLast"),
            j_(a),
            3 !== e.shape.length)
                throw new d_(`The input of a conv1dWithBias operation should be 3, but is ${e.shape.length} instead.`);
            if (3 !== t.shape.length)
                throw new d_(`The kernel for a conv1dWithBias operation should be 3, but is ${t.shape.length} instead`);
            if (null != n && 1 !== n.shape.length)
                throw new d_(`The bias for a conv1dWithBias operation should be 1, but is ${t.shape.length} instead`);
            if ("channelsFirst" === a && (e = Fc(e, [0, 2, 1])),
            "causal" === r)
                throw new f_("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");
            let o = Oh(e, t, s, "same" === r ? "same" : "valid", "NWC", i);
            return null != n && (o = wO(o, n)),
            o
        }
        ))
    }
    function Iz(e, t, n, s=[1, 1], r="valid", a, i, o=null) {
        return Qo((()=>{
            if (null == a && (a = "channelsLast"),
            j_(a),
            3 !== e.rank && 4 !== e.rank)
                throw new d_(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${e.rank}.`);
            if (3 !== t.rank && 4 !== t.rank)
                throw new d_(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${e.rank}.`);
            let l = wz(e, a);
            if ("causal" === r)
                throw new f_("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");
            return l = kl.conv2d({
                x: l,
                filter: t,
                strides: s,
                pad: "same" === r ? "same" : "valid",
                dilations: i,
                dataFormat: "NHWC",
                bias: n,
                activation: o
            }),
            "channelsFirst" === a && (l = Fc(l, [0, 3, 1, 2])),
            l
        }
        ))
    }
    function Sz(e, t, n, s=[1, 1, 1], r="valid", a, i) {
        return Qo((()=>{
            if (null == a && (a = "channelsLast"),
            j_(a),
            4 !== e.rank && 5 !== e.rank)
                throw new d_(`conv3dWithBias expects input to be of rank 4 or 5, but received ${e.rank}.`);
            if (4 !== t.rank && 5 !== t.rank)
                throw new d_(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ${e.rank}.`);
            let o = vz(e, a);
            if ("causal" === r)
                throw new f_("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");
            return o = Lh(o, t, s, "same" === r ? "same" : "valid", "NDHWC", i),
            null != n && (o = wO(o, n)),
            "channelsFirst" === a && (o = Fc(o, [0, 4, 1, 2, 3])),
            o
        }
        ))
    }
    gz.className = "Softmax",
    lf.registerClass(gz);
    class Nz extends aM {
        constructor(e, t) {
            if (super(t),
            this.bias = null,
            this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal",
            this.DEFAULT_BIAS_INITIALIZER = "zeros",
            Nz.verifyArgs(t),
            this.rank = e,
            D_(this.rank, "rank"),
            1 !== this.rank && 2 !== this.rank && 3 !== this.rank)
                throw new f_(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);
            if (this.kernelSize = yz(t.kernelSize, e, "kernelSize"),
            this.strides = yz(null == t.strides ? 1 : t.strides, e, "strides"),
            this.padding = null == t.padding ? "valid" : t.padding,
            q_(this.padding),
            this.dataFormat = null == t.dataFormat ? "channelsLast" : t.dataFormat,
            j_(this.dataFormat),
            this.activation = sz(t.activation),
            this.useBias = null == t.useBias || t.useBias,
            this.biasInitializer = GO(t.biasInitializer || this.DEFAULT_BIAS_INITIALIZER),
            this.biasConstraint = NM(t.biasConstraint),
            this.biasRegularizer = cz(t.biasRegularizer),
            this.activityRegularizer = cz(t.activityRegularizer),
            this.dilationRate = yz(null == t.dilationRate ? 1 : t.dilationRate, e, "dilationRate"),
            1 === this.rank && Array.isArray(this.dilationRate) && 1 !== this.dilationRate.length)
                throw new d_(`dilationRate must be a number or an array of a single number for 1D convolution, but received ${JSON.stringify(this.dilationRate)}`);
            if (2 === this.rank) {
                if ("number" == typeof this.dilationRate)
                    this.dilationRate = [this.dilationRate, this.dilationRate];
                else if (2 !== this.dilationRate.length)
                    throw new d_(`dilationRate must be a number or array of two numbers for 2D convolution, but received ${JSON.stringify(this.dilationRate)}`)
            } else if (3 === this.rank)
                if ("number" == typeof this.dilationRate)
                    this.dilationRate = [this.dilationRate, this.dilationRate, this.dilationRate];
                else if (3 !== this.dilationRate.length)
                    throw new d_(`dilationRate must be a number or array of three numbers for 3D convolution, but received ${JSON.stringify(this.dilationRate)}`)
        }
        static verifyArgs(e) {
            if (b_("kernelSize"in e, "required key 'kernelSize' not in config"),
            "number" != typeof e.kernelSize && !F_(e.kernelSize, "number", 1, 3))
                throw new d_(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(e.kernelSize)}.`)
        }
        getConfig() {
            const e = {
                kernelSize: this.kernelSize,
                strides: this.strides,
                padding: this.padding,
                dataFormat: this.dataFormat,
                dilationRate: this.dilationRate,
                activation: tz(this.activation),
                useBias: this.useBias,
                biasInitializer: VO(this.biasInitializer),
                biasRegularizer: lz(this.biasRegularizer),
                activityRegularizer: lz(this.activityRegularizer),
                biasConstraint: IM(this.biasConstraint)
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    class Tz extends Nz {
        constructor(e, t) {
            super(e, t),
            this.kernel = null,
            Tz.verifyArgs(t),
            this.filters = t.filters,
            D_(this.filters, "filters"),
            this.kernelInitializer = GO(t.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER),
            this.kernelConstraint = NM(t.kernelConstraint),
            this.kernelRegularizer = cz(t.kernelRegularizer)
        }
        build(e) {
            e = KO(e);
            const t = "channelsFirst" === this.dataFormat ? 1 : e.length - 1;
            if (null == e[t])
                throw new d_(`The channel dimension of the input should be defined. Found ${e[t]}`);
            const n = e[t]
              , s = this.kernelSize.concat([n, this.filters]);
            this.kernel = this.addWeight("kernel", s, null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint),
            this.useBias && (this.bias = this.addWeight("bias", [this.filters], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint)),
            this.inputSpec = [{
                ndim: this.rank + 2,
                axes: {
                    [t]: n
                }
            }],
            this.built = !0
        }
        call(e, t) {
            return Qo((()=>{
                let t;
                e = qO(e);
                const n = null == this.bias ? null : this.bias.read()
                  , s = O_(this.activation.getClassName());
                if (null != s && 2 === this.rank)
                    t = Iz(e, this.kernel.read(), n, this.strides, this.padding, this.dataFormat, this.dilationRate, s);
                else {
                    if (1 === this.rank)
                        t = kz(e, this.kernel.read(), n, this.strides[0], this.padding, this.dataFormat, this.dilationRate[0]);
                    else if (2 === this.rank)
                        t = Iz(e, this.kernel.read(), n, this.strides, this.padding, this.dataFormat, this.dilationRate);
                    else {
                        if (3 !== this.rank)
                            throw new f_("convolutions greater than 3D are not implemented yet.");
                        t = Sz(e, this.kernel.read(), n, this.strides, this.padding, this.dataFormat, this.dilationRate)
                    }
                    null != this.activation && (t = this.activation.apply(t))
                }
                return t
            }
            ))
        }
        computeOutputShape(e) {
            e = KO(e);
            const t = []
              , n = "channelsLast" === this.dataFormat ? e.slice(1, e.length - 1) : e.slice(2);
            for (let e = 0; e < n.length; ++e) {
                const s = bz(n[e], this.kernelSize[e], this.padding, this.strides[e], "number" == typeof this.dilationRate ? this.dilationRate : this.dilationRate[e]);
                t.push(s)
            }
            let s = [e[0]];
            return "channelsLast" === this.dataFormat ? (s = s.concat(t),
            s.push(this.filters)) : (s.push(this.filters),
            s = s.concat(t)),
            s
        }
        getConfig() {
            const e = {
                filters: this.filters,
                kernelInitializer: VO(this.kernelInitializer),
                kernelRegularizer: lz(this.kernelRegularizer),
                kernelConstraint: IM(this.kernelConstraint)
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
        static verifyArgs(e) {
            if (!("filters"in e) || "number" != typeof e.filters || e.filters < 1)
                throw new d_(`Convolution layer expected config.filters to be a 'number' > 0 but got ${JSON.stringify(e.filters)}`)
        }
    }
    class Cz extends Tz {
        constructor(e) {
            super(2, e),
            Cz.verifyArgs(e)
        }
        getConfig() {
            const e = super.getConfig();
            return delete e.rank,
            e
        }
        static verifyArgs(e) {
            if ("number" != typeof e.kernelSize && !F_(e.kernelSize, "number", 1, 2))
                throw new d_(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(e.kernelSize)}.`)
        }
    }
    Cz.className = "Conv2D",
    lf.registerClass(Cz);
    class $z extends Tz {
        constructor(e) {
            super(3, e),
            $z.verifyArgs(e)
        }
        getConfig() {
            const e = super.getConfig();
            return delete e.rank,
            e
        }
        static verifyArgs(e) {
            if ("number" != typeof e.kernelSize && (!Array.isArray(e.kernelSize) || 1 !== e.kernelSize.length && 3 !== e.kernelSize.length))
                throw new d_(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(e.kernelSize)}.`)
        }
    }
    $z.className = "Conv3D",
    lf.registerClass($z);
    class Ez extends Cz {
        constructor(e) {
            if (super(e),
            this.inputSpec = [new eM({
                ndim: 4
            })],
            "same" !== this.padding && "valid" !== this.padding)
                throw new d_(`Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)
        }
        build(e) {
            if (4 !== (e = KO(e)).length)
                throw new d_("Input should have rank 4; Received input shape: " + JSON.stringify(e));
            const t = "channelsFirst" === this.dataFormat ? 1 : e.length - 1;
            if (null == e[t])
                throw new d_("The channel dimension of the inputs should be defined. Found `None`.");
            const n = e[t]
              , s = this.kernelSize.concat([this.filters, n]);
            this.kernel = this.addWeight("kernel", s, "float32", this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint),
            this.useBias && (this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint)),
            this.inputSpec = [new eM({
                ndim: 4,
                axes: {
                    [t]: n
                }
            })],
            this.built = !0
        }
        call(e, t) {
            return Qo((()=>{
                let t = qO(e);
                if (4 !== t.shape.length)
                    throw new d_(`Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${t.shape.length}`);
                const n = t.shape
                  , s = n[0];
                let r, a;
                "channelsFirst" === this.dataFormat ? (r = 2,
                a = 3) : (r = 1,
                a = 2);
                const i = n[r]
                  , o = n[a]
                  , l = this.kernelSize[0]
                  , u = this.kernelSize[1]
                  , c = this.strides[0]
                  , h = this.strides[1]
                  , p = [s, xz(i, c, l, this.padding), xz(o, h, u, this.padding), this.filters];
                "channelsLast" !== this.dataFormat && (t = Fc(t, [0, 2, 3, 1]));
                let d = Mh(t, this.kernel.read(), p, this.strides, this.padding);
                return "channelsLast" !== this.dataFormat && (d = Fc(d, [0, 3, 1, 2])),
                null != this.bias && (d = wO(d, this.bias.read(), this.dataFormat)),
                null != this.activation && (d = this.activation.apply(d)),
                d
            }
            ))
        }
        computeOutputShape(e) {
            const t = (e = KO(e)).slice();
            let n, s, r;
            "channelsFirst" === this.dataFormat ? (n = 1,
            s = 2,
            r = 3) : (n = 3,
            s = 1,
            r = 2);
            const a = this.kernelSize[0]
              , i = this.kernelSize[1]
              , o = this.strides[0]
              , l = this.strides[1];
            return t[n] = this.filters,
            t[s] = xz(t[s], o, a, this.padding),
            t[r] = xz(t[r], l, i, this.padding),
            t
        }
        getConfig() {
            const e = super.getConfig();
            return delete e.dilationRate,
            e
        }
    }
    Ez.className = "Conv2DTranspose",
    lf.registerClass(Ez);
    class Az extends $z {
        constructor(e) {
            if (super(e),
            this.inputSpec = [new eM({
                ndim: 5
            })],
            "same" !== this.padding && "valid" !== this.padding)
                throw new d_(`Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)
        }
        build(e) {
            if (5 !== (e = KO(e)).length)
                throw new d_("Input should have rank 5; Received input shape: " + JSON.stringify(e));
            const t = "channelsFirst" === this.dataFormat ? 1 : e.length - 1;
            if (null == e[t])
                throw new d_("The channel dimension of the inputs should be defined. Found `None`.");
            const n = e[t]
              , s = this.kernelSize.concat([this.filters, n]);
            this.kernel = this.addWeight("kernel", s, "float32", this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint),
            this.useBias && (this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint)),
            this.inputSpec = [new eM({
                ndim: 5,
                axes: {
                    [t]: n
                }
            })],
            this.built = !0
        }
        call(e, t) {
            return Qo((()=>{
                let t = qO(e);
                if (5 !== t.shape.length)
                    throw new d_(`Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${t.shape.length}`);
                const n = t.shape
                  , s = n[0];
                let r, a, i;
                "channelsFirst" === this.dataFormat ? (i = 2,
                r = 3,
                a = 4) : (i = 1,
                r = 2,
                a = 3);
                const o = n[i]
                  , l = n[r]
                  , u = n[a]
                  , c = this.kernelSize[0]
                  , h = this.kernelSize[1]
                  , p = this.kernelSize[2]
                  , d = this.strides[0]
                  , f = this.strides[1]
                  , m = this.strides[2]
                  , g = [s, xz(o, d, c, this.padding), xz(l, f, h, this.padding), xz(u, m, p, this.padding), this.filters];
                "channelsLast" !== this.dataFormat && (t = Fc(t, [0, 2, 3, 4, 1]));
                let y = Bh(t, this.kernel.read(), g, this.strides, this.padding);
                return "channelsLast" !== this.dataFormat && (y = Fc(y, [0, 4, 1, 2, 3])),
                null !== this.bias && (y = wO(y, this.bias.read(), this.dataFormat)),
                null !== this.activation && (y = this.activation.apply(y)),
                y
            }
            ))
        }
        computeOutputShape(e) {
            const t = (e = KO(e)).slice();
            let n, s, r, a;
            "channelsFirst" === this.dataFormat ? (n = 1,
            s = 2,
            r = 3,
            a = 4) : (n = 4,
            s = 1,
            r = 2,
            a = 3);
            const i = this.kernelSize[0]
              , o = this.kernelSize[1]
              , l = this.kernelSize[2]
              , u = this.strides[0]
              , c = this.strides[1]
              , h = this.strides[2];
            return t[n] = this.filters,
            t[s] = xz(t[s], u, i, this.padding),
            t[r] = xz(t[r], c, o, this.padding),
            t[a] = xz(t[a], h, l, this.padding),
            t
        }
        getConfig() {
            const e = super.getConfig();
            return delete e.dilationRate,
            e
        }
    }
    Az.className = "Conv3DTranspose",
    lf.registerClass(Az);
    class Rz extends Tz {
        constructor(e, t) {
            if (super(e, t),
            this.DEFAULT_DEPTHWISE_INITIALIZER = "glorotUniform",
            this.DEFAULT_POINTWISE_INITIALIZER = "glorotUniform",
            this.depthwiseKernel = null,
            this.pointwiseKernel = null,
            null == t.filters)
                throw new d_("The `filters` configuration field is required by SeparableConv, but is unspecified.");
            if (null != t.kernelInitializer || null != t.kernelRegularizer || null != t.kernelConstraint)
                throw new d_("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");
            if (null != t.padding && "same" !== t.padding && "valid" !== t.padding)
                throw new d_(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received ${JSON.stringify(t.padding)}`);
            this.depthMultiplier = null == t.depthMultiplier ? 1 : t.depthMultiplier,
            this.depthwiseInitializer = GO(t.depthwiseInitializer || this.DEFAULT_DEPTHWISE_INITIALIZER),
            this.depthwiseRegularizer = cz(t.depthwiseRegularizer),
            this.depthwiseConstraint = NM(t.depthwiseConstraint),
            this.pointwiseInitializer = GO(t.depthwiseInitializer || this.DEFAULT_POINTWISE_INITIALIZER),
            this.pointwiseRegularizer = cz(t.pointwiseRegularizer),
            this.pointwiseConstraint = NM(t.pointwiseConstraint)
        }
        build(e) {
            if ((e = KO(e)).length < this.rank + 2)
                throw new d_(`Inputs to SeparableConv${this.rank}D should have rank ${this.rank + 2}, but received input shape: ${JSON.stringify(e)}`);
            const t = "channelsFirst" === this.dataFormat ? 1 : e.length - 1;
            if (null == e[t] || e[t] < 0)
                throw new d_(`The channel dimension of the inputs should be defined, but found ${JSON.stringify(e[t])}`);
            const n = e[t]
              , s = this.kernelSize.concat([n, this.depthMultiplier])
              , r = [];
            for (let e = 0; e < this.rank; ++e)
                r.push(1);
            r.push(n * this.depthMultiplier, this.filters);
            const a = !0;
            this.depthwiseKernel = this.addWeight("depthwise_kernel", s, "float32", this.depthwiseInitializer, this.depthwiseRegularizer, a, this.depthwiseConstraint),
            this.pointwiseKernel = this.addWeight("pointwise_kernel", r, "float32", this.pointwiseInitializer, this.pointwiseRegularizer, a, this.pointwiseConstraint),
            this.useBias ? this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, a, this.biasConstraint) : this.bias = null,
            this.inputSpec = [new eM({
                ndim: this.rank + 2,
                axes: {
                    [t]: n
                }
            })],
            this.built = !0
        }
        call(e, t) {
            return Qo((()=>{
                let t;
                if (e = qO(e),
                1 === this.rank)
                    throw new f_("1D separable convolution is not implemented yet.");
                return 2 === this.rank && ("channelsFirst" === this.dataFormat && (e = Fc(e, [0, 2, 3, 1])),
                t = pd(e, this.depthwiseKernel.read(), this.pointwiseKernel.read(), this.strides, this.padding, this.dilationRate, "NHWC")),
                this.useBias && (t = wO(t, this.bias.read(), this.dataFormat)),
                null != this.activation && (t = this.activation.apply(t)),
                "channelsFirst" === this.dataFormat && (t = Fc(t, [0, 3, 1, 2])),
                t
            }
            ))
        }
        getConfig() {
            const e = super.getConfig();
            return delete e.rank,
            delete e.kernelInitializer,
            delete e.kernelRegularizer,
            delete e.kernelConstraint,
            e.depthwiseInitializer = VO(this.depthwiseInitializer),
            e.pointwiseInitializer = VO(this.pointwiseInitializer),
            e.depthwiseRegularizer = lz(this.depthwiseRegularizer),
            e.pointwiseRegularizer = lz(this.pointwiseRegularizer),
            e.depthwiseConstraint = IM(this.depthwiseConstraint),
            e.pointwiseConstraint = IM(this.pointwiseConstraint),
            e
        }
    }
    Rz.className = "SeparableConv";
    class Fz extends Rz {
        constructor(e) {
            super(2, e)
        }
    }
    Fz.className = "SeparableConv2D",
    lf.registerClass(Fz);
    class Dz extends Tz {
        constructor(e) {
            super(1, e),
            Dz.verifyArgs(e),
            this.inputSpec = [{
                ndim: 3
            }]
        }
        getConfig() {
            const e = super.getConfig();
            return delete e.rank,
            delete e.dataFormat,
            e
        }
        static verifyArgs(e) {
            if ("number" != typeof e.kernelSize && !F_(e.kernelSize, "number", 1, 1))
                throw new d_(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(e.kernelSize)}.`)
        }
    }
    Dz.className = "Conv1D",
    lf.registerClass(Dz);
    class _z extends aM {
        constructor(e) {
            super(e),
            "number" == typeof e.cropping ? this.cropping = [[e.cropping, e.cropping], [e.cropping, e.cropping]] : "number" == typeof e.cropping[0] ? this.cropping = [[e.cropping[0], e.cropping[0]], [e.cropping[1], e.cropping[1]]] : this.cropping = e.cropping,
            this.dataFormat = void 0 === e.dataFormat ? "channelsLast" : e.dataFormat,
            this.inputSpec = [{
                ndim: 4
            }]
        }
        computeOutputShape(e) {
            return "channelsFirst" === this.dataFormat ? [e[0], e[1], e[2] - this.cropping[0][0] - this.cropping[0][1], e[3] - this.cropping[1][0] - this.cropping[1][1]] : [e[0], e[1] - this.cropping[0][0] - this.cropping[0][1], e[2] - this.cropping[1][0] - this.cropping[1][1], e[3]]
        }
        call(e, t) {
            return Qo((()=>{
                if (e = qO(e),
                "channelsLast" === this.dataFormat) {
                    const t = hO(e, this.cropping[0][0], e.shape[1] - this.cropping[0][0] - this.cropping[0][1], 2);
                    return hO(t, this.cropping[1][0], e.shape[2] - this.cropping[1][1] - this.cropping[1][0], 3)
                }
                {
                    const t = hO(e, this.cropping[0][0], e.shape[2] - this.cropping[0][0] - this.cropping[0][1], 3);
                    return hO(t, this.cropping[1][0], e.shape[3] - this.cropping[1][1] - this.cropping[1][0], 4)
                }
            }
            ))
        }
        getConfig() {
            const e = {
                cropping: this.cropping,
                dataFormat: this.dataFormat
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    _z.className = "Cropping2D",
    lf.registerClass(_z);
    class Oz extends aM {
        constructor(e) {
            var t;
            super(e),
            this.DEFAULT_SIZE = [2, 2],
            this.inputSpec = [{
                ndim: 4
            }],
            this.size = null == e.size ? this.DEFAULT_SIZE : e.size,
            this.dataFormat = null == e.dataFormat ? "channelsLast" : e.dataFormat,
            j_(this.dataFormat),
            this.interpolation = null == e.interpolation ? "nearest" : e.interpolation,
            t = this.interpolation,
            R_(W_, "InterpolationFormat", t)
        }
        computeOutputShape(e) {
            if ("channelsFirst" === this.dataFormat) {
                const t = null == e[2] ? null : this.size[0] * e[2]
                  , n = null == e[3] ? null : this.size[1] * e[3];
                return [e[0], e[1], t, n]
            }
            {
                const t = null == e[1] ? null : this.size[0] * e[1]
                  , n = null == e[2] ? null : this.size[1] * e[2];
                return [e[0], t, n, e[3]]
            }
        }
        call(e, t) {
            return Qo((()=>{
                let t = qO(e);
                const n = t.shape;
                if ("channelsFirst" === this.dataFormat) {
                    t = Fc(t, [0, 2, 3, 1]);
                    const e = this.size[0] * n[2]
                      , s = this.size[1] * n[3]
                      , r = "nearest" === this.interpolation ? nf.resizeNearestNeighbor(t, [e, s]) : nf.resizeBilinear(t, [e, s]);
                    return Fc(r, [0, 3, 1, 2])
                }
                {
                    const e = this.size[0] * n[1]
                      , s = this.size[1] * n[2];
                    return "nearest" === this.interpolation ? nf.resizeNearestNeighbor(t, [e, s]) : nf.resizeBilinear(t, [e, s])
                }
            }
            ))
        }
        getConfig() {
            const e = {
                size: this.size,
                dataFormat: this.dataFormat,
                interpolation: this.interpolation
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    Oz.className = "UpSampling2D",
    lf.registerClass(Oz);
    class Mz extends Nz {
        constructor(e) {
            super(2, e),
            this.depthwiseKernel = null,
            this.depthMultiplier = null == e.depthMultiplier ? 1 : e.depthMultiplier,
            this.depthwiseInitializer = GO(e.depthwiseInitializer || this.DEFAULT_KERNEL_INITIALIZER),
            this.depthwiseConstraint = NM(e.depthwiseConstraint),
            this.depthwiseRegularizer = cz(e.depthwiseRegularizer)
        }
        build(e) {
            if ((e = KO(e)).length < 4)
                throw new d_(`Inputs to DepthwiseConv2D should have rank 4. Received input shape: ${JSON.stringify(e)}.`);
            const t = "channelsFirst" === this.dataFormat ? 1 : 3;
            if (null == e[t] || e[t] < 0)
                throw new d_(`The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (${e[t]}).`);
            const n = e[t]
              , s = [this.kernelSize[0], this.kernelSize[1], n, this.depthMultiplier];
            this.depthwiseKernel = this.addWeight("depthwise_kernel", s, null, this.depthwiseInitializer, this.depthwiseRegularizer, !0, this.depthwiseConstraint),
            this.useBias ? this.bias = this.addWeight("bias", [n * this.depthMultiplier], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint) : this.bias = null,
            this.built = !0
        }
        call(e, t) {
            return Qo((()=>{
                let t = function(e, t, n=[1, 1], s="valid", r, a) {
                    return Qo((()=>{
                        null == r && (r = "channelsLast"),
                        j_(r);
                        let i = wz(e, r);
                        if (4 !== e.rank)
                            throw new d_(`Input for depthwiseConv2d is required to be 4-D, but is instead ${e.rank}-D`);
                        if (4 !== t.rank)
                            throw new d_(`depthwiseKernel is required to be 4-D, but is instead ${t.rank}-D`);
                        return i = lu(i, t, n, "same" === s ? "same" : "valid", "NHWC", a),
                        "channelsFirst" === r && (i = Fc(i, [0, 3, 1, 2])),
                        i
                    }
                    ))
                }(e = qO(e), this.depthwiseKernel.read(), this.strides, this.padding, this.dataFormat, null);
                return this.useBias && (t = wO(t, this.bias.read(), this.dataFormat)),
                null != this.activation && (t = this.activation.apply(t)),
                t
            }
            ))
        }
        computeOutputShape(e) {
            e = KO(e);
            const t = "channelsFirst" === this.dataFormat ? e[2] : e[1]
              , n = "channelsFirst" === this.dataFormat ? e[3] : e[2]
              , s = "channelsFirst" === this.dataFormat ? e[1] * this.depthMultiplier : e[3] * this.depthMultiplier
              , r = bz(t, this.kernelSize[0], this.padding, this.strides[0])
              , a = bz(n, this.kernelSize[1], this.padding, this.strides[1]);
            return "channelsFirst" === this.dataFormat ? [e[0], s, r, a] : [e[0], r, a, s]
        }
        getConfig() {
            const e = super.getConfig();
            return e.depthMultiplier = this.depthMultiplier,
            e.depthwiseInitializer = VO(this.depthwiseInitializer),
            e.depthwiseRegularizer = lz(this.depthwiseRegularizer),
            e.depthwiseConstraint = IM(this.depthwiseRegularizer),
            e
        }
    }
    Mz.className = "DepthwiseConv2D",
    lf.registerClass(Mz);
    var Lz = {};
    function zz(e, t, n, s) {
        if (Array.isArray(e)) {
            if (null != t || null != n)
                throw new d_("When inputs is an array, neither initialState or constants should be provided");
            null != s && (n = e.slice(e.length - s, e.length),
            e = e.slice(0, e.length - s)),
            e.length > 1 && (t = e.slice(1, e.length)),
            e = e[0]
        }
        function r(e) {
            return null == e || Array.isArray(e) ? e : [e]
        }
        return {
            inputs: e,
            initialState: t = r(t),
            constants: n = r(n)
        }
    }
    function Bz(e, t, n, s=!1, r, a, i=!1, o=!1) {
        return Qo((()=>{
            const l = t.shape.length;
            if (l < 3)
                throw new d_(`Input should be at least 3D, but is ${l}D.`);
            const u = [1, 0].concat(rO(2, l));
            if (t = Fc(t, u),
            null != a)
                throw new f_("The rnn() functoin of the deeplearn.js backend does not support constants yet.");
            i && console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend."),
            null != r && ((r = Ko(Ko(r, "bool"), "float32")).rank === l - 1 && (r = $c(r, -1)),
            r = Fc(r, u)),
            s && (t = xl(t, 0),
            null != r && (r = xl(r, 0)));
            const c = [];
            let h, p = n;
            const d = t.shape[0]
              , f = ic(t);
            let m, g;
            null != r && (m = ic(r));
            for (let t = 0; t < d; ++t) {
                const n = f[t]
                  , s = Qo((()=>e(n, p)));
                if (null == r)
                    h = s[0],
                    p = s[1];
                else {
                    const e = Qo((()=>{
                        const e = m[t]
                          , n = Yu(Ap(e), e);
                        return {
                            output: sl(il(s[0], e), il(p[0], n)),
                            newStates: p.map(((t,r)=>sl(il(s[1][r], e), il(t, n))))
                        }
                    }
                    ));
                    h = e.output,
                    p = e.newStates
                }
                o && c.push(h)
            }
            if (o) {
                g = ac(c, 1)
            }
            return [h, g, p]
        }
        ))
    }
    t(Lz, "ConvLSTM2DCell", (()=>Jz), (e=>Jz = e)),
    t(Lz, "ConvLSTM2D", (()=>Qz), (e=>Qz = e));
    class Pz extends aM {
        constructor(e) {
            let t;
            if (super(e),
            null == e.cell)
                throw new d_("cell property is missing for the constructor of RNN.");
            if (t = Array.isArray(e.cell) ? new Kz({
                cells: e.cell
            }) : e.cell,
            null == t.stateSize)
                throw new d_("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");
            this.cell = t,
            this.returnSequences = null != e.returnSequences && e.returnSequences,
            this.returnState = null != e.returnState && e.returnState,
            this.goBackwards = null != e.goBackwards && e.goBackwards,
            this._stateful = null != e.stateful && e.stateful,
            this.unroll = null != e.unroll && e.unroll,
            this.supportsMasking = !0,
            this.inputSpec = [new eM({
                ndim: 3
            })],
            this.stateSpec = null,
            this.states_ = null,
            this.numConstants = null,
            this.keptStates = []
        }
        getStates() {
            if (null == this.states_) {
                return rO(0, Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1).map((e=>null))
            }
            return this.states_
        }
        setStates(e) {
            this.states_ = e
        }
        computeOutputShape(e) {
            HO(e) && (e = e[0]);
            let t = this.cell.stateSize;
            Array.isArray(t) || (t = [t]);
            const n = t[0];
            let s;
            if (s = this.returnSequences ? [e[0], e[1], n] : [e[0], n],
            this.returnState) {
                const n = [];
                for (const s of t)
                    n.push([e[0], s]);
                return [s].concat(n)
            }
            return s
        }
        computeMask(e, t) {
            return Qo((()=>{
                Array.isArray(t) && (t = t[0]);
                const e = this.returnSequences ? t : null;
                if (this.returnState) {
                    const t = this.states.map((e=>null));
                    return [e].concat(t)
                }
                return e
            }
            ))
        }
        get states() {
            if (null == this.states_) {
                const e = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1
                  , t = [];
                for (let n = 0; n < e; ++n)
                    t.push(null);
                return t
            }
            return this.states_
        }
        set states(e) {
            this.states_ = e
        }
        build(e) {
            if (null != this.numConstants)
                throw new f_("Constants support is not implemented in RNN yet.");
            HO(e) && (e = e[0]);
            const t = this.stateful ? e[0] : null
              , n = e.slice(2);
            this.inputSpec[0] = new eM({
                shape: [t, null, ...n]
            });
            const s = [e[0]].concat(e.slice(2));
            let r;
            if (this.cell.build(s),
            r = Array.isArray(this.cell.stateSize) ? this.cell.stateSize : [this.cell.stateSize],
            null != this.stateSpec) {
                if (!Hs.arraysEqual(this.stateSpec.map((e=>e.shape[e.shape.length - 1])), r))
                    throw new d_(`An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=${this.stateSpec}; However cell.stateSize is ${this.cell.stateSize}`)
            } else
                this.stateSpec = r.map((e=>new eM({
                    shape: [null, e]
                })));
            this.stateful && this.resetStates()
        }
        resetStates(e, t=!1) {
            Qo((()=>{
                if (!this.stateful)
                    throw new h_("Cannot call resetStates() on an RNN Layer that is not stateful.");
                const n = this.inputSpec[0].shape[0];
                if (null == n)
                    throw new d_("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");
                if (null == this.states_)
                    Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map((e=>fl([n, e]))) : this.states_ = [fl([n, this.cell.stateSize])];
                else if (null == e)
                    el(this.states_),
                    null != this.keptStates && (el(this.keptStates),
                    this.keptStates = []),
                    Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map((e=>fl([n, e]))) : this.states_[0] = fl([n, this.cell.stateSize]);
                else {
                    if (Array.isArray(e) || (e = [e]),
                    e.length !== this.states_.length)
                        throw new d_(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${e.length} state value(s). Input received: ${e}`);
                    !0 === t ? this.keptStates.push(this.states_.slice()) : el(this.states_);
                    for (let t = 0; t < this.states_.length; ++t) {
                        const s = e[t]
                          , r = Array.isArray(this.cell.stateSize) ? this.cell.stateSize[t] : this.cell.stateSize
                          , a = [n, r];
                        if (!Hs.arraysEqual(s.shape, a))
                            throw new d_(`State ${t} is incompatible with layer ${this.name}: expected shape=${a}, received shape=${s.shape}`);
                        this.states_[t] = s
                    }
                }
                this.states_ = this.states_.map((e=>tl(e.clone())))
            }
            ))
        }
        apply(e, t) {
            let n = null == t ? null : t.initialState
              , s = null == t ? null : t.constants;
            null == t && (t = {});
            const r = zz(e, n, s, this.numConstants);
            e = r.inputs,
            n = r.initialState,
            s = r.constants;
            let a = []
              , i = [];
            if (null != n) {
                t.initialState = n,
                a = a.concat(n),
                this.stateSpec = [];
                for (const e of n)
                    this.stateSpec.push(new eM({
                        shape: e.shape
                    }));
                i = i.concat(this.stateSpec)
            }
            null != s && (t.constants = s,
            a = a.concat(s),
            this.numConstants = s.length);
            if (a[0]instanceof tM) {
                const n = [e].concat(a)
                  , s = this.inputSpec.concat(i)
                  , r = this.inputSpec;
                this.inputSpec = s;
                const o = super.apply(n, t);
                return this.inputSpec = r,
                o
            }
            return super.apply(e, t)
        }
        call(e, t) {
            return Qo((()=>{
                const n = null == t ? null : t.mask
                  , s = null == t ? null : t.training;
                let r = null == t ? null : t.initialState;
                e = qO(e),
                null == r && (r = this.stateful ? this.states_ : this.getInitialState(e));
                const a = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;
                if (r.length !== a)
                    throw new d_(`RNN Layer has ${a} state(s) but was passed ${r.length} initial state(s).`);
                this.unroll && console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");
                const i = {
                    training: s
                }
                  , o = Bz(((e,t)=>{
                    const n = this.cell.call([e].concat(t), i);
                    return [n[0], n.slice(1)]
                }
                ), e, r, this.goBackwards, n, null, this.unroll, this.returnSequences)
                  , l = o[0]
                  , u = o[1]
                  , c = o[2];
                this.stateful && this.resetStates(c, s);
                const h = this.returnSequences ? u : l;
                return this.returnState ? [h].concat(c) : h
            }
            ))
        }
        getInitialState(e) {
            return Qo((()=>{
                let t = fl(e.shape);
                return t = nu(t, [1, 2]),
                t = lO(t),
                Array.isArray(this.cell.stateSize) ? this.cell.stateSize.map((e=>e > 1 ? fO(t, [1, e]) : t)) : this.cell.stateSize > 1 ? [fO(t, [1, this.cell.stateSize])] : [t]
            }
            ))
        }
        get trainableWeights() {
            return this.trainable ? this.cell.trainableWeights : []
        }
        get nonTrainableWeights() {
            return this.trainable ? this.cell.nonTrainableWeights : this.cell.weights
        }
        setFastWeightInitDuringBuild(e) {
            super.setFastWeightInitDuringBuild(e),
            null != this.cell && this.cell.setFastWeightInitDuringBuild(e)
        }
        getConfig() {
            const e = super.getConfig()
              , t = {
                returnSequences: this.returnSequences,
                returnState: this.returnState,
                goBackwards: this.goBackwards,
                stateful: this.stateful,
                unroll: this.unroll
            };
            null != this.numConstants && (t.numConstants = this.numConstants);
            const n = this.cell.getConfig();
            return this.getClassName() === Pz.className && (t.cell = {
                className: this.cell.getClassName(),
                config: n
            }),
            Object.assign(Object.assign(Object.assign({}, n), e), t)
        }
        static fromConfig(e, t, n={}) {
            const s = LM(t.cell, n);
            return new e(Object.assign(t, {
                cell: s
            }))
        }
    }
    Pz.className = "RNN",
    lf.registerClass(Pz);
    class Wz extends aM {
    }
    class Uz extends Wz {
        constructor(e) {
            super(e),
            this.DEFAULT_ACTIVATION = "tanh",
            this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal",
            this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal",
            this.DEFAULT_BIAS_INITIALIZER = "zeros",
            this.units = e.units,
            D_(this.units, "units"),
            this.activation = sz(null == e.activation ? this.DEFAULT_ACTIVATION : e.activation),
            this.useBias = null == e.useBias || e.useBias,
            this.kernelInitializer = GO(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER),
            this.recurrentInitializer = GO(e.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER),
            this.biasInitializer = GO(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER),
            this.kernelRegularizer = cz(e.kernelRegularizer),
            this.recurrentRegularizer = cz(e.recurrentRegularizer),
            this.biasRegularizer = cz(e.biasRegularizer),
            this.kernelConstraint = NM(e.kernelConstraint),
            this.recurrentConstraint = NM(e.recurrentConstraint),
            this.biasConstraint = NM(e.biasConstraint),
            this.dropout = nO([1, sO([0, null == e.dropout ? 0 : e.dropout])]),
            this.recurrentDropout = nO([1, sO([0, null == e.recurrentDropout ? 0 : e.recurrentDropout])]),
            this.dropoutFunc = e.dropoutFunc,
            this.stateSize = this.units,
            this.dropoutMask = null,
            this.recurrentDropoutMask = null
        }
        build(e) {
            e = KO(e),
            this.kernel = this.addWeight("kernel", [e[e.length - 1], this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint),
            this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units], null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint),
            this.useBias ? this.bias = this.addWeight("bias", [this.units], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint) : this.bias = null,
            this.built = !0
        }
        call(e, t) {
            return Qo((()=>{
                if (2 !== e.length)
                    throw new d_(`SimpleRNNCell expects 2 input Tensors, got ${e.length}.`);
                let n = e[1];
                e = e[0];
                const s = null != t.training && t.training;
                let r;
                0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = Xz({
                    ones: ()=>Ap(e),
                    rate: this.dropout,
                    training: s,
                    dropoutFunc: this.dropoutFunc
                })),
                0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = Xz({
                    ones: ()=>Ap(n),
                    rate: this.recurrentDropout,
                    training: s,
                    dropoutFunc: this.dropoutFunc
                }));
                const a = this.dropoutMask
                  , i = this.recurrentDropoutMask;
                r = gO(null != a ? il(e, a) : e, this.kernel.read()),
                null != this.bias && (r = wO(r, this.bias.read())),
                null != i && (n = il(n, i));
                let o = sl(r, gO(n, this.recurrentKernel.read()));
                return null != this.activation && (o = this.activation.apply(o)),
                [o, o]
            }
            ))
        }
        getConfig() {
            const e = super.getConfig()
              , t = {
                units: this.units,
                activation: tz(this.activation),
                useBias: this.useBias,
                kernelInitializer: VO(this.kernelInitializer),
                recurrentInitializer: VO(this.recurrentInitializer),
                biasInitializer: VO(this.biasInitializer),
                kernelRegularizer: lz(this.kernelRegularizer),
                recurrentRegularizer: lz(this.recurrentRegularizer),
                biasRegularizer: lz(this.biasRegularizer),
                activityRegularizer: lz(this.activityRegularizer),
                kernelConstraint: IM(this.kernelConstraint),
                recurrentConstraint: IM(this.recurrentConstraint),
                biasConstraint: IM(this.biasConstraint),
                dropout: this.dropout,
                recurrentDropout: this.recurrentDropout
            };
            return Object.assign(Object.assign({}, e), t)
        }
    }
    Uz.className = "SimpleRNNCell",
    lf.registerClass(Uz);
    class Vz extends Pz {
        constructor(e) {
            e.cell = new Uz(e),
            super(e)
        }
        call(e, t) {
            return Qo((()=>{
                null != this.cell.dropoutMask && (el(this.cell.dropoutMask),
                this.cell.dropoutMask = null),
                null != this.cell.recurrentDropoutMask && (el(this.cell.recurrentDropoutMask),
                this.cell.recurrentDropoutMask = null);
                const n = null == t ? null : t.mask
                  , s = null == t ? null : t.training
                  , r = null == t ? null : t.initialState;
                return super.call(e, {
                    mask: n,
                    training: s,
                    initialState: r
                })
            }
            ))
        }
        static fromConfig(e, t) {
            return new e(t)
        }
    }
    Vz.className = "SimpleRNN",
    lf.registerClass(Vz);
    class Gz extends Wz {
        constructor(e) {
            if (super(e),
            this.DEFAULT_ACTIVATION = "tanh",
            this.DEFAULT_RECURRENT_ACTIVATION = "hardSigmoid",
            this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal",
            this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal",
            this.DEFAULT_BIAS_INITIALIZER = "zeros",
            e.resetAfter)
                throw new d_("GRUCell does not support reset_after parameter set to true.");
            this.units = e.units,
            D_(this.units, "units"),
            this.activation = sz(void 0 === e.activation ? this.DEFAULT_ACTIVATION : e.activation),
            this.recurrentActivation = sz(void 0 === e.recurrentActivation ? this.DEFAULT_RECURRENT_ACTIVATION : e.recurrentActivation),
            this.useBias = null == e.useBias || e.useBias,
            this.kernelInitializer = GO(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER),
            this.recurrentInitializer = GO(e.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER),
            this.biasInitializer = GO(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER),
            this.kernelRegularizer = cz(e.kernelRegularizer),
            this.recurrentRegularizer = cz(e.recurrentRegularizer),
            this.biasRegularizer = cz(e.biasRegularizer),
            this.kernelConstraint = NM(e.kernelConstraint),
            this.recurrentConstraint = NM(e.recurrentConstraint),
            this.biasConstraint = NM(e.biasConstraint),
            this.dropout = nO([1, sO([0, null == e.dropout ? 0 : e.dropout])]),
            this.recurrentDropout = nO([1, sO([0, null == e.recurrentDropout ? 0 : e.recurrentDropout])]),
            this.dropoutFunc = e.dropoutFunc,
            this.implementation = e.implementation,
            this.stateSize = this.units,
            this.dropoutMask = null,
            this.recurrentDropoutMask = null
        }
        build(e) {
            const t = (e = KO(e))[e.length - 1];
            this.kernel = this.addWeight("kernel", [t, 3 * this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint),
            this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, 3 * this.units], null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint),
            this.useBias ? this.bias = this.addWeight("bias", [3 * this.units], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint) : this.bias = null,
            this.built = !0
        }
        call(e, t) {
            return Qo((()=>{
                if (2 !== e.length)
                    throw new d_(`GRUCell expects 2 input Tensors (inputs, h, c), got ${e.length}.`);
                const n = null != t.training && t.training;
                let s = e[1];
                e = e[0],
                0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = Xz({
                    ones: ()=>Ap(e),
                    rate: this.dropout,
                    training: n,
                    count: 3,
                    dropoutFunc: this.dropoutFunc
                })),
                0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = Xz({
                    ones: ()=>Ap(s),
                    rate: this.recurrentDropout,
                    training: n,
                    count: 3,
                    dropoutFunc: this.dropoutFunc
                }));
                const r = this.dropoutMask
                  , a = this.recurrentDropoutMask;
                let i, o, l;
                0 < this.dropout && this.dropout < 1 && (e = il(e, r[0]));
                let u = gO(e, this.kernel.read());
                this.useBias && (u = wO(u, this.bias.read())),
                0 < this.recurrentDropout && this.recurrentDropout < 1 && (s = il(s, a[0]));
                const c = this.recurrentKernel.read()
                  , [h,p] = dl(c, [2 * this.units, this.units], c.rank - 1)
                  , d = gO(s, h)
                  , [f,m,g] = dl(u, 3, u.rank - 1)
                  , [y,b] = dl(d, 2, d.rank - 1);
                i = this.recurrentActivation.apply(sl(f, y)),
                o = this.recurrentActivation.apply(sl(m, b));
                const x = gO(il(o, s), p);
                l = this.activation.apply(sl(g, x));
                const w = sl(il(i, s), il(sl(1, Ac(i)), l));
                return [w, w]
            }
            ))
        }
        getConfig() {
            const e = super.getConfig()
              , t = {
                units: this.units,
                activation: tz(this.activation),
                recurrentActivation: tz(this.recurrentActivation),
                useBias: this.useBias,
                kernelInitializer: VO(this.kernelInitializer),
                recurrentInitializer: VO(this.recurrentInitializer),
                biasInitializer: VO(this.biasInitializer),
                kernelRegularizer: lz(this.kernelRegularizer),
                recurrentRegularizer: lz(this.recurrentRegularizer),
                biasRegularizer: lz(this.biasRegularizer),
                activityRegularizer: lz(this.activityRegularizer),
                kernelConstraint: IM(this.kernelConstraint),
                recurrentConstraint: IM(this.recurrentConstraint),
                biasConstraint: IM(this.biasConstraint),
                dropout: this.dropout,
                recurrentDropout: this.recurrentDropout,
                implementation: this.implementation,
                resetAfter: !1
            };
            return Object.assign(Object.assign({}, e), t)
        }
    }
    Gz.className = "GRUCell",
    lf.registerClass(Gz);
    class Hz extends Pz {
        constructor(e) {
            0 === e.implementation && console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),
            e.cell = new Gz(e),
            super(e)
        }
        call(e, t) {
            return Qo((()=>{
                null != this.cell.dropoutMask && (el(this.cell.dropoutMask),
                this.cell.dropoutMask = null),
                null != this.cell.recurrentDropoutMask && (el(this.cell.recurrentDropoutMask),
                this.cell.recurrentDropoutMask = null);
                const n = null == t ? null : t.mask
                  , s = null == t ? null : t.training
                  , r = null == t ? null : t.initialState;
                return super.call(e, {
                    mask: n,
                    training: s,
                    initialState: r
                })
            }
            ))
        }
        static fromConfig(e, t) {
            return 0 === t.implmentation && (t.implementation = 1),
            new e(t)
        }
    }
    Hz.className = "GRU",
    lf.registerClass(Hz);
    class jz extends Wz {
        constructor(e) {
            super(e),
            this.DEFAULT_ACTIVATION = "tanh",
            this.DEFAULT_RECURRENT_ACTIVATION = "hardSigmoid",
            this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal",
            this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal",
            this.DEFAULT_BIAS_INITIALIZER = "zeros",
            this.units = e.units,
            D_(this.units, "units"),
            this.activation = sz(void 0 === e.activation ? this.DEFAULT_ACTIVATION : e.activation),
            this.recurrentActivation = sz(void 0 === e.recurrentActivation ? this.DEFAULT_RECURRENT_ACTIVATION : e.recurrentActivation),
            this.useBias = null == e.useBias || e.useBias,
            this.kernelInitializer = GO(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER),
            this.recurrentInitializer = GO(e.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER),
            this.biasInitializer = GO(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER),
            this.unitForgetBias = e.unitForgetBias,
            this.kernelRegularizer = cz(e.kernelRegularizer),
            this.recurrentRegularizer = cz(e.recurrentRegularizer),
            this.biasRegularizer = cz(e.biasRegularizer),
            this.kernelConstraint = NM(e.kernelConstraint),
            this.recurrentConstraint = NM(e.recurrentConstraint),
            this.biasConstraint = NM(e.biasConstraint),
            this.dropout = nO([1, sO([0, null == e.dropout ? 0 : e.dropout])]),
            this.recurrentDropout = nO([1, sO([0, null == e.recurrentDropout ? 0 : e.recurrentDropout])]),
            this.dropoutFunc = e.dropoutFunc,
            this.implementation = e.implementation,
            this.stateSize = [this.units, this.units],
            this.dropoutMask = null,
            this.recurrentDropoutMask = null
        }
        build(e) {
            var t;
            const n = (e = KO(e))[e.length - 1];
            let s;
            if (this.kernel = this.addWeight("kernel", [n, 4 * this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint),
            this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, 4 * this.units], null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint),
            this.useBias) {
                if (this.unitForgetBias) {
                    const e = this.biasInitializer
                      , n = this.units;
                    s = new ((t = class extends NO {
                        apply(t, s) {
                            const r = e.apply([n])
                              , a = (new CO).apply([n])
                              , i = e.apply([2 * n]);
                            return dO(dO(r, a), i)
                        }
                    }
                    ).className = "CustomInit",
                    t)
                } else
                    s = this.biasInitializer;
                this.bias = this.addWeight("bias", [4 * this.units], null, s, this.biasRegularizer, !0, this.biasConstraint)
            } else
                this.bias = null;
            this.built = !0
        }
        call(e, t) {
            return Qo((()=>{
                const n = null != t.training && t.training;
                if (3 !== e.length)
                    throw new d_(`LSTMCell expects 3 input Tensors (inputs, h, c), got ${e.length}.`);
                let s = e[1];
                const r = e[2];
                e = e[0],
                0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = Xz({
                    ones: ()=>Ap(e),
                    rate: this.dropout,
                    training: n,
                    count: 4,
                    dropoutFunc: this.dropoutFunc
                })),
                0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = Xz({
                    ones: ()=>Ap(s),
                    rate: this.recurrentDropout,
                    training: n,
                    count: 4,
                    dropoutFunc: this.dropoutFunc
                }));
                const a = this.dropoutMask
                  , i = this.recurrentDropoutMask;
                let o, l, u, c;
                0 < this.dropout && this.dropout < 1 && (e = il(e, a[0]));
                let h = gO(e, this.kernel.read());
                0 < this.recurrentDropout && this.recurrentDropout < 1 && (s = il(s, i[0])),
                h = sl(h, gO(s, this.recurrentKernel.read())),
                this.useBias && (h = wO(h, this.bias.read()));
                const [p,d,f,m] = dl(h, 4, h.rank - 1);
                o = this.recurrentActivation.apply(p),
                l = this.recurrentActivation.apply(d),
                u = sl(il(l, r), il(o, this.activation.apply(f))),
                c = this.recurrentActivation.apply(m);
                const g = il(c, this.activation.apply(u));
                return [g, g, u]
            }
            ))
        }
        getConfig() {
            const e = super.getConfig()
              , t = {
                units: this.units,
                activation: tz(this.activation),
                recurrentActivation: tz(this.recurrentActivation),
                useBias: this.useBias,
                kernelInitializer: VO(this.kernelInitializer),
                recurrentInitializer: VO(this.recurrentInitializer),
                biasInitializer: VO(this.biasInitializer),
                unitForgetBias: this.unitForgetBias,
                kernelRegularizer: lz(this.kernelRegularizer),
                recurrentRegularizer: lz(this.recurrentRegularizer),
                biasRegularizer: lz(this.biasRegularizer),
                activityRegularizer: lz(this.activityRegularizer),
                kernelConstraint: IM(this.kernelConstraint),
                recurrentConstraint: IM(this.recurrentConstraint),
                biasConstraint: IM(this.biasConstraint),
                dropout: this.dropout,
                recurrentDropout: this.recurrentDropout,
                implementation: this.implementation
            };
            return Object.assign(Object.assign({}, e), t)
        }
    }
    jz.className = "LSTMCell",
    lf.registerClass(jz);
    class qz extends Pz {
        constructor(e) {
            0 === e.implementation && console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),
            e.cell = new jz(e),
            super(e)
        }
        call(e, t) {
            return Qo((()=>{
                null != this.cell.dropoutMask && (el(this.cell.dropoutMask),
                this.cell.dropoutMask = null),
                null != this.cell.recurrentDropoutMask && (el(this.cell.recurrentDropoutMask),
                this.cell.recurrentDropoutMask = null);
                const n = null == t ? null : t.mask
                  , s = null == t ? null : t.training
                  , r = null == t ? null : t.initialState;
                return super.call(e, {
                    mask: n,
                    training: s,
                    initialState: r
                })
            }
            ))
        }
        static fromConfig(e, t) {
            return 0 === t.implmentation && (t.implementation = 1),
            new e(t)
        }
    }
    qz.className = "LSTM",
    lf.registerClass(qz);
    class Kz extends Wz {
        constructor(e) {
            super(e),
            this.cells = e.cells
        }
        get stateSize() {
            const e = [];
            for (const t of this.cells.slice().reverse())
                Array.isArray(t.stateSize) ? e.push(...t.stateSize) : e.push(t.stateSize);
            return e
        }
        call(e, t) {
            return Qo((()=>{
                let n = e.slice(1);
                const s = [];
                for (const e of this.cells.slice().reverse())
                    Array.isArray(e.stateSize) ? s.push(n.splice(0, e.stateSize.length)) : s.push(n.splice(0, 1));
                s.reverse();
                const r = [];
                let a;
                for (let i = 0; i < this.cells.length; ++i) {
                    const o = this.cells[i];
                    n = s[i],
                    a = 0 === i ? [e[0]].concat(n) : [a[0]].concat(n),
                    a = o.call(a, t),
                    r.push(a.slice(1))
                }
                n = [];
                for (const e of r.slice().reverse())
                    n.push(...e);
                return [a[0]].concat(n)
            }
            ))
        }
        build(e) {
            let t;
            HO(e) && (e = e[0]),
            this.cells.forEach(((n,s)=>{
                Y_(`RNNCell_${s}`, (()=>{
                    n.build(e),
                    t = Array.isArray(n.stateSize) ? n.stateSize[0] : n.stateSize,
                    e = [e[0], t]
                }
                ))
            }
            )),
            this.built = !0
        }
        getConfig() {
            const e = super.getConfig()
              , t = {
                cells: this.cells.map((e=>({
                    className: e.getClassName(),
                    config: e.getConfig()
                })))
            };
            return Object.assign(Object.assign({}, e), t)
        }
        static fromConfig(e, t, n={}) {
            const s = [];
            for (const e of t.cells)
                s.push(LM(e, n));
            return new e({
                cells: s
            })
        }
        get trainableWeights() {
            if (!this.trainable)
                return [];
            const e = [];
            for (const t of this.cells)
                e.push(...t.trainableWeights);
            return e
        }
        get nonTrainableWeights() {
            const e = [];
            for (const t of this.cells)
                e.push(...t.nonTrainableWeights);
            if (!this.trainable) {
                const t = [];
                for (const e of this.cells)
                    t.push(...e.trainableWeights);
                return t.concat(e)
            }
            return e
        }
        getWeights() {
            const e = [];
            for (const t of this.cells)
                e.push(...t.weights);
            return JO(e)
        }
        setWeights(e) {
            const t = [];
            for (const n of this.cells) {
                const s = n.weights.length
                  , r = e.splice(s);
                for (let e = 0; e < n.weights.length; ++e)
                    t.push([n.weights[e], r[e]])
            }
            QO(t)
        }
    }
    function Xz(e) {
        const {ones: t, rate: n, training: s=!1, count: r=1, dropoutFunc: a} = e
          , i = ()=>null != a ? a(t(), n) : vO(t(), n)
          , o = ()=>kO(i, t, s);
        if (!r || r <= 1)
            return tl(o().clone());
        return Array(r).fill(void 0).map(o).map((e=>tl(e.clone())))
    }
    /**
 * @license
 * Copyright 2020 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */
    Kz.className = "StackedRNNCells",
    lf.registerClass(Kz);
    var Yz = function(e, t) {
        var n = {};
        for (var s in e)
            Object.prototype.hasOwnProperty.call(e, s) && t.indexOf(s) < 0 && (n[s] = e[s]);
        if (null != e && "function" == typeof Object.getOwnPropertySymbols) {
            var r = 0;
            for (s = Object.getOwnPropertySymbols(e); r < s.length; r++)
                t.indexOf(s[r]) < 0 && Object.prototype.propertyIsEnumerable.call(e, s[r]) && (n[s[r]] = e[s[r]])
        }
        return n
    };
    class Zz extends Pz {
        constructor(e) {
            if (e.unroll)
                throw new f_("Unrolling is not possible with convolutional RNNs.");
            if (Array.isArray(e.cell))
                throw new f_("It is not possible at the moment to stack convolutional cells.");
            super(e),
            this.inputSpec = [new eM({
                ndim: 5
            })]
        }
        call(e, t) {
            return Qo((()=>{
                if (null != this.cell.dropoutMask && (el(this.cell.dropoutMask),
                this.cell.dropoutMask = null),
                null != this.cell.recurrentDropoutMask && (el(this.cell.recurrentDropoutMask),
                this.cell.recurrentDropoutMask = null),
                t && t.constants)
                    throw new d_("ConvRNN2D cell does not support constants");
                const n = null == t ? null : t.mask
                  , s = null == t ? null : t.training
                  , r = null == t ? null : t.initialState;
                return super.call(e, {
                    mask: n,
                    training: s,
                    initialState: r
                })
            }
            ))
        }
        computeOutputShape(e) {
            let t = this.computeSingleOutputShape(e);
            return this.returnSequences || (t = [t[0], ...t.slice(2)]),
            this.returnState && (t = [t, ...Array(2).fill([e[0], ...t.slice(-3)])]),
            t
        }
        getInitialState(e) {
            return Qo((()=>{
                const {stateSize: t} = this.cell
                  , n = e.shape
                  , s = this.computeSingleOutputShape(n)
                  , r = fl([s[0], ...s.slice(2)]);
                return Array.isArray(t) ? Array(t.length).fill(r) : [r]
            }
            ))
        }
        resetStates(e, t=!1) {
            Qo((()=>{
                if (!this.stateful)
                    throw new h_("Cannot call resetStates() on an RNN Layer that is not stateful.");
                const n = this.inputSpec[0].shape
                  , s = this.computeSingleOutputShape(n)
                  , r = [s[0], ...s.slice(2)];
                if (null == n[0])
                    throw new d_("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");
                if (null == this.getStates())
                    Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map((()=>fl(r))) : this.states_ = [fl(r)];
                else if (null == e)
                    el(this.states_),
                    null != this.keptStates && (el(this.keptStates),
                    this.keptStates = []),
                    Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map((()=>fl(r))) : this.states_[0] = fl(r);
                else {
                    if (Array.isArray(e) || (e = [e]),
                    e.length !== this.states_.length)
                        throw new d_(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${e.length} state value(s). Input received: ${e}`);
                    t ? this.keptStates.push(this.states_.slice()) : el(this.states_);
                    for (let t = 0; t < this.states_.length; ++t) {
                        const n = e[t]
                          , s = r;
                        if (!Hs.arraysEqual(n.shape, s))
                            throw new d_(`State ${t} is incompatible with layer ${this.name}: expected shape=${s}, received shape=${n.shape}`);
                        this.states_[t] = n
                    }
                }
                this.states_ = this.states_.map((e=>tl(e.clone())))
            }
            ))
        }
        computeSingleOutputShape(e) {
            const {dataFormat: t, filters: n, kernelSize: s, padding: r, strides: a, dilationRate: i} = this.cell
              , o = "channelsFirst" === t
              , l = e[o ? 3 : 2]
              , u = e[o ? 4 : 3]
              , c = bz(l, s[0], r, a[0], i[0])
              , h = bz(u, s[1], r, a[1], i[1]);
            return [...e.slice(0, 2), ...o ? [n, c, h] : [c, h, n]]
        }
    }
    Zz.className = "ConvRNN2D";
    class Jz extends jz {
        constructor(e) {
            const {filters: t, kernelSize: n, strides: s, padding: r, dataFormat: a, dilationRate: i} = e;
            super(Object.assign(Object.assign({}, e), {
                units: t
            })),
            this.filters = t,
            D_(this.filters, "filters"),
            this.kernelSize = yz(n, 2, "kernelSize"),
            this.kernelSize.forEach((e=>D_(e, "kernelSize"))),
            this.strides = yz(s || 1, 2, "strides"),
            this.strides.forEach((e=>D_(e, "strides"))),
            this.padding = r || "valid",
            q_(this.padding),
            this.dataFormat = a || "channelsLast",
            j_(this.dataFormat),
            this.dilationRate = yz(i || 1, 2, "dilationRate"),
            this.dilationRate.forEach((e=>D_(e, "dilationRate")))
        }
        build(e) {
            var t;
            e = KO(e);
            const n = "channelsFirst" === this.dataFormat ? 1 : e.length - 1;
            if (null == e[n])
                throw new d_(`The channel dimension of the input should be defined. Found ${e[n]}`);
            const s = e[n]
              , r = this.kernelSize.concat([s, 4 * this.filters]);
            this.kernel = this.addWeight("kernel", r, null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint);
            const a = this.kernelSize.concat([this.filters, 4 * this.filters]);
            if (this.recurrentKernel = this.addWeight("recurrent_kernel", a, null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint),
            this.useBias) {
                let e;
                if (this.unitForgetBias) {
                    const n = this.biasInitializer
                      , s = this.filters;
                    e = new ((t = class extends NO {
                        apply(e, t) {
                            return pO([n.apply([s]), zc([s]), n.apply([2 * s])])
                        }
                    }
                    ).className = "CustomInit",
                    t)
                } else
                    e = this.biasInitializer;
                this.bias = this.addWeight("bias", [4 * this.filters], null, e, this.biasRegularizer, !0, this.biasConstraint)
            }
            this.built = !0
        }
        call(e, t) {
            return Qo((()=>{
                if (3 !== e.length)
                    throw new d_(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ${e.length}.`);
                const n = t.training || !1
                  , s = e[0]
                  , r = e[1]
                  , a = e[2];
                0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = Xz({
                    ones: ()=>Ap(s),
                    rate: this.dropout,
                    training: n,
                    count: 4,
                    dropoutFunc: this.dropoutFunc
                }));
                const i = this.dropoutMask
                  , o = (e,t,n)=>t && t[n] ? il(t[n], e) : e;
                let l = o(s, i, 0)
                  , u = o(s, i, 1)
                  , c = o(s, i, 2)
                  , h = o(s, i, 3);
                0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = Xz({
                    ones: ()=>Ap(r),
                    rate: this.recurrentDropout,
                    training: n,
                    count: 4,
                    dropoutFunc: this.dropoutFunc
                }));
                const p = this.recurrentDropoutMask;
                let d = o(r, p, 0)
                  , f = o(r, p, 1)
                  , m = o(r, p, 2)
                  , g = o(r, p, 3);
                const [y,b,x,w] = dl(this.kernel.read(), 4, 3)
                  , [v,k,I,S] = this.useBias ? dl(this.bias.read(), 4) : [null, null, null, null];
                l = this.inputConv(l, y, v, this.padding),
                u = this.inputConv(u, b, k, this.padding),
                c = this.inputConv(c, x, I, this.padding),
                h = this.inputConv(h, w, S, this.padding);
                const [N,T,C,$] = dl(this.recurrentKernel.read(), 4, 3);
                d = this.recurrentConv(d, N),
                f = this.recurrentConv(f, T),
                m = this.recurrentConv(m, C),
                g = this.recurrentConv(g, $);
                const E = this.recurrentActivation.apply(sl(l, d))
                  , A = this.recurrentActivation.apply(sl(u, f))
                  , R = sl(il(A, a), il(E, this.activation.apply(sl(c, m))))
                  , F = il(this.recurrentActivation.apply(sl(h, g)), this.activation.apply(R));
                return [F, F, R]
            }
            ))
        }
        getConfig() {
            const e = super.getConfig()
              , {units: t} = e
              , n = Yz(e, ["units"])
              , s = {
                filters: this.filters,
                kernelSize: this.kernelSize,
                padding: this.padding,
                dataFormat: this.dataFormat,
                dilationRate: this.dilationRate,
                strides: this.strides
            };
            return Object.assign(Object.assign({}, n), s)
        }
        inputConv(e, t, n, s) {
            const r = Hl(e, t, this.strides, s || "valid", "channelsFirst" === this.dataFormat ? "NCHW" : "NHWC", this.dilationRate);
            return n ? wO(r, n, this.dataFormat) : r
        }
        recurrentConv(e, t) {
            return Hl(e, t, 1, "same", "channelsFirst" === this.dataFormat ? "NCHW" : "NHWC")
        }
    }
    Jz.className = "ConvLSTM2DCell",
    lf.registerClass(Jz);
    class Qz extends Zz {
        constructor(e) {
            const t = new Jz(e);
            super(Object.assign(Object.assign({}, e), {
                cell: t
            }))
        }
        static fromConfig(e, t) {
            return new e(t)
        }
    }
    Qz.className = "ConvLSTM2D",
    lf.registerClass(Qz);
    class eB extends aM {
        constructor(e) {
            super(e),
            this.rate = Math.max(Math.min(e.rate, 1), 0),
            this.noiseShape = e.noiseShape,
            this.seed = e.seed,
            this.supportsMasking = !0
        }
        getNoiseShape(e) {
            if (null == this.noiseShape)
                return this.noiseShape;
            const t = e.shape
              , n = [];
            for (let e = 0; e < this.noiseShape.length; ++e)
                n.push(null == this.noiseShape[e] ? t[e] : this.noiseShape[e]);
            return n
        }
        call(e, t) {
            return Qo((()=>{
                this.invokeCallHook(e, t);
                const n = qO(e);
                if (0 < this.rate && this.rate < 1) {
                    const e = null != t.training && t.training
                      , s = this.getNoiseShape(n);
                    return kO((()=>vO(n, this.rate, s, this.seed)), (()=>n), e)
                }
                return e
            }
            ))
        }
        getConfig() {
            const e = {
                rate: this.rate,
                noiseShape: this.noiseShape,
                seed: this.seed
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
        dispose() {
            return super.dispose()
        }
    }
    eB.className = "Dropout",
    lf.registerClass(eB);
    class tB extends eB {
        constructor(e) {
            super(e),
            this.inputSpec = [{
                ndim: 3
            }]
        }
        getNoiseShape(e) {
            const t = e.shape;
            return [t[0], 1, t[2]]
        }
    }
    tB.className = "SpatialDropout1D",
    lf.registerClass(tB);
    class nB extends aM {
        constructor(e) {
            if (super(e),
            this.activation = null,
            this.useBias = !0,
            this.kernel = null,
            this.bias = null,
            this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal",
            this.DEFAULT_BIAS_INITIALIZER = "zeros",
            null == e.batchInputShape && null == e.inputShape && null != e.inputDim) {
                let t = null;
                null != e.batchSize && (t = e.batchSize),
                this.batchInputShape = [t, e.inputDim]
            }
            this.units = e.units,
            D_(this.units, "units"),
            this.activation = sz(e.activation),
            null != e.useBias && (this.useBias = e.useBias),
            this.kernelInitializer = GO(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER),
            this.biasInitializer = GO(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER),
            this.kernelConstraint = NM(e.kernelConstraint),
            this.biasConstraint = NM(e.biasConstraint),
            this.kernelRegularizer = cz(e.kernelRegularizer),
            this.biasRegularizer = cz(e.biasRegularizer),
            this.activityRegularizer = cz(e.activityRegularizer),
            this.supportsMasking = !0,
            this.inputSpec = [{
                minNDim: 2
            }]
        }
        build(e) {
            const t = (e = KO(e))[e.length - 1];
            null == this.kernel && (this.kernel = this.addWeight("kernel", [t, this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint),
            this.useBias && (this.bias = this.addWeight("bias", [this.units], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint))),
            this.inputSpec = [{
                minNDim: 2,
                axes: {
                    [-1]: t
                }
            }],
            this.built = !0
        }
        computeOutputShape(e) {
            const t = (e = KO(e)).slice();
            return t[t.length - 1] = this.units,
            t
        }
        call(e, t) {
            return Qo((()=>{
                this.invokeCallHook(e, t);
                const n = qO(e)
                  , s = O_(this.activation.getClassName());
                let r;
                return null != s ? r = gO(n, this.kernel.read(), s, this.bias ? this.bias.read() : null) : (r = gO(n, this.kernel.read()),
                null != this.bias && (r = wO(r, this.bias.read())),
                null != this.activation && (r = this.activation.apply(r))),
                r
            }
            ))
        }
        getConfig() {
            const e = {
                units: this.units,
                activation: tz(this.activation),
                useBias: this.useBias,
                kernelInitializer: VO(this.kernelInitializer),
                biasInitializer: VO(this.biasInitializer),
                kernelRegularizer: lz(this.kernelRegularizer),
                biasRegularizer: lz(this.biasRegularizer),
                activityRegularizer: lz(this.activityRegularizer),
                kernelConstraint: IM(this.kernelConstraint),
                biasConstraint: IM(this.biasConstraint)
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    nB.className = "Dense",
    lf.registerClass(nB);
    class sB extends aM {
        constructor(e) {
            super(e = e || {}),
            this.inputSpec = [{
                minNDim: 3
            }],
            this.dataFormat = e.dataFormat
        }
        computeOutputShape(e) {
            e = KO(e);
            for (const t of e.slice(1))
                if (null == t)
                    throw new d_(`The shape of the input to "Flatten" is not fully defined (got ${e.slice(1)}). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.`);
            return [e[0], tO(e, 1)]
        }
        call(e, t) {
            return Qo((()=>{
                this.invokeCallHook(e, t);
                let n = qO(e);
                if ("channelsFirst" === this.dataFormat && n.rank > 1) {
                    const e = [0];
                    for (let t = 2; t < n.rank; ++t)
                        e.push(t);
                    e.push(1),
                    n = Fc(n, e)
                }
                return function(e) {
                    if (e.rank <= 1)
                        throw new d_(`batchFlatten requires a minimum rank of 2. Got rank: ${e.rank}.`);
                    const t = [e.shape[0], tO(e.shape, 1)];
                    return hl(e, t)
                }(n)
            }
            ))
        }
        getConfig() {
            const e = {};
            null != this.dataFormat && (e.dataFormat = this.dataFormat);
            const t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    sB.className = "Flatten",
    lf.registerClass(sB);
    class rB extends aM {
        constructor(e) {
            super(e),
            this.supportsMasking = !0,
            this.activation = sz(e.activation)
        }
        call(e, t) {
            return Qo((()=>{
                this.invokeCallHook(e, t);
                const n = qO(e);
                return this.activation.apply(n)
            }
            ))
        }
        getConfig() {
            const e = {
                activation: tz(this.activation)
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    rB.className = "Activation",
    lf.registerClass(rB);
    class aB extends aM {
        constructor(e) {
            super(e),
            this.n = e.n,
            this.inputSpec = [{
                ndim: 2
            }]
        }
        computeOutputShape(e) {
            return [e[0], this.n, e[1]]
        }
        call(e, t) {
            return Qo((()=>{
                return e = qO(e),
                t = e,
                n = this.n,
                Qo((()=>{
                    if (2 !== t.shape.length)
                        throw new d_(`repeat() expects a rank-2 tensor, but received a rank-${t.shape.length} tensor.`);
                    return fO(lO(t, 1), [1, n, 1])
                }
                ));
                var t, n
            }
            ))
        }
        getConfig() {
            const e = {
                n: this.n
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    aB.className = "RepeatVector",
    lf.registerClass(aB);
    class iB extends aM {
        constructor(e) {
            super(e),
            this.targetShape = e.targetShape;
            for (let e = 0; e < this.targetShape.length; ++e)
                this.isUnknown(this.targetShape[e]) && (this.targetShape[e] = null)
        }
        isUnknown(e) {
            return e < 0 || null == e
        }
        fixUnknownDimension(e, t) {
            const n = "Total size of new array must be unchanged."
              , s = t.slice();
            let r = 1
              , a = null;
            for (let e = 0; e < s.length; ++e) {
                const t = s[e];
                if (this.isUnknown(t)) {
                    if (null !== a)
                        throw new d_("Can only specifiy one unknown dimension.");
                    a = e
                } else
                    r *= t
            }
            const i = tO(e);
            if (null !== a) {
                if (0 === r || i % r != 0)
                    throw new d_(n);
                s[a] = i / r
            } else if (i !== r)
                throw new d_(n);
            return s
        }
        computeOutputShape(e) {
            let t = !1;
            for (let n = 0; n < e.length; ++n)
                if (this.isUnknown(e[n])) {
                    t = !0;
                    break
                }
            return t ? e.slice(0, 1).concat(this.targetShape) : e.slice(0, 1).concat(this.fixUnknownDimension(e.slice(1), this.targetShape))
        }
        call(e, t) {
            return Qo((()=>{
                this.invokeCallHook(e, t);
                const n = qO(e)
                  , s = n.shape
                  , r = s.slice(0, 1).concat(this.fixUnknownDimension(s.slice(1), this.targetShape));
                return hl(n, r)
            }
            ))
        }
        getConfig() {
            const e = {
                targetShape: this.targetShape
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    iB.className = "Reshape",
    lf.registerClass(iB);
    class oB extends aM {
        constructor(e) {
            if (super(e),
            null == e.dims)
                throw new Error("Required configuration field `dims` is missing during Permute constructor call.");
            if (!Array.isArray(e.dims))
                throw new Error(`Permute constructor requires \`dims\` to be an Array, but received ${e.dims} instead.`);
            const t = rO(1, e.dims.length + 1);
            if (!Hs.arraysEqual(e.dims.slice().sort(), t))
                throw new Error("Invalid permutation `dims`: " + JSON.stringify(e.dims) + " `dims` must contain consecutive integers starting from 1.");
            this.dims = e.dims,
            this.dimsIncludingBatch = [0].concat(this.dims),
            this.inputSpec = [new eM({
                ndim: this.dims.length + 1
            })]
        }
        computeOutputShape(e) {
            const t = (e = KO(e)).slice();
            return this.dims.forEach(((n,s)=>{
                t[s + 1] = e[n]
            }
            )),
            t
        }
        call(e, t) {
            return Fc(qO(e), this.dimsIncludingBatch)
        }
        getConfig() {
            const e = {
                dims: this.dims
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    oB.className = "Permute",
    lf.registerClass(oB);
    class lB extends aM {
        constructor(e) {
            super(null == e ? {} : e),
            this.supportsMasking = !0,
            this.maskValue = null != e ? null == e.maskValue ? 0 : e.maskValue : 0
        }
        computeOutputShape(e) {
            return e
        }
        getConfig() {
            const e = super.getConfig()
              , t = {
                maskValue: this.maskValue
            };
            return Object.assign(t, e),
            t
        }
        computeMask(e, t) {
            const n = qO(e);
            return hh(Lc(n, this.maskValue), -1)
        }
        call(e, t) {
            return Qo((()=>{
                this.invokeCallHook(e, t);
                const n = qO(e)
                  , s = hh(Lc(n, this.maskValue), -1, !0);
                return il(n, Ko(s, n.dtype))
            }
            ))
        }
    }
    lB.className = "Masking",
    lf.registerClass(lB);
    class uB extends aM {
        constructor(e) {
            if (super(e),
            this.embeddings = null,
            this.DEFAULT_EMBEDDINGS_INITIALIZER = "randomUniform",
            null == e.batchInputShape && null == e.inputShape) {
                let t = null;
                null != e.batchSize && (t = e.batchSize),
                null == e.inputLength ? this.batchInputShape = [t, null] : this.batchInputShape = [t].concat(v_(e.inputLength))
            }
            this.inputDim = e.inputDim,
            D_(this.inputDim, "inputDim"),
            this.outputDim = e.outputDim,
            D_(this.outputDim, "outputDim"),
            this.embeddingsInitializer = GO(e.embeddingsInitializer || this.DEFAULT_EMBEDDINGS_INITIALIZER),
            this.embeddingsRegularizer = cz(e.embeddingsRegularizer),
            this.activityRegularizer = cz(e.activityRegularizer),
            this.embeddingsConstraint = NM(e.embeddingsConstraint),
            this.maskZero = e.maskZero,
            this.supportsMasking = e.maskZero,
            this.inputLength = e.inputLength
        }
        build(e) {
            this.embeddings = this.addWeight("embeddings", [this.inputDim, this.outputDim], this.dtype, this.embeddingsInitializer, this.embeddingsRegularizer, !0, this.embeddingsConstraint),
            this.built = !0
        }
        warnOnIncompatibleInputShape(e) {}
        computeMask(e, t) {
            return Qo((()=>this.maskZero ? (e = qO(e),
            Lc(e, ml(e))) : null))
        }
        computeOutputShape(e) {
            if (e = KO(e),
            null == this.inputLength)
                return [...e, this.outputDim];
            const t = v_(this.inputLength);
            if (t.length !== e.length - 1)
                throw new d_(`"inputLength" is ${this.inputLength}, but received input shape has shape ${e}`);
            {
                let n = 0;
                for (let s = 0; s < t.length; ++s) {
                    const r = t[s]
                      , a = e[s + 1];
                    if (null != r && null != a && r !== a)
                        throw new d_(`"inputLength" is ${this.inputLength}, but received input shape has shape ${e}`);
                    null == r && (t[n] = a),
                    n++
                }
            }
            return [e[0], ...t, this.outputDim]
        }
        call(e, t) {
            return Qo((()=>{
                this.invokeCallHook(e, t);
                let n = qO(e);
                "int32" !== n.dtype && (n = oO(n, "int32"));
                const s = yO(this.embeddings.read(), hl(n, [n.size]));
                return hl(s, KO(this.computeOutputShape(n.shape)))
            }
            ))
        }
        getConfig() {
            const e = {
                inputDim: this.inputDim,
                outputDim: this.outputDim,
                embeddingsInitializer: VO(this.embeddingsInitializer),
                embeddingsRegularizer: lz(this.embeddingsRegularizer),
                activityRegularizer: lz(this.activityRegularizer),
                embeddingsConstraint: IM(this.embeddingsConstraint),
                maskZero: this.maskZero,
                inputLength: this.inputLength
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    uB.className = "Embedding",
    lf.registerClass(uB);
    class cB extends aM {
        constructor(e) {
            super(e || {}),
            this.supportsMasking = !0
        }
        mergeFunction(e) {
            throw new f_
        }
        computeElementwiseOpOutputShape(e, t) {
            if (null == e || null == t)
                return null;
            if (e.length < t.length)
                return this.computeElementwiseOpOutputShape(t, e);
            if (0 === t.length)
                return e;
            const n = e.slice(0, e.length - t.length);
            for (let s = 0; s < t.length; ++s) {
                const r = e[e.length - t.length + s]
                  , a = t[s];
                if (null == r || null == a || r < 0 || a < 0)
                    n.push(null);
                else if (1 === r)
                    n.push(a);
                else if (1 === a)
                    n.push(r);
                else {
                    if (r !== a)
                        throw new d_("Operands could not be broadcast together with shapes " + JSON.stringify(e) + " " + JSON.stringify(t));
                    n.push(r)
                }
            }
            return n
        }
        build(e) {
            if (Array.isArray(e) && !Array.isArray(e[0]) && (e = [KO(e)]),
            e.length < 2)
                throw new d_(`A merge layer should be called on an Array of at least 2 inputs. Got ${e.length} input(s).`);
            let t = [];
            for (const n of e)
                null != n && null !== n[0] && t.push(n[0]);
            if (t = E_(t),
            t.length > 1)
                throw new d_(`Can not merge tensors with different batch sizes. Got tensors with shapes: ${JSON.stringify(e)}.`);
            let n = null == e[0] ? null : e[0].slice(1);
            for (let t = 1; t < e.length; ++t) {
                const s = null == e[t] ? null : e[t].slice(1);
                n = this.computeElementwiseOpOutputShape(n, s)
            }
            const s = e.map((e=>e.length));
            -1 === e.indexOf(null) && 1 === E_(s).length ? this.reshapeRequired = !1 : this.reshapeRequired = !0
        }
        call(e, t) {
            return Qo((()=>{
                if (this.reshapeRequired) {
                    const t = []
                      , n = e.map((e=>e.rank));
                    if (-1 === n.indexOf(null)) {
                        const s = sO(n);
                        for (let n of e) {
                            const e = n.rank;
                            for (let t = 0; t < s - e; ++t)
                                n = lO(n, 1);
                            t.push(n)
                        }
                        return this.mergeFunction(t)
                    }
                    {
                        let n = !1;
                        for (const s of e) {
                            const e = s.rank;
                            if (null == e) {
                                const e = s.shape
                                  , r = e[0]
                                  , a = e.slice(1).concat([r]);
                                let i = hl(s, [r].concat(tO(e.slice(1))));
                                i = Fc(i, [1, 0]),
                                i = hl(i, a),
                                t.push(i),
                                n = !0
                            } else if (e > 1) {
                                const r = rO(1, e).concat([0]);
                                t.push(Fc(s, r)),
                                n = !0
                            } else
                                t.push(s)
                        }
                        let s = this.mergeFunction(t);
                        const r = s.rank;
                        if (n)
                            if (null == r) {
                                const e = s.shape
                                  , t = e[e.length - 1]
                                  , n = [t].concat(e.slice(0, e.length - 1));
                                s = hl(Fc(hl(s, [-1, t]), [1, 0]), n)
                            } else if (r > 1) {
                                const e = [r - 1].concat(rO(0, r - 1));
                                s = Fc(s, e)
                            }
                        return s
                    }
                }
                return this.mergeFunction(e)
            }
            ))
        }
        computeOutputShape(e) {
            let t;
            t = null == e[0] ? null : e[0].slice(1);
            for (let n = 1; n < e.length; ++n) {
                const s = null == e[n] ? null : e[n].slice(1);
                t = this.computeElementwiseOpOutputShape(t, s)
            }
            let n = [];
            for (const t of e)
                null != t && null !== t[0] && n.push(t[0]);
            return n = E_(n),
            t = 1 === n.length ? n.concat(t) : [null].concat(t),
            t
        }
        computeMask(e, t) {
            return Qo((()=>{
                if (null == t)
                    return null;
                if (!Array.isArray(t))
                    throw new d_("`mask` should be an Array");
                if (!Array.isArray(e))
                    throw new d_("`inputs` should be an Array");
                if (t.length !== e.length)
                    throw new d_(`The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (${e.length} vs ${t.length})`);
                if (t.every((e=>null == e)))
                    return null;
                let n = (t = t.map((e=>null == e ? e : $c(e, 0))))[0];
                for (let e = 1; e < t.length - 1; ++e)
                    n = rc(n, t[e]);
                return n
            }
            ))
        }
    }
    class hB extends cB {
        constructor(e) {
            super(e)
        }
        mergeFunction(e) {
            return Qo((()=>{
                let t = e[0].clone();
                for (let n = 1; n < e.length; ++n)
                    t = sl(t, e[n]);
                return t
            }
            ))
        }
    }
    hB.className = "Add",
    lf.registerClass(hB);
    class pB extends cB {
        constructor(e) {
            super(e)
        }
        mergeFunction(e) {
            return Qo((()=>{
                let t = e[0].clone();
                for (let n = 1; n < e.length; ++n)
                    t = il(t, e[n]);
                return t
            }
            ))
        }
    }
    pB.className = "Multiply",
    lf.registerClass(pB);
    class dB extends cB {
        constructor(e) {
            super(e)
        }
        mergeFunction(e) {
            return Qo((()=>{
                let t = e[0].clone();
                for (let n = 1; n < e.length; ++n)
                    t = sl(t, e[n]);
                return il(1 / e.length, t)
            }
            ))
        }
    }
    dB.className = "Average",
    lf.registerClass(dB);
    class fB extends cB {
        constructor(e) {
            super(e)
        }
        mergeFunction(e) {
            return Qo((()=>{
                let t = e[0];
                for (let n = 1; n < e.length; ++n)
                    t = kp(t, e[n]);
                return t
            }
            ))
        }
    }
    fB.className = "Maximum",
    lf.registerClass(fB);
    class mB extends cB {
        constructor(e) {
            super(e)
        }
        mergeFunction(e) {
            return Qo((()=>{
                let t = e[0];
                for (let n = 1; n < e.length; ++n)
                    t = Vc(t, e[n]);
                return t
            }
            ))
        }
    }
    mB.className = "Minimum",
    lf.registerClass(mB);
    class gB extends cB {
        constructor(e) {
            super(e),
            this.DEFAULT_AXIS = -1,
            null == e && (e = {}),
            this.axis = null == e.axis ? this.DEFAULT_AXIS : e.axis,
            this.supportsMasking = !0,
            this.reshapeRequired = !1
        }
        build(e) {
            if (!Array.isArray(e) || !Array.isArray(e[0]) || 1 === e.length)
                throw new d_("A `Concatenate` layer should be called on a list of at least 2 inputs");
            let t = !0;
            for (const n of e)
                if (null != n) {
                    t = !1;
                    break
                }
            if (t)
                return;
            const n = [];
            for (let t = 0; t < e.length; ++t) {
                const s = e[t].slice();
                s.splice(this.axis, 1);
                let r = !1;
                for (const e of n)
                    if (Hs.arraysEqual(e, s)) {
                        r = !0;
                        break
                    }
                r || n.push(s)
            }
            if (n.length > 1)
                throw new d_("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: " + JSON.stringify(e))
        }
        mergeFunction(e) {
            return Qo((()=>pO(e, this.axis)))
        }
        computeOutputShape(e) {
            if (!Array.isArray(e) || !Array.isArray(e[0]))
                throw new d_("A `Concatenate` layer should be called on a list of inputs.");
            const t = e
              , n = t[0].slice()
              , s = this.axis < 0 ? n.length + this.axis : this.axis;
            for (const e of t.slice(1)) {
                if (null == n[s] || null == e[s]) {
                    n[s] = null;
                    break
                }
                n[s] += e[s]
            }
            return n
        }
        computeMask(e, t) {
            if (null == t)
                return null;
            if (!Array.isArray(t))
                throw new d_("`mask` should be an array for Concatenate");
            if (!Array.isArray(e))
                throw new d_("`inputs` should be an array for Concatenate");
            if (t.length !== e.length)
                throw new d_(`Mismatch in the length of mask (${t.length}) and the legnth of inputs (${e.length})`);
            return Qo((()=>{
                let n = !0;
                if (t.forEach((e=>{
                    null == e || (n = !1)
                }
                )),
                n)
                    return null;
                const s = [];
                for (let n = 0; n < e.length; ++n)
                    null == t[n] ? s.push(Ko(Ap(e[n]), "bool")) : t[n].rank < e[n].rank ? s.push($c(t[n], -1)) : s.push(t[n]);
                const r = ll(s, this.axis);
                return ch(r, -1, !1)
            }
            ))
        }
        getConfig() {
            const e = {
                axis: this.axis
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    function yB(e, t) {
        for (; e < 0; )
            e += t;
        return e
    }
    gB.className = "Concatenate",
    lf.registerClass(gB);
    class bB extends cB {
        constructor(e) {
            super(e),
            this.axes = e.axes,
            this.normalize = null != e.normalize && e.normalize,
            this.supportsMasking = !0,
            this.reshapeRequired = !1
        }
        build(e) {
            Hs.assert(Array.isArray(e) && 2 === e.length && Array.isArray(e[0]) && Array.isArray(e[1]), (()=>"A `Dot` layer should be called on a list of exactly 2 inputs."));
            const t = e[0]
              , n = e[1];
            if (t.length > 3 || n.length > 3)
                throw new f_("Dot layer does not support tensors of 4D or higher rank yet.");
            const s = this.interpretAxes(t, n);
            if (t[s[0]] !== n[s[1]])
                throw new d_(`Dimension incompatibility: ${t[s[0]]} !== ${n[s[1]]}`)
        }
        mergeFunction(e) {
            if (2 !== e.length)
                throw new d_(`A \`Dot\` layer must be called on exactly 2 inputs, but received ${e.length} input(s).`);
            let t, n = e[0], s = e[1];
            return t = Array.isArray(this.axes) ? this.axes.map(((t,n)=>yB(t, e[n].shape.length))) : [yB(this.axes, n.shape.length), yB(this.axes, s.shape.length)],
            this.normalize && (n = zM(n, t[0]),
            s = zM(s, t[1])),
            function(e, t, n) {
                if (e.shape.length > 3 || t.shape.length > 3)
                    throw new f_("batchDot is not implemented for tensors of 4D or higher rank yet");
                if (Hs.assert(e.shape.length >= 2, (()=>`batchDot requires the rank of x to be >= 2, but got ${e.shape.length}`)),
                Hs.assert(e.shape.length >= 2, (()=>`batchDot requires the rank of y to be >= 2, but got ${t.shape.length}`)),
                "number" == typeof n && (n = [n, n]),
                "complex64" === e.dtype || "complex64" === t.dtype)
                    throw new f_("batchDot is not implemented for complex64-type Tensors yet.");
                const s = e.shape.length
                  , r = t.shape.length;
                null == n && (n = [s - 1, r - 2]);
                const a = n;
                return Qo((()=>{
                    let n, i;
                    if (s > r) {
                        n = s - r;
                        const e = [];
                        for (let t = 0; t < n; ++t)
                            e.push(1);
                        t = hl(t, t.shape.concat(e))
                    } else if (r > s) {
                        n = r - s;
                        const t = [];
                        for (let e = 0; e < n; ++e)
                            t.push(1);
                        e = hl(e, e.shape.concat(t))
                    } else
                        n = 0;
                    if (2 === e.shape.length && 2 === t.shape.length)
                        i = a[0] === a[1] ? nu(il(e, t), a[0]) : nu(il(Fc(e, [1, 0]), t), a[1]);
                    else {
                        const n = a[0] !== e.shape.length - 1
                          , s = a[1] === t.shape.length - 1;
                        i = pu(e, t, n, s)
                    }
                    if (n > 0) {
                        let e;
                        e = s > r ? s + r - 3 : s - 1;
                        const t = [];
                        for (let s = e; s < e + n; ++s)
                            t.push(s);
                        i = Tc(i, t)
                    }
                    return 1 === i.shape.length && (i = $c(i, 1)),
                    i
                }
                ))
            }(n, s, t)
        }
        interpretAxes(e, t) {
            let n;
            return n = Array.isArray(this.axes) ? this.axes : [yB(this.axes, e.length), yB(this.axes, t.length)],
            n
        }
        computeOutputShape(e) {
            Hs.assert(Array.isArray(e) && 2 === e.length && Array.isArray(e[0]) && Array.isArray(e[1]), (()=>"A `Dot` layer should be called on a list of exactly 2 inputs."));
            const t = e[0].slice()
              , n = e[1].slice();
            if (t.length > 3 || n.length > 3)
                throw new f_("Dot layer does not support tensors of 4D or higher rank yet.");
            const s = this.interpretAxes(t, n);
            t.splice(s[0], 1),
            n.splice(s[1], 1),
            n.splice(0, 1);
            const r = t.concat(n);
            return 1 === r.length && r.push(1),
            r
        }
        computeMask(e, t) {
            return null
        }
        getConfig() {
            const e = {
                axes: this.axes,
                normalize: this.normalize
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    bB.className = "Dot",
    lf.registerClass(bB);
    class xB extends aM {
        constructor(e) {
            super(e),
            this.supportsMasking = !0,
            this.stddev = e.stddev
        }
        computeOutputShape(e) {
            return e
        }
        getConfig() {
            const e = super.getConfig()
              , t = {
                stddev: this.stddev
            };
            return Object.assign(t, e),
            t
        }
        call(e, t) {
            return Qo((()=>{
                this.invokeCallHook(e, t);
                const n = qO(e);
                return kO((()=>sl(mO(n.shape, 0, this.stddev), n)), (()=>n), t.training || !1)
            }
            ))
        }
    }
    xB.className = "GaussianNoise",
    lf.registerClass(xB);
    class wB extends aM {
        constructor(e) {
            super(e),
            this.supportsMasking = !0,
            this.rate = e.rate
        }
        computeOutputShape(e) {
            return e
        }
        getConfig() {
            const e = super.getConfig()
              , t = {
                rate: this.rate
            };
            return Object.assign(t, e),
            t
        }
        call(e, t) {
            return Qo((()=>{
                this.invokeCallHook(e, t);
                const n = qO(e);
                if (this.rate > 0 && this.rate < 1) {
                    return kO((()=>{
                        const e = Math.sqrt(this.rate / (1 - this.rate));
                        return il(n, mO(n.shape, 1, e))
                    }
                    ), (()=>n), t.training || !1)
                }
                return n
            }
            ))
        }
    }
    wB.className = "GaussianDropout",
    lf.registerClass(wB);
    class vB extends aM {
        constructor(e) {
            super(e),
            this.supportsMasking = !0,
            this.rate = e.rate,
            this.noiseShape = e.noiseShape
        }
        _getNoiseShape(e) {
            return this.noiseShape || qO(e).shape
        }
        computeOutputShape(e) {
            return e
        }
        getConfig() {
            const e = super.getConfig()
              , t = {
                rate: this.rate
            };
            return Object.assign(t, e),
            t
        }
        call(e, t) {
            return Qo((()=>{
                if (this.rate < 1 && this.rate > 0) {
                    const n = this._getNoiseShape(e);
                    return kO((()=>{
                        const t = qO(e)
                          , s = -1.7580993408473766;
                        let r = sc(rd(n), this.rate);
                        r = oO(r, "float32");
                        const a = ((1 - this.rate) * (1 + this.rate * s ** 2)) ** -.5
                          , i = -a * s * this.rate
                          , o = sl(il(t, r), il(sl(r, -1), s));
                        return sl(il(o, a), i)
                    }
                    ), (()=>qO(e)), t.training || !1)
                }
                return e
            }
            ))
        }
    }
    function kB(e, t, n, s, r, a=.001) {
        let i;
        if (2 === e.rank)
            i = Nh(e, t, n, s, r, a);
        else if (3 === e.rank)
            i = Th(e, t, n, s, r, a);
        else {
            if (4 !== e.rank)
                throw new f_(`batchNormalization is not implemented for array of rank ${e.rank} yet`);
            i = Ch(e, t, n, s, r, a)
        }
        return i
    }
    function IB(e, t, n, s, r=.001) {
        return Hs.arraysEqual(s.slice().sort(), rO(0, e.rank - 1)) ? function(e, t, n, s, r=.001) {
            return Qo((()=>{
                const a = Tp(e, s)
                  , i = a.mean
                  , o = a.variance;
                return [kB(e, i, o, n, t, r), i, o]
            }
            ))
        }(e, t, n, s, r) : function(e, t, n, s, r=.001) {
            return Qo((()=>{
                const a = Tp(e, s)
                  , i = a.mean
                  , o = a.variance
                  , l = [];
                for (const t of rO(0, e.rank))
                    -1 !== s.indexOf(t) ? l.push(1) : l.push(e.shape[t]);
                const u = hl(i, l)
                  , c = hl(o, l)
                  , h = null == t ? null : hl(t, l)
                  , p = null == n ? null : hl(n, l);
                return [kB(e, u, c, p, h, r), i, o]
            }
            ))
        }(e, t, n, s, r)
    }
    vB.className = "AlphaDropout",
    lf.registerClass(vB);
    class SB extends aM {
        constructor(e) {
            null == e && (e = {}),
            super(e),
            this.supportsMasking = !0,
            this.axis = null == e.axis ? -1 : e.axis,
            this.momentum = null == e.momentum ? .99 : e.momentum,
            this.epsilon = null == e.epsilon ? .001 : e.epsilon,
            this.center = null == e.center || e.center,
            this.scale = null == e.scale || e.scale,
            this.betaInitializer = GO(e.betaInitializer || "zeros"),
            this.gammaInitializer = GO(e.gammaInitializer || "ones"),
            this.movingMeanInitializer = GO(e.movingMeanInitializer || "zeros"),
            this.movingVarianceInitializer = GO(e.movingVarianceInitializer || "ones"),
            this.betaConstraint = NM(e.betaConstraint),
            this.gammaConstraint = NM(e.gammaConstraint),
            this.betaRegularizer = cz(e.betaRegularizer),
            this.gammaRegularizer = cz(e.gammaRegularizer)
        }
        build(e) {
            e = KO(e);
            const t = this.axis >= 0 ? this.axis : this.axis + e.length
              , n = e[t];
            if (null == n)
                throw new d_(`Axis ${t} of input tensor should have a defined dimension but the layer received an input with shape ${JSON.stringify(e)}.`);
            this.inputSpec = [new eM({
                ndim: e.length,
                axes: {
                    [t]: n
                }
            })];
            const s = [n];
            this.scale && (this.gamma = this.addWeight("gamma", s, null, this.gammaInitializer, this.gammaRegularizer, !0, this.gammaConstraint)),
            this.center && (this.beta = this.addWeight("beta", s, null, this.betaInitializer, this.betaRegularizer, !0, this.betaConstraint)),
            this.movingMean = this.addWeight("moving_mean", s, null, this.movingMeanInitializer, null, !1),
            this.movingVariance = this.addWeight("moving_variance", s, null, this.movingVarianceInitializer, null, !1),
            this.built = !0
        }
        call(e, t) {
            return Qo((()=>{
                const n = null != t.training && t.training
                  , s = qO(e)
                  , r = s.shape
                  , a = r.length
                  , i = rO(0, a)
                  , o = this.axis >= 0 ? this.axis : this.axis + a;
                i.splice(o, 1);
                const l = y_(1, a);
                l[o] = r[o];
                const u = i.slice();
                u.sort();
                const c = !Hs.arraysEqual(u, rO(0, a).slice(0, a - 1));
                if (!n)
                    return (()=>{
                        if (c) {
                            const e = hl(this.movingMean.read(), l)
                              , t = hl(this.movingVariance.read(), l)
                              , n = this.center ? hl(this.beta.read(), l) : null
                              , r = this.scale ? hl(this.gamma.read(), l) : null;
                            return kB(s, e, t, n, r, this.epsilon)
                        }
                        return kB(s, this.movingMean.read(), this.movingVariance.read(), null == this.beta ? null : this.beta.read(), null == this.gamma ? null : this.gamma.read(), this.epsilon)
                    }
                    )();
                const [h,p,d] = IB(s, this.gamma.read(), this.beta.read(), i, this.epsilon)
                  , f = (e,t,n)=>{
                    Qo((()=>{
                        const s = 1 - n
                          , r = e.read()
                          , a = il(Yu(r, t), s);
                        e.write(Yu(r, a))
                    }
                    ))
                }
                ;
                return (()=>{
                    f(this.movingMean, p, this.momentum),
                    f(this.movingVariance, d, this.momentum)
                }
                )(),
                h
            }
            ))
        }
        getConfig() {
            const e = {
                axis: this.axis,
                momentum: this.momentum,
                epsilon: this.epsilon,
                center: this.center,
                scale: this.scale,
                betaInitializer: VO(this.betaInitializer),
                gammaInitializer: VO(this.gammaInitializer),
                movingMeanInitializer: VO(this.movingMeanInitializer),
                movingVarianceInitializer: VO(this.movingVarianceInitializer),
                betaRegularizer: lz(this.betaRegularizer),
                gammaRegularizer: lz(this.gammaRegularizer),
                betaConstraint: IM(this.betaConstraint),
                gammaConstraint: IM(this.gammaConstraint)
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    SB.className = "BatchNormalization",
    lf.registerClass(SB);
    class NB extends aM {
        constructor(e) {
            if (null == e && (e = {}),
            super(e),
            this.axis = null == e.axis ? -1 : e.axis,
            "number" == typeof this.axis) {
                if (!Number.isInteger(this.axis))
                    throw new Error(`Expected axis to be an integer, but received ${this.axis}`)
            } else {
                if (!Array.isArray(this.axis))
                    throw new Error(`Expected axis to be an integer or an array of integers, but received ${JSON.stringify(this.axis)}`);
                for (const e of this.axis)
                    if (!Number.isInteger(e))
                        throw new Error(`Expected axis to be an array of integers, but received ${JSON.stringify(this.axis)}`)
            }
            this.epsilon = null == e.epsilon ? .001 : e.epsilon,
            this.center = null == e.center || e.center,
            this.scale = null == e.scale || e.scale,
            this.betaInitializer = GO(e.betaInitializer || "zeros"),
            this.gammaInitializer = GO(e.gammaInitializer || "ones"),
            this.betaRegularizer = cz(e.betaRegularizer),
            this.gammaRegularizer = cz(e.gammaRegularizer),
            this.supportsMasking = !0
        }
        build(e) {
            const t = (e = KO(e)).length;
            "number" == typeof this.axis && (this.axis = [this.axis]);
            for (let e = 0; e < this.axis.length; ++e)
                this.axis[e] < 0 && (this.axis[e] += t);
            for (const e of this.axis)
                if (e < 0 || e >= t)
                    throw new Error(`Invalid axis: ${e}`);
            if (this.axis.length !== E_(this.axis).length)
                throw new Error(`Found duplicate axes in: ${this.axis}`);
            const n = this.axis.map((t=>e[t]));
            this.scale ? this.gamma = this.addWeight("gamma", n, "float32", this.gammaInitializer, this.gammaRegularizer, true) : this.gamma = null,
            this.center ? this.beta = this.addWeight("beta", n, "float32", this.betaInitializer, this.betaRegularizer, true) : this.beta = null,
            this.built = !0
        }
        call(e, t) {
            const n = qO(e)
              , s = n.shape
              , r = s.length;
            return Qo((()=>{
                let {mean: e, variance: t} = Tp(n, this.axis, !0);
                const a = y_(1, r);
                for (const e of this.axis)
                    a[e] = s[e];
                const i = e=>null != e && e.shape.length !== r ? hl(e, a) : e;
                let o = this.scale ? i(this.gamma.read()) : null
                  , l = this.center ? i(this.beta.read()) : null;
                const u = []
                  , c = [];
                for (let e = 0; e < r; ++e)
                    -1 !== this.axis.indexOf(e) ? (u.push(s[e]),
                    c.push(1)) : (u.push(1),
                    c.push(s[e]));
                return e = Tu(e, u),
                t = Tu(t, u),
                null != o && (o = Tu(o, c)),
                null != l && (l = Tu(l, c)),
                kB(n, e, t, l, o, this.epsilon)
            }
            ))
        }
        getConfig() {
            const e = {
                axis: this.axis,
                epsilon: this.epsilon,
                center: this.center,
                scale: this.scale,
                betaInitializer: VO(this.betaInitializer),
                gammaInitializer: VO(this.gammaInitializer),
                betaRegularizer: lz(this.betaRegularizer),
                gammaRegularizer: lz(this.gammaRegularizer)
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    NB.className = "LayerNormalization",
    lf.registerClass(NB);
    class TB extends aM {
        constructor(e) {
            if (null == e && (e = {}),
            super(e),
            this.dataFormat = null == e.dataFormat ? "channelsLast" : e.dataFormat,
            null == e.padding)
                this.padding = [[1, 1], [1, 1]];
            else if ("number" == typeof e.padding)
                this.padding = [[e.padding, e.padding], [e.padding, e.padding]];
            else {
                if (e.padding = e.padding,
                2 !== e.padding.length)
                    throw new d_(`ZeroPadding2D expects padding to be a length-2 array, but received a length-${e.padding.length} array.`);
                let t, n;
                if ("number" == typeof e.padding[0])
                    t = [e.padding[0], e.padding[0]],
                    n = [e.padding[1], e.padding[1]];
                else {
                    if (e.padding = e.padding,
                    2 !== e.padding[0].length)
                        throw new d_(`ZeroPadding2D expects height padding to be a length-2 array, but received a length-${e.padding[0].length} array.`);
                    if (t = e.padding[0],
                    2 !== e.padding[1].length)
                        throw new d_(`ZeroPadding2D expects width padding to be a length-2 array, but received a length-${e.padding[1].length} array.`);
                    n = e.padding[1]
                }
                this.padding = [t, n]
            }
            this.inputSpec = [new eM({
                ndim: 4
            })]
        }
        computeOutputShape(e) {
            let t, n;
            return e = KO(e),
            "channelsFirst" === this.dataFormat ? (t = null != e[2] && e[2] >= 0 ? e[2] + this.padding[0][0] + this.padding[0][1] : null,
            n = null != e[3] && e[3] >= 0 ? e[3] + this.padding[1][0] + this.padding[1][1] : null,
            [e[0], e[1], t, n]) : (t = null != e[1] && e[1] >= 0 ? e[1] + this.padding[0][0] + this.padding[0][1] : null,
            n = null != e[2] && e[2] >= 0 ? e[2] + this.padding[1][0] + this.padding[1][1] : null,
            [e[0], t, n, e[3]])
        }
        call(e, t) {
            return Qo((()=>{
                return t = qO(e),
                n = this.padding,
                s = this.dataFormat,
                Qo((()=>{
                    if (4 !== t.rank)
                        throw new d_(`temporalPadding expects input tensor to be 4-D, but received a ${t.rank}-D tensor.`);
                    if (null == n && (n = [[1, 1], [1, 1]]),
                    2 !== n.length || 2 !== n[0].length || 2 !== n[1].length)
                        throw new d_("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");
                    if (null == s && (s = "channelsLast"),
                    "channelsLast" !== s && "channelsFirst" !== s)
                        throw new d_(`Unknown data format: ${s}. Supported data formats are 'channelsLast' and 'channelsFirst.`);
                    let e;
                    return e = "channelsFirst" === s ? [[0, 0], [0, 0], n[0], n[1]] : [[0, 0], n[0], n[1], [0, 0]],
                    Fp(t, e)
                }
                ));
                var t, n, s
            }
            ))
        }
        getConfig() {
            const e = {
                padding: this.padding,
                dataFormat: this.dataFormat
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    function CB(e, t, n, s, r, a) {
        return Qo((()=>{
            let i;
            j_(r),
            K_(a),
            q_(s),
            null == n && (n = [1, 1]),
            null == s && (s = "valid"),
            null == r && (r = "channelsLast"),
            null == a && (a = "max"),
            e = wz(e, r);
            const o = "same" === s ? "same" : "valid";
            return i = "max" === a ? xp(e, t, n, o) : xh(e, t, n, o),
            "channelsFirst" === r && (i = Fc(i, [0, 3, 1, 2])),
            i
        }
        ))
    }
    function $B(e, t, n, s, r, a) {
        return Qo((()=>{
            let i;
            j_(r),
            K_(a),
            q_(s),
            null == n && (n = [1, 1, 1]),
            null == s && (s = "valid"),
            null == r && (r = "channelsLast"),
            null == a && (a = "max"),
            e = vz(e, r);
            const o = "same" === s ? "same" : "valid";
            return i = "max" === a ? wp(e, t, n, o) : wh(e, t, n, o),
            "channelsFirst" === r && (i = Fc(i, [0, 4, 1, 2, 3])),
            i
        }
        ))
    }
    TB.className = "ZeroPadding2D",
    lf.registerClass(TB);
    class EB extends aM {
        constructor(e) {
            if (null == e.poolSize && (e.poolSize = 2),
            super(e),
            "number" == typeof e.poolSize)
                this.poolSize = [e.poolSize];
            else {
                if (!Array.isArray(e.poolSize) || 1 !== e.poolSize.length || "number" != typeof e.poolSize[0])
                    throw new d_(`poolSize for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(e.poolSize)}`);
                this.poolSize = e.poolSize
            }
            if (D_(this.poolSize, "poolSize"),
            null == e.strides)
                this.strides = this.poolSize;
            else if ("number" == typeof e.strides)
                this.strides = [e.strides];
            else {
                if (!Array.isArray(e.strides) || 1 !== e.strides.length || "number" != typeof e.strides[0])
                    throw new d_(`strides for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(e.strides)}`);
                this.strides = e.strides
            }
            D_(this.strides, "strides"),
            this.padding = null == e.padding ? "valid" : e.padding,
            q_(this.padding),
            this.inputSpec = [new eM({
                ndim: 3
            })]
        }
        computeOutputShape(e) {
            const t = bz((e = KO(e))[1], this.poolSize[0], this.padding, this.strides[0]);
            return [e[0], t, e[2]]
        }
        call(e, t) {
            return Qo((()=>{
                this.invokeCallHook(e, t),
                e = lO(qO(e), 2);
                const n = this.poolingFunction(qO(e), [this.poolSize[0], 1], [this.strides[0], 1], this.padding, "channelsLast");
                return Tc(n, [2])
            }
            ))
        }
        getConfig() {
            const e = {
                poolSize: this.poolSize,
                padding: this.padding,
                strides: this.strides
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    class AB extends EB {
        constructor(e) {
            super(e)
        }
        poolingFunction(e, t, n, s, r) {
            return j_(r),
            q_(s),
            CB(e, t, n, s, r, "max")
        }
    }
    AB.className = "MaxPooling1D",
    lf.registerClass(AB);
    class RB extends EB {
        constructor(e) {
            super(e)
        }
        poolingFunction(e, t, n, s, r) {
            return j_(r),
            q_(s),
            CB(e, t, n, s, r, "avg")
        }
    }
    RB.className = "AveragePooling1D",
    lf.registerClass(RB);
    class FB extends aM {
        constructor(e) {
            if (null == e.poolSize && (e.poolSize = [2, 2]),
            super(e),
            this.poolSize = Array.isArray(e.poolSize) ? e.poolSize : [e.poolSize, e.poolSize],
            null == e.strides)
                this.strides = this.poolSize;
            else if (Array.isArray(e.strides)) {
                if (2 !== e.strides.length)
                    throw new d_(`If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length ${e.strides.length}.`);
                this.strides = e.strides
            } else
                this.strides = [e.strides, e.strides];
            D_(this.poolSize, "poolSize"),
            D_(this.strides, "strides"),
            this.padding = null == e.padding ? "valid" : e.padding,
            this.dataFormat = null == e.dataFormat ? "channelsLast" : e.dataFormat,
            j_(this.dataFormat),
            q_(this.padding),
            this.inputSpec = [new eM({
                ndim: 4
            })]
        }
        computeOutputShape(e) {
            e = KO(e);
            let t = "channelsFirst" === this.dataFormat ? e[2] : e[1]
              , n = "channelsFirst" === this.dataFormat ? e[3] : e[2];
            return t = bz(t, this.poolSize[0], this.padding, this.strides[0]),
            n = bz(n, this.poolSize[1], this.padding, this.strides[1]),
            "channelsFirst" === this.dataFormat ? [e[0], e[1], t, n] : [e[0], t, n, e[3]]
        }
        call(e, t) {
            return Qo((()=>(this.invokeCallHook(e, t),
            this.poolingFunction(qO(e), this.poolSize, this.strides, this.padding, this.dataFormat))))
        }
        getConfig() {
            const e = {
                poolSize: this.poolSize,
                padding: this.padding,
                strides: this.strides,
                dataFormat: this.dataFormat
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    class DB extends FB {
        constructor(e) {
            super(e)
        }
        poolingFunction(e, t, n, s, r) {
            return j_(r),
            q_(s),
            CB(e, t, n, s, r, "max")
        }
    }
    DB.className = "MaxPooling2D",
    lf.registerClass(DB);
    class _B extends FB {
        constructor(e) {
            super(e)
        }
        poolingFunction(e, t, n, s, r) {
            return j_(r),
            q_(s),
            CB(e, t, n, s, r, "avg")
        }
    }
    _B.className = "AveragePooling2D",
    lf.registerClass(_B);
    class OB extends aM {
        constructor(e) {
            if (null == e.poolSize && (e.poolSize = [2, 2, 2]),
            super(e),
            this.poolSize = Array.isArray(e.poolSize) ? e.poolSize : [e.poolSize, e.poolSize, e.poolSize],
            null == e.strides)
                this.strides = this.poolSize;
            else if (Array.isArray(e.strides)) {
                if (3 !== e.strides.length)
                    throw new d_(`If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length ${e.strides.length}.`);
                this.strides = e.strides
            } else
                this.strides = [e.strides, e.strides, e.strides];
            D_(this.poolSize, "poolSize"),
            D_(this.strides, "strides"),
            this.padding = null == e.padding ? "valid" : e.padding,
            this.dataFormat = null == e.dataFormat ? "channelsLast" : e.dataFormat,
            j_(this.dataFormat),
            q_(this.padding),
            this.inputSpec = [new eM({
                ndim: 5
            })]
        }
        computeOutputShape(e) {
            e = KO(e);
            let t = "channelsFirst" === this.dataFormat ? e[2] : e[1]
              , n = "channelsFirst" === this.dataFormat ? e[3] : e[2]
              , s = "channelsFirst" === this.dataFormat ? e[4] : e[3];
            return t = bz(t, this.poolSize[0], this.padding, this.strides[0]),
            n = bz(n, this.poolSize[1], this.padding, this.strides[1]),
            s = bz(s, this.poolSize[2], this.padding, this.strides[2]),
            "channelsFirst" === this.dataFormat ? [e[0], e[1], t, n, s] : [e[0], t, n, s, e[4]]
        }
        call(e, t) {
            return Qo((()=>(this.invokeCallHook(e, t),
            this.poolingFunction(qO(e), this.poolSize, this.strides, this.padding, this.dataFormat))))
        }
        getConfig() {
            const e = {
                poolSize: this.poolSize,
                padding: this.padding,
                strides: this.strides,
                dataFormat: this.dataFormat
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    class MB extends OB {
        constructor(e) {
            super(e)
        }
        poolingFunction(e, t, n, s, r) {
            return j_(r),
            q_(s),
            $B(e, t, n, s, r, "max")
        }
    }
    MB.className = "MaxPooling3D",
    lf.registerClass(MB);
    class LB extends OB {
        constructor(e) {
            super(e)
        }
        poolingFunction(e, t, n, s, r) {
            return j_(r),
            q_(s),
            $B(e, t, n, s, r, "avg")
        }
    }
    LB.className = "AveragePooling3D",
    lf.registerClass(LB);
    class zB extends aM {
        constructor(e) {
            super(e),
            this.inputSpec = [new eM({
                ndim: 3
            })]
        }
        computeOutputShape(e) {
            return [e[0], e[2]]
        }
        call(e, t) {
            throw new f_
        }
    }
    class BB extends zB {
        constructor(e) {
            super(e || {})
        }
        call(e, t) {
            return Qo((()=>{
                const t = qO(e);
                return Mc(t, 1)
            }
            ))
        }
    }
    BB.className = "GlobalAveragePooling1D",
    lf.registerClass(BB);
    class PB extends zB {
        constructor(e) {
            super(e || {})
        }
        call(e, t) {
            return Qo((()=>{
                const t = qO(e);
                return xc(t, 1)
            }
            ))
        }
    }
    PB.className = "GlobalMaxPooling1D",
    lf.registerClass(PB);
    class WB extends aM {
        constructor(e) {
            super(e),
            this.dataFormat = null == e.dataFormat ? "channelsLast" : e.dataFormat,
            j_(this.dataFormat),
            this.inputSpec = [new eM({
                ndim: 4
            })]
        }
        computeOutputShape(e) {
            return "channelsLast" === this.dataFormat ? [e[0], e[3]] : [e[0], e[1]]
        }
        call(e, t) {
            throw new f_
        }
        getConfig() {
            const e = {
                dataFormat: this.dataFormat
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
    }
    class UB extends WB {
        call(e, t) {
            return Qo((()=>{
                const t = qO(e);
                return "channelsLast" === this.dataFormat ? Mc(t, [1, 2]) : Mc(t, [2, 3])
            }
            ))
        }
    }
    UB.className = "GlobalAveragePooling2D",
    lf.registerClass(UB);
    class VB extends WB {
        call(e, t) {
            return Qo((()=>{
                const t = qO(e);
                return "channelsLast" === this.dataFormat ? xc(t, [1, 2]) : xc(t, [2, 3])
            }
            ))
        }
    }
    VB.className = "GlobalMaxPooling2D",
    lf.registerClass(VB);
    class GB extends aM {
        constructor(e) {
            super(e),
            this.layer = e.layer
        }
        build(e) {
            this.built = !0
        }
        get trainable() {
            return null != this.layer && this.layer.trainable
        }
        set trainable(e) {
            null != this.layer && (this.layer.trainable = e)
        }
        get trainableWeights() {
            return this.layer.trainableWeights
        }
        get nonTrainableWeights() {
            return this.layer.nonTrainableWeights
        }
        get updates() {
            return this.layer._updates
        }
        get losses() {
            return this.layer.losses
        }
        getWeights() {
            return this.layer.getWeights()
        }
        setWeights(e) {
            this.layer.setWeights(e)
        }
        getConfig() {
            const e = {
                layer: {
                    className: this.layer.getClassName(),
                    config: this.layer.getConfig()
                }
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
        setFastWeightInitDuringBuild(e) {
            super.setFastWeightInitDuringBuild(e),
            null != this.layer && this.layer.setFastWeightInitDuringBuild(e)
        }
        static fromConfig(e, t, n={}) {
            const s = LM(t.layer, n);
            delete t.layer;
            const r = {
                layer: s
            };
            return Object.assign(r, t),
            new e(r)
        }
    }
    class HB extends GB {
        constructor(e) {
            super(e),
            this.supportsMasking = !0
        }
        build(e) {
            if ((e = KO(e)).length < 3)
                throw new d_(`TimeDistributed layer expects an input shape >= 3D, but received input shape ${JSON.stringify(e)}`);
            this.inputSpec = [{
                shape: e
            }];
            const t = [e[0]].concat(e.slice(2));
            this.layer.built || (this.layer.build(t),
            this.layer.built = !0),
            super.build(e)
        }
        computeOutputShape(e) {
            const t = [(e = KO(e))[0]].concat(e.slice(2))
              , n = this.layer.computeOutputShape(t)
              , s = e[1];
            return [n[0], s].concat(n.slice(1))
        }
        call(e, t) {
            return Qo((()=>Bz(((e,n)=>[qO(this.layer.call(e, t)), []]), e = qO(e), [], !1, null, null, !1, !0)[1]))
        }
    }
    HB.className = "TimeDistributed",
    lf.registerClass(HB);
    class jB extends GB {
        constructor(e) {
            super(e);
            const t = e.layer.getConfig()
              , n = {};
            n.className = e.layer.getClassName(),
            n.config = t,
            this.forwardLayer = LM(n),
            t.goBackwards = !0 !== t.goBackwards;
            const s = {};
            var r;
            if (s.className = e.layer.getClassName(),
            s.config = t,
            this.backwardLayer = LM(s),
            this.forwardLayer.name = "forward_" + this.forwardLayer.name,
            this.backwardLayer.name = "backward_" + this.backwardLayer.name,
            this.mergeMode = void 0 === e.mergeMode ? "concat" : e.mergeMode,
            r = this.mergeMode,
            R_(G_, "BidirectionalMergeMode", r),
            e.weights)
                throw new f_("weights support is not implemented for Bidirectional layer yet.");
            this._stateful = e.layer.stateful,
            this.returnSequences = e.layer.returnSequences,
            this.returnState = e.layer.returnState,
            this.supportsMasking = !0,
            this._trainable = !0,
            this.inputSpec = e.layer.inputSpec,
            this.numConstants = null
        }
        get trainable() {
            return this._trainable
        }
        set trainable(e) {
            this._trainable = e,
            null != this.forwardLayer && (this.forwardLayer.trainable = e),
            null != this.backwardLayer && (this.backwardLayer.trainable = e)
        }
        getWeights() {
            return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights())
        }
        setWeights(e) {
            const t = e.length
              , n = Math.floor(t / 2);
            this.forwardLayer.setWeights(e.slice(0, n)),
            this.backwardLayer.setWeights(e.slice(n))
        }
        computeOutputShape(e) {
            let t, n, s, r = this.forwardLayer.computeOutputShape(e);
            return Array.isArray(r) && Array.isArray(r[0]) || (r = [r]),
            this.returnState ? (s = r.slice(1),
            t = r[0]) : t = r[0],
            "concat" === this.mergeMode ? (t[t.length - 1] *= 2,
            n = [t]) : n = null == this.mergeMode ? [t, t.slice()] : [t],
            this.returnState ? null == this.mergeMode ? n.concat(s).concat(s.slice()) : [t].concat(s).concat(s.slice()) : w_(n)
        }
        apply(e, t) {
            let n = null == t ? null : t.initialState
              , s = null == t ? null : t.constants;
            null == t && (t = {});
            const r = zz(e, n, s, this.numConstants);
            if (e = r.inputs,
            n = r.initialState,
            s = r.constants,
            Array.isArray(e) && (n = e.slice(1),
            e = e[0]),
            (null == n || 0 === n.length) && null == s)
                return super.apply(e, t);
            const a = []
              , i = [];
            if (null != n) {
                const e = n.length;
                if (e % 2 > 0)
                    throw new d_("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");
                t.initialState = n,
                a.push(...n);
                const s = n.map((e=>new eM({
                    shape: e.shape
                })));
                this.forwardLayer.stateSpec = s.slice(0, e / 2),
                this.backwardLayer.stateSpec = s.slice(e / 2),
                i.push(...s)
            }
            if (null != s)
                throw new f_("Support for constants in Bidirectional layers is not implemented yet.");
            const o = a[0]instanceof tM;
            for (const e of a)
                if (e instanceof tM !== o)
                    throw new d_("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");
            if (o) {
                const n = [e].concat(a)
                  , s = this.inputSpec.concat(i)
                  , r = this.inputSpec;
                this.inputSpec = s;
                const o = super.apply(n, t);
                return this.inputSpec = r,
                o
            }
            return super.apply(e, t)
        }
        call(e, t) {
            return Qo((()=>{
                const n = t.initialState;
                let s, r, a, i;
                if (null == n)
                    s = this.forwardLayer.call(e, t),
                    r = this.backwardLayer.call(e, t);
                else {
                    const a = n.slice(0, n.length / 2)
                      , i = n.slice(n.length / 2);
                    s = this.forwardLayer.call(e, Object.assign(t, {
                        initialState: a
                    })),
                    r = this.backwardLayer.call(e, Object.assign(t, {
                        initialState: i
                    }))
                }
                return this.returnState && (Array.isArray(s) && (a = s.slice(1).concat(r.slice(1))),
                s = s[0],
                r = r[0]),
                this.returnSequences && (r = xl(r, 1)),
                "concat" === this.mergeMode ? i = pO([s, r]) : "sum" === this.mergeMode ? i = sl(s, r) : "ave" === this.mergeMode ? i = il(.5, sl(s, r)) : "mul" === this.mergeMode ? i = il(s, r) : null == this.mergeMode && (i = [s, r]),
                this.returnState ? null == this.mergeMode ? i.concat(a) : [i].concat(a) : i
            }
            ))
        }
        resetStates(e) {
            this.forwardLayer.resetStates(),
            this.backwardLayer.resetStates()
        }
        build(e) {
            Y_(this.forwardLayer.name, (()=>{
                this.forwardLayer.build(e)
            }
            )),
            Y_(this.backwardLayer.name, (()=>{
                this.backwardLayer.build(e)
            }
            )),
            this.built = !0
        }
        computeMask(e, t) {
            let n;
            if (Array.isArray(t) && (t = t[0]),
            n = this.returnSequences ? null == this.mergeMode ? [t, t] : t : null == this.mergeMode ? [null, null] : null,
            this.returnState) {
                const e = this.forwardLayer.states.map((e=>null));
                return Array.isArray(n) ? n.concat(e).concat(e) : [n].concat(e).concat(e)
            }
            return n
        }
        get trainableWeights() {
            return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights)
        }
        get nonTrainableWeights() {
            return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights)
        }
        setFastWeightInitDuringBuild(e) {
            super.setFastWeightInitDuringBuild(e),
            null != this.forwardLayer && this.forwardLayer.setFastWeightInitDuringBuild(e),
            null != this.backwardLayer && this.backwardLayer.setFastWeightInitDuringBuild(e)
        }
        getConfig() {
            const e = {
                mergeMode: this.mergeMode
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
        static fromConfig(e, t) {
            const n = LM(t.layer);
            if (delete t.layer,
            null != t.numConstants)
                throw new f_("Deserialization of a Bidirectional layer with numConstants present is not supported yet.");
            const s = t;
            return s.layer = n,
            new e(s)
        }
    }
    jB.className = "Bidirectional",
    lf.registerClass(jB);
    class qB extends aM {
        constructor(e) {
            super(e),
            this.scale = e.scale,
            e.offset ? this.offset = e.offset : this.offset = 0
        }
        getConfig() {
            const e = {
                scale: this.scale,
                offset: this.offset
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
        call(e, t) {
            return Qo((()=>("float32" !== (e = qO(e)).dtype && (e = oO(e, "float32")),
            sl(il(e, this.scale), this.offset))))
        }
    }
    qB.className = "Rescaling",
    lf.registerClass(qB);
    const {resizeBilinear: KB, cropAndResize: XB} = nf;
    class YB extends aM {
        constructor(e) {
            super(e),
            this.height = e.height,
            this.width = e.width
        }
        centerCrop(e, t, n, s, r, a, i, o) {
            return Qo((()=>{
                let l, u = !1;
                const c = [t / a, n / i, (s + t) / a, (r + n) / i]
                  , h = [];
                3 === e.rank ? (u = !0,
                l = ac([e])) : l = e;
                for (let e = 0; e < l.shape[0]; e++)
                    h.push(c);
                const p = Ba(h, [h.length, 4])
                  , d = ec(0, h.length, 1, "int32")
                  , f = XB(l, p, d, [s, r], "nearest");
                return oO(u ? qO(ic(f)) : f, o)
            }
            ))
        }
        upsize(e, t, n, s) {
            return Qo((()=>oO(KB(e, [t, n]), s)))
        }
        call(e, t) {
            return Qo((()=>{
                const t = qO(e)
                  , n = t.dtype
                  , s = t.shape
                  , r = s[s.length - 3]
                  , a = s[s.length - 2];
                let i = 0;
                r !== this.height && (i = Math.floor((r - this.height) / 2));
                let o = 0;
                return a !== this.width && (o = Math.floor((a - this.width) / 2),
                0 === o && (o = 1)),
                i >= 0 && o >= 0 ? this.centerCrop(t, i, o, this.height, this.width, r, a, n) : this.upsize(e, this.height, this.width, n)
            }
            ))
        }
        getConfig() {
            const e = {
                height: this.height,
                width: this.width
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
        computeOutputShape(e) {
            const t = (e = KO(e)).length - 3
              , n = e.length - 2;
            return e[t] = this.height,
            e[n] = this.width,
            e
        }
    }
    YB.className = "CenterCrop",
    lf.registerClass(YB);
    class ZB extends aM {
        constructor(e) {
            super(e),
            this.numTokens = e.numTokens,
            e.outputMode ? this.outputMode = e.outputMode : this.outputMode = "multiHot"
        }
        getConfig() {
            const e = {
                numTokens: this.numTokens,
                outputMode: this.outputMode
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
        computeOutputShape(e) {
            return null == (e = KO(e)) ? [this.numTokens] : "oneHot" === this.outputMode && 1 !== e[e.length - 1] ? (e.push(this.numTokens),
            e) : (e[e.length - 1] = this.numTokens,
            e)
        }
        call(e, t) {
            return Qo((()=>{
                let n;
                if ("int32" !== (e = qO(e)).dtype && (e = oO(e, "int32")),
                void 0 !== t.countWeights) {
                    if ("count" !== this.outputMode)
                        throw new d_(`countWeights is not used when outputMode !== count.\n              Received countWeights=${t.countWeights}`);
                    n = qO(t.countWeights)
                }
                const s = xc(e)
                  , r = wc(e)
                  , a = Xu(this.numTokens, s).bufferSync().get(0)
                  , i = sc(r, 0).bufferSync().get(0);
                if (!a || !i)
                    throw new d_(`Input values must be between 0 < values <= numTokens with numTokens=${this.numTokens}`);
                return function(e, t, n, s) {
                    let r = qO(e);
                    if ("int32" !== r.dtype && (r = oO(r, "int32")),
                    "int" === t)
                        return r;
                    const a = r.shape;
                    if (0 === r.rank && (r = $c(r, -1)),
                    "oneHot" === t && 1 !== r.shape[r.shape.length - 1] && (r = $c(r, -1)),
                    r.rank > 2)
                        throw new d_(`When outputMode is not int, maximum output rank is 2 Received outputMode ${t} and input shape ${a} which would result in output rank ${r.rank}.`);
                    const i = ["multiHot", "oneHot"].includes(t);
                    let o;
                    if (o = Gh(r, void 0 !== s && "count" === t ? s : [], n, i),
                    "tfIdf" !== t)
                        return o;
                    if (s)
                        return il(o, s);
                    throw new d_("When outputMode is 'tfIdf', weights must be provided.")
                }(e, this.outputMode, this.numTokens, n)
            }
            ))
        }
    }
    ZB.className = "CategoryEncoding",
    lf.registerClass(ZB);
    const JB = new Set(["bilinear", "nearest"]);
    class QB extends aM {
        constructor(e) {
            if (super(e),
            this.height = e.height,
            this.width = e.width,
            e.interpolation) {
                if (!JB.has(e.interpolation))
                    throw new d_(`Invalid interpolation parameter: ${e.interpolation} is not implemented`);
                this.interpolation = e.interpolation
            } else
                this.interpolation = "bilinear";
            this.cropToAspectRatio = Boolean(e.cropToAspectRatio)
        }
        computeOutputShape(e) {
            const t = (e = KO(e))[2];
            return [this.height, this.width, t]
        }
        getConfig() {
            const e = {
                height: this.height,
                width: this.width,
                interpolation: this.interpolation,
                cropToAspectRatio: this.cropToAspectRatio
            }
              , t = super.getConfig();
            return Object.assign(e, t),
            e
        }
        call(e, t) {
            return Qo((()=>{
                const t = [this.height, this.width];
                if ("bilinear" === this.interpolation)
                    return nf.resizeBilinear(e, t, !this.cropToAspectRatio);
                if ("nearest" === this.interpolation)
                    return nf.resizeNearestNeighbor(e, t, !this.cropToAspectRatio);
                throw new Error(`Interpolation is ${this.interpolation} but only ${[...JB]} are supported`)
            }
            ))
        }
    }
    QB.className = "Resizing",
    lf.registerClass(QB);
    var eP, tP;
    ie().registerFlag("KEEP_INTERMEDIATE_TENSORS", (()=>!1), (e=>{
        e && console.warn("Keep intermediate tensors is ON. This will print the values of all intermediate tensors during model inference. Not all models support this mode. For details, check e2e/benchmarks/ model_config.js. This significantly impacts performance.")
    }
    )),
    function(e) {
        e[e.DT_INVALID = 0] = "DT_INVALID",
        e[e.DT_FLOAT = 1] = "DT_FLOAT",
        e[e.DT_DOUBLE = 2] = "DT_DOUBLE",
        e[e.DT_INT32 = 3] = "DT_INT32",
        e[e.DT_UINT8 = 4] = "DT_UINT8",
        e[e.DT_INT16 = 5] = "DT_INT16",
        e[e.DT_INT8 = 6] = "DT_INT8",
        e[e.DT_STRING = 7] = "DT_STRING",
        e[e.DT_COMPLEX64 = 8] = "DT_COMPLEX64",
        e[e.DT_INT64 = 9] = "DT_INT64",
        e[e.DT_BOOL = 10] = "DT_BOOL",
        e[e.DT_QINT8 = 11] = "DT_QINT8",
        e[e.DT_QUINT8 = 12] = "DT_QUINT8",
        e[e.DT_QINT32 = 13] = "DT_QINT32",
        e[e.DT_BFLOAT16 = 14] = "DT_BFLOAT16",
        e[e.DT_QINT16 = 15] = "DT_QINT16",
        e[e.DT_QUINT16 = 16] = "DT_QUINT16",
        e[e.DT_UINT16 = 17] = "DT_UINT16",
        e[e.DT_COMPLEX128 = 18] = "DT_COMPLEX128",
        e[e.DT_HALF = 19] = "DT_HALF",
        e[e.DT_RESOURCE = 20] = "DT_RESOURCE",
        e[e.DT_VARIANT = 21] = "DT_VARIANT",
        e[e.DT_UINT32 = 22] = "DT_UINT32",
        e[e.DT_UINT64 = 23] = "DT_UINT64",
        e[e.DT_FLOAT_REF = 101] = "DT_FLOAT_REF",
        e[e.DT_DOUBLE_REF = 102] = "DT_DOUBLE_REF",
        e[e.DT_INT32_REF = 103] = "DT_INT32_REF",
        e[e.DT_UINT8_REF = 104] = "DT_UINT8_REF",
        e[e.DT_INT16_REF = 105] = "DT_INT16_REF",
        e[e.DT_INT8_REF = 106] = "DT_INT8_REF",
        e[e.DT_STRING_REF = 107] = "DT_STRING_REF",
        e[e.DT_COMPLEX64_REF = 108] = "DT_COMPLEX64_REF",
        e[e.DT_INT64_REF = 109] = "DT_INT64_REF",
        e[e.DT_BOOL_REF = 110] = "DT_BOOL_REF",
        e[e.DT_QINT8_REF = 111] = "DT_QINT8_REF",
        e[e.DT_QUINT8_REF = 112] = "DT_QUINT8_REF",
        e[e.DT_QINT32_REF = 113] = "DT_QINT32_REF",
        e[e.DT_BFLOAT16_REF = 114] = "DT_BFLOAT16_REF",
        e[e.DT_QINT16_REF = 115] = "DT_QINT16_REF",
        e[e.DT_QUINT16_REF = 116] = "DT_QUINT16_REF",
        e[e.DT_UINT16_REF = 117] = "DT_UINT16_REF",
        e[e.DT_COMPLEX128_REF = 118] = "DT_COMPLEX128_REF",
        e[e.DT_HALF_REF = 119] = "DT_HALF_REF",
        e[e.DT_RESOURCE_REF = 120] = "DT_RESOURCE_REF",
        e[e.DT_VARIANT_REF = 121] = "DT_VARIANT_REF",
        e[e.DT_UINT32_REF = 122] = "DT_UINT32_REF",
        e[e.DT_UINT64_REF = 123] = "DT_UINT64_REF"
    }(eP || (eP = {})),
    function(e) {
        let t;
        var n;
        (n = t = e.CheckpointFormatVersion || (e.CheckpointFormatVersion = {}))[n.LEGACY = 0] = "LEGACY",
        n[n.V1 = 1] = "V1",
        n[n.V2 = 2] = "V2"
    }(tP || (tP = {}));
    var nP = {};
    t(nP, "json", (()=>sP));
    const sP = [{
        tfOpName: "Add",
        category: "arithmetic",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "AddV2",
        category: "arithmetic",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "AddN",
        category: "arithmetic",
        inputs: [{
            start: 0,
            end: 0,
            name: "tensors",
            type: "tensors"
        }]
    }, {
        tfOpName: "BiasAdd",
        category: "arithmetic",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }, {
            tfName: "data_format",
            name: "dataFormat",
            type: "string",
            notSupported: !0
        }]
    }, {
        tfOpName: "Sub",
        category: "arithmetic",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "RealDiv",
        category: "arithmetic",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Div",
        category: "arithmetic",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "DivNoNan",
        category: "arithmetic",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "FloorDiv",
        category: "arithmetic",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Mul",
        category: "arithmetic",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Maximum",
        category: "arithmetic",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Minimum",
        category: "arithmetic",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Pow",
        category: "arithmetic",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "SquaredDifference",
        category: "arithmetic",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Mod",
        category: "arithmetic",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "FloorMod",
        category: "arithmetic",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }];
    var rP = {};
    t(rP, "json", (()=>aP));
    const aP = [{
        tfOpName: "Abs",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Acos",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Asin",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Atan",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Atan2",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "y",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Ceil",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "ClipByValue",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "clipValueMin",
            type: "number"
        }, {
            start: 2,
            name: "clipValueMax",
            type: "number"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Complex",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "real",
            type: "tensor"
        }, {
            start: 1,
            name: "imag",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "ComplexAbs",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Cos",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Cosh",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Elu",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Exp",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Floor",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Log",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Imag",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }, {
            tfName: "Tout",
            name: "outputType",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Neg",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Real",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }, {
            tfName: "Tout",
            name: "outputType",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Prelu",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "alpha",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Relu",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Relu6",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Selu",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Sigmoid",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Sin",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Sinh",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Sqrt",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Rsqrt",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Square",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Tan",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Tanh",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Sign",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Round",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Expm1",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Log1p",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Reciprocal",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Softplus",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Asinh",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Acosh",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Atanh",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Erf",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Prod",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "axes",
            type: "number[]"
        }],
        attrs: [{
            tfName: "keep_dims",
            name: "keepDims",
            type: "bool",
            notSupported: !0
        }, {
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "LeakyRelu",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "alpha",
            name: "alpha",
            type: "number",
            defaultValue: .2
        }, {
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "IsNan",
        category: "basic_math",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }];
    var iP = {};
    t(iP, "json", (()=>oP));
    const oP = [{
        tfOpName: "EmptyTensorList",
        category: "control",
        inputs: [{
            start: 0,
            name: "elementShape",
            type: "shape"
        }, {
            start: 1,
            name: "maxNumElements",
            type: "number"
        }],
        attrs: [{
            tfName: "element_dtype",
            name: "elementDType",
            type: "dtype"
        }]
    }, {
        tfOpName: "LoopCond",
        category: "control",
        inputs: [{
            start: 0,
            name: "pred",
            type: "tensor"
        }]
    }, {
        tfOpName: "Switch",
        category: "control",
        inputs: [{
            start: 0,
            name: "data",
            type: "tensor"
        }, {
            start: 1,
            name: "pred",
            type: "tensor"
        }]
    }, {
        tfOpName: "Merge",
        category: "control",
        inputs: [{
            start: 0,
            end: 0,
            name: "tensors",
            type: "tensors"
        }]
    }, {
        tfOpName: "Enter",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensor",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }, {
            tfName: "frame_name",
            name: "frameName",
            type: "string"
        }, {
            tfName: "is_constant",
            name: "isConstant",
            type: "bool"
        }]
    }, {
        tfOpName: "Exit",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensor",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "NextIteration",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensor",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "TensorArrayV3",
        category: "control",
        inputs: [{
            start: 0,
            name: "size",
            type: "number"
        }],
        attrs: [{
            tfName: "dtype",
            name: "dtype",
            type: "dtype"
        }, {
            tfName: "element_shape",
            name: "elementShape",
            type: "shape"
        }, {
            tfName: "dynamic_size",
            name: "dynamicSize",
            type: "bool"
        }, {
            tfName: "clear_after_read",
            name: "clearAfterRead",
            type: "bool"
        }, {
            tfName: "identical_element_shapes",
            name: "identicalElementShapes",
            type: "bool"
        }, {
            tfName: "tensor_array_name",
            name: "name",
            type: "string"
        }]
    }, {
        tfOpName: "TensorArrayWriteV3",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensorArrayId",
            type: "tensor"
        }, {
            start: 1,
            name: "index",
            type: "number"
        }, {
            start: 2,
            name: "tensor",
            type: "tensor"
        }, {
            start: 3,
            name: "flowIn",
            type: "number"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "TensorArrayReadV3",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensorArrayId",
            type: "tensor"
        }, {
            start: 1,
            name: "index",
            type: "number"
        }, {
            start: 2,
            name: "flowIn",
            type: "number"
        }],
        attrs: [{
            tfName: "dtype",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "TensorArrayGatherV3",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensorArrayId",
            type: "tensor"
        }, {
            start: 1,
            name: "indices",
            type: "number[]"
        }, {
            start: 2,
            name: "flowIn",
            type: "number"
        }],
        attrs: [{
            tfName: "dtype",
            name: "dtype",
            type: "dtype"
        }, {
            tfName: "element_shape",
            name: "elementShape",
            type: "shape"
        }]
    }, {
        tfOpName: "TensorArrayScatterV3",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensorArrayId",
            type: "tensor"
        }, {
            start: 1,
            name: "indices",
            type: "number[]"
        }, {
            start: 2,
            name: "tensor",
            type: "tensor"
        }, {
            start: 3,
            name: "flowIn",
            type: "number"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype"
        }]
    }, {
        tfOpName: "TensorArrayConcatV3",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensorArrayId",
            type: "tensor"
        }, {
            start: 1,
            name: "flowIn",
            type: "number"
        }],
        attrs: [{
            tfName: "dtype",
            name: "dtype",
            type: "dtype"
        }, {
            tfName: "element_shape_except0",
            name: "elementShapeExcept0",
            type: "shape",
            notSupported: !0
        }]
    }, {
        tfOpName: "TensorArraySplitV3",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensorArrayId",
            type: "tensor"
        }, {
            start: 1,
            name: "tensor",
            type: "tensor"
        }, {
            start: 2,
            name: "lengths",
            type: "number[]"
        }, {
            start: 3,
            name: "flowIn",
            type: "number"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype"
        }]
    }, {
        tfOpName: "TensorArraySizeV3",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensorArrayId",
            type: "tensor"
        }, {
            start: 1,
            name: "flowIn",
            type: "number"
        }]
    }, {
        tfOpName: "TensorArrayCloseV3",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensorArrayId",
            type: "tensor"
        }]
    }, {
        tfOpName: "StatelessIf",
        category: "control",
        inputs: [{
            start: 0,
            name: "cond",
            type: "tensor"
        }, {
            start: 1,
            end: 0,
            name: "args",
            type: "tensors"
        }],
        attrs: [{
            tfName: "then_branch",
            name: "thenBranch",
            type: "func"
        }, {
            tfName: "else_branch",
            name: "elseBranch",
            type: "func"
        }]
    }, {
        tfOpName: "If",
        category: "control",
        inputs: [{
            start: 0,
            name: "cond",
            type: "tensor"
        }, {
            start: 1,
            end: 0,
            name: "args",
            type: "tensors"
        }],
        attrs: [{
            tfName: "then_branch",
            name: "thenBranch",
            type: "func"
        }, {
            tfName: "else_branch",
            name: "elseBranch",
            type: "func"
        }]
    }, {
        tfOpName: "StatelessWhile",
        category: "control",
        inputs: [{
            start: 0,
            end: 0,
            name: "args",
            type: "tensors"
        }],
        attrs: [{
            tfName: "cond",
            name: "cond",
            type: "func"
        }, {
            tfName: "body",
            name: "body",
            type: "func"
        }]
    }, {
        tfOpName: "While",
        category: "control",
        inputs: [{
            start: 0,
            end: 0,
            name: "args",
            type: "tensors"
        }],
        attrs: [{
            tfName: "cond",
            name: "cond",
            type: "func"
        }, {
            tfName: "body",
            name: "body",
            type: "func"
        }]
    }, {
        tfOpName: "TensorListScatter",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensor",
            type: "tensor"
        }, {
            start: 1,
            name: "indices",
            type: "number[]"
        }, {
            start: 2,
            name: "elementShape",
            type: "shape"
        }],
        attrs: [{
            tfName: "element_dtype",
            name: "elementDType",
            type: "dtype"
        }]
    }, {
        tfOpName: "TensorListScatterV2",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensor",
            type: "tensor"
        }, {
            start: 1,
            name: "indices",
            type: "number[]"
        }, {
            start: 2,
            name: "elementShape",
            type: "shape"
        }, {
            start: 3,
            name: "numElements",
            type: "number"
        }],
        attrs: [{
            tfName: "element_dtype",
            name: "elementDType",
            type: "dtype"
        }]
    }, {
        tfOpName: "TensorListGather",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensorListId",
            type: "tensor"
        }, {
            start: 1,
            name: "indices",
            type: "number[]"
        }, {
            start: 2,
            name: "elementShape",
            type: "shape"
        }],
        attrs: [{
            tfName: "element_dtype",
            name: "elementDType",
            type: "dtype"
        }]
    }, {
        tfOpName: "TensorListGetItem",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensorListId",
            type: "tensor"
        }, {
            start: 1,
            name: "index",
            type: "number"
        }, {
            start: 2,
            name: "elementShape",
            type: "shape"
        }],
        attrs: [{
            tfName: "element_dtype",
            name: "elementDType",
            type: "dtype"
        }]
    }, {
        tfOpName: "TensorListSetItem",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensorListId",
            type: "tensor"
        }, {
            start: 1,
            name: "index",
            type: "number"
        }, {
            start: 2,
            name: "tensor",
            type: "tensor"
        }],
        attrs: [{
            tfName: "element_dtype",
            name: "elementDType",
            type: "dtype"
        }]
    }, {
        tfOpName: "TensorListReserve",
        category: "control",
        inputs: [{
            start: 0,
            name: "elementShape",
            type: "shape"
        }, {
            start: 1,
            name: "numElements",
            type: "number"
        }],
        attrs: [{
            tfName: "element_dtype",
            name: "elementDType",
            type: "dtype"
        }]
    }, {
        tfOpName: "TensorListFromTensor",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensor",
            type: "tensor"
        }, {
            start: 1,
            name: "elementShape",
            type: "shape"
        }],
        attrs: [{
            tfName: "element_dtype",
            name: "elementDType",
            type: "dtype"
        }]
    }, {
        tfOpName: "TensorListStack",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensorListId",
            type: "tensor"
        }, {
            start: 1,
            name: "elementShape",
            type: "shape"
        }],
        attrs: [{
            tfName: "element_dtype",
            name: "elementDType",
            type: "dtype"
        }, {
            tfName: "num_elements",
            name: "numElements",
            type: "dtype"
        }]
    }, {
        tfOpName: "TensorListSplit",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensor",
            type: "tensor"
        }, {
            start: 1,
            name: "elementShape",
            type: "shape"
        }, {
            start: 2,
            name: "lengths",
            type: "number[]"
        }],
        attrs: [{
            tfName: "element_dtype",
            name: "elementDType",
            type: "dtype"
        }]
    }, {
        tfOpName: "TensorListConcat",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensorListId",
            type: "tensor"
        }],
        attrs: [{
            tfName: "element_shape",
            name: "elementShape",
            type: "shape"
        }, {
            tfName: "element_dtype",
            name: "elementDType",
            type: "dtype"
        }]
    }, {
        tfOpName: "TensorListConcatV2",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensorListId",
            type: "tensor"
        }],
        attrs: [{
            tfName: "element_shape",
            name: "elementShape",
            type: "shape"
        }, {
            tfName: "element_dtype",
            name: "elementDType",
            type: "dtype"
        }]
    }, {
        tfOpName: "TensorListPopBack",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensorListId",
            type: "tensor"
        }, {
            start: 1,
            name: "elementShape",
            type: "shape"
        }],
        attrs: [{
            tfName: "element_dtype",
            name: "elementDType",
            type: "dtype"
        }]
    }, {
        tfOpName: "TensorListPushBack",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensorListId",
            type: "tensor"
        }, {
            start: 1,
            name: "tensor",
            type: "tensor"
        }],
        attrs: [{
            tfName: "element_dtype",
            name: "elementDType",
            type: "dtype"
        }]
    }, {
        tfOpName: "TensorListLength",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensorListId",
            type: "tensor"
        }]
    }, {
        tfOpName: "TensorListResize",
        category: "control",
        inputs: [{
            start: 0,
            name: "tensorListId",
            type: "tensor"
        }, {
            start: 1,
            name: "size",
            type: "number"
        }]
    }];
    var lP = {};
    t(lP, "json", (()=>uP));
    const uP = [{
        tfOpName: "AvgPool",
        category: "convolution",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "strides",
            name: "strides",
            type: "number[]"
        }, {
            tfName: "padding",
            name: "pad",
            type: "string"
        }, {
            tfName: "data_format",
            name: "dataFormat",
            type: "string",
            notSupported: !0
        }, {
            tfName: "ksize",
            name: "kernelSize",
            type: "number[]"
        }, {
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "MaxPool",
        category: "convolution",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "strides",
            name: "strides",
            type: "number[]"
        }, {
            tfName: "padding",
            name: "pad",
            type: "string"
        }, {
            tfName: "data_format",
            name: "dataFormat",
            type: "string",
            notSupported: !0
        }, {
            tfName: "ksize",
            name: "kernelSize",
            type: "number[]"
        }, {
            tfName: "explicit_paddings",
            name: "explicitPaddings",
            type: "number[]",
            defaultValue: [],
            notSupported: !0
        }, {
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "MaxPoolWithArgmax",
        category: "convolution",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "strides",
            name: "strides",
            type: "number[]"
        }, {
            tfName: "padding",
            name: "pad",
            type: "string"
        }, {
            tfName: "ksize",
            name: "kernelSize",
            type: "number[]"
        }, {
            tfName: "include_batch_in_index",
            name: "includeBatchInIndex",
            type: "bool"
        }, {
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "AvgPool3D",
        category: "convolution",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "strides",
            name: "strides",
            type: "number[]"
        }, {
            tfName: "padding",
            name: "pad",
            type: "string"
        }, {
            tfName: "data_format",
            name: "dataFormat",
            type: "string",
            notSupported: !0
        }, {
            tfName: "ksize",
            name: "kernelSize",
            type: "number[]"
        }, {
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "MaxPool3D",
        category: "convolution",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "strides",
            name: "strides",
            type: "number[]"
        }, {
            tfName: "padding",
            name: "pad",
            type: "string"
        }, {
            tfName: "data_format",
            name: "dataFormat",
            type: "string",
            notSupported: !0
        }, {
            tfName: "ksize",
            name: "kernelSize",
            type: "number[]"
        }, {
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Conv1D",
        category: "convolution",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "filter",
            type: "tensor"
        }],
        attrs: [{
            tfName: "stride",
            name: "stride",
            type: "number"
        }, {
            tfName: "padding",
            name: "pad",
            type: "string"
        }, {
            tfName: "data_format",
            name: "dataFormat",
            type: "string",
            defaultValue: "NWC"
        }, {
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }, {
            tfName: "dilation",
            name: "dilation",
            type: "number",
            defaultValue: 1
        }]
    }, {
        tfOpName: "Conv2D",
        category: "convolution",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "filter",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }, {
            tfName: "strides",
            name: "strides",
            type: "number[]"
        }, {
            tfName: "padding",
            name: "pad",
            type: "string"
        }, {
            tfName: "useCudnnOnGpu",
            name: "useCudnnOnGpu",
            type: "bool"
        }, {
            tfName: "data_format",
            name: "dataFormat",
            type: "string",
            defaultValue: "NHWC"
        }, {
            tfName: "explicit_paddings",
            name: "explicitPaddings",
            type: "number[]",
            defaultValue: []
        }, {
            tfName: "dilations",
            name: "dilations",
            type: "number[]"
        }]
    }, {
        tfOpName: "_FusedConv2D",
        category: "convolution",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "filter",
            type: "tensor"
        }, {
            start: 2,
            end: 0,
            name: "args",
            type: "tensors"
        }],
        attrs: [{
            tfName: "num_args",
            name: "numArgs",
            type: "number"
        }, {
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }, {
            tfName: "strides",
            name: "strides",
            type: "number[]"
        }, {
            tfName: "padding",
            name: "pad",
            type: "string"
        }, {
            tfName: "explicit_paddings",
            name: "explicitPaddings",
            type: "number[]",
            defaultValue: []
        }, {
            tfName: "use_cudnn_on_gpu",
            name: "useCudnnOnGpu",
            type: "bool",
            defaultValue: !0
        }, {
            tfName: "data_format",
            name: "dataFormat",
            type: "string",
            defaultValue: "NHWC"
        }, {
            tfName: "dilations",
            name: "dilations",
            type: "number[]",
            defaultValue: [1, 1, 1, 1]
        }, {
            tfName: "fused_ops",
            name: "fusedOps",
            type: "string[]",
            defaultValue: []
        }, {
            tfName: "epsilon",
            name: "epsilon",
            type: "number",
            defaultValue: 1e-4
        }, {
            tfName: "leakyrelu_alpha",
            name: "leakyreluAlpha",
            type: "number",
            defaultValue: .2
        }]
    }, {
        tfOpName: "Conv2DBackpropInput",
        category: "convolution",
        inputs: [{
            start: 2,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "filter",
            type: "tensor"
        }, {
            start: 0,
            name: "outputShape",
            type: "number[]"
        }],
        attrs: [{
            tfName: "strides",
            name: "strides",
            type: "number[]"
        }, {
            tfName: "padding",
            name: "pad",
            type: "string"
        }, {
            tfName: "data_format",
            name: "dataFormat",
            type: "string",
            notSupported: !0
        }, {
            tfName: "explicit_paddings",
            name: "explicitPaddings",
            type: "number[]",
            defaultValue: []
        }, {
            tfName: "dilations",
            name: "dilations",
            type: "number[]",
            notSupported: !0
        }]
    }, {
        tfOpName: "DepthwiseConv2d",
        category: "convolution",
        inputs: [{
            start: 0,
            name: "input",
            type: "tensor"
        }, {
            start: 1,
            name: "filter",
            type: "tensor"
        }],
        attrs: [{
            tfName: "strides",
            name: "strides",
            type: "number[]"
        }, {
            tfName: "padding",
            name: "pad",
            type: "string"
        }, {
            tfName: "data_format",
            name: "dataFormat",
            type: "string",
            defaultValue: "NHWC"
        }, {
            tfName: "explicit_paddings",
            name: "explicitPaddings",
            type: "number[]",
            defaultValue: []
        }, {
            tfName: "dilations",
            name: "dilations",
            type: "number[]"
        }]
    }, {
        tfOpName: "DepthwiseConv2dNative",
        category: "convolution",
        inputs: [{
            start: 0,
            name: "input",
            type: "tensor"
        }, {
            start: 1,
            name: "filter",
            type: "tensor"
        }],
        attrs: [{
            tfName: "strides",
            name: "strides",
            type: "number[]"
        }, {
            tfName: "padding",
            name: "pad",
            type: "string"
        }, {
            tfName: "data_format",
            name: "dataFormat",
            type: "string",
            defaultValue: "NHWC"
        }, {
            tfName: "explicit_paddings",
            name: "explicitPaddings",
            type: "number[]",
            defaultValue: []
        }, {
            tfName: "dilations",
            name: "dilations",
            type: "number[]"
        }]
    }, {
        tfOpName: "FusedDepthwiseConv2dNative",
        category: "convolution",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "filter",
            type: "tensor"
        }, {
            start: 2,
            end: 0,
            name: "args",
            type: "tensors"
        }],
        attrs: [{
            tfName: "num_args",
            name: "numArgs",
            type: "number"
        }, {
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }, {
            tfName: "strides",
            name: "strides",
            type: "number[]"
        }, {
            tfName: "padding",
            name: "pad",
            type: "string"
        }, {
            tfName: "data_format",
            name: "dataFormat",
            type: "string",
            defaultValue: "NHWC"
        }, {
            tfName: "dilations",
            name: "dilations",
            type: "number[]",
            defaultValue: [1, 1, 1, 1]
        }, {
            tfName: "fused_ops",
            name: "fusedOps",
            type: "string[]",
            defaultValue: []
        }, {
            tfName: "explicit_paddings",
            name: "explicitPaddings",
            type: "number[]",
            defaultValue: []
        }]
    }, {
        tfOpName: "Conv3D",
        category: "convolution",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "filter",
            type: "tensor"
        }],
        attrs: [{
            tfName: "strides",
            name: "strides",
            type: "number[]"
        }, {
            tfName: "padding",
            name: "pad",
            type: "string"
        }, {
            tfName: "data_format",
            name: "dataFormat",
            type: "string",
            defaultValue: "NHWC"
        }, {
            tfName: "dilations",
            name: "dilations",
            type: "number[]"
        }]
    }, {
        tfOpName: "Dilation2D",
        category: "convolution",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "filter",
            type: "tensor"
        }],
        attrs: [{
            tfName: "strides",
            name: "strides",
            type: "number[]"
        }, {
            tfName: "rates",
            name: "dilations",
            type: "number[]"
        }, {
            tfName: "padding",
            name: "pad",
            type: "string"
        }]
    }];
    var cP = {};
    t(cP, "json", (()=>hP));
    const hP = [{
        tfOpName: "Fill",
        category: "creation",
        inputs: [{
            start: 0,
            name: "shape",
            type: "number[]"
        }, {
            start: 1,
            name: "value",
            type: "number"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype"
        }]
    }, {
        tfOpName: "LinSpace",
        category: "creation",
        inputs: [{
            start: 0,
            name: "start",
            type: "number"
        }, {
            start: 1,
            name: "stop",
            type: "number"
        }, {
            start: 2,
            name: "num",
            type: "number"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "OneHot",
        category: "creation",
        inputs: [{
            start: 0,
            name: "indices",
            type: "tensor"
        }, {
            start: 1,
            name: "depth",
            type: "number"
        }, {
            start: 2,
            name: "onValue",
            type: "number",
            defaultValue: 1
        }, {
            start: 3,
            name: "offValue",
            type: "number",
            defaultValue: 0
        }],
        attrs: [{
            tfName: "axis",
            name: "axis",
            type: "number",
            notSupported: !0
        }, {
            tfName: "T",
            name: "dtype",
            type: "dtype"
        }]
    }, {
        tfOpName: "Ones",
        category: "creation",
        inputs: [{
            start: 0,
            name: "shape",
            type: "number[]"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype"
        }]
    }, {
        tfOpName: "OnesLike",
        category: "creation",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "dtype",
            name: "dtype",
            type: "dtype"
        }]
    }, {
        tfOpName: "RandomStandardNormal",
        category: "creation",
        inputs: [{
            start: 0,
            name: "shape",
            type: "number[]"
        }],
        attrs: [{
            tfName: "seed",
            name: "seed",
            type: "number",
            defaultValue: 0
        }, {
            tfName: "seed2",
            name: "seed2",
            type: "number",
            defaultValue: 0,
            notSupported: !0
        }, {
            tfName: "dtype",
            name: "dtype",
            type: "dtype"
        }, {
            tfName: "T",
            name: "T",
            type: "number",
            notSupported: !0
        }]
    }, {
        tfOpName: "RandomUniform",
        category: "creation",
        inputs: [{
            start: 0,
            name: "shape",
            type: "number[]"
        }],
        attrs: [{
            tfName: "minval",
            name: "minval",
            type: "number",
            defaultValue: 0
        }, {
            tfName: "maxval",
            name: "maxval",
            type: "number",
            defaultValue: 1
        }, {
            tfName: "dtype",
            name: "dtype",
            type: "dtype"
        }, {
            tfName: "seed",
            name: "seed",
            type: "number",
            defaultValue: 0
        }, {
            tfName: "seed2",
            name: "seed2",
            type: "number",
            defaultValue: 0,
            notSupported: !0
        }, {
            tfName: "T",
            name: "T",
            type: "number",
            notSupported: !0
        }]
    }, {
        tfOpName: "Range",
        category: "creation",
        inputs: [{
            start: 0,
            name: "start",
            type: "number"
        }, {
            start: 1,
            name: "stop",
            type: "number"
        }, {
            start: 2,
            name: "step",
            type: "number",
            defaultValue: 0
        }],
        attrs: [{
            tfName: "Tidx",
            name: "dtype",
            type: "dtype"
        }]
    }, {
        tfOpName: "TruncatedNormal",
        category: "creation",
        inputs: [{
            start: 0,
            name: "shape",
            type: "number[]"
        }],
        attrs: [{
            tfName: "means",
            name: "mean",
            type: "number",
            defaultValue: 0
        }, {
            tfName: "stddev",
            name: "stdDev",
            type: "number",
            defaultValue: 1
        }, {
            tfName: "seed",
            name: "seed",
            type: "number"
        }, {
            tfName: "seed2",
            name: "seed2",
            type: "number",
            defaultValue: 0,
            notSupported: !0
        }, {
            tfName: "dtype",
            name: "dtype",
            type: "dtype"
        }, {
            tfName: "T",
            name: "T",
            type: "number",
            notSupported: !0
        }]
    }, {
        tfOpName: "Zeros",
        category: "creation",
        inputs: [{
            start: 0,
            name: "shape",
            type: "number[]"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype"
        }]
    }, {
        tfOpName: "ZerosLike",
        category: "creation",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype"
        }]
    }, {
        tfOpName: "Multinomial",
        category: "creation",
        inputs: [{
            start: 0,
            name: "logits",
            type: "tensor"
        }, {
            start: 1,
            name: "numSamples",
            type: "number"
        }],
        attrs: [{
            tfName: "seed",
            name: "seed",
            type: "number"
        }, {
            tfName: "seed2",
            name: "seed2",
            type: "number"
        }, {
            tfName: "T",
            name: "dtype",
            type: "dtype"
        }, {
            tfName: "output_dtype",
            name: "output_dtype",
            type: "dtype"
        }]
    }];
    var pP = {};
    t(pP, "json", (()=>dP));
    const dP = [{
        tfOpName: "NonMaxSuppressionV2",
        category: "dynamic",
        inputs: [{
            start: 0,
            name: "boxes",
            type: "tensor"
        }, {
            start: 1,
            name: "scores",
            type: "tensor"
        }, {
            start: 2,
            name: "maxOutputSize",
            type: "number"
        }, {
            start: 3,
            name: "iouThreshold",
            type: "number"
        }]
    }, {
        tfOpName: "NonMaxSuppressionV3",
        category: "dynamic",
        inputs: [{
            start: 0,
            name: "boxes",
            type: "tensor"
        }, {
            start: 1,
            name: "scores",
            type: "tensor"
        }, {
            start: 2,
            name: "maxOutputSize",
            type: "number"
        }, {
            start: 3,
            name: "iouThreshold",
            type: "number"
        }, {
            start: 4,
            name: "scoreThreshold",
            type: "number"
        }]
    }, {
        tfOpName: "NonMaxSuppressionV4",
        category: "dynamic",
        inputs: [{
            start: 0,
            name: "boxes",
            type: "tensor"
        }, {
            start: 1,
            name: "scores",
            type: "tensor"
        }, {
            start: 2,
            name: "maxOutputSize",
            type: "number"
        }, {
            start: 3,
            name: "iouThreshold",
            type: "number"
        }, {
            start: 4,
            name: "scoreThreshold",
            type: "number"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }, {
            tfName: "T_threshold",
            name: "threshold",
            type: "dtype",
            notSupported: !0
        }, {
            tfName: "pad_to_max_output_size",
            name: "padToMaxOutputSize",
            type: "bool"
        }]
    }, {
        tfOpName: "NonMaxSuppressionV5",
        category: "dynamic",
        inputs: [{
            start: 0,
            name: "boxes",
            type: "tensor"
        }, {
            start: 1,
            name: "scores",
            type: "tensor"
        }, {
            start: 2,
            name: "maxOutputSize",
            type: "number"
        }, {
            start: 3,
            name: "iouThreshold",
            type: "number"
        }, {
            start: 4,
            name: "scoreThreshold",
            type: "number"
        }, {
            start: 5,
            name: "softNmsSigma",
            type: "number"
        }]
    }, {
        tfOpName: "Where",
        category: "dynamic",
        inputs: [{
            start: 0,
            name: "condition",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "ListDiff",
        category: "dynamic",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "y",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }];
    var fP = {};
    t(fP, "json", (()=>mP));
    const mP = [{
        tfOpName: "LowerBound",
        category: "evaluation",
        inputs: [{
            start: 0,
            name: "sortedSequence",
            type: "tensor"
        }, {
            start: 1,
            name: "values",
            type: "tensor"
        }]
    }, {
        tfOpName: "TopKV2",
        category: "evaluation",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "k",
            type: "number"
        }],
        attrs: [{
            tfName: "sorted",
            name: "sorted",
            type: "bool"
        }]
    }, {
        tfOpName: "UpperBound",
        category: "evaluation",
        inputs: [{
            start: 0,
            name: "sortedSequence",
            type: "tensor"
        }, {
            start: 1,
            name: "values",
            type: "tensor"
        }]
    }, {
        tfOpName: "Unique",
        category: "evaluation",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }]
    }, {
        tfOpName: "UniqueV2",
        category: "evaluation",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "axis",
            type: "number"
        }]
    }];
    var gP = {};
    t(gP, "json", (()=>yP));
    const yP = [{
        tfOpName: "PlaceholderWithDefault",
        category: "graph",
        inputs: [{
            start: 0,
            name: "default",
            type: "tensor"
        }],
        attrs: [{
            tfName: "shape",
            name: "shape",
            type: "shape"
        }, {
            tfName: "dtype",
            name: "dtype",
            type: "dtype"
        }]
    }, {
        tfOpName: "Placeholder",
        category: "graph",
        attrs: [{
            tfName: "shape",
            name: "shape",
            type: "shape"
        }, {
            tfName: "dtype",
            name: "dtype",
            type: "dtype"
        }]
    }, {
        tfOpName: "Const",
        category: "graph"
    }, {
        tfOpName: "Identity",
        category: "graph",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }]
    }, {
        tfOpName: "IdentityN",
        category: "graph",
        inputs: [{
            start: 0,
            end: 0,
            name: "x",
            type: "tensors"
        }]
    }, {
        tfOpName: "Snapshot",
        category: "graph",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }]
    }, {
        tfOpName: "Rank",
        category: "graph",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }]
    }, {
        tfOpName: "Size",
        category: "graph",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }]
    }, {
        tfOpName: "Shape",
        category: "graph",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }]
    }, {
        tfOpName: "ShapeN",
        category: "graph",
        inputs: [{
            start: 0,
            end: 0,
            name: "x",
            type: "tensors"
        }]
    }, {
        tfOpName: "Print",
        category: "graph",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "data",
            type: "tensors"
        }],
        attrs: [{
            tfName: "message",
            name: "message",
            type: "string"
        }, {
            tfName: "first_n",
            name: "firstN",
            type: "number",
            notSupported: !0
        }, {
            tfName: "summarize",
            name: "summarize",
            type: "number",
            defaultValue: 3
        }]
    }, {
        tfOpName: "NoOp",
        category: "graph",
        inputs: []
    }, {
        tfOpName: "StopGradient",
        category: "graph",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }]
    }, {
        tfOpName: "FakeQuantWithMinMaxVars",
        category: "graph",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "min",
            name: "min",
            type: "number"
        }, {
            tfName: "max",
            name: "max",
            type: "number"
        }]
    }];
    var bP = {};
    t(bP, "json", (()=>xP));
    const xP = [{
        tfOpName: "HashTable",
        category: "hash_table",
        inputs: [],
        attrs: [{
            tfName: "shared_name",
            name: "sharedName",
            type: "string"
        }, {
            tfName: "use_node_name_sharing",
            name: "useNodeNameSharing",
            type: "bool"
        }, {
            tfName: "key_dtype",
            name: "keyDType",
            type: "dtype"
        }, {
            tfName: "value_dtype",
            name: "valueDType",
            type: "dtype"
        }]
    }, {
        tfOpName: "HashTableV2",
        category: "hash_table",
        inputs: [],
        attrs: [{
            tfName: "shared_name",
            name: "sharedName",
            type: "string"
        }, {
            tfName: "use_node_name_sharing",
            name: "useNodeNameSharing",
            type: "bool"
        }, {
            tfName: "key_dtype",
            name: "keyDType",
            type: "dtype"
        }, {
            tfName: "value_dtype",
            name: "valueDType",
            type: "dtype"
        }]
    }, {
        tfOpName: "LookupTableImport",
        category: "hash_table",
        inputs: [{
            start: 0,
            name: "tableHandle",
            type: "tensor"
        }, {
            start: 1,
            name: "keys",
            type: "tensor"
        }, {
            start: 2,
            name: "values",
            type: "tensor"
        }],
        attrs: [{
            tfName: "Tin",
            name: "tIn",
            type: "dtype",
            notSupported: !0
        }, {
            tfName: "Tout",
            name: "tOut",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "LookupTableImportV2",
        category: "hash_table",
        inputs: [{
            start: 0,
            name: "tableHandle",
            type: "tensor"
        }, {
            start: 1,
            name: "keys",
            type: "tensor"
        }, {
            start: 2,
            name: "values",
            type: "tensor"
        }],
        attrs: [{
            tfName: "Tin",
            name: "tIn",
            type: "dtype",
            notSupported: !0
        }, {
            tfName: "Tout",
            name: "tOut",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "LookupTableFind",
        category: "hash_table",
        inputs: [{
            start: 0,
            name: "tableHandle",
            type: "tensor"
        }, {
            start: 1,
            name: "keys",
            type: "tensor"
        }, {
            start: 2,
            name: "defaultValue",
            type: "tensor"
        }],
        attrs: [{
            tfName: "Tin",
            name: "tIn",
            type: "dtype",
            notSupported: !0
        }, {
            tfName: "Tout",
            name: "tOut",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "LookupTableFindV2",
        category: "hash_table",
        inputs: [{
            start: 0,
            name: "tableHandle",
            type: "tensor"
        }, {
            start: 1,
            name: "keys",
            type: "tensor"
        }, {
            start: 2,
            name: "defaultValue",
            type: "tensor"
        }],
        attrs: [{
            tfName: "Tin",
            name: "tIn",
            type: "dtype",
            notSupported: !0
        }, {
            tfName: "Tout",
            name: "tOut",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "LookupTableSize",
        category: "hash_table",
        inputs: [{
            start: 0,
            name: "tableHandle",
            type: "tensor"
        }]
    }, {
        tfOpName: "LookupTableSizeV2",
        category: "hash_table",
        inputs: [{
            start: 0,
            name: "tableHandle",
            type: "tensor"
        }]
    }, {
        tfOpName: "InitializeTable",
        category: "hash_table",
        inputs: [{
            start: 0,
            name: "tableHandle",
            type: "tensor"
        }, {
            start: 1,
            name: "keys",
            type: "tensor"
        }, {
            start: 2,
            name: "values",
            type: "tensor"
        }]
    }, {
        tfOpName: "InitializeTableV2",
        category: "hash_table",
        inputs: [{
            start: 0,
            name: "tableHandle",
            type: "tensor"
        }, {
            start: 1,
            name: "keys",
            type: "tensor"
        }, {
            start: 2,
            name: "values",
            type: "tensor"
        }]
    }];
    var wP = {};
    t(wP, "json", (()=>vP));
    const vP = [{
        tfOpName: "ResizeBilinear",
        category: "image",
        inputs: [{
            start: 0,
            name: "images",
            type: "tensor"
        }, {
            start: 1,
            name: "size",
            type: "number[]"
        }],
        attrs: [{
            tfName: "align_corners",
            name: "alignCorners",
            type: "bool"
        }, {
            tfName: "half_pixel_centers",
            name: "halfPixelCenters",
            type: "bool"
        }, {
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "ResizeNearestNeighbor",
        category: "image",
        inputs: [{
            start: 0,
            name: "images",
            type: "tensor"
        }, {
            start: 1,
            name: "size",
            type: "number[]"
        }],
        attrs: [{
            tfName: "align_corners",
            name: "alignCorners",
            type: "bool"
        }, {
            tfName: "half_pixel_centers",
            name: "halfPixelCenters",
            type: "bool"
        }, {
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "CropAndResize",
        category: "image",
        inputs: [{
            start: 0,
            name: "image",
            type: "tensor"
        }, {
            start: 1,
            name: "boxes",
            type: "tensor"
        }, {
            start: 2,
            name: "boxInd",
            type: "tensor"
        }, {
            start: 3,
            name: "cropSize",
            type: "number[]"
        }],
        attrs: [{
            tfName: "method",
            name: "method",
            type: "string"
        }, {
            tfName: "extrapolation_value",
            name: "extrapolationValue",
            type: "number"
        }]
    }, {
        tfOpName: "ImageProjectiveTransformV3",
        category: "image",
        inputs: [{
            start: 0,
            name: "images",
            type: "tensor"
        }, {
            start: 1,
            name: "transforms",
            type: "tensor"
        }, {
            start: 2,
            name: "outputShape",
            type: "number[]"
        }, {
            start: 3,
            name: "fillValue",
            type: "number"
        }],
        attrs: [{
            tfName: "interpolation",
            name: "interpolation",
            type: "string"
        }, {
            tfName: "fill_mode",
            name: "fillMode",
            type: "string"
        }]
    }];
    var kP = {};
    t(kP, "json", (()=>IP));
    const IP = [{
        tfOpName: "Equal",
        category: "logical",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "NotEqual",
        category: "logical",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Greater",
        category: "logical",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "GreaterEqual",
        category: "logical",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Less",
        category: "logical",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "LessEqual",
        category: "logical",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "LogicalAnd",
        category: "logical",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "LogicalNot",
        category: "logical",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "LogicalOr",
        category: "logical",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Select",
        category: "logical",
        inputs: [{
            start: 0,
            name: "condition",
            type: "tensor"
        }, {
            start: 1,
            name: "a",
            type: "tensor"
        }, {
            start: 2,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "SelectV2",
        category: "logical",
        inputs: [{
            start: 0,
            name: "condition",
            type: "tensor"
        }, {
            start: 1,
            name: "a",
            type: "tensor"
        }, {
            start: 2,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }];
    var SP = {};
    t(SP, "json", (()=>NP));
    const NP = [{
        tfOpName: "_FusedMatMul",
        category: "matrices",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }, {
            start: 2,
            end: 0,
            name: "args",
            type: "tensors"
        }],
        attrs: [{
            tfName: "num_args",
            name: "numArgs",
            type: "number"
        }, {
            tfName: "fused_ops",
            name: "fusedOps",
            type: "string[]",
            defaultValue: []
        }, {
            tfName: "epsilon",
            name: "epsilon",
            type: "number",
            defaultValue: 1e-4
        }, {
            tfName: "transpose_a",
            name: "transposeA",
            type: "bool",
            defaultValue: !1
        }, {
            tfName: "transpose_b",
            name: "transposeB",
            type: "bool",
            defaultValue: !1
        }, {
            tfName: "leakyrelu_alpha",
            name: "leakyreluAlpha",
            type: "number",
            defaultValue: .2
        }, {
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "MatMul",
        category: "matrices",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "transpose_a",
            name: "transposeA",
            type: "bool",
            defaultValue: !1
        }, {
            tfName: "transpose_b",
            name: "transposeB",
            type: "bool",
            defaultValue: !1
        }, {
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "BatchMatMul",
        category: "matrices",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "adj_x",
            name: "transposeA",
            type: "bool",
            defaultValue: !1
        }, {
            tfName: "adj_y",
            name: "transposeB",
            type: "bool",
            defaultValue: !1
        }, {
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "BatchMatMulV2",
        category: "matrices",
        inputs: [{
            start: 0,
            name: "a",
            type: "tensor"
        }, {
            start: 1,
            name: "b",
            type: "tensor"
        }],
        attrs: [{
            tfName: "adj_x",
            name: "transposeA",
            type: "bool",
            defaultValue: !1
        }, {
            tfName: "adj_y",
            name: "transposeB",
            type: "bool",
            defaultValue: !1
        }, {
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Transpose",
        category: "matrices",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "perm",
            type: "number[]"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "Einsum",
        category: "matrices",
        inputs: [{
            start: 0,
            end: 0,
            name: "tensors",
            type: "tensors"
        }],
        attrs: [{
            tfName: "equation",
            name: "equation",
            type: "string"
        }, {
            tfName: "N",
            name: "n",
            type: "number",
            defaultValue: 2
        }, {
            tfName: "T",
            name: "dtype",
            type: "dtype"
        }]
    }];
    var TP = {};
    t(TP, "json", (()=>CP));
    const CP = [{
        tfOpName: "EuclideanNorm",
        category: "normalization",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "axis",
            type: "number[]"
        }],
        attrs: [{
            tfName: "keep_dims",
            name: "keepDims",
            type: "bool",
            defaultValue: !1
        }]
    }, {
        tfOpName: "FusedBatchNorm",
        category: "normalization",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "scale",
            type: "tensor"
        }, {
            start: 2,
            name: "offset",
            type: "tensor"
        }, {
            start: 3,
            name: "mean",
            type: "tensor"
        }, {
            start: 4,
            name: "variance",
            type: "tensor"
        }],
        attrs: [{
            tfName: "epsilon",
            name: "epsilon",
            type: "number",
            defaultValue: .001
        }, {
            tfName: "data_format",
            name: "dataFormat",
            type: "string",
            notSupported: !0
        }]
    }, {
        tfOpName: "FusedBatchNormV2",
        category: "normalization",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "scale",
            type: "tensor"
        }, {
            start: 2,
            name: "offset",
            type: "tensor"
        }, {
            start: 3,
            name: "mean",
            type: "tensor"
        }, {
            start: 4,
            name: "variance",
            type: "tensor"
        }],
        attrs: [{
            tfName: "epsilon",
            name: "epsilon",
            type: "number",
            defaultValue: .001
        }, {
            tfName: "data_format",
            name: "dataFormat",
            type: "string",
            notSupported: !0
        }]
    }, {
        tfOpName: "FusedBatchNormV3",
        category: "normalization",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "scale",
            type: "tensor"
        }, {
            start: 2,
            name: "offset",
            type: "tensor"
        }, {
            start: 3,
            name: "mean",
            type: "tensor"
        }, {
            start: 4,
            name: "variance",
            type: "tensor"
        }],
        attrs: [{
            tfName: "epsilon",
            name: "epsilon",
            type: "number",
            defaultValue: .001
        }, {
            tfName: "data_format",
            name: "dataFormat",
            type: "string",
            notSupported: !0
        }]
    }, {
        tfOpName: "LRN",
        category: "normalization",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "depth_radius",
            name: "radius",
            type: "number",
            defaultValue: 5
        }, {
            tfName: "bias",
            name: "bias",
            type: "number",
            defaultValue: 1
        }, {
            tfName: "alpha",
            name: "alpha",
            type: "number",
            defaultValue: 1
        }, {
            tfName: "beta",
            name: "beta",
            type: "number",
            defaultValue: .5
        }]
    }, {
        tfOpName: "Softmax",
        category: "normalization",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }]
    }, {
        tfOpName: "LogSoftmax",
        category: "normalization",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }]
    }, {
        tfOpName: "SparseToDense",
        category: "normalization",
        inputs: [{
            start: 0,
            name: "sparseIndices",
            type: "tensor"
        }, {
            start: 1,
            name: "outputShape",
            type: "number[]"
        }, {
            start: 2,
            name: "sparseValues",
            type: "tensor"
        }, {
            start: 3,
            name: "defaultValue",
            type: "tensor"
        }],
        attrs: [{
            tfName: "validate_indices",
            name: "validateIndices",
            type: "bool",
            defaultValue: !0,
            notSupported: !0
        }]
    }];
    var $P = {};
    t($P, "json", (()=>EP));
    const EP = [{
        tfOpName: "Bincount",
        category: "reduction",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "size",
            type: "number"
        }, {
            start: 2,
            name: "weights",
            type: "tensor"
        }]
    }, {
        tfOpName: "DenseBincount",
        category: "reduction",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "size",
            type: "number"
        }, {
            start: 2,
            name: "weights",
            type: "tensor"
        }],
        attrs: [{
            tfName: "binary_output",
            name: "binaryOutput",
            type: "bool"
        }]
    }, {
        tfOpName: "Max",
        category: "reduction",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "axis",
            type: "number[]"
        }],
        attrs: [{
            tfName: "keep_dims",
            name: "keepDims",
            type: "bool"
        }]
    }, {
        tfOpName: "Mean",
        category: "reduction",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "axis",
            type: "number[]"
        }],
        attrs: [{
            tfName: "keep_dims",
            name: "keepDims",
            type: "bool"
        }]
    }, {
        tfOpName: "Min",
        category: "reduction",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "axis",
            type: "number[]"
        }],
        attrs: [{
            tfName: "keep_dims",
            name: "keepDims",
            type: "bool"
        }]
    }, {
        tfOpName: "Sum",
        category: "reduction",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "axis",
            type: "number[]"
        }],
        attrs: [{
            tfName: "keep_dims",
            name: "keepDims",
            type: "bool"
        }]
    }, {
        tfOpName: "All",
        category: "reduction",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "axis",
            type: "number[]"
        }],
        attrs: [{
            tfName: "keep_dims",
            name: "keepDims",
            type: "bool"
        }]
    }, {
        tfOpName: "Any",
        category: "reduction",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "axis",
            type: "number[]"
        }],
        attrs: [{
            tfName: "keep_dims",
            name: "keepDims",
            type: "bool"
        }]
    }, {
        tfOpName: "ArgMax",
        category: "reduction",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "axis",
            type: "number"
        }]
    }, {
        tfOpName: "ArgMin",
        category: "reduction",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "axis",
            type: "number"
        }]
    }, {
        tfOpName: "Prod",
        category: "reduction",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "axis",
            type: "number[]"
        }],
        attrs: [{
            tfName: "keep_dims",
            name: "keepDims",
            type: "bool"
        }]
    }, {
        tfOpName: "Cumprod",
        category: "reduction",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "axis",
            type: "number"
        }],
        attrs: [{
            tfName: "exclusive",
            name: "exclusive",
            type: "bool"
        }, {
            tfName: "reverse",
            name: "reverse",
            type: "bool"
        }]
    }, {
        tfOpName: "Cumsum",
        category: "reduction",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "axis",
            type: "number"
        }],
        attrs: [{
            tfName: "exclusive",
            name: "exclusive",
            type: "bool"
        }, {
            tfName: "reverse",
            name: "reverse",
            type: "bool"
        }]
    }];
    var AP = {};
    t(AP, "json", (()=>RP));
    const RP = [{
        tfOpName: "ConcatV2",
        category: "slice_join",
        inputs: [{
            start: 0,
            end: -1,
            name: "tensors",
            type: "tensors"
        }, {
            start: -1,
            name: "axis",
            type: "number"
        }],
        attrs: [{
            tfName: "N",
            name: "n",
            type: "number",
            defaultValue: 2
        }]
    }, {
        tfOpName: "Concat",
        category: "slice_join",
        inputs: [{
            start: 1,
            end: 0,
            name: "tensors",
            type: "tensors"
        }, {
            start: 0,
            name: "axis",
            type: "number"
        }],
        attrs: [{
            tfName: "N",
            name: "n",
            type: "number",
            defaultValue: 2
        }]
    }, {
        tfOpName: "GatherV2",
        category: "slice_join",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "indices",
            type: "tensor"
        }, {
            start: 2,
            name: "axis",
            type: "number",
            defaultValue: 0
        }],
        attrs: [{
            tfName: "batch_dims",
            name: "batchDims",
            type: "number",
            defaultValue: 0
        }]
    }, {
        tfOpName: "Gather",
        category: "slice_join",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "indices",
            type: "tensor"
        }],
        attrs: [{
            tfName: "validate_indices",
            name: "validateIndices",
            type: "bool",
            notSupported: !0
        }]
    }, {
        tfOpName: "Reverse",
        category: "slice_join",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "dims",
            type: "bool[]"
        }]
    }, {
        tfOpName: "ReverseV2",
        category: "slice_join",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "axis",
            type: "number[]"
        }]
    }, {
        tfOpName: "Slice",
        category: "slice_join",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "begin",
            type: "number[]"
        }, {
            start: 2,
            name: "size",
            type: "number[]"
        }]
    }, {
        tfOpName: "StridedSlice",
        category: "slice_join",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "begin",
            type: "number[]"
        }, {
            start: 2,
            name: "end",
            type: "number[]"
        }, {
            start: 3,
            name: "strides",
            type: "number[]"
        }],
        attrs: [{
            tfName: "begin_mask",
            name: "beginMask",
            type: "number",
            defaultValue: 0
        }, {
            tfName: "end_mask",
            name: "endMask",
            type: "number",
            defaultValue: 0
        }, {
            tfName: "new_axis_mask",
            name: "newAxisMask",
            type: "number",
            defaultValue: 0
        }, {
            tfName: "ellipsis_mask",
            name: "ellipsisMask",
            type: "number",
            defaultValue: 0
        }, {
            tfName: "shrink_axis_mask",
            name: "shrinkAxisMask",
            type: "number",
            defaultValue: 0
        }]
    }, {
        tfOpName: "Pack",
        category: "slice_join",
        inputs: [{
            start: 0,
            end: 0,
            name: "tensors",
            type: "tensors"
        }],
        attrs: [{
            tfName: "axis",
            name: "axis",
            type: "number",
            defaultValue: 0
        }]
    }, {
        tfOpName: "Unpack",
        category: "slice_join",
        inputs: [{
            start: 0,
            name: "tensor",
            type: "tensor"
        }],
        attrs: [{
            tfName: "axis",
            name: "axis",
            type: "number",
            defaultValue: 0
        }, {
            tfName: "num",
            name: "num",
            type: "number",
            defaultValue: 0,
            notSupported: !0
        }]
    }, {
        tfOpName: "Tile",
        category: "slice_join",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "reps",
            type: "number[]"
        }]
    }, {
        tfOpName: "Split",
        category: "slice_join",
        inputs: [{
            start: 0,
            name: "axis",
            type: "number",
            defaultValue: 0
        }, {
            start: 1,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "num_split",
            name: "numOrSizeSplits",
            type: "number",
            defaultValue: 1
        }]
    }, {
        tfOpName: "SplitV",
        category: "slice_join",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "numOrSizeSplits",
            type: "number[]"
        }, {
            start: 2,
            name: "axis",
            type: "number",
            defaultValue: 0
        }]
    }, {
        tfOpName: "ScatterNd",
        category: "slice_join",
        inputs: [{
            start: 0,
            name: "indices",
            type: "tensor"
        }, {
            start: 1,
            name: "values",
            type: "tensor"
        }, {
            start: 2,
            name: "shape",
            type: "number[]"
        }]
    }, {
        tfOpName: "GatherNd",
        category: "slice_join",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "indices",
            type: "tensor"
        }]
    }, {
        tfOpName: "SparseToDense",
        category: "slice_join",
        inputs: [{
            start: 0,
            name: "sparseIndices",
            type: "tensor"
        }, {
            start: 1,
            name: "outputShape",
            type: "number[]"
        }, {
            start: 2,
            name: "sparseValues",
            type: "tensor"
        }, {
            start: 3,
            name: "defaultValue",
            type: "tensor"
        }],
        attrs: [{
            tfName: "validate_indices",
            name: "validateIndices",
            type: "bool",
            defaultValue: !1,
            notSupported: !0
        }]
    }];
    var FP = {};
    t(FP, "json", (()=>DP));
    const DP = [{
        tfOpName: "SparseFillEmptyRows",
        category: "sparse",
        inputs: [{
            start: 0,
            name: "indices",
            type: "tensor"
        }, {
            start: 1,
            name: "values",
            type: "tensor"
        }, {
            start: 2,
            name: "denseShape",
            type: "tensor"
        }, {
            start: 3,
            name: "defaultValue",
            type: "tensor"
        }]
    }, {
        tfOpName: "SparseReshape",
        category: "sparse",
        inputs: [{
            start: 0,
            name: "inputIndices",
            type: "tensor"
        }, {
            start: 1,
            name: "inputShape",
            type: "tensor"
        }, {
            start: 2,
            name: "newShape",
            type: "tensor"
        }],
        attrs: [{
            tfName: "T",
            name: "dtype",
            type: "dtype",
            notSupported: !0
        }]
    }, {
        tfOpName: "SparseSegmentMean",
        category: "sparse",
        inputs: [{
            start: 0,
            name: "data",
            type: "tensor"
        }, {
            start: 1,
            name: "indices",
            type: "tensor"
        }, {
            start: 2,
            name: "segmentIds",
            type: "tensor"
        }]
    }, {
        tfOpName: "SparseSegmentSum",
        category: "sparse",
        inputs: [{
            start: 0,
            name: "data",
            type: "tensor"
        }, {
            start: 1,
            name: "indices",
            type: "tensor"
        }, {
            start: 2,
            name: "segmentIds",
            type: "tensor"
        }]
    }];
    var _P = {};
    t(_P, "json", (()=>OP));
    const OP = [{
        tfOpName: "FFT",
        category: "spectral",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }]
    }, {
        tfOpName: "IFFT",
        category: "spectral",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }]
    }, {
        tfOpName: "RFFT",
        category: "spectral",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "fft_length",
            type: "number",
            notSupported: !0
        }]
    }, {
        tfOpName: "IRFFT",
        category: "spectral",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "fft_length",
            type: "number",
            notSupported: !0
        }]
    }];
    var MP = {};
    t(MP, "json", (()=>LP));
    const LP = [{
        tfOpName: "StringNGrams",
        category: "string",
        inputs: [{
            start: 0,
            name: "data",
            type: "tensor"
        }, {
            start: 1,
            name: "dataSplits",
            type: "tensor"
        }],
        attrs: [{
            tfName: "separator",
            name: "separator",
            type: "string"
        }, {
            tfName: "ngram_widths",
            name: "nGramWidths",
            type: "number[]"
        }, {
            tfName: "left_pad",
            name: "leftPad",
            type: "string"
        }, {
            tfName: "right_pad",
            name: "rightPad",
            type: "string"
        }, {
            tfName: "pad_width",
            name: "padWidth",
            type: "number"
        }, {
            tfName: "preserve_short_sequences",
            name: "preserveShortSequences",
            type: "bool"
        }],
        outputs: ["ngrams", "ngrams_splits"]
    }, {
        tfOpName: "StringSplit",
        category: "string",
        inputs: [{
            start: 0,
            name: "input",
            type: "tensor"
        }, {
            start: 1,
            name: "delimiter",
            type: "tensor"
        }],
        attrs: [{
            tfName: "skip_empty",
            name: "skipEmpty",
            type: "bool"
        }],
        outputs: ["indices", "values", "shape"]
    }, {
        tfOpName: "StringToHashBucketFast",
        category: "string",
        inputs: [{
            start: 0,
            name: "input",
            type: "tensor"
        }],
        attrs: [{
            tfName: "num_buckets",
            name: "numBuckets",
            type: "number"
        }]
    }];
    var zP = {};
    t(zP, "json", (()=>BP));
    const BP = [{
        tfOpName: "Cast",
        category: "transformation",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "SrcT",
            name: "sdtype",
            type: "dtype",
            notSupported: !0
        }, {
            tfName: "DstT",
            name: "dtype",
            type: "dtype"
        }]
    }, {
        tfOpName: "ExpandDims",
        category: "transformation",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "axis",
            type: "number"
        }]
    }, {
        tfOpName: "MirrorPad",
        category: "transformation",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "padding",
            type: "number[]"
        }],
        attrs: [{
            tfName: "mode",
            name: "mode",
            type: "string"
        }]
    }, {
        tfOpName: "Pad",
        category: "transformation",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "padding",
            type: "number[]"
        }],
        attrs: [{
            tfName: "constant_value",
            name: "constantValue",
            type: "number",
            defaultValue: 0
        }]
    }, {
        tfOpName: "PadV2",
        category: "transformation",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "padding",
            type: "number[]"
        }, {
            start: 2,
            name: "constantValue",
            type: "number",
            defaultValue: 0
        }]
    }, {
        tfOpName: "Reshape",
        category: "transformation",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "shape",
            type: "number[]"
        }]
    }, {
        tfOpName: "Squeeze",
        category: "transformation",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "axis",
            tfDeprecatedName: "squeeze_dims",
            name: "axis",
            type: "number[]"
        }]
    }, {
        tfOpName: "SpaceToBatchND",
        category: "transformation",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "blockShape",
            type: "number[]"
        }, {
            start: 2,
            name: "paddings",
            type: "number[]"
        }]
    }, {
        tfOpName: "BatchToSpaceND",
        category: "transformation",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "blockShape",
            type: "number[]"
        }, {
            start: 2,
            name: "crops",
            type: "number[]"
        }]
    }, {
        tfOpName: "DepthToSpace",
        category: "transformation",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }],
        attrs: [{
            tfName: "block_size",
            name: "blockSize",
            type: "number"
        }, {
            tfName: "data_format",
            name: "dataFormat",
            type: "string"
        }]
    }, {
        tfOpName: "BroadcastTo",
        category: "transformation",
        inputs: [{
            start: 0,
            name: "x",
            type: "tensor"
        }, {
            start: 1,
            name: "shape",
            type: "number[]"
        }],
        attrs: []
    }, {
        tfOpName: "BroadcastArgs",
        category: "transformation",
        inputs: [{
            start: 0,
            name: "s0",
            type: "tensor"
        }, {
            start: 1,
            name: "s1",
            type: "tensor"
        }],
        attrs: []
    }];
    var PP = {};
    n(PP, ol);
    let WP, UP = async()=>{
        if (null == WP) {
            WP = await zL("tfjs_model/model.json");
            const e = (await fetch("tfjs_model/foo.csv").then((e=>e.text()))).split(",").map(parseFloat)
              , t = e.length / 4.5e3
              , n = hl(e, [1, 25, 90, 1])
              , s = WP.predict(n)
              , r = ph(s, axis = 2).arraySync();
            let a = "";
            for (let e = 0; e < t; e++)
                a += r[e].map((e=>String.fromCharCode(e + 97))).join("");
            return console.log("turn on"),
            "turn on"
        }
        return console.log("isready"),
        "isready"
    }
    ;
    UP(),
    chrome.runtime.onMessage.addListener((async function(e, t, n) {
        if ("createmodel" == e.type) {
            n(await UP())
        } else if ("predit" == e.type) {
            const t = new ImageData(Uint8ClampedArray.from(e.saveimage),e.width,e.height);
            let s = Uf.fromPixels(t).asType("float32").div(wl(255)).mean(-1, !0)
              , r = [];
            r.push(s),
            r = ac(r),
            null == WP && (WP = await zL("tfjs_model/model.json"));
            const a = WP.predict(r);
            n(ph(a, axis = 2).arraySync()[0].map((e=>String.fromCharCode(e + 97))).join(""))
        }
        return !0
    }
    ))
}
)();
//# sourceMappingURL=service_worker.js.map
